//7828
export const exam6 = {
    "attemptAnswers": [
        {
            "attemptAnswerId": 329661,
            "questionId": 7539,
            "questionText": "<p>A developer wants to reduce risk when deploying a new version of an existing AWS Lambda function. To test the Lambda function, the developer needs to split the traffic between the existing version and the new version of the Lambda function.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer muá»‘n deploy <strong>new version</strong> cá»§a Lambda function vá»›i <strong>reduce risk (giáº£m thiá»ƒu rá»§i ro)</strong></p></li><li><p>Cáº§n <strong>split traffic</strong> giá»¯a existing version vÃ  new version Ä‘á»ƒ test</p></li><li><p>TÃ¬m solution Ä‘Ã¡p á»©ng requirements</p></li></ul><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create a function alias. Configure the alias to split the traffic between the two versions of the Lambda function.</strong></p><ul><li><p>Lambda alias há»— trá»£ traffic shifting giá»¯a cÃ¡c versions (routing configuration)</p></li><li><p>CÃ³ thá»ƒ configure weight-based routing: VD 90% traffic â†’ version 1, 10% â†’ version 2</p></li><li><p>Native feature cá»§a Lambda, khÃ´ng cáº§n thÃªm service khÃ¡c</p></li><li><p>ThÆ°á»ng dÃ¹ng cho canary deployments vÃ  blue/green deployments</p></li><li><p>Dá»… rollback náº¿u new version cÃ³ váº¥n Ä‘á»</p></li></ul><p></p><p><em>HÃ¬nh minh hoáº¡</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1760833427138-k1bs3j21-image.png\" alt=\"\" title=\"\" width=\"547\" height=\"453.0128645833333\" style=\"max-width: 547px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure a weighted routing policy in Amazon Route 53. Associate the versions of the Lambda function with the weighted routing policy.</strong></p><ul><li><p>Route 53 dÃ¹ng Ä‘á»ƒ route DNS traffic Ä‘áº¿n endpoints (nhÆ° ALB, CloudFront, EC2), khÃ´ng thá»ƒ route trá»±c tiáº¿p Ä‘áº¿n Lambda versions</p></li><li><p>Lambda versions khÃ´ng pháº£i DNS endpoints</p></li></ul><p></p><p>âŒ <strong>Create an Application Load Balancer (ALB) that uses the Lambda function as a target. Configure the ALB to split the traffic between the two versions of the Lambda function.</strong></p><ul><li><p>ALB cÃ³ thá»ƒ invoke Lambda function nhÆ°ng khÃ´ng thá»ƒ target nhiá»u versions cá»§a cÃ¹ng má»™t function</p></li><li><p>ALB chá»‰ route Ä‘áº¿n má»™t Lambda function ARN, khÃ´ng support version-level routing</p></li><li><p>ThÃªm ALB cÅ©ng phá»©c táº¡p vÃ  tá»‘n chi phÃ­ khÃ´ng cáº§n thiáº¿t</p></li></ul><p></p><p>âŒ <strong>Create the new version of the Lambda function as a Lambda layer on the existing version. Configure the function to split the traffic between the two layers.</strong></p><ul><li><p>Lambda layers dÃ¹ng Ä‘á»ƒ share code/libraries giá»¯a cÃ¡c functions, khÃ´ng pháº£i Ä‘á»ƒ versioning hay traffic splitting</p></li><li><p>Layers khÃ´ng cÃ³ khÃ¡i niá»‡m traffic routing</p></li><li><p>Sai concept hoÃ n toÃ n</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Split traffic between Lambda versions\"</strong> â†’ <strong>Lambda Alias</strong> vá»›i weighted routing</p></li><li><p>Lambda deployment strategies:</p><ul><li><p><strong>Alias</strong> = pointer Ä‘áº¿n version + há»— trá»£ traffic shifting</p></li><li><p><strong>Version</strong> = immutable snapshot cá»§a function code</p></li></ul></li><li><p><strong>\"Canary/Blue-Green deployment\"</strong> â†’ <strong>Lambda Alias</strong></p></li><li><p><strong>Route 53</strong> khÃ´ng route Ä‘áº¿n Lambda versions</p></li><li><p><strong>Lambda Layers</strong> = code sharing, khÃ´ng pháº£i versioning/routing</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html\">Create an alias for a Lambda function</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a function alias. Configure the alias to split the traffic between the two versions of the Lambda function.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure a weighted routing policy in Amazon Route 53. Associate the versions of the Lambda function with the weighted routing policy.</p>",
                "<p>Create a function alias. Configure the alias to split the traffic between the two versions of the Lambda function.</p>",
                "<p>Create an Application Load Balancer (ALB) that uses the Lambda function as a target. Configure the ALB to split the traffic between the two versions of the Lambda function.</p>",
                "<p>Create the new version of the Lambda function as a Lambda layer on the existing version. Configure the function to split the traffic between the two layers.</p>"
            ],
            "answersPos": "[1,3,2,0]",
            "pos": 0
        },
        {
            "attemptAnswerId": 329662,
            "questionId": 7540,
            "questionText": "<p>A developer is creating an AWS Lambda function that will connect to an Amazon RDS for MySQL instance. The developer wants to store the database credentials. The database credentials need to be encrypted and the database password needs to be automatically rotated.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Lambda function cáº§n connect Ä‘áº¿n <strong>RDS for MySQL instance</strong></p></li><li><p>Developer cáº§n store <strong>database credentials</strong></p></li><li><p>Requirements:</p><ul><li><p>Credentials pháº£i Ä‘Æ°á»£c <strong>encrypted</strong></p></li><li><p>Database password cáº§n <strong>automatic rotation</strong></p></li></ul></li><li><p>TÃ¬m solution Ä‘Ã¡p á»©ng cáº£ hai requirements</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Store the database credentials in AWS Secrets Manager. Set up managed rotation on the database credentials.</strong></p><ul><li><p><strong>Secrets Manager</strong> há»— trá»£ <strong>automatic encryption</strong> vÃ  cÃ³ <strong>managed rotation</strong> cho RDS credentials (built-in)</p></li><li><p>Rotation tá»± Ä‘á»™ng update password trong cáº£ <strong>Secrets Manager vÃ  RDS database</strong></p></li><li><p>Best practice cho RDS credentials management</p></li></ul><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1760833957859-4qwezrsz-image.png\" alt=\"\" title=\"\" width=\"794\" height=\"444.7640625\" style=\"max-width: 794px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Store the database credentials as environment variables for the Lambda function. Set the environment variables to rotate automatically.</strong></p><ul><li><p>Environment variables khÃ´ng há»— trá»£ automatic rotation</p></li><li><p>Pháº£i manually update vÃ  redeploy Lambda function má»—i láº§n Ä‘á»•i password</p></li></ul><p></p><p>âŒ <strong>Store the database credentials in AWS Systems Manager Parameter Store as secure string parameters. Set up managed rotation on the parameters.</strong></p><ul><li><p>Parameter Store há»— trá»£ encryption nhÆ°ng KHÃ”NG cÃ³ managed rotation feature</p></li><li><p>Pháº£i tá»± build custom rotation logic</p></li></ul><p></p><p>âŒ <strong>Store the database credentials in the X-Amz-Security-Token parameter. Set up managed rotation on the parameter.</strong></p><ul><li><p>X-Amz-Security-Token lÃ  temporary security token cá»§a STS, khÃ´ng pháº£i credential storage service</p></li><li><p>Sai concept hoÃ n toÃ n</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Database credentials + automatic rotation\"</strong> â†’ <strong>AWS Secrets Manager</strong></p></li><li><p><strong>Secrets Manager vs Parameter Store:</strong></p><ul><li><p>Secrets Manager = credentials storage + <strong>managed rotation</strong> + versioning</p></li><li><p>Parameter Store = config data + encryption, <strong>KHÃ”NG cÃ³ managed rotation</strong></p></li></ul></li><li><p><strong>\"RDS credentials rotation\"</strong> â†’ Secrets Manager cÃ³ built-in rotation functions</p></li><li><p><strong>X-Amz-Security-Token</strong> = STS temporary token, khÃ´ng pháº£i storage</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html\">Rotate AWS Secrets Manager secrets</a></p></li></ul>",
            "correctAnswer": [
                "<p>Store the database credentials in AWS Secrets Manager. Set up managed rotation on the database credentials.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Store the database credentials as environment variables for the Lambda function. Set the environment variables to rotate automatically.</p>",
                "<p>Store the database credentials in AWS Secrets Manager. Set up managed rotation on the database credentials.</p>",
                "<p>Store the database credentials in AWS Systems Manager Parameter Store as secure string parameters. Set up managed rotation on the parameters.</p>",
                "<p>Store the database credentials in the X-Amz-Security-Token parameter. Set up managed rotation on the parameter.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 1
        },
        {
            "attemptAnswerId": 329663,
            "questionId": 7541,
            "questionText": "<p>A developer registered an AWS Lambda function as a target for an Application Load Balancer (ALB) using a CLI command. However, the Lambda function is not being invoked when the client sends requests through the ALB.<br><br>Why is the Lambda function not being invoked?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer Ä‘Ã£ register <strong>Lambda function as target</strong> cho ALB báº±ng CLI command</p></li><li><p>Client gá»­i requests qua ALB nhÆ°ng <strong>Lambda function khÃ´ng Ä‘Æ°á»£c invoke</strong></p></li><li><p>TÃ¬m nguyÃªn nhÃ¢n táº¡i sao Lambda khÃ´ng Ä‘Æ°á»£c invoked</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>The permissions to invoke the Lambda function are missing.</strong></p><ul><li><p>ALB cáº§n <strong>Lambda invoke permissions</strong> Ä‘á»ƒ cÃ³ thá»ƒ trigger Lambda function</p></li><li><p>Pháº£i thÃªm <strong>resource-based policy</strong> cho Lambda function cho phÃ©p ALB invoke</p></li><li><p>Command cáº§n thiáº¿t: <code>aws lambda add-permission</code> vá»›i <code>--principal elasticloadbalancing.amazonaws.com</code></p></li><li><p>Chá»‰ register Lambda lÃ m target thÃ´i chÆ°a Ä‘á»§, cáº§n permission riÃªng</p></li></ul><p></p><p><em>Permissions to invoke the Lambda function</em></p><pre><code>aws lambda add-permission \\\n    --function-name lambda-function-arn-with-alias-name \\ \n    --statement-id elb1 \\\n    --principal elasticloadbalancing.amazonaws.com \\\n    --action lambda:InvokeFunction \\\n    --source-arn target-group-arn \\\n    --source-account target-group-account-id</code></pre><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>A Lambda function cannot be registered as a target for an ALB.</strong></p><ul><li><p>Lambda CÃ“ THá»‚ Ä‘Æ°á»£c register lÃ m target cho ALB</p></li><li><p>ALB há»— trá»£ 4 loáº¡i targets: EC2 instances, IP addresses, ECS tasks, vÃ  Lambda functions</p></li></ul><p></p><p>âŒ <strong>A Lambda function can be registered with an ALB using AWS Management Console only.</strong></p><ul><li><p>Lambda cÃ³ thá»ƒ register vá»›i ALB qua CLI, Console, CloudFormation, hoáº·c SDK</p></li><li><p>CLI hoÃ n toÃ n Ä‘Æ°á»£c support</p></li></ul><p></p><p>âŒ <strong>Cross-zone is not enabled on the ALB.</strong></p><ul><li><p>Cross-zone load balancing khÃ´ng liÃªn quan Ä‘áº¿n Lambda invocation</p></li><li><p>Cross-zone chá»‰ áº£nh hÆ°á»Ÿng cÃ¡ch distribute traffic across AZs cho EC2/IP targets</p></li></ul><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1760834265537-y57gkgui-image.png\" alt=\"\" title=\"\" width=\"754\" height=\"406.0604166666667\" style=\"max-width: 754px\" data-keep-ratio=\"true\"></span></span></p><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"ALB + Lambda not invoked\"</strong> â†’ kiá»ƒm tra <strong>Lambda permissions</strong> (resource-based policy)</p></li><li><p>ALB invoke Lambda cáº§n 2 bÆ°á»›c:</p><ul><li><p>Register Lambda as target</p></li><li><p>Add <strong>invoke permission</strong> cho Lambda function</p></li></ul></li><li><p>Command: <code>aws lambda add-permission --function-name xxx --principal elasticloadbalancing.amazonaws.com</code></p></li><li><p>ALB supported targets: <strong>EC2, IP addresses, Lambda functions, ECS task</strong></p></li><li><p>Cross-zone load balancing = phÃ¢n phá»‘i traffic across AZs, khÃ´ng liÃªn quan Lambda</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/lambda-functions.html\">Use Lambda functions as targets of an Application Load Balancer</a></p></li></ul>",
            "correctAnswer": [
                "<p>The permissions to invoke the Lambda function are missing.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>A Lambda function cannot be registered as a target for an ALB.</p>",
                "<p>A Lambda function can be registered with an ALB using AWS Management Console only.</p>",
                "<p>The permissions to invoke the Lambda function are missing.</p>",
                "<p>Cross-zone is not enabled on the ALB.</p>"
            ],
            "answersPos": "[2,1,3,0]",
            "pos": 2
        },
        {
            "attemptAnswerId": 329664,
            "questionId": 7542,
            "questionText": "<p>A developer is planning to use an Amazon API Gateway and AWS Lambda to provide a REST API. The developer will have three distinct environments to manage: development, test, and production.<br><br>How should the application be deployed while minimizing the number of resources to manage?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer dÃ¹ng <strong>API Gateway + Lambda</strong> Ä‘á»ƒ provide REST API</p></li><li><p>Cáº§n manage <strong>3 environments</strong>: development, test, production</p></li><li><p>Requirement: <strong>minimizing the number of resources</strong> to manage</p></li><li><p>TÃ¬m deployment approach tá»‘i Æ°u</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create one API Gateway with multiple stages with one Lambda function with multiple aliases.</strong></p><ul><li><p><strong>API Gateway stages</strong> cho phÃ©p deploy multiple versions (dev, test, prod) tá»« cÃ¹ng má»™t API</p></li><li><p><strong>Lambda aliases</strong> point Ä‘áº¿n different versions cá»§a Lambda function cho má»—i environment</p></li><li><p>Map má»—i <strong>API Gateway stage</strong> Ä‘áº¿n <strong>Lambda alias</strong> tÆ°Æ¡ng á»©ng (dev stage â†’ dev alias, prod stage â†’ prod alias)</p></li><li><p>Minimize resources: chá»‰ cáº§n 1 API Gateway vÃ  1 Lambda function, dÃ¹ng stages/aliases Ä‘á»ƒ phÃ¢n biá»‡t environments</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a separate API Gateway and separate Lambda function for each environment in the same Region.</strong></p><ul><li><p>Táº¡o 3 API Gateways vÃ  3 Lambda functions = nhiá»u resources pháº£i manage nháº¥t</p></li><li><p>KhÃ´ng minimize resources nhÆ° yÃªu cáº§u</p></li></ul><p></p><p>âŒ <strong>Assign a Region for each environment and deploy API Gateway and Lambda to each Region.</strong></p><ul><li><p>Deploy across multiple Regions tá»‘n kÃ©m vÃ  phá»©c táº¡p hÆ¡n</p></li><li><p>KhÃ´ng cáº§n thiáº¿t cho environment separation, cross-region chá»‰ cáº§n cho disaster recovery/latency</p></li></ul><p></p><p>âŒ <strong>Create one API Gateway and one Lambda function, and use a REST parameter to identify the environment.</strong></p><ul><li><p>KhÃ´ng cÃ³ cÃ¡ch isolate environments properly (cÃ¹ng chung code/config)</p></li><li><p>KhÃ³ manage permissions, configs, vÃ  testing riÃªng cho tá»«ng environment</p></li><li><p>KhÃ´ng pháº£i best practice</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Multiple environments + minimize resources\"</strong> â†’ <strong>API Gateway Stages + Lambda Aliases</strong></p></li><li><p><strong>API Gateway Stages</strong> = dev, test, prod deployments cá»§a cÃ¹ng má»™t API</p></li><li><p><strong>Lambda Aliases</strong> = pointers Ä‘áº¿n specific Lambda versions (stable naming cho environments)</p></li><li><p>Pattern phá»• biáº¿n:</p><ul><li><p>dev stage â†’ dev alias â†’ Lambda version X</p></li><li><p>prod stage â†’ prod alias â†’ Lambda version Y</p></li></ul></li><li><p><strong>Separate Regions</strong> = disaster recovery/global latency, khÃ´ng pháº£i environment separation</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-set-stage-variables-aws-console.html\">Set up stage variables for REST APIs in API Gateway</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create one API Gateway with multiple stages with one Lambda function with multiple aliases.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a separate API Gateway and separate Lambda function for each environment in the same Region.</p>",
                "<p>Assign a Region for each environment and deploy API Gateway and Lambda to each Region.</p>",
                "<p>Create one API Gateway with multiple stages with one Lambda function with multiple aliases.</p>",
                "<p>Create one API Gateway and one Lambda function, and use a REST parameter to identify the environment.</p>"
            ],
            "answersPos": "[1,2,3,0]",
            "pos": 3
        },
        {
            "attemptAnswerId": 329665,
            "questionId": 7543,
            "questionText": "<p>A company is hosting a workshop for external users and wants to share the reference documents with the external users for 7 days. The company stores the reference documents in an Amazon S3 bucket that the company owns.<br><br>What is the MOST secure way to share the documents with the external users?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company cáº§n share <strong>reference documents</strong> vá»›i <strong>external users</strong> trong <strong>7 days</strong></p></li><li><p>Documents lÆ°u trong <strong>S3 bucket</strong> cá»§a company</p></li><li><p>Requirement: <strong>MOST secure way</strong> to share</p></li><li><p>TÃ¬m solution báº£o máº­t nháº¥t</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use S3 presigned URLs to share the documents with the external users. Set an expiration time of 7 days.</strong></p><ul><li><p><strong>Presigned URLs</strong> cho phÃ©p temporary access Ä‘áº¿n S3 objects mÃ  khÃ´ng cáº§n AWS credentials</p></li><li><p>Set <strong>expiration time = 7 days</strong>, sau Ä‘Ã³ URLs tá»± Ä‘á»™ng invalid</p></li><li><p>KhÃ´ng cáº§n táº¡o IAM users/roles cho external users</p></li><li><p>Secure vÃ¬ chá»‰ grant access Ä‘áº¿n specific objects vÃ  tá»± Ä‘á»™ng expire</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Move the documents to an Amazon WorkDocs folder. Share the links of the WorkDocs folder with the external users.</strong></p><ul><li><p>Pháº£i migrate documents sang WorkDocs (thÃªm complexity vÃ  cost)</p></li><li><p>WorkDocs cáº§n setup users/permissions riÃªng</p></li><li><p>KhÃ´ng cáº§n thiáº¿t khi Ä‘Ã£ cÃ³ S3, presigned URLs Ä‘Æ¡n giáº£n hÆ¡n</p></li></ul><p></p><p>âŒ <strong>Create temporary IAM users that have read-only access to the S3 bucket. Share the access keys with the external users. Expire the credentials after 7 days.</strong></p><ul><li><p>Sharing access keys vá»›i external users = <strong>security risk</strong> (keys cÃ³ thá»ƒ bá»‹ leak)</p></li><li><p>Pháº£i manually manage IAM users vÃ  cleanup sau 7 days</p></li><li><p>Vi pháº¡m best practice: khÃ´ng nÃªn share long-term credentials</p></li></ul><p></p><p>âŒ <strong>Create a role that has read-only access to the S3 bucket. Share the Amazon Resource Name (ARN) of this role with the external users.</strong></p><ul><li><p>External users khÃ´ng cÃ³ AWS account, khÃ´ng thá»ƒ assume IAM role</p></li><li><p>Chá»‰ share ARN khÃ´ng cho phÃ©p access, cáº§n credentials Ä‘á»ƒ assume role</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Temporary access to S3 + external users\"</strong> â†’ <strong>S3 Presigned URLs</strong></p></li><li><p><strong>Presigned URLs</strong> = temporary URLs vá»›i embedded credentials, khÃ´ng cáº§n IAM users</p></li><li><p><strong>NEVER share IAM access keys</strong> vá»›i external users (security risk)</p></li><li><p>IAM roles cáº§n AWS credentials Ä‘á»ƒ assume, khÃ´ng work cho external users khÃ´ng cÃ³ AWS account</p></li><li><p><strong>Presigned URL use cases</strong>: share private objects temporarily, upload/download without AWS credentials</p></li><li><p>WorkDocs = document collaboration service, overkill cho simple file sharing</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html\">Sharing objects with presigned URLs</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-presigned-url.html\">Download and upload objects with presigned URLs</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use S3 presigned URLs to share the documents with the external users. Set an expiration time of 7 days.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use S3 presigned URLs to share the documents with the external users. Set an expiration time of 7 days.</p>",
                "<p>Move the documents to an Amazon WorkDocs folder. Share the links of the WorkDocs folder with the external users.</p>",
                "<p>Create temporary IAM users that have read-only access to the S3 bucket. Share the access keys with the external users. Expire the credentials after 7 days.</p>",
                "<p>Create a role that has read-only access to the S3 bucket. Share the Amazon Resource Name (ARN) of this role with the external users.</p>"
            ],
            "answersPos": "[1,2,3,0]",
            "pos": 4
        },
        {
            "attemptAnswerId": 329666,
            "questionId": 7597,
            "questionText": "<p>A developer has built an application that inserts data into an Amazon DynamoDB table. The table is configured to use provisioned capacity. The application is deployed on a burstable nano Amazon EC2 instance. The application logs show that the application has been failing because of a ProvisionedThroughputExceededException error.<br><br>Which actions should the developer take to resolve this issue? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application insert data vÃ o <strong>DynamoDB table</strong> vá»›i <strong>provisioned capacity</strong></p></li><li><p>Deploy trÃªn <strong>burstable nano EC2 instance</strong></p></li><li><p>Lá»—i: <strong>ProvisionedThroughputExceededException</strong></p></li><li><p>Requirement: chá»n <strong>2 actions</strong> Ä‘á»ƒ resolve issue</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Reduce the frequency of requests to DynamoDB by implementing exponential backoff.</strong></p><ul><li><p><strong>Exponential backoff</strong> retry logic giáº£m request rate khi gáº·p throttling</p></li><li><p>AWS SDK best practice Ä‘á»ƒ handle throttling errors</p></li><li><p>Tá»± Ä‘á»™ng tÄƒng delay giá»¯a cÃ¡c retries, giáº£m Ã¡p lá»±c lÃªn DynamoDB</p></li></ul><p></p><p><strong>Change the capacity mode of the DynamoDB table from provisioned to on-demand.</strong></p><ul><li><p><strong>On-demand mode</strong> tá»± Ä‘á»™ng scale theo workload, khÃ´ng bá»‹ throttle</p></li><li><p>PhÃ¹ há»£p cho unpredictable/bursty traffic patterns</p></li><li><p>KhÃ´ng cáº§n manage capacity units manually</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Move the application to a larger EC2 instance.</strong></p><ul><li><p>Lá»—i xáº£y ra á»Ÿ <strong>DynamoDB throughput</strong>, khÃ´ng pháº£i EC2 compute capacity</p></li><li><p>TÄƒng EC2 size khÃ´ng giáº£i quyáº¿t DynamoDB throttling</p></li></ul><p></p><p>âŒ <strong>Increase the number of read capacity units (RCUs) that are provisioned for the DynamoDB table.</strong></p><ul><li><p>Application Ä‘ang <strong>insert data</strong> = write operations, khÃ´ng pháº£i reads</p></li><li><p>Cáº§n tÄƒng <strong>WCUs (Write Capacity Units)</strong>, khÃ´ng pháº£i RCUs</p></li></ul><p></p><p>âŒ <strong>Increase the frequency of requests to DynamoDB by decreasing the retry delay.</strong></p><ul><li><p>TÄƒng request frequency lÃ m throttling <strong>Tá»† HÆ N</strong>, khÃ´ng giáº£i quyáº¿t váº¥n Ä‘á»</p></li><li><p>NgÆ°á»£c láº¡i vá»›i logic cáº§n thiáº¿t</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>ProvisionedThroughputExceededException</strong> = DynamoDB throttling do vÆ°á»£t quÃ¡ provisioned capacity</p></li><li><p><strong>Solutions cho throttling:</strong></p><ul><li><p>Implement <strong>exponential backoff</strong> (retry logic)</p></li><li><p>Increase <strong>WCUs/RCUs</strong> (náº¿u Ä‘Ãºng loáº¡i operation)</p></li><li><p>Switch to <strong>on-demand mode</strong></p></li></ul></li><li><p><strong>Insert/Write operations</strong> = cáº§n WCUs, khÃ´ng pháº£i RCUs</p></li><li><p><strong>Exponential backoff</strong> = AWS SDK best practice cho retry logic</p></li><li><p>EC2 instance size khÃ´ng liÃªn quan Ä‘áº¿n DynamoDB throughput</p></li><li><p><strong>On-demand mode</strong> = auto-scaling, phÃ¹ há»£p unpredictable workloads</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/retry-backoff.html\">Retry with backoff pattern</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/wellarchitected/latest/serverless-applications-lens/capacity.html\">DynamoDB on-demand and provisioned capacity</a></p></li></ul>",
            "correctAnswer": [
                "<p>Reduce the frequency of requests to DynamoDB by implementing exponential backoff.</p>",
                "<p>Change the capacity mode of the DynamoDB table from provisioned to on-demand.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Move the application to a larger EC2 instance.</p>",
                "<p>Increase the number of read capacity units (RCUs) that are provisioned for the DynamoDB table.</p>",
                "<p>Reduce the frequency of requests to DynamoDB by implementing exponential backoff.</p>",
                "<p>Increase the frequency of requests to DynamoDB by decreasing the retry delay.</p>",
                "<p>Change the capacity mode of the DynamoDB table from provisioned to on-demand.</p>"
            ],
            "answersPos": "[4,3,2,1,0]",
            "pos": 5
        },
        {
            "attemptAnswerId": 329667,
            "questionId": 7544,
            "questionText": "<p>Given the following AWS CloudFormation template:</p><p></p><pre><code>Description: Creates a new Amazon S3 bucket for shared content. Uses a random bucket name to avoid conflicts.\n\nResources:\n  ContentBucket:\n    Type: AWS::S3::Bucket\n\nOutputs:\n  ContentBucketName:\n    Value: !Ref ContentBucket</code></pre><p></p><p>What is the MOST efficient way to reference the new Amazon S3 bucket from another AWS CloudFormation template?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>CÃ³ CloudFormation template táº¡o <strong>S3 bucket</strong> vá»›i <strong>Output = ContentBucketName</strong></p></li><li><p>Output Ä‘Ã£ cÃ³ <code>Value: !Ref ContentBucket</code> nhÆ°ng <strong>chÆ°a cÃ³ Export</strong></p></li><li><p>Cáº§n reference S3 bucket nÃ y tá»« <strong>another CloudFormation template</strong></p></li><li><p>Requirement: <strong>MOST efficient way</strong> to reference</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Add an Export declaration to the Outputs section of the original template and use ImportValue in other templates.</strong></p><ul><li><p>ThÃªm <strong>Export</strong> vÃ o Outputs section Ä‘á»ƒ share value across stacks</p></li><li><p>Modified template: </p><pre><code class=\"language-yaml\">Outputs:\n    ContentBucketName:\n      Value: !Ref ContentBucket\n      Export:\n        Name: SharedContentBucketName\n</code></pre></li><li><p>Other stacks dÃ¹ng <strong>Fn::ImportValue</strong> Ä‘á»ƒ reference: <code>!ImportValue SharedContentBucketName</code></p></li><li><p>Native CloudFormation feature, efficient vÃ  Ä‘Æ¡n giáº£n nháº¥t</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Add Exported: true to the Content.Bucket in the original template and use ImportResource in other templates.</strong></p><ul><li><p>KhÃ´ng cÃ³ property <strong>Exported: true</strong> trong CloudFormation</p></li><li><p>KhÃ´ng cÃ³ function <strong>ImportResource</strong></p></li><li><p>Sai syntax hoÃ n toÃ n</p></li></ul><p></p><p>âŒ <strong>Create a custom AWS CloudFormation resource that gets the bucket name from the ContentBucket resource of the first stack.</strong></p><ul><li><p>Custom resource phá»©c táº¡p, cáº§n viáº¿t Lambda function</p></li><li><p>KhÃ´ng efficient khi cÃ³ native Export/Import feature</p></li><li><p>Overkill cho use case Ä‘Æ¡n giáº£n nÃ y</p></li></ul><p></p><p>âŒ <strong>Use Fn::Include to include the existing template in other templates and use the ContentBucket resource directly.</strong></p><ul><li><p>KhÃ´ng cÃ³ function <strong>Fn::Include</strong> trong CloudFormation</p></li><li><p>KhÃ´ng thá»ƒ include templates nhÆ° váº­y</p></li><li><p>Sai concept</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Reference resource across stacks\"</strong> â†’ <strong>Export/ImportValue pattern</strong></p></li><li><p>Cross-stack reference pattern:</p><ul><li><p>Stack A: Add <strong>Export</strong> trong Outputs</p></li><li><p>Stack B: Use <strong>Fn::ImportValue</strong> or <strong>!ImportValue</strong></p></li></ul></li><li><p>Export syntax cáº§n thÃªm vÃ o existing Output: </p><pre><code class=\"language-yaml\">Export:\n    Name: UniqueExportName\n</code></pre></li><li><p>Export Name pháº£i <strong>unique</strong> trong Region</p></li><li><p>KhÃ´ng cÃ³ <strong>Exported: true</strong>, <strong>ImportResource</strong>, hay <strong>Fn::Include</strong></p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-stack-exports.html\">Get exported outputs from a deployed CloudFormation stack</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/intrinsic-function-reference-importvalue.html\">Fn::ImportValue function</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add an Export declaration to the Outputs section of the original template and use ImportValue in other templates.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add an Export declaration to the Outputs section of the original template and use ImportValue in other templates.</p>",
                "<p>Add Exported: true to the Content.Bucket in the original template and use ImportResource in other templates.</p>",
                "<p>Create a custom AWS CloudFormation resource that gets the bucket name from the ContentBucket resource of the first stack.</p>",
                "<p>Use Fn::Include to include the existing template in other templates and use the ContentBucket resource directly.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 6
        },
        {
            "attemptAnswerId": 329668,
            "questionId": 7545,
            "questionText": "<p>An application is real-time processing millions of events that are received through an API.<br><br>What service could be used to allow multiple consumers to process the data concurrently and MOST cost-effectively?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application nháº­n <strong>millions of events</strong> qua API</p></li><li><p>Cáº§n <strong>real-time processing</strong></p></li><li><p>Cho phÃ©p <strong>multiple consumers</strong> process data <strong>concurrently</strong></p></li><li><p>Requirement: <strong>MOST cost-effective</strong></p></li><li><p>TÃ¬m service phÃ¹ há»£p nháº¥t</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Amazon Kinesis Data Streams</strong></p><ul><li><p><strong>Built for real-time streaming</strong> vá»›i kháº£ nÄƒng handle millions of events per second</p></li><li><p><strong>Multiple consumers</strong> cÃ³ thá»ƒ process cÃ¹ng data concurrently (Enhanced Fan-Out hoáº·c shared throughput)</p></li><li><p>Data <strong>persist trong stream</strong> (1-365 days), consumers cÃ³ thá»ƒ replay vÃ  process independently</p></li><li><p>Optimized cho <strong>high-throughput real-time processing</strong>, khÃ´ng pháº£i simple messaging</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Amazon SNS with fanout to an SQS queue for each application</strong></p><ul><li><p>SNS/SQS lÃ  <strong>messaging service</strong>, khÃ´ng pháº£i real-time streaming platform</p></li><li><p>Vá»›i millions of events real-time, cÃ³ <strong>higher latency</strong> so vá»›i Kinesis</p></li><li><p>SQS khÃ´ng persist data nhÆ° stream, queue-based processing khÃ¡c streaming processing</p></li></ul><p></p><p>âŒ <strong>Amazon SNS with fanout to an SQS FIFO (first-in, first-out) queue for each application</strong></p><ul><li><p>FIFO queue cÃ³ <strong>throughput limit 300-3000 TPS</strong>, khÃ´ng handle Ä‘Æ°á»£c millions of events</p></li><li><p>Äáº¯t hÆ¡n Standard SQS</p></li><li><p>KhÃ´ng phÃ¹ há»£p cho high-volume real-time streaming</p></li></ul><p></p><p>âŒ <strong>Amazon Kinesis Firehose</strong></p><ul><li><p>Firehose dÃ¹ng Ä‘á»ƒ <strong>deliver/load data</strong> Ä‘áº¿n destinations (S3, Redshift, Elasticsearch)</p></li><li><p>KhÃ´ng support <strong>multiple consumers processing concurrently</strong> cÃ¹ng real-time data</p></li><li><p>Use case: data delivery/ETL, khÃ´ng pháº£i real-time concurrent processing</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Millions of events + real-time processing\"</strong> â†’ <strong>Kinesis Data Streams</strong></p></li><li><p><strong>Kinesis Data Streams vs SNS/SQS:</strong></p><ul><li><p>Kinesis = <strong>streaming platform</strong>, real-time analytics, persist data, high throughput</p></li><li><p>SNS/SQS = <strong>messaging service</strong>, decoupling, queue-based, khÃ´ng tá»‘i Æ°u cho streaming</p></li></ul></li><li><p><strong>Kinesis Data Streams vs Firehose:</strong></p><ul><li><p>Data Streams = <strong>processing</strong> vá»›i multiple consumers</p></li><li><p>Firehose = <strong>delivery</strong> Ä‘áº¿n destinations</p></li></ul></li><li><p><strong>\"Multiple consumers + real-time\"</strong> â†’ Kinesis Enhanced Fan-Out (dedicated throughput per consumer)</p></li><li><p>FIFO SQS cÃ³ throughput limit â†’ khÃ´ng phÃ¹ há»£p millions of events</p></li><li><p><strong>Cost-effective cho streaming</strong> = Kinesis (optimized for throughput), khÃ´ng pháº£i SNS/SQS</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/streams/latest/dev/building-consumers.html\">Read data from Amazon Kinesis Data Streams</a></p></li></ul>",
            "correctAnswer": [
                "<p>Amazon Kinesis Data Streams</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Amazon SNS with fanout to an SQS queue for each application</p>",
                "<p>Amazon SNS with fanout to an SQS FIFO (first-in, first-out) queue for each application</p>",
                "<p>Amazon Kinesis Firehose</p>",
                "<p>Amazon Kinesis Data Streams</p>"
            ],
            "answersPos": "[2,0,1,3]",
            "pos": 7
        },
        {
            "attemptAnswerId": 329669,
            "questionId": 7546,
            "questionText": "<p>A web application is using Amazon Kinesis Data Streams for clickstream data that may not be consumed for up to 12 hours.<br><br>How can the developer implement encryption at rest for data within the Kinesis Data Streams?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Web application dÃ¹ng <strong>Kinesis Data Streams</strong> cho clickstream data</p></li><li><p>Data cÃ³ thá»ƒ <strong>khÃ´ng Ä‘Æ°á»£c consume trong 12 hours</strong></p></li><li><p>Cáº§n implement <strong>encryption at rest</strong> cho data trong Kinesis Data Streams</p></li><li><p>TÃ¬m cÃ¡ch encrypt data at rest</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Enable server-side encryption in Kinesis Data Streams.</strong></p><ul><li><p>Kinesis Data Streams há»— trá»£ <strong>server-side encryption (SSE)</strong> vá»›i AWS KMS</p></li><li><p>Tá»± Ä‘á»™ng encrypt data <strong>at rest</strong> khi data Ä‘Æ°á»£c stored trong stream</p></li><li><p>Enable báº±ng cÃ¡ch specify KMS key khi táº¡o hoáº·c update stream</p></li><li><p>Encryption/decryption tá»± Ä‘á»™ng xá»­ lÃ½ bá»Ÿi Kinesis, application khÃ´ng cáº§n modify code</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Enable SSL connections to Kinesis.</strong></p><ul><li><p>SSL/TLS lÃ  <strong>encryption in transit</strong>, khÃ´ng pháº£i encryption at rest</p></li><li><p>SSL chá»‰ protect data khi transfer giá»¯a client vÃ  Kinesis</p></li><li><p>KhÃ´ng encrypt data khi stored trong stream</p></li></ul><p></p><p>âŒ <strong>Use Amazon Kinesis Consumer Library.</strong></p><ul><li><p>Kinesis Consumer Library (KCL) lÃ  <strong>library Ä‘á»ƒ build consumer applications</strong></p></li><li><p>KCL khÃ´ng cÃ³ chá»©c nÄƒng encryption</p></li><li><p>KCL chá»‰ giÃºp manage consumers, checkpointing, load balancing</p></li></ul><p></p><p>âŒ <strong>Encrypt the data once it is at rest with a Lambda function.</strong></p><ul><li><p>Data \"at rest\" nghÄ©a lÃ  Ä‘Ã£ stored trong Kinesis stream</p></li><li><p>KhÃ´ng thá»ƒ dÃ¹ng Lambda Ä‘á»ƒ encrypt data <strong>sau khi</strong> Ä‘Ã£ at rest</p></li><li><p>Pháº£i encrypt <strong>trÆ°á»›c</strong> hoáº·c <strong>trong quÃ¡ trÃ¬nh</strong> storing, khÃ´ng pháº£i sau</p></li></ul><p></p><p>ğŸ”‘ Tips and tricks:</p><ul><li><p><strong>\"Encryption at rest\"</strong> â†’ <strong>Server-side encryption (SSE)</strong></p></li><li><p><strong>Encryption types:</strong></p><ul><li><p><strong>At rest</strong> = data stored (SSE, KMS)</p></li><li><p><strong>In transit</strong> = data transferring (SSL/TLS, HTTPS)</p></li></ul></li><li><p><strong>Kinesis encryption:</strong></p><ul><li><p>Enable <strong>server-side encryption</strong> vá»›i AWS KMS key</p></li><li><p>Automatic encryption/decryption</p></li></ul></li><li><p><strong>SSL/TLS</strong> = encryption in transit, khÃ´ng pháº£i at rest</p></li><li><p><strong>KCL</strong> = consumer library, khÃ´ng liÃªn quan encryption</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/streams/latest/dev/server-side-encryption.html\">Data protection in Amazon Kinesis Data Streams</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/streams/latest/dev/getting-started-with-sse.html\">How do I enable server-side encryption for Kinesis Data Streams</a></p></li></ul>",
            "correctAnswer": [
                "<p>Enable server-side encryption in Kinesis Data Streams.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Enable SSL connections to Kinesis.</p>",
                "<p>Use Amazon Kinesis Consumer Library.</p>",
                "<p>Encrypt the data once it is at rest with a Lambda function.</p>",
                "<p>Enable server-side encryption in Kinesis Data Streams.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 8
        },
        {
            "attemptAnswerId": 329670,
            "questionId": 7547,
            "questionText": "<p>An application uses AWS X-Ray to generate a large amount of trace data on an hourly basis. A developer wants to use filter expressions to limit the returned results through user-specified custom attributes.<br><br>How should the developer use filter expressions to filter the results in X-Ray?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application dÃ¹ng <strong>AWS X-Ray</strong> generate large amount of trace data hourly</p></li><li><p>Developer muá»‘n dÃ¹ng <strong>filter expressions</strong> Ä‘á»ƒ limit results</p></li><li><p>Filter dá»±a trÃªn <strong>user-specified custom attributes</strong></p></li><li><p>TÃ¬m cÃ¡ch implement filter expressions vá»›i custom attributes</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Add custom attributes as annotations in the segment document.</strong></p><ul><li><p><strong>Annotations</strong> lÃ  key-value pairs Ä‘Æ°á»£c <strong>indexed by X-Ray</strong></p></li><li><p>CÃ³ thá»ƒ dÃ¹ng trong <strong>filter expressions</strong> Ä‘á»ƒ search vÃ  filter traces</p></li><li><p>Support filtering trong X-Ray console vÃ  API</p></li><li><p>Annotations phÃ¹ há»£p cho attributes cáº§n searchable/filterable</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Add custom attributes as metadata in the segment document.</strong></p><ul><li><p><strong>Metadata</strong> lÃ  key-value pairs <strong>KHÃ”NG Ä‘Æ°á»£c indexed</strong></p></li><li><p>KhÃ´ng thá»ƒ dÃ¹ng metadata trong filter expressions</p></li><li><p>Metadata chá»‰ Ä‘á»ƒ store additional info, khÃ´ng searchable</p></li></ul><p></p><p>âŒ <strong>Add custom attributes as new segment fields in the segment document.</strong></p><ul><li><p>KhÃ´ng thá»ƒ tá»± Ã½ thÃªm custom fields vÃ o segment document structure</p></li><li><p>Segment document cÃ³ fixed schema</p></li><li><p>Pháº£i dÃ¹ng annotations hoáº·c metadata cho custom data</p></li></ul><p></p><p>âŒ <strong>Create new sampling rules that are based on custom attributes.</strong></p><ul><li><p><strong>Sampling rules</strong> quyáº¿t Ä‘á»‹nh traces nÃ o Ä‘Æ°á»£c <strong>recorded</strong>, khÃ´ng pháº£i filtering results</p></li><li><p>Sampling xáº£y ra trÆ°á»›c khi trace Ä‘Æ°á»£c ghi, khÃ´ng pháº£i lÃºc query</p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n filter expressions Ä‘á»ƒ query traces</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Filter expressions + custom attributes\"</strong> â†’ <strong>Annotations</strong></p></li><li><p><strong>Annotations vs Metadata:</strong></p><ul><li><p><strong>Annotations</strong> = indexed, searchable, filterable, max 50 annotations</p></li><li><p><strong>Metadata</strong> = not indexed, chá»‰ Ä‘á»ƒ view, no filter support</p></li></ul></li><li><p><strong>Sampling vs Filtering:</strong></p><ul><li><p><strong>Sampling</strong> = quyáº¿t Ä‘á»‹nh traces nÃ o Ä‘Æ°á»£c recorded</p></li><li><p><strong>Filtering</strong> = query/search traces Ä‘Ã£ recorded</p></li></ul></li><li><p>X-Ray segment document structure lÃ  fixed, khÃ´ng custom fields</p></li><li><p>Use annotations cho data cáº§n filter/search</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html#xray-concepts-annotations\">https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html#xray-concepts-annotations</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html#xray-concepts-filterexpressions\">https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html#xray-concepts-filterexpressions</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add custom attributes as annotations in the segment document.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add custom attributes as annotations in the segment document.</p>",
                "<p>Add custom attributes as metadata in the segment document.</p>",
                "<p>Add custom attributes as new segment fields in the segment document.</p>",
                "<p>Create new sampling rules that are based on custom attributes.</p>"
            ],
            "answersPos": "[2,0,1,3]",
            "pos": 9
        },
        {
            "attemptAnswerId": 329671,
            "questionId": 7548,
            "questionText": "<p>A developer is designing a serverless application that customers use to select seats for a concert venue. Customers send the ticket requests to an Amazon API Gateway API with an AWS Lambda function that acknowledges the order and generates an order ID. The application includes two additional Lambda functions: one for inventory management and one for payment processing. These two Lambda functions run in parallel and write the order to an Amazon Dynamo DB table.<br><br>The application must provide seats to customers according to the following requirements. If a seat is accidently sold more than once, the first order that the application received must get the seat. In these cases, the application must process the payment for only the first order. However, if the first order is rejected during payment processing, the second order must get the seat. In these cases, the application must process the payment for the second order.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Serverless application cho concert seat selection</p></li><li><p>Flow: API Gateway â†’ Lambda (táº¡o order ID) â†’ 2 Lambda functions <strong>run in parallel</strong>:</p><ul><li><p>Inventory management</p></li><li><p>Payment processing</p></li></ul></li><li><p>Requirements phá»©c táº¡p:</p><ul><li><p>Náº¿u seat <strong>bá»‹ bÃ¡n 2 láº§n (accidentally sold twice)</strong>: <strong>first order</strong> nháº­n seat vÃ  process payment</p></li><li><p>Náº¿u <strong>first order rejected</strong> khi payment processing: <strong>second order</strong> nháº­n seat vÃ  process payment</p></li><li><p>Cáº§n <strong>Ä‘áº£m báº£o thá»© tá»± (ordering guarantee)</strong> Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ä‘Æ¡n hÃ ng nÃ o Ä‘áº¿n trÆ°á»›c/sau</p></li></ul></li><li><p>TÃ¬m solution Ä‘Ã¡p á»©ng ordering requirements</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Send the order ID to an Amazon Simple Notification Service (Amazon SNS) FIFO topic that fans out to one Amazon Simple Queue Service (Amazon SQS) FIFO queue for inventory management and another SQS FIFO queue for payment processing.</strong></p><ul><li><p><strong>SNS FIFO topic</strong> giá»¯ <strong>nghiÃªm ngáº·t ordering</strong> khi fanout messages</p></li><li><p><strong>SQS FIFO queues</strong> Ä‘áº£m báº£o messages Ä‘Æ°á»£c process theo <strong>exact order</strong> received</p></li><li><p>FIFO guarantee: first order arrive â†’ process first â†’ náº¿u fail thÃ¬ second order process</p></li><li><p>Parallel processing váº«n maintain order trong má»—i queue</p></li></ul><p></p><p><em>HÃ¬nh minh hoáº¡:</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1760841296063-cm7wd8sm-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"310.2916666666667\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Change the Lambda function that generates the order ID to initiate the Lambda function for inventory management. Then initiate the Lambda function for payment processing.</strong></p><ul><li><p>Sequential invocation (inventory â†’ payment), khÃ´ng pháº£i <strong>parallel</strong> nhÆ° requirement</p></li><li><p>Äá» yÃªu cáº§u hai functions <strong>run in parallel</strong></p></li><li><p>Sequential slow hÆ¡n vÃ  khÃ´ng match architecture hiá»‡n táº¡i</p></li></ul><p></p><p>âŒ <strong>Send the order ID to an Amazon Simple Queue Service (Amazon SQS) topic. Subscribe the Lambda functions for inventory management and payment processing to the topic.</strong></p><ul><li><p><strong>Standard SNS topic</strong> khÃ´ng guarantee ordering</p></li><li><p>Messages cÃ³ thá»ƒ arrive out-of-order á»Ÿ consumers</p></li><li><p>KhÃ´ng Ä‘áº£m báº£o first/second order processing correctly</p></li></ul><p></p><p>âŒ <strong>Deliver the order ID to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the Lambda functions for inventory management and payment processing to poll the queue.</strong></p><ul><li><p>Chá»‰ cÃ³ <strong>1 queue</strong> cho 2 functions â†’ khÃ´ng thá»ƒ parallel processing properly</p></li><li><p>Message chá»‰ consumed má»™t láº§n, khÃ´ng fanout Ä‘Æ°á»£c cho cáº£ 2 functions</p></li><li><p>Má»™t function consume thÃ¬ function kia khÃ´ng nháº­n Ä‘Æ°á»£c message</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Ordering guarantee + parallel processing\"</strong> â†’ <strong>SNS FIFO + SQS FIFO</strong></p></li><li><p><strong>SNS FIFO fanout:</strong></p><ul><li><p>Maintain <strong>message ordering</strong> khi fanout</p></li><li><p>Má»—i SQS FIFO queue nháº­n messages theo Ä‘Ãºng order</p></li></ul></li><li><p><strong>Standard SNS vs FIFO SNS:</strong></p><ul><li><p>Standard = no ordering guarantee</p></li><li><p>FIFO = strict ordering + exactly-once delivery</p></li></ul></li><li><p><strong>1 SQS queue cho multiple consumers</strong> = khÃ´ng work (message consumed once)</p></li><li><p><strong>Sequential Lambda invocation</strong> â‰  parallel processing</p></li><li><p>Pattern: SNS FIFO topic â†’ multiple SQS FIFO queues = ordered fanout</p></li></ul><p></p><p>ğŸ“– Reference:</p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/blogs/aws/introducing-amazon-sns-fifo-first-in-first-out-pub-sub-messaging/\">Introducing Amazon SNS FIFO â€“ First-In-First-Out Pub/Sub Messaging</a></p></li></ul>",
            "correctAnswer": [
                "<p>Send the order ID to an Amazon Simple Notification Service (Amazon SNS) FIFO topic that fans out to one Amazon Simple Queue Service (Amazon SQS) FIFO queue for inventory management and another SQS FIFO queue for payment processing.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Send the order ID to an Amazon Simple Notification Service (Amazon SNS) FIFO topic that fans out to one Amazon Simple Queue Service (Amazon SQS) FIFO queue for inventory management and another SQS FIFO queue for payment processing.</p>",
                "<p>Change the Lambda function that generates the order ID to initiate the Lambda function for inventory management. Then initiate the Lambda function for payment processing.</p>",
                "<p>Send the order ID to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the Lambda functions for inventory management and payment processing to the topic.</p>",
                "<p>Deliver the order ID to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the Lambda functions for inventory management and payment processing to poll the queue.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 10
        },
        {
            "attemptAnswerId": 329672,
            "questionId": 7549,
            "questionText": "<p>An application needs to use the IP address of the client in its processing. The application has been moved into AWS and has been placed behind an Application Load Balancer (ALB). However, all the client IP addresses now appear to be the same. The application must maintain the ability to scale horizontally.<br><br>Based on this scenario, what is the MOST cost-effective solution to this problem?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application cáº§n <strong>IP address of the client</strong> Ä‘á»ƒ processing</p></li><li><p>Application behind <strong>ALB</strong></p></li><li><p>Hiá»‡n táº¡i táº¥t cáº£ client IP addresses <strong>appear to be the same</strong> (tháº¥y ALB IP)</p></li><li><p>Must maintain <strong>ability to scale horizontally</strong></p></li><li><p>Requirement: <strong>MOST cost-effective solution</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Alter the application code to inspect the X-Forwarded-For header. Ensure that the code can work properly if a list of IP addresses is passed in the header.</strong></p><ul><li><p>ALB tá»± Ä‘á»™ng thÃªm <strong>X-Forwarded-For (XFF) header</strong> chá»©a original client IP</p></li><li><p>Application chá»‰ cáº§n Ä‘á»c XFF header Ä‘á»ƒ láº¥y client IP</p></li><li><p>XFF cÃ³ thá»ƒ chá»©a <strong>list of IP addresses</strong> (qua nhiá»u proxies): <code>client, proxy1, proxy2</code></p></li><li><p>Cost-effective: chá»‰ modify application code, khÃ´ng thay Ä‘á»•i infrastructure</p></li><li><p>Maintain horizontal scaling vá»›i ALB</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Remove the application from the ALB. Delete the ALB and change Amazon Route 53 to direct traffic to the instance running the application.</strong></p><ul><li><p>Máº¥t kháº£ nÄƒng <strong>horizontal scaling</strong> (khÃ´ng cÃ³ load balancer)</p></li><li><p>Route 53 khÃ´ng thá»ƒ distribute traffic vÃ  health check nhÆ° ALB</p></li><li><p>Vi pháº¡m requirement \"maintain ability to scale horizontally\"</p></li></ul><p></p><p>âŒ <strong>Remove the application from the ALB. Create a Classic Load Balancer in its place. Direct traffic to the application using the HTTP protocol.</strong></p><ul><li><p>Classic Load Balancer cÅ©ng dÃ¹ng <strong>X-Forwarded-For header</strong> giá»‘ng ALB</p></li><li><p>KhÃ´ng giáº£i quyáº¿t váº¥n Ä‘á», váº«n cáº§n modify code Ä‘á»ƒ Ä‘á»c XFF</p></li><li><p>CLB lÃ  legacy, ALB cÃ³ nhiá»u features hÆ¡n vÃ  cost-effective hÆ¡n</p></li></ul><p></p><p>âŒ <strong>Alter the application code to inspect a custom header. Alter the client code to pass the IP address in the custom header.</strong></p><ul><li><p>Pháº£i modify <strong>cáº£ client code vÃ  application code</strong> (phá»©c táº¡p hÆ¡n)</p></li><li><p>KhÃ´ng cost-effective vÃ¬ pháº£i control vÃ  update clients</p></li><li><p>XFF header Ä‘Ã£ cÃ³ sáºµn tá»« ALB, khÃ´ng cáº§n custom header</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"ALB + client IP\"</strong> â†’ <strong>X-Forwarded-For header</strong></p></li><li><p>ALB automatically adds XFF header chá»©a original client IP</p></li><li><p><strong>X-Forwarded-For format</strong>: <code>client-ip, proxy1-ip, proxy2-ip</code> (comma-separated list)</p></li><li><p>Code pháº£i handle list of IPs, láº¥y <strong>first IP = original client</strong></p></li><li><p><strong>Classic vs Application Load Balancer</strong>: cáº£ hai Ä‘á»u dÃ¹ng XFF, ALB modern hÆ¡n</p></li><li><p>Remove load balancer = máº¥t horizontal scaling capability</p></li><li><p>Custom header = unnecessary complexity khi Ä‘Ã£ cÃ³ XFF</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/x-forwarded-headers.html\">HTTP headers and Application Load Balancers</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/x-forwarded-headers.html#x-forwarded-for\">X-Forwarded-For header</a></p></li></ul>",
            "correctAnswer": [
                "<p>Alter the application code to inspect the X-Forwarded-For header. Ensure that the code can work properly if a list of IP addresses is passed in the header.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Remove the application from the ALB. Delete the ALB and change Amazon Route 53 to direct traffic to the instance running the application.</p>",
                "<p>Remove the application from the ALCreate a Classic Load Balancer in its place. Direct traffic to the application using the HTTP protocol.</p>",
                "<p>Alter the application code to inspect the X-Forwarded-For header. Ensure that the code can work properly if a list of IP addresses is passed in the header.</p>",
                "<p>Alter the application code to inspect a custom header. Alter the client code to pass the IP address in the custom header.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 11
        },
        {
            "attemptAnswerId": 329673,
            "questionId": 7550,
            "questionText": "<p>A developer is receiving HTTP 400: ThrottlingException errors intermittently when calling the Amazon CloudWatch API. When a call fails, no data is retrieved.<br><br>What best practice should first be applied to address this issue?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer nháº­n <strong>HTTP 400: ThrottlingException</strong> errors <strong>intermittently</strong> khi call CloudWatch API</p></li><li><p>Khi call fails, <strong>no data is retrieved</strong></p></li><li><p>TÃ¬m <strong>best practice</strong> nÃªn apply Ä‘áº§u tiÃªn Ä‘á»ƒ address issue</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Retry the call with exponential backoff.</strong></p><ul><li><p><strong>ThrottlingException</strong> = API rate limit exceeded, cáº§n retry vá»›i backoff strategy</p></li><li><p><strong>Exponential backoff</strong> = AWS best practice cho retry logic: tÄƒng delay exponentially giá»¯a retries (1s, 2s, 4s, 8s...)</p></li><li><p>Giáº£m request rate tá»± Ä‘á»™ng khi gáº·p throttling</p></li><li><p>AWS SDKs cÃ³ built-in exponential backoff, chá»‰ cáº§n enable retry logic</p></li><li><p>Cost-effective vÃ  giáº£i quyáº¿t intermittent throttling</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Contact AWS Support for a limit increase.</strong></p><ul><li><p>Limit increase chá»‰ cáº§n khi throttling xáº£y ra <strong>consistently</strong>, khÃ´ng pháº£i intermittently</p></li><li><p>Best practice lÃ  implement retry logic trÆ°á»›c khi request limit increase</p></li><li><p>Increase limit tá»‘n thá»i gian vÃ  cÃ³ thá»ƒ khÃ´ng cáº§n thiáº¿t</p></li></ul><p></p><p>âŒ <strong>Use the AWS CLI to get the metrics.</strong></p><ul><li><p>AWS CLI cÅ©ng call <strong>same CloudWatch API</strong>, váº«n bá»‹ throttling</p></li><li><p>CLI khÃ´ng giáº£i quyáº¿t throttling issue</p></li><li><p>Chá»‰ Ä‘á»•i tool, khÃ´ng fix root cause</p></li></ul><p></p><p>âŒ <strong>Analyze the applications and remove the API call.</strong></p><ul><li><p>Remove API call = máº¥t functionality cáº§n thiáº¿t</p></li><li><p>Throttling lÃ  temporary issue, khÃ´ng cáº§n remove calls</p></li><li><p>KhÃ´ng pháº£i solution, mÃ  lÃ  workaround tá»“i</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"ThrottlingException + intermittent\"</strong> â†’ <strong>Exponential backoff retry</strong></p></li><li><p><strong>Exponential backoff pattern</strong>: delay = base_delay * (2 ^ retry_count)</p></li><li><p>AWS SDK auto-retry vá»›i exponential backoff (default behavior)</p></li><li><p><strong>Throttling solutions theo thá»© tá»±:</strong></p><ol><li><p>Implement <strong>exponential backoff</strong> (first step)</p></li><li><p>Optimize code Ä‘á»ƒ reduce API calls</p></li><li><p>Request <strong>limit increase</strong> (last resort náº¿u consistently throttled)</p></li></ol></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/retry-backoff.html\">Retry with backoff pattern</a></p></li></ul>",
            "correctAnswer": [
                "<p>Retry the call with exponential backoff.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Contact AWS Support for a limit increase.</p>",
                "<p>Use the AWS CLI to get the metrics.</p>",
                "<p>Analyze the applications and remove the API call.</p>",
                "<p>Retry the call with exponential backoff.</p>"
            ],
            "answersPos": "[0,1,3,2]",
            "pos": 12
        },
        {
            "attemptAnswerId": 329674,
            "questionId": 7551,
            "questionText": "<p>A company has an existing application that has hardcoded database credentials. A developer needs to modify the existing application. The application is deployed in two AWS Regions with an active-passive failover configuration to meet companyâ€™s disaster recovery strategy.<br><br>The developer needs a solution to store the credentials outside the code. The solution must comply with the companyâ€™s disaster recovery strategy.<br><br>Which solution will meet these requirements in the MOST secure way?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Existing application cÃ³ <strong>hardcoded database credentials</strong></p></li><li><p>Application deployed trong <strong>2 Regions</strong> vá»›i <strong>active-passive failover</strong> (disaster recovery strategy)</p></li><li><p>Cáº§n store credentials <strong>outside the code</strong></p></li><li><p>Solution pháº£i comply vá»›i <strong>disaster recovery strategy</strong></p></li><li><p>Requirement: <strong>MOST secure way</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Store the credentials in AWS Secrets Manager in the primary Region. Enable secret replication to the secondary Region. Update the application to use the Amazon Resource Name (ARN) based on the Region.</strong></p><ul><li><p><strong>Secrets Manager</strong> designed specifically cho storing vÃ  managing credentials securely</p></li><li><p>Há»— trá»£ <strong>automatic secret replication</strong> across Regions cho disaster recovery</p></li><li><p>Encrypted at rest vá»›i <strong>AWS KMS</strong></p></li><li><p>Support <strong>automatic rotation</strong> cá»§a credentials</p></li><li><p>Application dÃ¹ng ARN Ä‘á»ƒ retrieve secrets based on Region (primary hoáº·c secondary)</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Store credentials in AWS Systems Manager Parameter Store in the primary Region. Enable parameter replication to the secondary Region. Update the application to use the Amazon Resource Name (ARN) based on the Region.</strong></p><ul><li><p>Parameter Store há»— trá»£ replication vÃ  encryption</p></li><li><p>NhÆ°ng <strong>KHÃ”NG cÃ³ automatic rotation</strong> cho credentials nhÆ° Secrets Manager</p></li><li><p>Less secure cho database credentials management</p></li></ul><p></p><p>âŒ <strong>Store credentials in a config file. Upload the config file to an S3 bucket in the primary Region. Enable Cross-Region Replication (CRR) to an S3 bucket in the secondary region. Update the application to access the config file from the S3 bucket, based on the Region.</strong></p><ul><li><p>Config file trong S3 <strong>KHÃ”NG secure</strong> cho credentials (dÃ¹ cÃ³ encryption)</p></li><li><p>Pháº£i manage encryption/decryption manually</p></li><li><p>KhÃ´ng cÃ³ automatic rotation</p></li><li><p>S3 khÃ´ng designed cho secrets management</p></li></ul><p></p><p>âŒ <strong>Store credentials in a config file. Upload the config file to an Amazon Elastic File System (Amazon EFS) file system. Update the application to use the Amazon EFS file system Regional endpoints to access the config file in the primary and secondary Regions.</strong></p><ul><li><p>EFS <strong>khÃ´ng support cross-region replication</strong> natively</p></li><li><p>Config file approach khÃ´ng secure</p></li><li><p>KhÃ´ng cÃ³ versioning hay rotation cho credentials</p></li><li><p>EFS khÃ´ng phÃ¹ há»£p cho disaster recovery across Regions</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Database credentials + secure + DR\"</strong> â†’ <strong>Secrets Manager with replication</strong></p></li><li><p><strong>Secrets Manager vs Parameter Store:</strong></p><ul><li><p>Secrets Manager = credentials management + <strong>automatic rotation</strong> + cross-region replication</p></li><li><p>Parameter Store = configuration data + SecureString, <strong>NO automatic rotation</strong></p></li></ul></li><li><p><strong>\"MOST secure for credentials\"</strong> â†’ Secrets Manager</p></li><li><p><strong>Disaster recovery</strong> â†’ enable replication to secondary Region</p></li><li><p>Config files trong S3/EFS = <strong>NOT secure</strong> cho credentials</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/secretsmanager/latest/userguide/replicate-secrets.html\">Replicate AWS Secrets Manager secrets across Regions</a></p></li></ul>",
            "correctAnswer": [
                "<p>Store the credentials in AWS Secrets Manager in the primary Region. Enable secret replication to the secondary Region. Update the application to use the Amazon Resource Name (ARN) based on the Region.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Store the credentials in AWS Secrets Manager in the primary Region. Enable secret replication to the secondary Region. Update the application to use the Amazon Resource Name (ARN) based on the Region.</p>",
                "<p>Store credentials in AWS Systems Manager Parameter Store in the primary Region. Enable parameter replication to the secondary Region. Update the application to use the Amazon Resource Name (ARN) based on the Region.</p>",
                "<p>Store credentials in a config file. Upload the config file to an S3 bucket in the primary Region. Enable Cross-Region Replication (CRR) to an S3 bucket in the secondary region. Update the application to access the config file from the S3 bucket, based on the Region.</p>",
                "<p>Store credentials in a config file. Upload the config file to an Amazon Elastic File System (Amazon EFS) file system. Update the application to use the Amazon EFS file system Regional endpoints to access the config file in the primary and secondary Regions.</p>"
            ],
            "answersPos": "[0,1,3,2]",
            "pos": 13
        },
        {
            "attemptAnswerId": 329675,
            "questionId": 7552,
            "questionText": "<p>A company requires that all applications running on Amazon EC2 use IAM roles to gain access to AWS services. A developer is modifying an application that currently relies on IAM user access keys stored in environment variables to access Amazon DynamoDB tables using boto, the AWS SDK for Python.<br><br>The developer associated a role with the same permissions as the IAM user to the EC2 instance, then deleted the IAM user. When the application was restarted, the AWS AccessDeniedException messages started appearing in the application logs. The developer was able to use their personal account on the server to run DynamoDB API commands using the AWS CLI.<br><br>What is the MOST likely cause of the exception?</p>",
            "explanation": "<p>ğŸ“ TÃ³m táº¯t Ä‘á»:</p><ul><li><p>Application trÃªn EC2 Ä‘ang dÃ¹ng <strong>IAM user access keys</strong> stored trong <strong>environment variables</strong></p></li><li><p>Developer Ä‘Ã£:</p><ul><li><p>Associate <strong>IAM role</strong> (same permissions) vá»›i EC2 instance</p></li><li><p><strong>Delete IAM user</strong></p></li><li><p>Restart application</p></li></ul></li><li><p>Káº¿t quáº£: <strong>AccessDeniedException</strong> xuáº¥t hiá»‡n trong logs</p></li><li><p>Developer cÃ³ thá»ƒ run <strong>AWS CLI commands</strong> successfully trÃªn server vá»›i personal account</p></li><li><p>TÃ¬m <strong>MOST likely cause</strong> cá»§a exception</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Disabled environment variable credentials are still being used by the application.</strong></p><ul><li><p>Thá»© tá»± Æ°u tiÃªn credentials cá»§a AWS SDK: environment variables â†’ instance metadata</p></li><li><p>Application váº«n Ä‘á»c <strong>environment variables</strong> (access keys cá»§a deleted IAM user)</p></li><li><p>Environment variables chá»©a invalid credentials (user Ä‘Ã£ deleted) â†’ AccessDeniedException</p></li><li><p>Pháº£i <strong>remove/unset environment variables</strong> Ä‘á»ƒ boto fallback sang instance role</p></li><li><p>CLI works vÃ¬ developer dÃ¹ng personal account credentials (khÃ¡c vá»›i app's env vars)</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>IAM policies might take a few minutes to propagate to resources.</strong></p><ul><li><p>IAM policy changes thÆ°á»ng <strong>Ã¡p dá»¥ng ngay láº­p tá»©c (immediately)</strong> hoáº·c trong vÃ i giÃ¢y</p></li><li><p>Developer cÃ³ thá»ƒ run CLI successfully â†’ permissions Ä‘Ã£ cÃ³ hiá»‡u lá»±c</p></li><li><p>KhÃ´ng pháº£i propagation delay issue</p></li></ul><p></p><p>âŒ <strong>The AWS SDK does not support credentials obtained using an instance role.</strong></p><ul><li><p>AWS SDK (boto3) <strong>FULLY supports</strong> instance roles via instance metadata</p></li><li><p>Instance role lÃ  recommended best practice</p></li><li><p>Sai hoÃ n toÃ n vá» SDK capabilities</p></li></ul><p></p><p>âŒ <strong>The instance's security group does not allow access to </strong><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"http://169.254.169.254\"><strong>http://169.254.169.254</strong></a><strong>.</strong></p><ul><li><p>Instance metadata endpoint <code>169.254.169.254</code> <strong>khÃ´ng bá»‹ block</strong> bá»Ÿi security groups</p></li><li><p>Metadata endpoint accessible tá»« instance regardless of security group rules</p></li><li><p>Developer cÃ³ thá»ƒ run CLI (cÅ©ng cáº§n access metadata) â†’ metadata accessible</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>AWS SDK credential chain order:</strong></p><ol><li><p><strong>Environment variables</strong> (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)</p></li><li><p>Shared credentials file (~/.aws/credentials)</p></li><li><p><strong>Instance metadata</strong> (IAM role)</p></li></ol></li><li><p><strong>\"Deleted IAM user + env vars still set\"</strong> â†’ credentials invalid nhÆ°ng still used</p></li><li><p>Pháº£i <strong>unset environment variables</strong> Ä‘á»ƒ boto use instance role: </p><pre><code class=\"language-bash\">unset AWS_ACCESS_KEY_ID\nunset AWS_SECRET_ACCESS_KEY\n</code></pre></li><li><p>Instance metadata endpoint <code>169.254.169.254</code> <strong>khÃ´ng bá»‹ security group block</strong></p></li><li><p>CLI works vá»›i personal account â‰  application credentials working</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/cli/v1/userguide/cli-chap-authentication.html\">Authentication and access credentials for the AWS CLI</a></p></li></ul>",
            "correctAnswer": [
                "<p>Disabled environment variable credentials are still being used by the application.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>IAM policies might take a few minutes to propagate to resources.</p>",
                "<p>Disabled environment variable credentials are still being used by the application.</p>",
                "<p>The AWS SDK does not support credentials obtained using an instance role.</p>",
                "<p>The instanceâ€™s security group does not allow access to http://169.254.169.254.</p>"
            ],
            "answersPos": "[3,2,0,1]",
            "pos": 14
        },
        {
            "attemptAnswerId": 329676,
            "questionId": 7553,
            "questionText": "<p>A developer has built a market application that stores pricing data in Amazon DynamoDB with Amazon ElastiCache in front. The prices of items in the market change frequently. Sellers have begun complaining that, after they update the price of an item, the price does not actually change in the product listing.<br><br>What could be causing this issue?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Market application stores <strong>pricing data</strong> trong DynamoDB</p></li><li><p><strong>ElastiCache in front</strong> of DynamoDB</p></li><li><p>Prices <strong>change frequently</strong></p></li><li><p>Issue: sau khi sellers <strong>update price</strong>, price <strong>does not change</strong> trong product listing</p></li><li><p>TÃ¬m nguyÃªn nhÃ¢n causing issue</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>The cache is not being invalidated when the price of the item is changed.</strong></p><ul><li><p>ElastiCache Ä‘ang serve <strong>stale/old data</strong> tá»« cache</p></li><li><p>Khi price update trong DynamoDB, <strong>cache khÃ´ng Ä‘Æ°á»£c invalidate/refresh</strong></p></li><li><p>Product listing Ä‘á»c tá»« cache (chÆ°a update) thay vÃ¬ DynamoDB (Ä‘Ã£ update)</p></li><li><p>Solution: implement <strong>cache invalidation</strong> khi update price trong DynamoDB</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>The price of the item is being retrieved using a write-through ElastiCache cluster.</strong></p><ul><li><p><strong>Write-through</strong> pattern: write to cache vÃ  database <strong>cÃ¹ng lÃºc</strong></p></li><li><p>Náº¿u dÃ¹ng write-through, cache sáº½ Ä‘Æ°á»£c update khi price change</p></li><li><p>Write-through giáº£i quyáº¿t issue nÃ y, khÃ´ng pháº£i nguyÃªn nhÃ¢n</p></li></ul><p></p><p>âŒ <strong>The DynamoDB table was provisioned with insufficient read capacity.</strong></p><ul><li><p>Insufficient read capacity gÃ¢y <strong>throttling errors</strong>, khÃ´ng pháº£i stale data (data cÅ©)</p></li><li><p>Application váº«n Ä‘á»c Ä‘Æ°á»£c data (tá»« cache), chá»‰ lÃ  data cÅ©</p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n cache staleness</p></li></ul><p></p><p>âŒ <strong>The DynamoDB table was provisioned with insufficient write capacity.</strong></p><ul><li><p>Insufficient write capacity gÃ¢y <strong>write throttling</strong>, update sáº½ fail</p></li><li><p>Náº¿u update fail, sellers sáº½ tháº¥y error, khÃ´ng pháº£i \"price khÃ´ng change\"</p></li><li><p>Issue lÃ  cache stale, khÃ´ng pháº£i write failure</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Cache + data not updating\"</strong> â†’ <strong>Cache invalidation issue</strong></p></li><li><p><strong>Caching patterns:</strong></p><ul><li><p><strong>Lazy loading</strong> (cache-aside): read from cache â†’ if miss, read from DB â†’ write to cache. Risk: <strong>stale data</strong> náº¿u khÃ´ng invalidate</p></li><li><p><strong>Write-through</strong>: write to cache vÃ  DB cÃ¹ng lÃºc â†’ always fresh data</p></li></ul></li><li><p><strong>Cache invalidation strategies:</strong></p><ul><li><p>Invalidate cache khi update DB</p></li><li><p>Set TTL (Time-To-Live) cho cache entries</p></li><li><p>Use write-through pattern</p></li></ul></li><li><p><strong>Stale data</strong> = old data trong cache, DB Ä‘Ã£ update nhÆ°ng cache chÆ°a</p></li><li><p>Insufficient capacity = throttling/errors, khÃ´ng pháº£i stale data</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonElastiCache/latest/dg/Strategies.html\">Caching strategies with Amazon ElastiCache</a></p></li></ul>",
            "correctAnswer": [
                "<p>The cache is not being invalidated when the price of the item is changed.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>The cache is not being invalidated when the price of the item is changed.</p>",
                "<p>The price of the item is being retrieved using a write-through ElastiCache cluster.</p>",
                "<p>The DynamoDB table was provisioned with insufficient read capacity.</p>",
                "<p>The DynamoDB table was provisioned with insufficient write capacity.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 15
        },
        {
            "attemptAnswerId": 329677,
            "questionId": 7554,
            "questionText": "<p>A developer is working on an AWS Lambda function that accesses Amazon DynamoDB. The Lambda function must retrieve an item and update some of its attributes, or create the item if it does not exist. The Lambda function has access to the primary key.<br><br>Which IAM permissions should the developer request for the Lambda function to achieve this functionality?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Lambda function cáº§n access <strong>DynamoDB</strong></p></li><li><p>Functionality requirements:</p><ul><li><p><strong>Retrieve item</strong> vÃ  <strong>update some attributes</strong></p></li><li><p>Hoáº·c <strong>create item</strong> náº¿u item does not exist</p></li></ul></li><li><p>Lambda cÃ³ access to <strong>primary key</strong></p></li><li><p>TÃ¬m IAM permissions cáº§n thiáº¿t</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>dynamodb:UpdateItem</strong></p><p><strong>dynamodb:GetItem</strong></p><p><strong>dynamodb:PutItem</strong></p><ul><li><p><strong>GetItem</strong>: retrieve item tá»« DynamoDB báº±ng primary key</p></li><li><p><strong>UpdateItem</strong>: update attributes cá»§a existing item</p></li><li><p><strong>PutItem</strong>: create new item náº¿u item khÃ´ng exist (hoáº·c replace entire item)</p></li><li><p>3 permissions nÃ y Ä‘á»§ Ä‘á»ƒ implement logic: retrieve â†’ update náº¿u exist, create náº¿u khÃ´ng exist</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>dynamodb:DeleteItem, dynamodb:GetItem, dynamodb:PutItem</strong></p><ul><li><p><strong>DeleteItem</strong> khÃ´ng cáº§n thiáº¿t cho use case nÃ y</p></li><li><p>KhÃ´ng cÃ³ UpdateItem Ä‘á»ƒ update attributes</p></li><li><p>PutItem cÃ³ thá»ƒ replace item nhÆ°ng khÃ´ng pháº£i best practice cho updating attributes</p></li></ul><p></p><p>âŒ <strong>dynamodb:UpdateItem, dynamodb:GetItem, dynamodb:DescribeTable</strong></p><ul><li><p><strong>DescribeTable</strong> chá»‰ Ä‘á»ƒ get metadata vá» table (schema, status), khÃ´ng thao tÃ¡c data</p></li><li><p>Thiáº¿u <strong>PutItem</strong> Ä‘á»ƒ create item khi khÃ´ng exist</p></li><li><p>DescribeTable khÃ´ng cáº§n cho use case nÃ y</p></li></ul><p></p><p>âŒ <strong>dynamodb:GetRecords, dynamodb:PutItem, dynamodb:UpdateTable</strong></p><ul><li><p><strong>GetRecords</strong> dÃ¹ng cho DynamoDB Streams, khÃ´ng pháº£i get item tá»« table</p></li><li><p><strong>UpdateTable</strong> Ä‘á»ƒ modify table structure (provisioned capacity, GSI), khÃ´ng pháº£i data</p></li><li><p>Thiáº¿u GetItem Ä‘á»ƒ retrieve item</p></li><li><p>Sai hoÃ n toÃ n vá» API operations</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>DynamoDB data operations:</strong></p><ul><li><p><strong>GetItem</strong> = retrieve single item by primary key</p></li><li><p><strong>PutItem</strong> = create new item hoáº·c replace entire item</p></li><li><p><strong>UpdateItem</strong> = update specific attributes cá»§a existing item</p></li><li><p><strong>DeleteItem</strong> = delete item</p></li></ul></li><li><p><strong>DynamoDB control operations:</strong></p><ul><li><p><strong>DescribeTable</strong> = get table metadata</p></li><li><p><strong>UpdateTable</strong> = modify table settings (capacity, indexes)</p></li></ul></li><li><p><strong>Pattern \"retrieve + update or create\":</strong></p><ul><li><p>Cáº§n <strong>GetItem + UpdateItem + PutItem</strong></p></li><li><p>Hoáº·c dÃ¹ng <strong>UpdateItem vá»›i upsert behavior</strong> (táº¡o náº¿u khÃ´ng exist)</p></li></ul></li><li><p><strong>GetRecords</strong> = DynamoDB Streams API, khÃ´ng pháº£i table operations</p></li><li><p>Principle of least privilege: chá»‰ grant permissions thá»±c sá»± cáº§n thiáº¿t</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Operations.html\">DynamoDB API actions</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html\">Working with items and attributes in DynamoDB</a></p></li></ul>",
            "correctAnswer": [
                "<p>dynamodb:UpdateItem</p><p>dynamodb:GetItem</p><p>dynamodb:PutItem</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>dynamodb:DeleleItem</p><p>dynamodb:GetItem</p><p>dynamodb:PutItem</p>",
                "<p>dynamodb:UpdateItem</p><p>dynamodb:GetItem</p><p>dynamodb:DescribeTable</p>",
                "<p>dynamodb:GetRecords</p><p>dynamodb:PutItem</p><p>dynamodb:UpdateTable</p>",
                "<p>dynamodb:UpdateItem</p><p>dynamodb:GetItem</p><p>dynamodb:PutItem</p>"
            ],
            "answersPos": "[0,1,3,2]",
            "pos": 16
        },
        {
            "attemptAnswerId": 329678,
            "questionId": 7555,
            "questionText": "<p>A developer needs to manage AWS infrastructure as code and must be able to deploy multiple identical copies of the infrastructure, stage changes, and revert to previous versions.<br><br>Which approach addresses these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer cáº§n manage <strong>AWS infrastructure as code</strong></p></li><li><p>Requirements:</p><ul><li><p>Deploy <strong>multiple identical copies</strong> cá»§a infrastructure</p></li><li><p><strong>Stage changes</strong> (testing changes trÆ°á»›c khi apply)</p></li><li><p><strong>Revert to previous versions</strong></p></li></ul></li><li><p>TÃ¬m approach Ä‘Ã¡p á»©ng táº¥t cáº£ requirements</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use AWS CloudFormation and AWS CodeCommit to deploy and manage the infrastructure.</strong></p><ul><li><p><strong>CloudFormation</strong> = Infrastructure as Code (IaC) tool Ä‘á»ƒ define vÃ  deploy AWS resources</p></li><li><p>Deploy <strong>multiple identical stacks</strong> tá»« same template (multiple copies)</p></li><li><p><strong>Version control</strong> templates trong CodeCommit â†’ revert to previous versions dá»… dÃ ng</p></li><li><p><strong>Change sets</strong> trong CloudFormation Ä‘á»ƒ preview/stage changes trÆ°á»›c khi apply</p></li><li><p>ÄÃ¡p á»©ng Ä‘áº§y Ä‘á»§ cáº£ 3 requirements</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use cost allocation reports and AWS OpsWorks to deploy and manage the infrastructure.</strong></p><ul><li><p><strong>Cost allocation reports</strong> Ä‘á»ƒ track costs, khÃ´ng pháº£i Infrastructure as Code</p></li><li><p><strong>OpsWorks</strong> lÃ  configuration management (Chef/Puppet), khÃ´ng pháº£i thuáº©n IaC nhÆ° CloudFormation</p></li><li><p>KhÃ´ng phÃ¹ há»£p cho managing infrastructure as code vá»›i versioning</p></li></ul><p></p><p>âŒ <strong>Use Amazon CloudWatch metrics and alerts along with resource tagging to deploy and manage the infrastructure.</strong></p><ul><li><p><strong>CloudWatch</strong> Ä‘á»ƒ monitoring/alerting, khÃ´ng pháº£i deploy infrastructure</p></li><li><p><strong>Resource tagging</strong> Ä‘á»ƒ organize resources, khÃ´ng pháº£i IaC</p></li><li><p>KhÃ´ng cÃ³ kháº£ nÄƒng deploy hoáº·c version control infrastructure</p></li></ul><p></p><p>âŒ <strong>Use AWS Elastic Beanstalk and AWS CodeCommit to deploy and manage the infrastructure.</strong></p><ul><li><p><strong>Elastic Beanstalk</strong> lÃ  PaaS cho deploying <strong>applications</strong>, khÃ´ng pháº£i general infrastructure management</p></li><li><p>Beanstalk abstract infrastructure, khÃ´ng control full infrastructure as code</p></li><li><p>KhÃ´ng phÃ¹ há»£p cho managing arbitrary AWS infrastructure</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Infrastructure as Code (IaC)\"</strong> â†’ <strong>AWS CloudFormation</strong> (hoáº·c Terraform, CDK)</p></li><li><p><strong>CloudFormation capabilities:</strong></p><ul><li><p>Define infrastructure trong <strong>templates</strong> (JSON/YAML)</p></li><li><p>Deploy <strong>multiple stacks</strong> tá»« same template</p></li><li><p><strong>Change sets</strong> Ä‘á»ƒ preview changes</p></li><li><p><strong>Stack updates</strong> vá»›i rollback capability</p></li></ul></li><li><p><strong>Version control IaC</strong> â†’ store templates trong <strong>Git repositories</strong> (CodeCommit, GitHub)</p></li><li><p><strong>\"Multiple identical copies\"</strong> â†’ CloudFormation stacks tá»« same template</p></li><li><p><strong>\"Stage changes\"</strong> â†’ CloudFormation change sets</p></li><li><p><strong>\"Revert to previous versions\"</strong> â†’ Git version control + CloudFormation rollback</p></li><li><p>OpsWorks = configuration management, khÃ´ng pháº£i pure IaC</p></li><li><p>Elastic Beanstalk = application deployment, khÃ´ng pháº£i infrastructure management</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html\">What is AWS CloudFormation</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use AWS CloudFormation and AWS CodeCommit to deploy and manage the infrastructure.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use cost allocation reports and AWS OpsWorks to deploy and manage the infrastructure.</p>",
                "<p>Use Amazon CloudWatch metrics and alerts along with resource tagging to deploy and manage the infrastructure.</p>",
                "<p>Use AWS Elastic Beanstalk and AWS CodeCommit to deploy and manage the infrastructure.</p>",
                "<p>Use AWS CloudFormation and AWS CodeCommit to deploy and manage the infrastructure.</p>"
            ],
            "answersPos": "[2,1,3,0]",
            "pos": 17
        },
        {
            "attemptAnswerId": 329679,
            "questionId": 7556,
            "questionText": "<p>A developer needs to launch a new Amazon EC2 instance by using the AWS CLI.<br><br>Which AWS CLI command should the developer use to meet this requirement?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer cáº§n <strong>launch a new EC2 instance</strong> báº±ng AWS CLI</p></li><li><p>TÃ¬m AWS CLI command Ä‘Ãºng</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>aws ec2 run-instances</strong></p><ul><li><p><strong>run-instances</strong> lÃ  command Ä‘á»ƒ <strong>launch (create) new EC2 instances</strong></p></li><li><p>Specify AMI ID, instance type, security groups, key pairs, etc.</p></li><li><p>Táº¡o vÃ  start instance má»›i tá»« Ä‘áº§u</p></li></ul><p></p><p><em>Example</em></p><pre><code>aws ec2 run-instances \\\n    --image-id ami-0abcdef1234567890 \\\n    --instance-type t2.micro \\\n    --key-name MyKeyPair</code></pre><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>aws ec2 bundle-instance</strong></p><ul><li><p><strong>bundle-instance</strong> Ä‘á»ƒ create instance store-backed AMI tá»« running instance</p></li><li><p>KhÃ´ng pháº£i Ä‘á»ƒ launch new instance</p></li><li><p>Legacy command cho instance store instances</p></li></ul><p></p><p>âŒ <strong>aws ec2 start-instances</strong></p><ul><li><p><strong>start-instances</strong> Ä‘á»ƒ <strong>start existing stopped instances</strong></p></li><li><p>KhÃ´ng táº¡o new instance, chá»‰ start instance Ä‘Ã£ tá»“n táº¡i</p></li><li><p>Cáº§n instance ID cá»§a stopped instance</p></li></ul><p></p><p><em>Example:</em></p><pre><code>aws ec2 start-instances --instance-ids i-1234567890abcdef0</code></pre><p></p><p>âŒ <strong>aws ec2 confirm-product-instance</strong></p><ul><li><p><strong>confirm-product-instance</strong> Ä‘á»ƒ verify product code associated vá»›i instance</p></li><li><p>DÃ¹ng cho marketplace AMIs validation</p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n launching instances</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>EC2 instance lifecycle commands:</strong></p><ul><li><p><strong>run-instances</strong> = launch/create <strong>new</strong> instance</p></li><li><p><strong>start-instances</strong> = start <strong>stopped</strong> instance</p></li><li><p><strong>stop-instances</strong> = stop running instance</p></li><li><p><strong>terminate-instances</strong> = delete instance</p></li><li><p><strong>reboot-instances</strong> = restart instance</p></li></ul></li><li><p><strong>\"Launch new instance\"</strong> â†’ <strong>run-instances</strong></p></li><li><p><strong>\"Start stopped instance\"</strong> â†’ <strong>start-instances</strong></p></li><li><p>bundle-instance = create AMI (legacy), khÃ´ng pháº£i launch</p></li><li><p>confirm-product-instance = marketplace verification</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/cli/latest/reference/ec2/run-instances.html\">AWS CLI ec2 run-instances</a></p></li></ul>",
            "correctAnswer": [
                "<p>aws ec2 run-instances</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>aws ec2 bundle-instance</p>",
                "<p>aws ec2 start-instances</p>",
                "<p>aws ec2 confirm-product-instance</p>",
                "<p>aws ec2 run-instances</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 18
        },
        {
            "attemptAnswerId": 329680,
            "questionId": 7598,
            "questionText": "<p>A developer needs to troubleshoot an AWS Lambda function in a development environment. The Lambda function is configured in VPC mode and needs to connect to an existing Amazon RDS for SQL Server DB instance. The DB instance is deployed in a private subnet and accepts connections by using port 1433.<br><br>When the developer tests the function, the function reports an error when it tries to connect to the database.<br><br>Which combination of steps should the developer take to diagnose this issue? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Lambda function <strong>in VPC mode</strong> cáº§n connect Ä‘áº¿n <strong>RDS for SQL Server</strong></p></li><li><p>RDS deployed trong <strong>private subnet</strong>, accept connections trÃªn <strong>port 1433</strong></p></li><li><p>Function reports <strong>error khi connect</strong> to database</p></li><li><p>Chá»n <strong>2 steps</strong> Ä‘á»ƒ chuáº©n Ä‘oÃ¡n issue</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Check that the function's security group has outbound access on port 1433 to the DB instance's security group. Check that the DB instance's security group has inbound access on port 1433 from the function's security group.</strong></p><ul><li><p>Lambda cáº§n <strong>outbound rule</strong> trÃªn port 1433 Ä‘á»ƒ connect ra ngoÃ i</p></li><li><p>RDS cáº§n <strong>inbound rule</strong> trÃªn port 1433 Ä‘á»ƒ accept connections tá»« Lambda</p></li><li><p>Security groups pháº£i allow communication 2 chiá»u: Lambda outbound â†’ RDS inbound</p></li><li><p>ÄÃ¢y lÃ  common issue khi Lambda VPC khÃ´ng connect Ä‘Æ°á»£c database</p></li></ul><p></p><p><strong>Check that the function's execution role permissions include ec2:CreateNetworkInterface, ec2:DescribeNetworkInterfaces, and ec2:DeleteNetworkInterface.</strong></p><ul><li><p>Lambda <strong>in VPC mode</strong> cáº§n <strong>EC2 network permissions</strong> Ä‘á»ƒ create ENI (Elastic Network Interface) trong VPC</p></li><li><p>Permissions nÃ y required cho Lambda VPC configuration</p></li><li><p>Náº¿u thiáº¿u permissions, Lambda khÃ´ng thá»ƒ establish network connections trong VPC</p></li></ul><p></p><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-saa-dva/aws-secrets-manager-integration-with-amazon-rds\"><em>Kiáº¿n trÃºc tham kháº£o:</em></a></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1760854769055-hjkgu7l0-image.png\" alt=\"\" title=\"\" width=\"644\" height=\"558.8377083333334\" style=\"max-width: 644px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Check that the function's security group has inbound access on port 1433 from the DB instance's security group. Check that the DB instance's security group has outbound access on port 1433 to the function's security group.</strong></p><ul><li><p>Sai chiá»u traffic flow</p></li><li><p>Lambda <strong>initiate connection</strong> (outbound), RDS <strong>receive connection</strong> (inbound)</p></li><li><p>KhÃ´ng pháº£i RDS connect Ä‘áº¿n Lambda</p></li></ul><p></p><p>âŒ <strong>Check that the VPC is set up for a NAT gateway. Check that the DB instance has the public access option turned on.</strong></p><ul><li><p><strong>NAT gateway</strong> chá»‰ cáº§n náº¿u Lambda cáº§n access <strong>internet</strong>, khÃ´ng pháº£i private RDS</p></li><li><p>RDS trong <strong>private subnet</strong> khÃ´ng cáº§n public access</p></li><li><p>Public access lÃ  security risk, khÃ´ng phÃ¹ há»£p</p></li></ul><p></p><p>âŒ <strong>Check that the function's execution role permissions include rds:DescribeDBInstances, rds:ModifyDBInstance, and rds:DescribeDBSecurityGroups for the DB instance.</strong></p><ul><li><p>Permissions nÃ y Ä‘á»ƒ <strong>manage RDS resources</strong> qua AWS API</p></li><li><p>KhÃ´ng cáº§n cho <strong>database connections</strong> (connect qua SQL protocol)</p></li><li><p>Lambda connect Ä‘áº¿n RDS qua network, khÃ´ng qua AWS API</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>Lambda VPC mode requirements:</strong></p><ul><li><p><strong>Security group rules</strong>: Lambda outbound â†’ RDS inbound</p></li><li><p><strong>EC2 permissions</strong>: CreateNetworkInterface, DescribeNetworkInterfaces, DeleteNetworkInterface</p></li><li><p>Subnet vá»›i available IP addresses</p></li></ul></li><li><p><strong>Security group troubleshooting:</strong></p><ul><li><p>Lambda (client) = <strong>outbound</strong> rule</p></li><li><p>RDS (server) = <strong>inbound</strong> rule</p></li></ul></li><li><p><strong>NAT gateway</strong> chá»‰ cáº§n cho <strong>internet access</strong>, khÃ´ng pháº£i private resources</p></li><li><p><strong>RDS permissions</strong> (rds:*) = API operations, khÃ´ng pháº£i database connections</p></li><li><p>Database connections dÃ¹ng <strong>network + database credentials</strong>, khÃ´ng pháº£i IAM permissions</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html\">Giving Lambda functions access to resources in an Amazon VPC</a></p></li></ul>",
            "correctAnswer": [
                "<p>Check that the functionâ€™s execution role permissions include ec2:CreateNetworkInterface, ec2:DescribeNetworkInterfaces, and ec2:DeleteNetworkInterface.</p>",
                "<p>Check that the functionâ€™s security group has outbound access on port 1433 to the DB instanceâ€™s security group. Check that the DB instanceâ€™s security group has inbound access on port 1433 from the functionâ€™s security group.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Check that the functionâ€™s security group has outbound access on port 1433 to the DB instanceâ€™s security group. Check that the DB instanceâ€™s security group has inbound access on port 1433 from the functionâ€™s security group.</p>",
                "<p>Check that the functionâ€™s security group has inbound access on port 1433 from the DB instanceâ€™s security group. Check that the DB instanceâ€™s security group has outbound access on port 1433 to the functionâ€™s security group.</p>",
                "<p>Check that the VPC is set up for a NAT gateway. Check that the DB instance has the public access option turned on.</p>",
                "<p>Check that the functionâ€™s execution role permissions include rds:DescribeDBInstances, rds:ModifyDBInstance. and rds:DescribeDBSecurityGroups for the DB instance.</p>",
                "<p>Check that the functionâ€™s execution role permissions include ec2:CreateNetworkInterface, ec2:DescribeNetworkInterfaces, and ec2:DeleteNetworkInterface.</p>"
            ],
            "answersPos": "[4,3,2,1,0]",
            "pos": 19
        },
        {
            "attemptAnswerId": 329681,
            "questionId": 7557,
            "questionText": "<p>A company uses Amazon DynamoDB as a data store for its order management system. The company frontend application stores orders in a DynamoDB table. The DynamoDB table is configured to send change events to a DynamoDB stream. The company uses an AWS Lambda function to log and process the incoming orders based on data from the DynamoDB stream.<br><br>An operational review reveals that the order quantity of incoming orders is sometimes set to 0. A developer needs to create a dashboard that will show how many unique customers this problem affects each day.<br><br>What should the developer do to implement the dashboard?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>DynamoDB table stores orders, send change events Ä‘áº¿n <strong>DynamoDB stream</strong></p></li><li><p><strong>Lambda function</strong> process incoming orders tá»« DynamoDB stream</p></li><li><p>Issue: <strong>order quantity sometimes = 0</strong></p></li><li><p>Requirement: táº¡o <strong>dashboard</strong> hiá»ƒn thá»‹ <strong>bao nhiÃªu unique customers bá»‹ áº£nh hÆ°á»Ÿng má»—i ngÃ y</strong></p></li><li><p>TÃ¬m solution Ä‘á»ƒ implement dashboard</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Grant the Lambda function's execution role permissions to upload logs to Amazon CloudWatch Logs. Implement a CloudWatch Logs Insights query that selects the number of unique customers for orders with order quantity equal to 0 and groups the results in 1-day periods. Add the CloudWatch Logs Insights query to a CloudWatch dashboard.</strong></p><ul><li><p>Lambda <strong>log orders vá»›i quantity = 0</strong> (bao gá»“m customer ID) vÃ o CloudWatch Logs</p></li><li><p><strong>CloudWatch Logs Insights</strong> query Ä‘á»ƒ analyze logs: filter quantity = 0, count unique customers, group by day</p></li><li><p>Add query results vÃ o <strong>CloudWatch dashboard</strong> Ä‘á»ƒ visualize daily metrics</p></li><li><p>Simple vÃ  cost-effective solution sá»­ dá»¥ng existing Lambda processing</p></li></ul><p></p><p><em>Kiáº¿n trÃºc tham kháº£o:</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1760855482016-iegsx6kf-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"268.375\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use Amazon Athena to query AWS CloudTrail API logs for API calls. Implement an Athena query that selects the number of unique customers for orders with order quantity equal to 0 and groups the results in 1-day periods. Add the Athena query to an Amazon CloudWatch dashboard.</strong></p><ul><li><p><strong>CloudTrail logs</strong> chá»‰ capture <strong>AWS API calls</strong>, khÃ´ng chá»©a business data (order quantity, customer info)</p></li><li><p>CloudTrail khÃ´ng cÃ³ order details tá»« DynamoDB stream</p></li><li><p>Athena query khÃ´ng thá»ƒ access order data tá»« CloudTrail</p></li></ul><p></p><p>âŒ <strong>Configure the Lambda function to send events to Amazon EventBridge. Create an EventBridge rule that groups the number of unique customers for orders with order quantity equal to 0 in 1-day periods. Add a CloudWatch dashboard as the target of the rule.</strong></p><ul><li><p><strong>EventBridge rules</strong> khÃ´ng cÃ³ capability Ä‘á»ƒ <strong>group vÃ  count unique values</strong> across time periods</p></li><li><p>EventBridge route events, khÃ´ng pháº£i analytics/aggregation tool</p></li><li><p>Dashboard khÃ´ng pháº£i valid EventBridge target cho aggregated metrics</p></li></ul><p></p><p>âŒ <strong>Turn on custom Amazon CloudWatch metrics for the DynamoDB stream of the DynamoDB table. Create a CloudWatch alarm that groups the number of unique customers for orders with order quantity equal to 0 in 1-day periods. Add the CloudWatch alarm to a CloudWatch dashboard.</strong></p><ul><li><p><strong>DynamoDB streams khÃ´ng cÃ³ built-in custom metrics</strong> cho business logic filtering</p></li><li><p><strong>CloudWatch alarms</strong> dÃ¹ng Ä‘á»ƒ alert, khÃ´ng pháº£i group/count unique customers</p></li><li><p>KhÃ´ng thá»ƒ turn on custom metrics directly tá»« DynamoDB stream</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Analyze logs + create dashboard\"</strong> â†’ <strong>CloudWatch Logs Insights + CloudWatch Dashboard</strong></p></li><li><p><strong>CloudWatch Logs Insights</strong> capabilities:</p><ul><li><p>Query logs vá»›i SQL-like syntax</p></li><li><p>Count unique values (distinct customers)</p></li><li><p>Group by time periods</p></li><li><p>Visualize trong dashboard</p></li></ul></li><li><p><strong>CloudTrail</strong> = AWS API calls audit, khÃ´ng chá»©a application data</p></li><li><p><strong>EventBridge</strong> = event routing, khÃ´ng pháº£i analytics/aggregation</p></li><li><p><strong>DynamoDB streams</strong> khÃ´ng cÃ³ custom metrics cho business logic</p></li><li><p><strong>Pattern</strong>: Lambda log data â†’ CloudWatch Logs â†’ Logs Insights query â†’ Dashboard</p></li></ul><p></p><p>ğŸ“– Reference:</p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html\">Analyzing log data with CloudWatch Logs Insights</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_ExportQueryResults.html\">Add a query to a CloudWatch dashboard</a></p></li></ul>",
            "correctAnswer": [
                "<p>Grant the Lambda functionâ€™s execution role permissions to upload logs to Amazon CloudWatch Logs. Implement a CloudWatch Logs Insights query that selects the number of unique customers for orders with order quantity equal to 0 and groups the results in 1-day periods. Add the CloudWatch Logs Insights query to a CloudWatch dashboard.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Grant the Lambda functionâ€™s execution role permissions to upload logs to Amazon CloudWatch Logs. Implement a CloudWatch Logs Insights query that selects the number of unique customers for orders with order quantity equal to 0 and groups the results in 1-day periods. Add the CloudWatch Logs Insights query to a CloudWatch dashboard.</p>",
                "<p>Use Amazon Athena to query AWS CloudTrail API logs for API calls. Implement an Athena query that selects the number of unique customers for orders with order quantity equal to 0 and groups the results in 1-day periods. Add the Athena query to an Amazon CloudWatch dashboard.</p>",
                "<p>Configure the Lambda function to send events to Amazon EventBridge. Create an EventBridge rule that groups the number of unique customers for orders with order quantity equal to 0 in 1-day periods. Add a CloudWatch dashboard as the target of the rule.</p>",
                "<p>Turn on custom Amazon CloudWatch metrics for the DynamoDB stream of the DynamoDB table. Create a CloudWatch alarm that groups the number of unique customers for orders with order quantity equal to 0 in 1-day periods. Add the CloudWatch alarm to a CloudWatch dashboard.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 20
        },
        {
            "attemptAnswerId": 329682,
            "questionId": 7558,
            "questionText": "<p>A developer is creating an AWS Lambda function that will generate and export a file. The function requires 100 MB of temporary storage for temporary files while running. These files will not be needed after the function is complete.<br><br>How can the developer MOST efficiently handle the temporary files?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Lambda function cáº§n <strong>100 MB temporary storage</strong> cho temporary files</p></li><li><p>Files chá»‰ cáº§n trong khi function <strong>running</strong></p></li><li><p>Files <strong>not needed after function complete</strong></p></li><li><p>Requirement: <strong>MOST efficiently</strong> handle temporary files</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Store the files in the /tmp directory and delete the files at the end of the Lambda function.</strong></p><ul><li><p>Lambda cÃ³ <strong>built-in /tmp directory</strong> vá»›i <strong>512 MB - 10 GB storage</strong> (configurable)</p></li><li><p><strong>/tmp persistent</strong> across invocations trong cÃ¹ng execution environment (nhÆ°ng khÃ´ng guaranteed)</p></li><li><p><strong>No additional cost</strong> cho /tmp usage</p></li><li><p>Cleanup /tmp at end of function Ä‘á»ƒ free space cho invocations tiáº¿p theo</p></li><li><p>Most efficient: khÃ´ng cáº§n external storage services</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Store the files in Amazon Elastic Block Store (Amazon EBS) and delete the files at the end of the Lambda function.</strong></p><ul><li><p>Lambda <strong>khÃ´ng thá»ƒ directly attach EBS volumes</strong></p></li><li><p>EBS dÃ¹ng cho EC2 instances, khÃ´ng pháº£i Lambda</p></li><li><p>KhÃ´ng compatible vá»›i Lambda architecture</p></li></ul><p></p><p>âŒ <strong>Copy the files to Amazon Elastic File System (Amazon EFS) and delete the files at the end of the Lambda function.</strong></p><ul><li><p>EFS cÃ³ thá»ƒ mount vÃ o Lambda nhÆ°ng <strong>overkill cho temporary files</strong></p></li><li><p>EFS cÃ³ <strong>additional cost</strong> (storage + throughput)</p></li><li><p>Slower performance so vá»›i /tmp (network latency)</p></li><li><p>KhÃ´ng hiá»‡u quáº£ cho simple temporary storage</p></li></ul><p></p><p>âŒ <strong>Copy the files to an Amazon S3 bucket with a lifecycle policy to delete the files.</strong></p><ul><li><p>S3 cÃ³ <strong>additional cost</strong> (PUT requests + storage)</p></li><li><p><strong>Network latency</strong> khi upload/download files</p></li><li><p>Lifecycle policy minimum 1 day expiration</p></li><li><p>Overkill vÃ  khÃ´ng efficient cho temporary files chá»‰ cáº§n trong function execution</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>Lambda /tmp directory:</strong></p><ul><li><p>Default <strong>512 MB</strong>, configurable up to <strong>10 GB</strong></p></li><li><p><strong>Ephemeral storage</strong> - cÃ³ thá»ƒ persist across invocations nhÆ°ng not guaranteed</p></li><li><p><strong>No additional cost</strong> (included trong Lambda pricing)</p></li></ul></li><li><p><strong>\"Temporary files during Lambda execution\"</strong> â†’ <strong>/tmp directory</strong></p></li><li><p><strong>Best practices:</strong></p><ul><li><p>Cleanup /tmp files at end of function</p></li><li><p>Check /tmp size náº¿u files lá»›n</p></li></ul></li><li><p>Lambda <strong>KHÃ”NG support EBS volumes</strong></p></li><li><p><strong>EFS</strong> = persistent shared file system, overkill cho temp files</p></li><li><p><strong>S3</strong> = object storage, khÃ´ng efficient cho temporary runtime files</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-ephemeral-storage.html\">Configuring ephemeral storage for Lambda</a></p></li></ul>",
            "correctAnswer": [
                "<p>Store the files in the /tmp directory and delete the files at the end of the Lambda function.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Store the files in Amazon Elastic Block Store (Amazon EBS) and delete the files at the end of the Lambda function.</p>",
                "<p>Copy the files to Amazon Elastic File System (Amazon EFS) and delete the files at the end of the Lambda function.</p>",
                "<p>Store the files in the /tmp directory and delete the files at the end of the Lambda function.</p>",
                "<p>Copy the files to an Amazon S3 bucket with a lifecycle policy to delete the files.</p>"
            ],
            "answersPos": "[0,1,3,2]",
            "pos": 21
        },
        {
            "attemptAnswerId": 329683,
            "questionId": 7559,
            "questionText": "<p>A company uses Amazon API Gateway to expose a set of APIs to customers. The APIs have caching enabled in API Gateway. Customers need a way to invalidate the cache for each API when they test the API.<br><br>What should a developer do to give customers the ability to invalidate the API cache?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company dÃ¹ng <strong>API Gateway</strong> expose APIs to customers</p></li><li><p>APIs cÃ³ <strong>caching enabled</strong> trong API Gateway</p></li><li><p>Customers cáº§n <strong>invalidate cache</strong> khi test APIs</p></li><li><p>TÃ¬m cÃ¡ch cho customers ability to invalidate API cache</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Attach an InvalidateCache policy to the IAM execution role that the customers use to invoke the API. Ask the customers to send a request that contains the Cache-Control:max-age=0 HTTP header when they make an API call.</strong></p><ul><li><p>Attach <strong>InvalidateCache policy</strong> cho phÃ©p customers invalidate cache</p></li><li><p>Customers gá»­i <strong>Cache-Control: max-age=0 header</strong> trong API request Ä‘á»ƒ invalidate cache</p></li><li><p>API Gateway check IAM permissions vÃ  header Ä‘á»ƒ invalidate cache cho specific request</p></li><li><p>Standard HTTP caching mechanism, dá»… implement</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Ask the customers to use AWS credentials to call the InvalidateCache API operation.</strong></p><ul><li><p><strong>InvalidateCache API operation</strong> khÃ´ng tá»“n táº¡i trong API Gateway API</p></li><li><p>Customers khÃ´ng nÃªn cÃ³ direct access Ä‘áº¿n AWS management APIs</p></li><li><p>KhÃ´ng pháº£i standard way Ä‘á»ƒ invalidate API Gateway cache</p></li></ul><p></p><p>âŒ <strong>Ask the customers to use the AWS SDK API Gateway class to invoke the InvalidateCache API operation.</strong></p><ul><li><p>KhÃ´ng cÃ³ <strong>InvalidateCache API operation</strong> trong API Gateway SDK</p></li><li><p>Customers khÃ´ng nÃªn dÃ¹ng AWS SDK Ä‘á»ƒ manage API Gateway resources</p></li><li><p>SDK lÃ  management tool, khÃ´ng pháº£i cho API consumers</p></li></ul><p></p><p>âŒ <strong>Attach an InvalidateCache policy to the IAM execution role that the customers use to invoke the API. Ask the customers to add the INVALIDATE_CACHE query string parameter when they make an API call.</strong></p><ul><li><p><strong>INVALIDATE_CACHE query string parameter</strong> khÃ´ng pháº£i valid method</p></li><li><p>API Gateway khÃ´ng recognize parameter nÃ y Ä‘á»ƒ invalidate cache</p></li><li><p>KhÃ´ng pháº£i documented approach</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>API Gateway cache invalidation methods:</strong></p><ul><li><p><strong>Cache-Control: max-age=0</strong> header (per-request invalidation)</p></li><li><p>Console/CLI flush entire cache (admin operation)</p></li></ul></li><li><p><strong>Cache invalidation permissions:</strong></p><ul><li><p>Attach <strong>InvalidateCache policy</strong> cho IAM role</p></li><li><p>Permission format: <code>execute-api:InvalidateCache</code></p></li></ul></li><li><p><strong>\"Customers invalidate cache when testing\"</strong> â†’ <strong>Cache-Control header</strong></p></li><li><p>KhÃ´ng cÃ³ InvalidateCache API operation trong API Gateway</p></li><li><p>Query string parameters khÃ´ng dÃ¹ng cho cache invalidation</p></li><li><p><strong>Cache-Control header</strong> = standard HTTP caching mechanism</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html\">Cache settings for REST APIs in API Gateway</a></p></li></ul>",
            "correctAnswer": [
                "<p>Attach an InvalidateCache policy to the IAM execution role that the customers use to invoke the API. Ask the customers to send a request that contains the Cache-Control:max-age=0 HTTP header when they make an API call.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Ask the customers to use AWS credentials to call the InvalidateCache API operation.</p>",
                "<p>Attach an InvalidateCache policy to the IAM execution role that the customers use to invoke the API. Ask the customers to send a request that contains the Cache-Control:max-age=0 HTTP header when they make an API call.</p>",
                "<p>Ask the customers to use the AWS SDK API Gateway class to invoke the InvalidateCache API operation.</p>",
                "<p>Attach an InvalidateCache policy to the IAM execution role that the customers use to invoke the API. Ask the customers to add the INVALIDATE_CACHE query string parameter when they make an API call.</p>"
            ],
            "answersPos": "[0,2,3,1]",
            "pos": 22
        },
        {
            "attemptAnswerId": 329684,
            "questionId": 7560,
            "questionText": "<p>A developer is writing a serverless application that requires an AWS Lambda function to be invoked every 10 minutes.</p><p></p><p>What is an automated and serverless way to invoke the function?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Lambda function cáº§n Ä‘Æ°á»£c <strong>invoked every 10 minutes</strong></p></li><li><p>Requirement: <strong>automated and serverless</strong> way to invoke</p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create an Amazon EventBridge rule that runs on a regular schedule to invoke the Lambda function.</strong></p><ul><li><p><strong>EventBridge (CloudWatch Events)</strong> há»— trá»£ <strong>scheduled rules</strong> vá»›i cron/rate expressions</p></li><li><p>Serverless, fully managed service</p></li><li><p>Rate expression: <code>rate(10 minutes)</code> hoáº·c cron expression</p></li><li><p>Automatically invoke Lambda function theo schedule</p></li><li><p>No infrastructure management</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Deploy an Amazon EC2 instance based on Linux, and edit its /etc/crontab file by adding a command to periodically invoke the Lambda function.</strong></p><ul><li><p>EC2 instance <strong>KHÃ”NG serverless</strong> - pháº£i manage infrastructure</p></li><li><p>Tá»‘n chi phÃ­ cháº¡y EC2 instance 24/7 chá»‰ Ä‘á»ƒ invoke Lambda</p></li><li><p>KhÃ´ng automated (pháº£i maintain instance, crontab)</p></li><li><p>Vi pháº¡m yÃªu cáº§u serverless</p></li></ul><p></p><p>âŒ <strong>Configure an environment variable named PERIOD for the Lambda function. Set the value to 600.</strong></p><ul><li><p>Environment variables <strong>khÃ´ng trigger Lambda execution</strong></p></li><li><p>Environment variables chá»‰ Ä‘á»ƒ pass configuration vÃ o function</p></li><li><p>KhÃ´ng cÃ³ scheduling mechanism</p></li><li><p>KhÃ´ng giáº£i quyáº¿t váº¥n Ä‘á»</p></li></ul><p></p><p>âŒ <strong>Create an Amazon Simple Notification Service (Amazon SNS) topic that has a subscription to the Lambda function with a 600-second timer.</strong></p><ul><li><p>SNS <strong>khÃ´ng cÃ³ timer/scheduling capability</strong></p></li><li><p>SNS lÃ  pub/sub messaging service, khÃ´ng pháº£i scheduler</p></li><li><p>KhÃ´ng thá»ƒ set timer trÃªn SNS subscription</p></li><li><p>Sai concept hoÃ n toÃ n</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Invoke Lambda periodically/scheduled\"</strong> â†’ <strong>EventBridge (CloudWatch Events) scheduled rules</strong></p></li><li><p><strong>EventBridge scheduled expressions:</strong></p><ul><li><p><strong>Rate expression</strong>: <code>rate(10 minutes)</code>, <code>rate(1 hour)</code>, <code>rate(1 day)</code></p></li><li><p><strong>Cron expression</strong>: <code>cron(0/10 * * * ? *)</code> (every 10 minutes)</p></li></ul></li><li><p><strong>Serverless scheduling options:</strong></p><ul><li><p>EventBridge rules (recommended)</p></li><li><p><s>CloudWatch Events</s> (legacy, now EventBridge)</p></li></ul></li><li><p>EC2 with cron = <strong>NOT serverless</strong></p></li><li><p>Environment variables = configuration, <strong>NOT triggers</strong></p></li><li><p>SNS = messaging, <strong>NO scheduling capability</strong></p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-create-rule-schedule.html\">Creating a rule that runs on a schedule in Amazon EventBridge</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an Amazon EventBridge rule that runs on a regular schedule to invoke the Lambda function.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Deploy an Amazon EC2 instance based on Linux, and edit its /etc/crontab file by adding a command to periodically invoke the Lambda function.</p>",
                "<p>Configure an environment variable named PERIOD for the Lambda function. Set the value to 600.</p>",
                "<p>Create an Amazon EventBridge rule that runs on a regular schedule to invoke the Lambda function.</p>",
                "<p>Create an Amazon Simple Notification Service (Amazon SNS) topic that has a subscription to the Lambda function with a 600-second timer.</p>"
            ],
            "answersPos": "[1,0,2,3]",
            "pos": 23
        },
        {
            "attemptAnswerId": 329685,
            "questionId": 7561,
            "questionText": "<p>A developer is preparing to begin development of a new version of an application. The previous version of the application is deployed in a production environment. The developer needs to deploy fixes and updates to the current version during the development of the new version of the application. The code for the new version of the application is stored in AWS CodeCommit.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer Ä‘ang develop <strong>new version</strong> cá»§a application</p></li><li><p><strong>Previous version</strong> Ä‘ang deployed trong <strong>production</strong></p></li><li><p>Cáº§n deploy <strong>fixes and updates</strong> to current version <strong>during development</strong> cá»§a new version</p></li><li><p>Code stored trong <strong>AWS CodeCommit</strong></p></li><li><p>Requirement: manage cáº£ hai versions simultaneously</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>From the main branch, create a feature branch for production bug fixes. Create a second feature branch from the main branch for development of the new version.</strong></p><ul><li><p><strong>Branching strategy</strong> cho phÃ©p parallel development:</p><ul><li><p><strong>Feature branch cho bug fixes</strong> â†’ merge vÃ o main â†’ deploy to production</p></li><li><p><strong>Feature branch cho new version</strong> â†’ develop independently</p></li></ul></li><li><p>Main branch remain stable cho production releases</p></li><li><p>Isolate changes giá»¯a bug fixes vÃ  new development</p></li><li><p>Standard Git workflow, easy to manage</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a Git tag of the code that is currently deployed in production. Create a Git tag for the development of the new version. Push the two tags to the CodeCommit repository.</strong></p><ul><li><p><strong>Git tags</strong> dÃ¹ng Ä‘á»ƒ <strong>mark specific points</strong> in history (releases), khÃ´ng pháº£i active development</p></li><li><p>Tags are <strong>immutable</strong> (read-only), cannot commit changes to tags</p></li><li><p>KhÃ´ng thá»ƒ develop hoáº·c fix bugs trÃªn tags</p></li><li><p>Sai use case cho tags</p></li></ul><p></p><p>âŒ <strong>From the main branch, create a branch of the code that is currently deployed in production. Apply an IAM policy that ensures no other users can push or merge to the branch.</strong></p><ul><li><p>Táº¡o branch cho production code lÃ  Ä‘Ãºng</p></li><li><p>NhÆ°ng <strong>IAM policy khÃ´ng control Git push/merge permissions</strong> trong CodeCommit</p></li><li><p>CodeCommit dÃ¹ng <strong>IAM policies</strong> cho repository access, khÃ´ng pháº£i branch-level control</p></li><li><p>KhÃ´ng cÃ³ branch cho new version development</p></li></ul><p></p><p>âŒ <strong>Create a new CodeCommit repository for development of the new version of the application. Create a Git tag for the development of the new version.</strong></p><ul><li><p><strong>Separate repository</strong> phá»©c táº¡p vÃ  khÃ´ng cáº§n thiáº¿t</p></li><li><p>KhÃ³ share code vÃ  maintain consistency giá»¯a versions</p></li><li><p>Git tags khÃ´ng dÃ¹ng cho active development</p></li><li><p>KhÃ´ng operationally efficient</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Parallel development + bug fixes\"</strong> â†’ <strong>Feature branches</strong></p></li><li><p><strong>Git branching strategies:</strong></p><ul><li><p><strong>Main/Master branch</strong> = stable production code</p></li><li><p><strong>Feature branches</strong> = new features hoáº·c bug fixes</p></li><li><p><strong>Release branches</strong> = prepare releases</p></li></ul></li><li><p><strong>Git tags vs Branches:</strong></p><ul><li><p><strong>Tags</strong> = immutable markers (v1.0, v2.0), khÃ´ng develop trÃªn tags</p></li><li><p><strong>Branches</strong> = active development, can commit changes</p></li></ul></li><li><p><strong>Workflow pattern:</strong></p><ul><li><p>Bug fixes â†’ feature branch â†’ merge to main â†’ deploy</p></li><li><p>New version â†’ feature branch â†’ develop independently</p></li></ul></li><li><p>IAM policies control <strong>repository access</strong>, khÃ´ng pháº£i branch permissions</p></li><li><p>Multiple repositories = unnecessary complexity cho same application</p></li></ul>",
            "correctAnswer": [
                "<p>From the main branch, create a feature branch for production bug fixes. Create a second feature branch from the main branch for development of the new version.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>From the main branch, create a feature branch for production bug fixes. Create a second feature branch from the main branch for development of the new version.</p>",
                "<p>Create a Git tag of the code that is currently deployed in production. Create a Git tag for the development of the new version. Push the two tags to the CodeCommit repository.</p>",
                "<p>From the main branch, create a branch of the code that is currently deployed in production. Apply an IAM policy that ensures no other users can push or merge to the branch.</p>",
                "<p>Create a new CodeCommit repository for development of the new version of the application. Create a Git tag for the development of the new version.</p>"
            ],
            "answersPos": "[1,0,2,3]",
            "pos": 24
        },
        {
            "attemptAnswerId": 329686,
            "questionId": 7562,
            "questionText": "<p>A developer is building a serverless application that connects to an Amazon Aurora PostgreSQL database. The serverless application consists of hundreds of AWS Lambda functions. During every Lambda function scale out, a new database connection is made that increases database resource consumption.<br><br>The developer needs to decrease the number of connections made to the database. The solution must not impact the scalability of the Lambda functions.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Serverless application vá»›i <strong>hundreds of Lambda functions</strong> connect Ä‘áº¿n <strong>Aurora PostgreSQL</strong></p></li><li><p>Issue: má»—i Lambda <strong>scale out</strong> táº¡o <strong>new database connection</strong> â†’ tÄƒng database resource consumption</p></li><li><p>Requirement:</p><ul><li><p><strong>Decrease sá»‘ connections</strong> Ä‘áº¿n database</p></li><li><p><strong>Not impact scalability</strong> cá»§a Lambda functions</p></li></ul></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use Amazon RDS Proxy to create a connection pool to manage the database connections. Change the connection string of each Lambda function to reference the proxy.</strong></p><ul><li><p><strong>RDS Proxy</strong> táº¡o <strong>connection pool</strong> giá»¯a Lambda vÃ  Aurora</p></li><li><p><strong>Connection pooling</strong>: reuse existing connections thay vÃ¬ táº¡o new connections má»—i invocation</p></li><li><p>Reduce database connections drastically (hundreds â†’ vÃ i chá»¥c)</p></li><li><p>Lambda functions váº«n scale tá»± do, RDS Proxy manage connections hiá»‡u quáº£</p></li><li><p>Built-in for serverless architectures vá»›i Lambda</p></li></ul><p></p><p><em>Kiáº¿n trÃºc tham tháº£o:</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1760939870424-f02j1ey6-image.png\" alt=\"\" title=\"\" width=\"709\" height=\"492.23802083333334\" style=\"max-width: 709px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure provisioned concurrency for each Lambda function by setting the ProvisionedConcurrentExecutions parameter to 10.</strong></p><ul><li><p><strong>Provisioned concurrency</strong> giá»¯ Lambda instances warm Ä‘á»ƒ reduce <strong>cold starts</strong></p></li><li><p>KhÃ´ng giáº£i quyáº¿t connection pooling issue</p></li><li><p>Tá»‘n chi phÃ­ cho provisioned concurrency</p></li></ul><p></p><p>âŒ <strong>Enable cluster cache management for Aurora PostgreSQL. Change the connection string of each Lambda function to point to cluster cache management.</strong></p><ul><li><p><strong>Cluster cache management</strong> khÃ´ng pháº£i real feature cá»§a Aurora PostgreSQL</p></li><li><p>KhÃ´ng giáº£i quyáº¿t database connection issue</p></li><li><p>Sai concept</p></li></ul><p></p><p>âŒ <strong>Configure reserved concurrency for each Lambda function by setting the ReservedConcurrentExecutions parameter to 10.</strong></p><ul><li><p><strong>Reserved concurrency</strong> limit concurrent executions cá»§a function</p></li><li><p>Limit to 10 per function <strong>severely impacts scalability</strong></p></li><li><p>KhÃ´ng giáº£i quyáº¿t connection pooling</p></li><li><p>Vi pháº¡m requirement \"not impact scalability\"</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Lambda + database connections\"</strong> â†’ <strong>RDS Proxy vá»›i connection pooling</strong></p></li><li><p><strong>Provisioned/Reserved concurrency</strong> limit scalability, khÃ´ng giáº£i quyáº¿t connection issue</p></li><li><p>RDS Proxy benefits:</p><ul><li><p>Connection pooling</p></li><li><p>Reduce DB load</p></li><li><p>Automatic failover</p></li></ul></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/blogs/compute/using-amazon-rds-proxy-with-aws-lambda/\">Using Amazon RDS Proxy with Lambda</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy-connections.html\">RDS Proxy connection considerations</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use Amazon RDS Proxy to create a connection pool to manage the database connections. Change the connection string of each Lambda function to reference the proxy.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure provisioned concurrency for each Lambda function by setting the ProvisionedConcurrentExecutions parameter to 10.</p>",
                "<p>Enable cluster cache management for Aurora PostgreSQL. Change the connection string of each Lambda function to point to cluster cache management.</p>",
                "<p>Use Amazon RDS Proxy to create a connection pool to manage the database connections. Change the connection string of each Lambda function to reference the proxy.</p>",
                "<p>Configure reserved concurrency for each Lambda function by setting the ReservedConcurrentExecutions parameter to 10.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 25
        },
        {
            "attemptAnswerId": 329687,
            "questionId": 7563,
            "questionText": "<p>A developer is setting up infrastructure by using AWS CloudFormation. If an error occurs when the resources described in the Cloud Formation template are provisioned, successfully provisioned resources must be preserved. The developer must provision and update the CloudFormation stack by using the AWS CLI.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer setup infrastructure báº±ng <strong>CloudFormation</strong></p></li><li><p>Requirement: náº¿u <strong>error occurs during provisioning</strong>, <strong>successfully provisioned resources must be preserved</strong></p></li><li><p>Provision vÃ  update stack báº±ng <strong>AWS CLI</strong></p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Add a --disable-rollback command line option to the create-stack command and the update-stack command.</strong></p><ul><li><p><code>--disable-rollback</code> ngÄƒn cháº·n CloudFormation xoÃ¡ nhá»¯ng successfully created resources khi stack creation fails</p></li><li><p>Default behavior: CloudFormation rollback vÃ  delete all resources náº¿u cÃ³ error</p></li><li><p>Vá»›i disable-rollback: successfully provisioned resources Ä‘Æ°á»£c <strong>preserved (giá»¯ láº¡i)</strong> Ä‘á»ƒ troubleshoot</p></li><li><p>Useful cho debugging - cÃ³ thá»ƒ inspect resources Ä‘Ã£ táº¡o thÃ nh cÃ´ng</p></li></ul><p></p><p><em>create-stack command:</em></p><pre><code>aws cloudformation create-stack \\\n--stack-name my-app-stack \\\n--template-body file://my-template.yaml \\\n--parameters ParameterKey=InstanceType,ParameterValue=t2.micro \\\n--disable-rollback</code></pre><p></p><p><em>update-stack command:</em></p><pre><code>aws cloudformation update-stack \\\n--stack-name my-app-stack \\\n--template-body file://my-template-updated.yaml \\\n--parameters ParameterKey=InstanceType,ParameterValue=t2.medium \\\n--disable-rollback</code></pre><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Add an --enable-termination-protection command line option to the create-stack command and the update-stack command.</strong></p><ul><li><p><strong>Termination protection</strong> ngÄƒn cháº·n <strong>accidental deletion</strong> cá»§a entire stack</p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n giá»¯ láº¡i resources khi provisioning fails</p></li><li><p>KhÃ´ng áº£nh hÆ°á»Ÿng rollback behavior during stack creation errors</p></li></ul><p></p><p>âŒ <strong>Add a --parameters ParameterKey=PreserveResources,ParameterValue=True command line option to the create-stack command and the update-stack command.</strong></p><ul><li><p><strong>Parameters</strong> dÃ¹ng Ä‘á»ƒ pass values vÃ o CloudFormation template</p></li><li><p><strong>PreserveResources</strong> khÃ´ng pháº£i built-in CloudFormation parameter</p></li><li><p>KhÃ´ng cÃ³ effect trÃªn rollback behavior</p></li></ul><p></p><p>âŒ <strong>Add a --tags Key=PreserveResources,Value=True command line option to the create-stack command and the update-stack command.</strong></p><ul><li><p><strong>Tags</strong> dÃ¹ng Ä‘á»ƒ organize vÃ  track resources</p></li><li><p>Tags khÃ´ng control rollback behavior</p></li><li><p>KhÃ´ng preserve resources khi error occurs</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Preserve resources on failure\"</strong> â†’ <code>--disable-rollback</code></p></li><li><p><strong>CloudFormation rollback behavior:</strong></p><ul><li><p>Default: rollback vÃ  <strong>delete all resources</strong> on failure</p></li><li><p>--disable-rollback: <strong>keep successfully created resources</strong></p></li></ul></li><li><p><strong>Termination protection</strong> = ngÄƒn cháº·n stack deletion, khÃ´ng pháº£i giá»¯ láº¡i resource khi error</p></li><li><p>Parameters vÃ  Tags khÃ´ng affect rollback behavior</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/cli/latest/reference/cloudformation/create-stack.html\">create-stack CLI command</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add a --disable-rollback command line option to the create-stack command and the update-stack command.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add an --enable-termination-protection command line option to the create-stack command and the update-stack command.</p>",
                "<p>Add a --disable-rollback command line option to the create-stack command and the update-stack command.</p>",
                "<p>Add a --parameters ParameterKey=PreserveResources,ParameterValue=True command line option to the create-stack command and the update-stack command.</p>",
                "<p>Add a --tags Key=PreserveResources,Value=True command line option to the create-stack command and the update-stack command.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 26
        },
        {
            "attemptAnswerId": 329688,
            "questionId": 7564,
            "questionText": "<p>A developer is working on an application that processes operating data from IoT devices. Each IoT device uploads a data file once every hour to an Amazon S3 bucket. The developer wants to immediately process each data file when the data file is uploaded to Amazon S3.<br><br>The developer will use an AWS Lambda function to process the data files from Amazon S3. The Lambda function is configured with the S3 bucket information where the files are uploaded. The developer wants to configure the Lambda function to immediately invoke after each data file is uploaded.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>IoT devices upload <strong>data file má»—i giá»</strong> to <strong>S3 bucket</strong></p></li><li><p>Developer muá»‘n <strong>immediately process</strong> má»—i data file khi uploaded</p></li><li><p>Sá»­ dá»¥ng <strong>Lambda function</strong> Ä‘á»ƒ process files tá»« S3</p></li><li><p>Requirement: configure Lambda Ä‘á»ƒ <strong>immediately invoke</strong> after má»—i file uploaded</p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Add a trigger to the Lambda function. Select the S3 bucket as the source.</strong></p><ul><li><p><strong>S3 event trigger</strong> cho Lambda function tá»± Ä‘á»™ng invoke khi cÃ³ object uploaded</p></li><li><p>Configure S3 event notifications (ObjectCreated:Put, ObjectCreated:Post)</p></li><li><p>Lambda immediately invoked khi file uploaded to S3</p></li><li><p>Native integration giá»¯a S3 vÃ  Lambda</p></li></ul><p></p><p><em>Using an Amazon S3 trigger to invoke a Lambda function</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1760941026203-15owmwcm-image.png\" alt=\"\" title=\"\" width=\"647\" height=\"422.2011979166667\" style=\"max-width: 647px\" data-keep-ratio=\"true\"></span></span></p><p></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Add an asynchronous invocation to the Lambda function. Select the S3 bucket as the source.</strong></p><ul><li><p><strong>Asynchronous invocation</strong> lÃ  invocation mode cá»§a Lambda, khÃ´ng pháº£i trigger mechanism</p></li><li><p>KhÃ´ng configure Ä‘Æ°á»£c S3 bucket lÃ m source cho asynchronous invocation</p></li><li><p>KhÃ´ng tá»± Ä‘á»™ng invoke khi file uploaded</p></li></ul><p></p><p>âŒ <strong>Add an Amazon EventBridge event to the Lambda function. Select the S3 bucket as the source.</strong></p><ul><li><p>S3 cÃ³ thá»ƒ send events Ä‘áº¿n EventBridge nhÆ°ng pháº£i <strong>enable EventBridge integration</strong> trÃªn S3 bucket trÆ°á»›c</p></li><li><p><strong>Direct S3 trigger</strong> Ä‘Æ¡n giáº£n hÆ¡n vÃ  native hÆ¡n cho use case nÃ y</p></li><li><p>EventBridge adds unnecessary complexity</p></li></ul><p></p><p>âŒ <strong>Add a layer to the Lambda function. Select the S3 bucket as the source.</strong></p><ul><li><p><strong>Lambda layers</strong> dÃ¹ng Ä‘á»ƒ share code, libraries, dependencies</p></li><li><p>Layers khÃ´ng pháº£i trigger mechanism</p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n S3 events</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"S3 upload â†’ immediately invoke Lambda\"</strong> â†’ <strong>S3 event trigger</strong></p></li><li><p><strong>S3 event types</strong>: ObjectCreated:Put, ObjectCreated:Post, ObjectCreated:<em>, ObjectRemoved:</em></p></li><li><p><strong>Direct S3 trigger</strong> = simplest solution cho S3 â†’ Lambda integration</p></li><li><p>EventBridge cÃ³ thá»ƒ dÃ¹ng nhÆ°ng overkill cho simple S3 â†’ Lambda</p></li><li><p>Lambda layers = code sharing, khÃ´ng pháº£i triggers</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/with-s3-example.html\">Tutorial: Using an Amazon S3 trigger to invoke a Lambda function</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add a trigger to the Lambda function. Select the S3 bucket as the source.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add an asynchronous invocation to the Lambda function. Select the S3 bucket as the source.</p>",
                "<p>Add an Amazon EventBridge event to the Lambda function. Select the S3 bucket as the source.</p>",
                "<p>Add a trigger to the Lambda function. Select the S3 bucket as the source.</p>",
                "<p>Add a layer to the Lambda function. Select the S3 bucket as the source.</p>"
            ],
            "answersPos": "[2,1,3,0]",
            "pos": 27
        },
        {
            "attemptAnswerId": 329689,
            "questionId": 7565,
            "questionText": "<p>A developer is building a serverless application by using the AWS Serverless Application Model (AWS SAM). The developer is currently testing the application in a development environment. When the application is nearly finished, the developer will need to set up additional testing and staging environments for a quality assurance team.<br><br>The developer wants to use a feature of the AWS SAM to set up deployments to multiple environments.<br><br>Which solution will meet these requirements with the LEAST development effort?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer building serverless app báº±ng <strong>AWS SAM</strong></p></li><li><p>Hiá»‡n táº¡i test trong <strong>development environment</strong></p></li><li><p>Cáº§n setup thÃªm <strong>testing and staging environments</strong> cho QA team</p></li><li><p>Requirement: sá»­ dá»¥ng <strong>AWS SAM feature</strong> Ä‘á»ƒ deploy to <strong>multiple environments</strong> vá»›i <strong>LEAST development effort</strong></p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Add a configuration file in TOML format to group configuration entries to every environment. Add a table for each testing and staging environment. Deploy updates to the environments by using the sam deploy command and the --config-env flag that corresponds to each environment.</strong></p><ul><li><p><strong>SAM configuration file (samconfig.toml)</strong> cho phÃ©p define multiple environment configs trong má»™t file</p></li><li><p>Má»—i environment cÃ³ <strong>dedicated section/table</strong> vá»›i specific parameters</p></li><li><p>Deploy dá»… dÃ ng: <code>sam deploy --config-env dev</code>, <code>sam deploy --config-env staging</code>, <code>sam deploy --config-env prod</code></p></li><li><p>Least effort: centralized config, no custom scripts, no template duplication</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create additional AWS SAM templates for each testing and staging environment. Write a custom shell script that uses the sam deploy command and the --template-file flag to deploy updates to the environments.</strong></p><ul><li><p>Duplicate SAM templates cho má»—i environment = <strong>maintenance overhead</strong></p></li><li><p>Custom shell script = <strong>additional development effort</strong></p></li><li><p>KhÃ´ng pháº£i least effort approach</p></li></ul><p></p><p>âŒ <strong>Create one AWS SAM configuration file that has default parameters. Perform updates to the testing and staging environments by using the --parameter-overrides flag in the AWS SAM CLI and the parameters that the updates will override.</strong></p><ul><li><p><strong>--parameter-overrides</strong> pháº£i pass parameters má»—i láº§n deploy (command line dÃ i, dá»… máº¯c lá»—i)</p></li><li><p>KhÃ´ng centralized config management</p></li><li><p>More effort so vá»›i config file approach</p></li></ul><p></p><p>âŒ <strong>Use the existing AWS SAM template. Add additional parameters to configure specific attributes for the serverless function and database table resources that are in each environment. Deploy updates to the testing and staging environments by using the sam deploy command.</strong></p><ul><li><p>KhÃ´ng specify cÃ¡ch manage different environment configs</p></li><li><p><code>sam deploy</code> alone khÃ´ng automatically deploy to different environments vá»›i different configs</p></li><li><p>Thiáº¿u cÃ³ cháº¿ Ä‘á»ƒ differentiate environments</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Multiple environments + least effort\"</strong> â†’ <strong>samconfig.toml vá»›i --config-env</strong></p></li><li><p><strong>samconfig.toml structure:</strong> </p><pre><code class=\"language-toml\">[dev.deploy.parameters]\nstack_name = \"app-dev\"\n\n[staging.deploy.parameters]\nstack_name = \"app-staging\"</code></pre></li><li><p>Deploy: <code>sam deploy --config-env dev</code> hoáº·c <code>sam deploy --config-env staging</code></p></li><li><p>Avoid: template duplication, custom scripts, manual parameter overrides</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-config.html\">AWS SAM configuration file</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://dev.to/a-k-0047/managing-multiple-environments-in-aws-sam-devprod-4o6k\">Deploying to multiple environments with SAM</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add a configuration file in TOML format to group configuration entries to every environment. Add a table for each testing and staging environment. Deploy updates to the environments by using the sam deploy command and the --config-env flag that corresponds to each environment.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add a configuration file in TOML format to group configuration entries to every environment. Add a table for each testing and staging environment. Deploy updates to the environments by using the sam deploy command and the --config-env flag that corresponds to each environment.</p>",
                "<p>Create additional AWS SAM templates for each testing and staging environment. Write a custom shell script that uses the sam deploy command and the --template-file flag to deploy updates to the environments.</p>",
                "<p>Create one AWS SAM configuration file that has default parameters. Perform updates to the testing and staging environments by using the --parameter-overrides flag in the AWS SAM CLI and the parameters that the updates will override.</p>",
                "<p>Use the existing AWS SAM template. Add additional parameters to configure specific attributes for the serverless function and database table resources that are in each environment. Deploy updates to the testing and staging environments by using the sam deploy command.</p>"
            ],
            "answersPos": "[0,1,3,2]",
            "pos": 28
        },
        {
            "attemptAnswerId": 329690,
            "questionId": 7566,
            "questionText": "<p>An IT department uses Amazon S3 to store sensitive images. After more than 1 year, the company moves the images into archival storage. The company rarely accesses the images, but the company wants a storage solution that maximizes resiliency. The IT department needs access to the images that have been moved to archival storage within 24 hours.<br><br>Which solution will meet these requirements MOST cost-effectively?</p>",
            "explanation": "<p>ğŸ“ TÃ³m táº¯t Ä‘á»:</p><ul><li><p>IT department stores <strong>sensitive images</strong> trong S3</p></li><li><p>After <strong>&gt; 1 year</strong>, move images vÃ o <strong>archival storage</strong></p></li><li><p>Company <strong>rarely accesses</strong> archived images</p></li><li><p>Requirements:</p><ul><li><p>Storage solution <strong>maximizes resiliency</strong></p></li><li><p>Access to archived images <strong>within 24 hours</strong></p></li><li><p><strong>MOST cost-effective</strong></p></li></ul></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images.</strong></p><ul><li><p><strong>S3 Standard-IA</strong>: infrequent access, <strong>high resiliency (multi-AZ)</strong>, cost-effective cho images &lt; 1 year</p></li><li><p><strong>Glacier Deep Archive</strong>: lowest cost archival storage cho rarely accessed data</p></li><li><p><strong>Standard retrieval</strong>: <strong>12 hours</strong> retrieval time, Ä‘Ã¡p á»©ng requirement <strong>within 24 hours</strong></p></li><li><p>Standard-IA multi-AZ maximizes resiliency cho sensitive images</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with bulk retrieval to store and retrieve archived images.</strong></p><ul><li><p><strong>Bulk retrieval</strong> = <strong>48 hours</strong> retrieval time</p></li><li><p><strong>KHÃ”NG Ä‘Ã¡p á»©ng</strong> requirement \"within 24 hours\"</p></li><li><p>Vi pháº¡m access time requirement</p></li></ul><p></p><p>âŒ <strong>Use S3 Intelligent-Tiering to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images.</strong></p><ul><li><p><strong>S3 Intelligent-Tiering</strong> cÃ³ <strong>monitoring and automation fees</strong></p></li><li><p>Äáº¯t hÆ¡n Standard-IA cho known access pattern (infrequent &lt; 1 year)</p></li><li><p>KhÃ´ng pháº£i most cost-effective</p></li></ul><p></p><p>âŒ <strong>Use S3 One Zone-Infrequent Access (S3 One Zone-IA) to store the images. Use S3 Glacier Deep Archive with bulk retrieval to store and retrieve archived images.</strong></p><ul><li><p><strong>One Zone-IA</strong> stores data trong <strong>single AZ</strong>, <strong>lower resiliency (kháº£ nÄƒng phá»¥c há»“i)</strong></p></li><li><p>Vi pháº¡m requirement \"<strong>maximizes resiliency</strong>\" cho sensitive images</p></li><li><p>Bulk retrieval (48 hours) khÃ´ng meet 24-hour requirement</p></li></ul><p></p><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Maximize resiliency\"</strong> â†’ Multi-AZ storage (Standard-IA), NOT One Zone-IA</p></li><li><p><strong>Glacier Deep Archive retrieval:</strong></p><ul><li><p><strong>Standard retrieval</strong> = <strong>12 hours</strong></p></li><li><p><strong>Bulk retrieval</strong> = <strong>48 hours</strong> (cheapest nhÆ°ng slower)</p></li></ul></li><li><p><strong>\"Within 24 hours\"</strong> â†’ chá»‰ Standard retrieval Ä‘Ã¡p á»©ng</p></li><li><p>S3 Intelligent-Tiering cÃ³ monitoring fees, not cost-effective cho known patterns</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.html\">S3 Glacier Deep Archive retrieval options</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images.</p>",
                "<p>Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with bulk retrieval to store and retrieve archived images.</p>",
                "<p>Use S3 Intelligent-Tiering to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images.</p>",
                "<p>Use S3 One Zone-Infrequent Access (S3 One Zone-IA) to store the images. Use S3 Glacier Deep Archive with bulk retrieval to store and retrieve archived images.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 29
        },
        {
            "attemptAnswerId": 329691,
            "questionId": 7567,
            "questionText": "<p>A developer must provide an API key to an AWS Lambda function to authenticate with a third-party system. The Lambda function will run on a schedule. The developer needs to ensure that the API key remains encrypted at rest.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Lambda function cáº§n <strong>API key</strong> Ä‘á»ƒ authenticate vá»›i third-party system</p></li><li><p>Lambda function <strong>runs on a schedule</strong> (automated, no user interaction)</p></li><li><p>Requirement: ensure API key <strong>remains encrypted at rest</strong></p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Store the API key as a Lambda environment variable by using an AWS Key Management Service (AWS KMS) customer managed key.</strong></p><ul><li><p><strong>Lambda environment variables</strong> cÃ³ thá»ƒ encrypted at rest báº±ng <strong>AWS KMS</strong></p></li><li><p><strong>Customer managed KMS key</strong> cho full control over encryption key</p></li><li><p>Lambda automatically decrypt environment variables khi function executes</p></li><li><p>Secure vÃ  compliant vá»›i encryption at rest requirement</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure the application to prompt the user to provide the password to the Lambda function on the first run.</strong></p><ul><li><p>Lambda <strong>runs on schedule</strong> = automated, <strong>no user interaction</strong></p></li><li><p>Cannot prompt (nháº¯c nhá»Ÿ) user cho scheduled automated runs</p></li><li><p>KhÃ´ng kháº£ thi cho use case nÃ y</p></li></ul><p></p><p>âŒ <strong>Store the API key as a value in the application code.</strong></p><ul><li><p>Hardcoding API key trong code = <strong>security risk</strong></p></li><li><p>Code khÃ´ng encrypted at rest (stored trong deployment package)</p></li><li><p>Vi pháº¡m security best practices</p></li><li><p>API key exposed trong source code</p></li></ul><p></p><p>âŒ <strong>Use Lambda@Edge and only communicate over the HTTPS protocol.</strong></p><ul><li><p><strong>Lambda@Edge</strong> dÃ¹ng Ä‘á»ƒ run Lambda at CloudFront edge locations</p></li><li><p><strong>HTTPS</strong> = encryption <strong>in transit</strong>, khÃ´ng pháº£i <strong>at rest</strong></p></li><li><p>KhÃ´ng address viá»‡c store API key securely</p></li><li><p>KhÃ´ng giáº£i quyáº¿t encryption at rest requirement</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Store secrets + encrypted at rest\"</strong> â†’ <strong>Lambda environment variables with KMS</strong> hoáº·c <strong>Secrets Manager</strong></p></li><li><p><strong>Lambda environment variables encryption:</strong></p><ul><li><p>Default: encrypted vá»›i AWS managed key</p></li><li><p>Better: encrypted vá»›i <strong>customer managed KMS key</strong></p></li></ul></li><li><p><strong>Encryption types:</strong></p><ul><li><p><strong>At rest</strong> = data stored (KMS, environment variables)</p></li><li><p><strong>In transit</strong> = data transferring (HTTPS, TLS)</p></li></ul></li><li><p>NEVER hardcode secrets trong application code</p></li><li><p>Lambda@Edge khÃ´ng liÃªn quan Ä‘áº¿n secret storage</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars-encryption.html\">Securing Lambda environment variables with KMS</a></p></li></ul>",
            "correctAnswer": [
                "<p>Store the API key as a Lambda environment variable by using an AWS Key Management Service (AWS KMS) customer managed key.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Store the API key as a Lambda environment variable by using an AWS Key Management Service (AWS KMS) customer managed key.</p>",
                "<p>Configure the application to prompt the user to provide the password to the Lambda function on the first run.</p>",
                "<p>Store the API key as a value in the application code.</p>",
                "<p>Use Lambda@Edge and only communicate over the HTTPS protocol.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 30
        },
        {
            "attemptAnswerId": 329692,
            "questionId": 7568,
            "questionText": "<p>A company has an application that stores data in Amazon RDS instances. The application periodically experiences surges of high traffic that cause performance problems. During periods of peak traffic, a developer notices a reduction in query speed in all database queries.<br><br>The teamâ€™s technical lead determines that a multi-threaded and scalable caching solution should be used to offload the heavy read traffic. The solution needs to improve performance.<br><br>Which solution will meet these requirements with the LEAST complexity?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application stores data trong <strong>Amazon RDS</strong></p></li><li><p>Äá»‹nh ká»³ cÃ³ <strong>surges of high traffic (lÆ°u lÆ°á»£ng tÄƒng Ä‘á»™t biáº¿n)</strong> gÃ¢y performance problems</p></li><li><p>During peak traffic: <strong>query speed giáº£m</strong> trong all database queries</p></li><li><p>Requirement:</p><ul><li><p><strong>Multi-threaded and scalable caching solution</strong></p></li><li><p><strong>Offload heavy read traffic</strong></p></li><li><p>Improve performance</p></li><li><p><strong>LEAST complexity</strong></p></li></ul></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use Amazon ElastiCache for Memcached to offload read requests from the main database.</strong></p><ul><li><p><strong>Memcached</strong> lÃ  <strong>multi-threaded</strong> caching engine (requirement match)</p></li><li><p>Simple key-value cache, <strong>least complexity</strong> to implement</p></li><li><p>Highly scalable, handle high-throughput read workloads</p></li><li><p>Offload read traffic tá»« RDS effectively</p></li><li><p>No data persistence needed cho cache use case</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Replicate the data to Amazon DynamoDB. Set up a DynamoDB Accelerator (DAX) cluster.</strong></p><ul><li><p>Pháº£i <strong>migrate/replicate data</strong> tá»« RDS sang DynamoDB = <strong>high complexity</strong></p></li><li><p>DAX chá»‰ work vá»›i DynamoDB, khÃ´ng cache cho RDS</p></li><li><p>Maintain dual databases (RDS + DynamoDB) = operational overhead</p></li><li><p>KhÃ´ng pháº£i least complexity</p></li></ul><p></p><p>âŒ <strong>Configure the Amazon RDS instances to use Multi-AZ deployment with one standby instance. Offload read requests from the main database to the standby instance.</strong></p><ul><li><p><strong>Multi-AZ standby</strong> dÃ¹ng cho <strong>failover</strong>, <strong>KHÃ”NG pháº£i read offloading</strong></p></li><li><p>Standby instance khÃ´ng accept read traffic (synchronous replication only)</p></li><li><p>Pháº£i dÃ¹ng <strong>Read Replicas</strong> cho read offloading, khÃ´ng pháº£i Multi-AZ standby</p></li><li><p>Sai concept</p></li></ul><p></p><p>âŒ <strong>Use Amazon ElastiCache for Redis to offload read requests from the main database.</strong></p><ul><li><p><strong>Redis</strong> support caching nhÆ°ng <strong>single-threaded</strong> (per core)</p></li><li><p>Requirement chá»‰ Ä‘á»‹nh <strong>multi-threaded</strong> solution</p></li><li><p>Redis cÃ³ nhiá»u features (persistence, data structures) = more complexity so vá»›i Memcached</p></li><li><p>Memcached Ä‘Æ¡n giáº£n hÆ¡n cho pure caching use case</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Multi-threaded caching\"</strong> â†’ <strong>Memcached</strong></p></li><li><p><strong>Memcached vs Redis:</strong></p><ul><li><p><strong>Memcached</strong> = multi-threaded, simple key-value cache, least complexity</p></li><li><p><strong>Redis</strong> = single-threaded (per core), data structures, persistence, more features</p></li></ul></li><li><p><strong>RDS Multi-AZ vs Read Replicas:</strong></p><ul><li><p><strong>Multi-AZ</strong> = failover, standby KHÃ”NG serve reads</p></li><li><p><strong>Read Replicas</strong> = offload read traffic</p></li></ul></li><li><p><strong>\"Least complexity + caching\"</strong> â†’ ElastiCache Memcached</p></li><li><p>DynamoDB + DAX = high complexity, requires data migration</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/elasticache/redis-vs-memcached/\">Choosing between Memcached and Redis</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use Amazon ElastiCache for Memcached to offload read requests from the main database.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use Amazon ElastiCache for Memcached to offload read requests from the main database.</p>",
                "<p>Replicate the data to Amazon DynamoDSet up a DynamoDB Accelerator (DAX) cluster.</p>",
                "<p>Configure the Amazon RDS instances to use Multi-AZ deployment with one standby instance. Offload read requests from the main database to the standby instance.</p>",
                "<p>Use Amazon ElastiCache for Redis to offload read requests from the main database.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 31
        },
        {
            "attemptAnswerId": 329693,
            "questionId": 7569,
            "questionText": "<p>A company has a serverless application on AWS that uses a fleet of AWS Lambda functions that have aliases. The company regularly publishes new Lambda function by using an in-house deployment solution. The company wants to improve the release process and to use traffic shifting. A newly published function version should initially make available only to a fixed percentage of production users.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Serverless application vá»›i <strong>fleet of Lambda functions cÃ³ aliases</strong></p></li><li><p>Company thÆ°á»ng xuyÃªn publishes new Lambda functions</p></li><li><p>Requirements:</p><ul><li><p>Improve release process</p></li><li><p>Use <strong>traffic shifting</strong></p></li><li><p>New function version <strong>ban Ä‘áº§u chá»‰ available</strong> cho <strong>fixed percentage (tá»· lá»‡ cá»‘ Ä‘á»‹nh)</strong> of production users</p></li></ul></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Configure routing on the alias of the new function by using a weighted alias.</strong></p><ul><li><p><strong>Weighted alias</strong> cho phÃ©p split traffic giá»¯a two Lambda versions</p></li><li><p>Configure weight: VD 90% traffic â†’ version 1, 10% â†’ version 2 (fixed percentage)</p></li><li><p>Manual control over traffic percentage</p></li><li><p>Native Lambda feature, simple to implement</p></li></ul><p></p><p><em>HÃ¬nh mÃ¬nh hoáº¡</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1760946129564-ijzhs740-image.png\" alt=\"\" title=\"\" width=\"692\" height=\"388.9977083333333\" style=\"max-width: 692px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure a canary deployment type for Lambda.</strong></p><ul><li><p><strong>Canary deployment</strong> tá»± Ä‘á»™ng shift traffic <strong>incrementally over time</strong> (VD: 10% â†’ 50% â†’ 100%)</p></li><li><p>KhÃ´ng pháº£i <strong>fixed percentage</strong> nhÆ° requirement</p></li><li><p>Canary lÃ  feature cá»§a <strong>AWS CodeDeploy</strong>, khÃ´ng pháº£i native Lambda config</p></li><li><p>More complex so vá»›i weighted alias</p></li></ul><p></p><p>âŒ <strong>Configure routing on the new versions by using environment variables.</strong></p><ul><li><p><strong>Environment variables</strong> khÃ´ng control traffic routing</p></li><li><p>Environment variables chá»‰ pass configuration vÃ o function</p></li><li><p>KhÃ´ng cÃ³ cÆ¡ cháº¿ Ä‘á»ƒ traffic shifting</p></li></ul><p></p><p>âŒ <strong>Configure a linear deployment type for Lambda.</strong></p><ul><li><p><strong>Linear deployment</strong> shift traffic <strong>gradually in equal increments (tÄƒng dáº§n Ä‘á»u)</strong> over time (VD: +10% every 10 minutes)</p></li><li><p>KhÃ´ng pháº£i <strong>fixed percentage initially</strong> nhÆ° requirement</p></li><li><p>Linear lÃ  CodeDeploy feature, more complex</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Fixed percentage of users\"</strong> â†’ <strong>Weighted alias</strong></p></li><li><p><strong>Lambda alias routing:</strong></p><ul><li><p><strong>Weighted alias</strong> = manual traffic split (VD: 90/10, 80/20)</p></li><li><p>Point alias to two versions vá»›i different weights</p></li></ul></li><li><p><strong>CodeDeploy deployment types:</strong></p><ul><li><p><strong>Canary</strong> = shift percentage, then shift rest (VD: 10% â†’ 100%)</p></li><li><p><strong>Linear</strong> = gradual increments (VD: +10% every X minutes)</p></li><li><p><strong>All-at-once</strong> = immediate full shift</p></li></ul></li><li><p>Environment variables khÃ´ng control routing</p></li><li><p>Weighted alias = simplest cho fixed percentage requirement</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuring-alias-routing.html\">Implement Lambda canary deployments using a weighted alias</a></p></li></ul>",
            "correctAnswer": [
                "<p>Configure routing on the alias of the new function by using a weighted alias.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure routing on the alias of the new function by using a weighted alias.</p>",
                "<p>Configure a canary deployment type for Lambda.</p>",
                "<p>Configure routing on the new versions by using environment variables.</p>",
                "<p>Configure a linear deployment type for Lambda.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 32
        },
        {
            "attemptAnswerId": 329694,
            "questionId": 7570,
            "questionText": "<p>A developer is creating a new REST API by using Amazon API Gateway and AWS Lambda. The development team tests the API and validates responses for the known use cases before deploying the API to the production environment.<br><br>The developer wants to make the REST API available for testing by using API Gateway locally.<br><br>Which AWS Serverless Application Model Command Line Interface (AWS SAM CLI) subcommand will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer táº¡o <strong>REST API</strong> báº±ng <strong>API Gateway vÃ  Lambda</strong></p></li><li><p>Team tests API vÃ  validates responses trÆ°á»›c khi deploy to production</p></li><li><p>Developer muá»‘n make <strong>REST API available for testing locally</strong> báº±ng API Gateway</p></li><li><p>TÃ¬m <strong>AWS SAM CLI subcommand</strong> phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>sam local start-api</strong></p><ul><li><p><code>sam local start-api</code> start local HTTP server emulating (mÃ´ phá»ng) <strong>API Gateway</strong></p></li><li><p>Expose REST API endpoints locally Ä‘á»ƒ test</p></li><li><p>Automatically invoke Lambda functions khi receive HTTP requests</p></li><li><p>Best cho testing <strong>entire API Gateway + Lambda integration</strong> locally</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>sam local invoke</strong></p><ul><li><p><code>sam local invoke</code> chá»‰ invoke <strong>single Lambda function</strong> locally</p></li><li><p>KhÃ´ng start API Gateway endpoint</p></li><li><p>KhÃ´ng test REST API routes/integration</p></li><li><p>PhÃ¹ há»£p cho testing individual functions, khÃ´ng pháº£i API</p></li></ul><p></p><p>âŒ <strong>sam local generate-event</strong></p><ul><li><p><code>sam local generate-event</code> táº¡o <strong>sample event payloads</strong> (S3, API Gateway, etc.)</p></li><li><p>KhÃ´ng start local API server</p></li><li><p>Chá»‰ generate test events, khÃ´ng run API</p></li></ul><p></p><p>âŒ <strong>sam local start-lambda</strong></p><ul><li><p><code>sam local start-lambda</code> start local <strong>Lambda endpoint</strong> emulating Lambda service</p></li><li><p>DÃ¹ng Ä‘á»ƒ invoke functions qua AWS SDK/CLI locally</p></li><li><p><strong>KHÃ”NG emulate API Gateway</strong>, khÃ´ng expose REST API endpoints</p></li><li><p>KhÃ´ng phÃ¹ há»£p cho testing REST API</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Test REST API locally\"</strong> â†’ <code>sam local start-api</code></p></li><li><p><strong>SAM CLI local testing commands:</strong></p><ul><li><p><code>sam local start-api</code> = emulate <strong>API Gateway</strong> + expose REST endpoints</p></li><li><p><code>sam local start-lambda</code> = emulate <strong>Lambda service</strong> endpoint</p></li><li><p><code>sam local invoke</code> = invoke <strong>single function</strong> once</p></li><li><p><code>sam local generate-event</code> = generate sample event payloads</p></li></ul></li><li><p><strong>start-api vs start-lambda:</strong></p><ul><li><p>start-api = HTTP server vá»›i API routes</p></li><li><p>start-lambda = Lambda service endpoint (khÃ´ng pháº£i HTTP REST API)</p></li></ul></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-local-start-api.html\">AWS SAM CLI - sam local start-api</a></p></li></ul>",
            "correctAnswer": [
                "<p>Sam local start-api</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Sam local invoke</p>",
                "<p>Sam local generate-event</p>",
                "<p>Sam local start-lambda</p>",
                "<p>Sam local start-api</p>"
            ],
            "answersPos": "[3,0,1,2]",
            "pos": 33
        },
        {
            "attemptAnswerId": 329695,
            "questionId": 7571,
            "questionText": "<p>A developer has created an AWS Lambda function that makes queries to an Amazon Aurora MySQL DB instance. When the developer performs a test, the DB instance shows an error for too many connections.<br><br>Which solution will meet these requirements with the LEAST operational effort?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Lambda function makes queries Ä‘áº¿n <strong>Aurora MySQL DB instance</strong></p></li><li><p>Khi developer test, DB instance shows <strong>error for too many connections</strong></p></li><li><p>Requirement: solution vá»›i <strong>LEAST operational effort</strong></p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create a proxy in Amazon RDS Proxy. Query the proxy instead of the DB instance.</strong></p><ul><li><p><strong>RDS Proxy</strong> táº¡o <strong>connection pool</strong> giá»¯a Lambda vÃ  Aurora</p></li><li><p>Reuse existing connections thay vÃ¬ má»—i Lambda invocation táº¡o new connection</p></li><li><p>Reduce sá»‘ connections Ä‘áº¿n DB drastically</p></li><li><p>Least operational effort: managed service, minimal code changes (chá»‰ Ä‘á»•i connection string)</p></li><li><p>Built-in cho Lambda + RDS/Aurora integration</p></li></ul><p></p><p><em>HÃ¬nh minh há»a</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1761035430127-3rhsegu6-image.png\" alt=\"\" title=\"\" width=\"701\" height=\"391.24562499999996\" style=\"max-width: 701px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a read replica for the DB instance. Query the replica DB instance instead of the primary DB instance.</strong></p><ul><li><p>Read replica <strong>KHÃ”NG giáº£i quyáº¿t \"too many connections\" issue</strong></p></li><li><p>Váº«n cÃ³ too many connections problem trÃªn replica</p></li><li><p>Read replica dÃ¹ng cho <strong>read scaling</strong>, khÃ´ng pháº£i connection management</p></li></ul><p></p><p>âŒ <strong>Migrate the data to an Amazon DynamoDB database.</strong></p><ul><li><p>Migration sang DynamoDB = <strong>high operational effort</strong></p></li><li><p>Pháº£i rewrite application logic, schema design</p></li><li><p>KhÃ´ng pháº£i least operational effort</p></li><li><p>Overkill cho connection issue</p></li></ul><p></p><p>âŒ <strong>Configure the Amazon Aurora MySQL DB instance for Multi-AZ deployment.</strong></p><ul><li><p><strong>Multi-AZ</strong> dÃ¹ng cho <strong>high availability/failover</strong>, khÃ´ng pháº£i connection management</p></li><li><p>KHÃ”NG giáº£i quyáº¿t \"too many connections\" problem</p></li><li><p>Váº«n cÃ³ same connection limit</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Lambda + too many DB connections\"</strong> â†’ <strong>RDS Proxy</strong></p></li><li><p><strong>RDS Proxy benefits:</strong></p><ul><li><p><strong>Connection pooling</strong> = reuse connections</p></li><li><p>Reduce connection overhead</p></li><li><p>Automatic scaling</p></li></ul></li><li><p><strong>Read replica</strong> = read scaling, KHÃ”NG giáº£i quyáº¿t connection limits</p></li><li><p><strong>Multi-AZ</strong> = failover/HA, KHÃ”NG giáº£i quyáº¿t connections</p></li><li><p>RDS Proxy = least effort solution cho Lambda connection issues</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html\">Amazon RDS Proxy</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/blogs/compute/using-amazon-rds-proxy-with-aws-lambda/\">Using Amazon RDS Proxy with AWS Lambda</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a proxy in Amazon RDS Proxy. Query the proxy instead of the DB instance.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a read replica for the DB instance. Query the replica DB instance instead of the primary DB instance.</p>",
                "<p>Migrate the data to an Amazon DynamoDB database.</p>",
                "<p>Configure the Amazon Aurora MySQL DB instance for Multi-AZ deployment.</p>",
                "<p>Create a proxy in Amazon RDS Proxy. Query the proxy instead of the DB instance.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 34
        },
        {
            "attemptAnswerId": 329696,
            "questionId": 7572,
            "questionText": "<p>A company needs to set up secure database credentials for all its AWS Cloud resources. The companyâ€™s resources include Amazon RDS DB instances, Amazon DocumentDB clusters, and Amazon Aurora DB instances. The companyâ€™s security policy mandates that database credentials be encrypted at rest and rotated at a regular interval.<br><br>Which solution will meet these requirements MOST securely?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company cáº§n setup <strong>secure database credentials</strong> cho RDS, DocumentDB, Aurora</p></li><li><p>Security policy báº¯t buá»™c:</p><ul><li><p>Credentials <strong>encrypted at rest</strong></p></li><li><p><strong>Rotated at regular interval</strong></p></li></ul></li><li><p>Requirement: <strong>MOST securely</strong> solution</p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create an AWS Lambda function by using the SecretsManagerRotationTemplate template in the AWS Secrets Manager console. Create secrets for the database credentials in Secrets Manager. Set up secrets rotation on a schedule.</strong></p><ul><li><p><strong>Secrets Manager</strong> designed specifically cho <strong>storing vÃ  rotating credentials</strong></p></li><li><p><strong>Automatic encryption at rest</strong> vá»›i AWS KMS</p></li><li><p><strong>Built-in rotation</strong> cho RDS, DocumentDB, Aurora vá»›i rotation templates</p></li><li><p>Rotation tá»± Ä‘á»™ng update credentials trong <strong>cáº£ Secrets Manager vÃ  database</strong></p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Set up IAM database authentication for token-based access. Generate user tokens to provide centralized access to RDS DB instances, Amazon DocumentDB clusters, and Aurora DB instances.</strong></p><ul><li><p>IAM database authentication dÃ¹ng <strong>temporary tokens</strong>, khÃ´ng pháº£i traditional credentials</p></li><li><p><strong>DocumentDB KHÃ”NG support IAM authentication</strong></p></li><li><p>KhÃ´ng satisfy requirement vá» storing/rotating traditional database credentials</p></li></ul><p></p><p>âŒ <strong>Create parameters for the database credentials in AWS Systems Manager Parameter Store. Set the Type parameter to SecureString. Set up automatic rotation on the parameters.</strong></p><ul><li><p>Parameter Store há»— trá»£ encryption vá»›i SecureString</p></li><li><p>NhÆ°ng Parameter Store <strong>KHÃ”NG cÃ³ built-in automatic rotation</strong></p></li><li><p>Pháº£i tá»± build custom rotation logic</p></li><li><p>KhÃ´ng pháº£i most secure solution</p></li></ul><p></p><p>âŒ <strong>Store the database access credentials as an encrypted Amazon S3 object in an S3 bucket. Block all public access on the S3 bucket. Use S3 server-side encryption to set up automatic rotation on the encryption key.</strong></p><ul><li><p>S3 <strong>KHÃ”NG pháº£i secret management service</strong></p></li><li><p><strong>S3 encryption key rotation</strong> khÃ¡c vá»›i <strong>credential rotation</strong></p></li><li><p>Rotating encryption key khÃ´ng rotate database credentials</p></li><li><p>KhÃ´ng cÃ³ mechanism Ä‘á»ƒ update credentials trong database khi rotate</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Database credentials + rotation\"</strong> â†’ <strong>AWS Secrets Manager</strong></p></li><li><p><strong>Secrets Manager vs Parameter Store:</strong></p><ul><li><p>Secrets Manager = <strong>automatic rotation</strong> + versioning + audit</p></li><li><p>Parameter Store = config data + encryption, <strong>NO automatic rotation</strong></p></li></ul></li><li><p><strong>Secrets Manager rotation:</strong></p><ul><li><p>Built-in templates cho RDS, DocumentDB, Aurora</p></li><li><p>Automatically update credentials trong database</p></li></ul></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/blogs/security/rotate-amazon-rds-database-credentials-automatically-with-aws-secrets-manager/\">Rotate Amazon RDS database credentials automatically with AWS Secrets Manager</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an AWS Lambda function by using the SecretsManagerRotationTemplate template in the AWS Secrets Manager console. Create secrets for the database credentials in Secrets Manager. Set up secrets rotation on a schedule.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Set up IAM database authentication for token-based access. Generate user tokens to provide centralized access to RDS DB instances, Amazon DocumentDB clusters, and Aurora DB instances.</p>",
                "<p>Create parameters for the database credentials in AWS Systems Manager Parameter Store. Set the Type parameter to SecureString. Set up automatic rotation on the parameters.</p>",
                "<p>Store the database access credentials as an encrypted Amazon S3 object in an S3 bucket. Block all public access on the S3 bucket. Use S3 server-side encryption to set up automatic rotation on the encryption key.</p>",
                "<p>Create an AWS Lambda function by using the SecretsManagerRotationTemplate template in the AWS Secrets Manager console. Create secrets for the database credentials in Secrets Manager. Set up secrets rotation on a schedule.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 35
        },
        {
            "attemptAnswerId": 329697,
            "questionId": 7573,
            "questionText": "<p>A company built a new application in the AWS Cloud. The company automated the bootstrapping of new resources with an Auto Scaling group by using AWS CloudFormation templates. The bootstrap scripts contain sensitive data.<br><br>The company needs a solution that is integrated with CloudFormation to manage the sensitive data in the bootstrap scripts.<br><br>Which solution will meet these requirements in the MOST secure way?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company automated bootstrapping cá»§a new resources vá»›i <strong>Auto Scaling group</strong> báº±ng <strong>CloudFormation</strong></p></li><li><p><strong>Bootstrap scripts contain sensitive data</strong></p></li><li><p>Requirement: solution <strong>integrated with CloudFormation</strong> Ä‘á»ƒ manage sensitive data <strong>MOST securely</strong></p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Put the sensitive data into AWS Systems Manager Parameter Store as a secure string parameter. Update the CloudFormation templates to use dynamic references to specify template values.</strong></p><ul><li><p><strong>Parameter Store SecureString</strong> encrypt sensitive data at rest vá»›i AWS KMS</p></li><li><p><strong>CloudFormation dynamic references</strong> (<code>{{resolve:ssm-secure:parameter-name}}</code>) natively integrated</p></li><li><p>CloudFormation automatically retrieve vÃ  decrypt parameters during stack operations</p></li><li><p>Secure: credentials khÃ´ng expose trong templates hoáº·c stack outputs</p></li><li><p>Best practice cho sensitive data trong CloudFormation</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Put the sensitive data into a CloudFormation parameter. Encrypt the CloudFormation templates by using an AWS Key Management Service (AWS KMS) key.</strong></p><ul><li><p>CloudFormation parameters <strong>khÃ´ng encrypted</strong> khi stored</p></li><li><p>Parameters visible trong <strong>CloudFormation console vÃ  API calls</strong></p></li><li><p>Encrypting templates khÃ´ng encrypt parameter values in transit/at rest</p></li><li><p>KhÃ´ng secure cho sensitive data</p></li></ul><p></p><p>âŒ <strong>Put the sensitive data into an Amazon S3 bucket. Update the CloudFormation templates to download the object from Amazon S3 during bootstrap.</strong></p><ul><li><p>S3 cÃ³ thá»ƒ encrypt objects nhÆ°ng <strong>khÃ´ng integrated</strong> vá»›i CloudFormation natively</p></li><li><p>Pháº£i manually download tá»« S3 trong bootstrap scripts</p></li><li><p>Phá»©c táº¡p hÆ¡n vÃ  less secure so vá»›i Parameter Store dynamic references</p></li><li><p>S3 khÃ´ng designed cho secrets management</p></li></ul><p></p><p>âŒ <strong>Put the sensitive data into Amazon Elastic File System (Amazon EFS). Enforce EFS encryption after file system creation. Update the CloudFormation templates to retrieve data from Amazon EFS.</strong></p><ul><li><p>EFS khÃ´ng designed cho <strong>secrets management</strong></p></li><li><p>Pháº£i mount EFS vÃ  retrieve files = complexity</p></li><li><p>KhÃ´ng cÃ³ native CloudFormation integration cho secrets</p></li><li><p>Overkill vÃ  khÃ´ng secure nhÆ° Parameter Store</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Sensitive data + CloudFormation\"</strong> â†’ <strong>Parameter Store + Dynamic References</strong></p></li><li><p><strong>CloudFormation dynamic references:</strong></p><ul><li><p>SSM Parameter: <code>{{resolve:ssm:parameter-name:version}}</code></p></li><li><p>SSM SecureString: <code>{{resolve:ssm-secure:parameter-name:version}}</code></p></li><li><p>Secrets Manager: <code>{{resolve:secretsmanager:secret-id:SecretString:key}}</code></p></li></ul></li><li><p><strong>CloudFormation parameters</strong> = NOT encrypted, visible trong console</p></li><li><p>S3/EFS khÃ´ng designed cho secrets, khÃ´ng cÃ³ native CloudFormation integration</p></li><li><p>Parameter Store SecureString = encrypted at rest vá»›i KMS</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html\">Get values stored in other services using dynamic references</a></p></li></ul><p></p><p><em>Get a plaintext value from Systems Manager Parameter Store</em></p><pre><code>Resources:\n  MyInstance:\n    Type: AWS::EC2::Instance\n    Properties:\n      ImageId: '{{resolve:ssm:/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-6.1-x86_64}}'\n      InstanceType: t2.micro</code></pre>",
            "correctAnswer": [
                "<p>Put the sensitive data into AWS Systems Manager Parameter Store as a secure string parameter. Update the CloudFormation templates to use dynamic references to specify template values.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Put the sensitive data into a CloudFormation parameter. Encrypt the CloudFormation templates by using an AWS Key Management Service (AWS KMS) key.</p>",
                "<p>Put the sensitive data into an Amazon S3 bucket. Update the CloudFormation templates to download the object from Amazon S3 during bootstrap.</p>",
                "<p>Put the sensitive data into AWS Systems Manager Parameter Store as a secure string parameter. Update the CloudFormation templates to use dynamic references to specify template values.</p>",
                "<p>Put the sensitive data into Amazon Elastic File System (Amazon EFS). Enforce EFS encryption after file system creation. Update the CloudFormation templates to retrieve data from Amazon EFS.</p>"
            ],
            "answersPos": "[3,2,0,1]",
            "pos": 36
        },
        {
            "attemptAnswerId": 329698,
            "questionId": 7574,
            "questionText": "<p>A developer is setting up a deployment pipeline. The pipeline includes an AWS CodeBuild build stage that requires access to a database to run integration tests. The developer is using a buildspec.yml file to configure the database connection. Company policy requires automatic rotation of all database credentials.</p><p></p><p>Which solution will handle the database credentials MOST securely?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer setup <strong>deployment pipeline</strong> vá»›i <strong>CodeBuild build stage</strong></p></li><li><p>CodeBuild cáº§n <strong>access database</strong> Ä‘á»ƒ run integration tests</p></li><li><p>DÃ¹ng <strong>buildspec.yml</strong> Ä‘á»ƒ configure database connection</p></li><li><p>Company policy requires <strong>automatic rotation</strong> cá»§a all database credentials</p></li><li><p>Requirement: handle credentials <strong>MOST securely</strong></p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Retrieve the credentials from an environment variable that is linked to an AWS Secrets Manager secret. Configure Secrets Manager for automatic rotation.</strong></p><ul><li><p><strong>Secrets Manager</strong> designed specifically cho <strong>database credentials vá»›i automatic rotation</strong></p></li><li><p>CodeBuild environment variable link Ä‘áº¿n Secrets Manager secret</p></li><li><p><strong>Built-in rotation templates</strong> cho databases (RDS, DocumentDB, etc.)</p></li><li><p>Rotation automatically update credentials trong <strong>cáº£ Secrets Manager vÃ  database</strong></p></li><li><p>Most secure: encryption at rest, versioning, audit logging</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Retrieve the credentials from variables that are hardcoded in the buildspec.yml file. Configure an AWS Lambda function to rotate the credentials.</strong></p><ul><li><p><strong>Hardcoding credentials</strong> trong buildspec.yml = <strong>major security risk</strong></p></li><li><p>buildspec.yml stored trong source control â†’ credentials exposed</p></li><li><p>Vi pháº¡m security best practices nghiÃªm trá»ng</p></li><li><p>Lambda rotation khÃ´ng giÃºp náº¿u credentials hardcoded</p></li></ul><p></p><p>âŒ <strong>Retrieve the credentials from an environment variable that is linked to a SecureString parameter in AWS Systems Manager Parameter Store. Configure Parameter Store for automatic rotation.</strong></p><ul><li><p>Parameter Store há»— trá»£ SecureString encryption</p></li><li><p>NhÆ°ng Parameter Store <strong>KHÃ”NG cÃ³ built-in automatic rotation</strong></p></li><li><p>Pháº£i tá»± build custom rotation logic</p></li><li><p>KhÃ´ng pháº£i most secure solution</p></li></ul><p></p><p>âŒ <strong>Retrieve the credentials from an environment variable that contains the connection string in plaintext. Configure an Amazon EventBridge event to rotate the credentials.</strong></p><ul><li><p><strong>Plaintext credentials</strong> trong environment variable = <strong>NOT secure</strong></p></li><li><p>EventBridge khÃ´ng cÃ³ built-in credential rotation capability</p></li><li><p>EventBridge dÃ¹ng cho event routing, khÃ´ng pháº£i secrets management</p></li><li><p>KhÃ´ng giáº£i quyáº¿t security requirement</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Database credentials + automatic rotation\"</strong> â†’ <strong>AWS Secrets Manager</strong></p></li><li><p><strong>CodeBuild + Secrets:</strong></p><ul><li><p>Environment variables link to Secrets Manager secrets</p></li><li><p>CodeBuild automatically retrieve vÃ  inject secrets at runtime</p></li></ul></li><li><p><strong>Secrets Manager vs Parameter Store:</strong></p><ul><li><p>Secrets Manager = <strong>automatic rotation</strong> + versioning</p></li><li><p>Parameter Store = config data, <strong>NO automatic rotation</strong></p></li></ul></li><li><p><strong>NEVER hardcode credentials</strong> trong buildspec.yml hoáº·c code</p></li><li><p>Plaintext credentials = major security violation</p></li></ul>",
            "correctAnswer": [
                "<p>Retrieve the credentials from an environment variable that is linked to an AWS Secrets Manager secret. Configure Secrets Manager for automatic rotation.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Retrieve the credentials from variables that are hardcoded in the buildspec.yml file. Configure an AWS Lambda function to rotate the credentials.</p>",
                "<p>Retrieve the credentials from an environment variable that is linked to a SecureString parameter in AWS Systems Manager Parameter Store. Configure Parameter Store for automatic rotation.</p>",
                "<p>Retrieve the credentials from an environment variable that is linked to an AWS Secrets Manager secret. Configure Secrets Manager for automatic rotation.</p>",
                "<p>Retrieve the credentials from an environment variable that contains the connection string in plaintext. Configure an Amazon EventBridge event to rotate the credentials.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 37
        },
        {
            "attemptAnswerId": 329699,
            "questionId": 7575,
            "questionText": "<p>A company has developed a new serverless application using AWS Lambda functions that will be deployed using the AWS Serverless Application Model (AWS SAM) CLI.<br><br>Which step should the developer complete prior to deploying the application?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company developed <strong>new serverless application</strong> báº±ng <strong>AWS Lambda functions</strong></p></li><li><p>Application sáº½ Ä‘Æ°á»£c deployed báº±ng <strong>AWS SAM CLI</strong></p></li><li><p>TÃ¬m step developer pháº£i complete <strong>prior to deploying</strong> the application</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Bundle the serverless application using a SAM package.</strong></p><ul><li><p><strong>sam package</strong> (hoáº·c <strong>sam build</strong>) lÃ  required step <strong>trÆ°á»›c khi deploy</strong></p></li><li><p>Package command:</p><ul><li><p>Build application code vÃ  dependencies</p></li><li><p>Upload artifacts (code, layers) lÃªn <strong>S3 bucket</strong></p></li><li><p>Generate CloudFormation template vá»›i S3 URIs</p></li></ul></li><li><p>Sau Ä‘Ã³ má»›i cháº¡y <strong>sam deploy</strong> Ä‘á»ƒ deploy stack</p></li><li><p>Standard SAM deployment workflow</p></li></ul><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Compress the application to a .zip file and upload it into AWS Lambda.</strong></p><ul><li><p><strong>Manual upload</strong> khÃ´ng pháº£i SAM CLI workflow</p></li><li><p>SAM CLI automatically handle packaging vÃ  uploading</p></li><li><p>KhÃ´ng cáº§n manually compress vÃ  upload khi dÃ¹ng SAM</p></li></ul><p></p><p>âŒ <strong>Test the new AWS Lambda function by first tracing it in AWS X-Ray.</strong></p><ul><li><p><strong>X-Ray tracing</strong> lÃ  optional monitoring feature, khÃ´ng pháº£i required deployment step</p></li><li><p>Testing cÃ³ thá»ƒ lÃ m sau deployment hoáº·c locally</p></li><li><p>KhÃ´ng pháº£i prerequisite Ä‘á»ƒ deploy</p></li></ul><p></p><p>âŒ <strong>Create the application environment using the eb create my-env command.</strong></p><ul><li><p><strong>eb create</strong> lÃ  <strong>Elastic Beanstalk CLI command</strong>, khÃ´ng pháº£i SAM</p></li><li><p>SAM khÃ´ng dÃ¹ng Elastic Beanstalk</p></li><li><p>Sai tool hoÃ n toÃ n</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>SAM deployment workflow:</strong></p><ol><li><p><strong>sam build</strong> (hoáº·c <strong>sam package</strong>) = build vÃ  package application</p></li><li><p><strong>sam deploy</strong> = deploy CloudFormation stack</p></li></ol></li><li><p><strong>sam package:</strong></p><ul><li><p>Upload code/artifacts to S3</p></li><li><p>Transform SAM template to CloudFormation template</p></li><li><p>Replace local paths vá»›i S3 URIs</p></li></ul></li><li><p>SAM CLI automatically handle compression vÃ  upload</p></li><li><p><strong>eb create</strong> = Elastic Beanstalk, khÃ´ng pháº£i SAM</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-package.html\">AWS SAM CLI - sam package</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-deploying.html\">Deploy your application and resources with AWS SAM</a></p></li></ul>",
            "correctAnswer": [
                "<p>Bundle the serverless application using a SAM package.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Compress the application to a .zip file and upload it into AWS Lambda.</p>",
                "<p>Test the new AWS Lambda function by first tracing it in AWS X-Ray.</p>",
                "<p>Bundle the serverless application using a SAM package.</p>",
                "<p>Create the application environment using the eb create my-env command.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 38
        },
        {
            "attemptAnswerId": 329700,
            "questionId": 7576,
            "questionText": "<p>A developer is creating a mobile application that will not require users to log in.<br><br>What is the MOST efficient method to grant users access to AWS resources?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer táº¡o <strong>mobile application</strong></p></li><li><p>Application <strong>will NOT require users to log in</strong> (unauthenticated users)</p></li><li><p>Requirement: <strong>MOST efficient method</strong> to grant users access to AWS resources</p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use Amazon Cognito to associate unauthenticated users with an IAM role that has limited access to resources.</strong></p><ul><li><p><strong>Amazon Cognito Identity Pools</strong> há»— trá»£ <strong>unauthenticated identities</strong> (guest access)</p></li><li><p>Cognito automatically provide temporary AWS credentials cho unauthenticated users</p></li><li><p>Associate unauthenticated users vá»›i <strong>IAM role cÃ³ limited permissions</strong></p></li><li><p>Most efficient: managed service, no user management needed, automatic credential rotation</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use an identity provider to securely authenticate with the application.</strong></p><ul><li><p>Identity provider dÃ¹ng cho <strong>authenticated users</strong> (login required)</p></li><li><p>Äá» bÃ i nÃ³i application <strong>will NOT require login</strong></p></li><li><p>KhÃ´ng phÃ¹ há»£p vá»›i unauthenticated use case</p></li></ul><p></p><p>âŒ <strong>Create an AWS Lambda function to create an IAM user when a user accesses the application.</strong></p><ul><li><p>Táº¡o <strong>IAM user cho má»—i app user</strong> = security risk vÃ  khÃ´ng scalable</p></li><li><p>IAM users lÃ  long-term credentials, khÃ´ng phÃ¹ há»£p cho mobile apps</p></li><li><p>Quáº£n lÃ½ vÃ  cleanup IAM users ráº¥t phá»©c táº¡p</p></li><li><p>KhÃ´ng hiá»‡u quáº£</p></li></ul><p></p><p>âŒ <strong>Create credentials using AWS KMS and apply these credentials to users when using the application.</strong></p><ul><li><p><strong>AWS KMS</strong> dÃ¹ng cho <strong>encryption keys</strong>, khÃ´ng pháº£i user credentials</p></li><li><p>KMS khÃ´ng táº¡o IAM credentials hoáº·c temporary tokens</p></li><li><p>Sai use case hoÃ n toÃ n</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Unauthenticated mobile app users + AWS access\"</strong> â†’ <strong>Amazon Cognito Identity Pools (unauthenticated identities)</strong></p></li><li><p><strong>Cognito Identity Pools:</strong></p><ul><li><p><strong>Authenticated identities</strong> = users logged in qua identity provider</p></li><li><p><strong>Unauthenticated identities</strong> = guest access, no login required</p></li></ul></li><li><p>Cognito provide <strong>temporary AWS credentials</strong> (STS tokens)</p></li><li><p>Associate vá»›i IAM role cÃ³ <strong>limited permissions</strong> cho security</p></li><li><p>NEVER create individual IAM users cho mobile app users</p></li><li><p>KMS = encryption keys, khÃ´ng pháº£i credentials</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-identity.html\">Amazon Cognito identity pools</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use Amazon Cognito to associate unauthenticated users with an IAM role that has limited access to resources.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use an identity provider to securely authenticate with the application.</p>",
                "<p>Create an AWS Lambda function to create an IAM user when a user accesses the application.</p>",
                "<p>Create credentials using AWS KMS and apply these credentials to users when using the application.</p>",
                "<p>Use Amazon Cognito to associate unauthenticated users with an IAM role that has limited access to resources.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 39
        },
        {
            "attemptAnswerId": 329701,
            "questionId": 7577,
            "questionText": "<p>A company is migrating its PostgreSQL database into the AWS Cloud. The company wants to use a database that will secure and regularly rotate database credentials. The company wants a solution that does not require additional programming overhead.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company migrating <strong>PostgreSQL database</strong> to AWS Cloud</p></li><li><p>Requirements:</p><ul><li><p>Database <strong>secure vÃ  regularly rotate credentials</strong></p></li><li><p>Solution <strong>does NOT require additional programming overhead</strong></p></li></ul></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… ÄÃ¡p Ã¡n Ä‘Ãºng:</p><p><strong>Use Amazon Aurora PostgreSQL for the database. Store the database credentials in AWS Secrets Manager. Turn on rotation.</strong></p><ul><li><p><strong>Aurora PostgreSQL</strong> = managed PostgreSQL-compatible database</p></li><li><p><strong>Secrets Manager</strong> thiáº¿t káº¿ Ä‘áº·c biá»‡t cho <strong>database credentials vá»›i automatic rotation</strong></p></li><li><p><strong>Built-in rotation templates</strong> cho Aurora PostgreSQL</p></li><li><p>Rotation automatically update credentials trong <strong>cáº£ Secrets Manager vÃ  database</strong></p></li><li><p>No additional programming overhead: fully managed rotation</p></li></ul><p></p><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-saa-dva/aws-secrets-manager-integration-with-amazon-rds\"><em>Tham kháº£o: AWS Secrets Manager Integration with Amazon RDS</em></a></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1761373560756-blalap0r-image.png\" alt=\"\" title=\"\" width=\"599\" height=\"519.8040885416666\" style=\"max-width: 599px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use Amazon Aurora PostgreSQL for the database. Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation.</strong></p><ul><li><p>Aurora PostgreSQL Ä‘Ãºng cho PostgreSQL migration</p></li><li><p>NhÆ°ng <strong>Parameter Store KHÃ”NG cÃ³ built-in automatic rotation</strong></p></li><li><p>Pháº£i tá»± build custom rotation logic = <strong>additional programming overhead</strong></p></li><li><p>Vi pháº¡m requirement \"no additional programming overhead\"</p></li></ul><p></p><p>âŒ <strong>Use Amazon DynamoDB for the database. Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation.</strong></p><ul><li><p><strong>DynamoDB</strong> lÃ  <strong>NoSQL database</strong>, khÃ´ng pháº£i PostgreSQL</p></li><li><p>PostgreSQL â†’ DynamoDB migration = <strong>pháº£i rewrite application</strong></p></li><li><p>Parameter Store khÃ´ng cÃ³ automatic rotation</p></li><li><p>KhÃ´ng phÃ¹ há»£p cho PostgreSQL migration</p></li></ul><p></p><p>âŒ <strong>Use Amazon DynamoDB for the database. Store the database credentials in AWS Secrets Manager. Turn on rotation.</strong></p><ul><li><p><strong>DynamoDB</strong> khÃ´ng pháº£i PostgreSQL-compatible database</p></li><li><p>Requires significant application changes (pháº£i thay Ä‘á»•i application Ä‘Ã¡ng ká»ƒ)</p></li><li><p>KhÃ´ng Ä‘Ã¡p á»©ng PostgreSQL migration requirement</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"PostgreSQL migration\"</strong> â†’ <strong>Aurora PostgreSQL</strong> (hoáº·c RDS PostgreSQL)</p></li><li><p><strong>\"Database credentials + automatic rotation + no overhead\"</strong> â†’ <strong>Secrets Manager</strong></p></li><li><p><strong>Secrets Manager vs Parameter Store:</strong></p><ul><li><p>Secrets Manager = <strong>automatic rotation</strong> cho databases, no programming needed</p></li><li><p>Parameter Store = <strong>NO automatic rotation</strong>, requires custom Lambda</p></li></ul></li><li><p>Aurora PostgreSQL = PostgreSQL-compatible, managed service</p></li><li><p>DynamoDB = NoSQL, khÃ´ng compatible vá»›i PostgreSQL</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/rds-secrets-manager.html\">Password management with Amazon Aurora and AWS Secrets Manager</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use Amazon Aurora PostgreSQL for the database. Store the database credentials in AWS Secrets Manager. Turn on rotation.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use Amazon Aurora PostgreSQL for the database. Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation.</p>",
                "<p>Use Amazon Aurora PostgreSQL for the database. Store the database credentials in AWS Secrets Manager. Turn on rotation.</p>",
                "<p>Use Amazon DynamoDB for the database. Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation.</p>",
                "<p>Use Amazon DynamoDB for the database. Store the database credentials in AWS Secrets Manager. Turn on rotation.</p>"
            ],
            "answersPos": "[0,1,3,2]",
            "pos": 40
        },
        {
            "attemptAnswerId": 329702,
            "questionId": 7578,
            "questionText": "<p>A developer is testing an application that invokes an AWS Lambda function asynchronously. During the testing phase, the Lambda function fails to process after two retries.<br><br>How can the developer troubleshoot the failure?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer testing application invoke <strong>Lambda function asynchronously</strong></p></li><li><p>Lambda function <strong>fails to process after two retries</strong></p></li><li><p>TÃ¬m cÃ¡ch <strong>troubleshoot the failure</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Configure Dead Letter Queues by sending events to Amazon SQS for investigation.</strong></p><ul><li><p><strong>Dead Letter Queue (DLQ)</strong> capture failed events sau khi háº¿t táº¥t cáº£ cÃ¡c láº§n retries</p></li><li><p>Configure Lambda <strong>asynchronous invocation</strong> vá»›i DLQ (SQS hoáº·c SNS)</p></li><li><p>Failed events sent to DLQ Ä‘á»ƒ investigate</p></li><li><p>DLQ giá»¯ láº¡i event payload vÃ  error info Ä‘á»ƒ troubleshoot</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure AWS CloudTrail logging to investigate the invocation failures.</strong></p><ul><li><p><strong>CloudTrail</strong> logs <strong>AWS API calls</strong>, khÃ´ng pháº£i Lambda execution details</p></li><li><p>CloudTrail khÃ´ng capture Lambda function errors hoáº·c failed event payloads</p></li><li><p>Pháº£i dÃ¹ng <strong>CloudWatch Logs</strong> cho Lambda execution logs, khÃ´ng pháº£i CloudTrail</p></li></ul><p></p><p>âŒ <strong>Configure Amazon Simple Workflow Service to process any direct unprocessed events.</strong></p><ul><li><p><strong>SWF</strong> lÃ  workflow orchestration service, khÃ´ng pháº£i error handling mechanism</p></li><li><p>SWF khÃ´ng automatically capture failed Lambda events</p></li><li><p>KhÃ´ng liÃªn quan cho troubleshooting Lambda failures</p></li></ul><p></p><p>âŒ <strong>Configure AWS Config to process any direct unprocessed events.</strong></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-soa/introduction-aws-config\"><strong>AWS Config</strong></a> track configuration changes cá»§a AWS resources</p></li><li><p>KhÃ´ng capture hoáº·c process failed Lambda events</p></li><li><p>KhÃ´ng pháº£i troubleshooting tool cho Lambda failures</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Lambda asynchronous invocation failures\"</strong> â†’ <strong>Dead Letter Queue (DLQ)</strong></p></li><li><p><strong>Lambda DLQ:</strong></p><ul><li><p>Configure vá»›i <strong>SQS queue</strong> hoáº·c <strong>SNS topic</strong></p></li><li><p>Capture events sau khi all retries Fail</p></li><li><p>Giá»¯ láº¡i event payload Ä‘á»ƒ investigate</p></li></ul></li><li><p><strong>CloudTrail vs CloudWatch Logs:</strong></p><ul><li><p>CloudTrail = API calls audit</p></li><li><p>CloudWatch Logs = Lambda execution logs vÃ  errors</p></li></ul></li><li><p>SWF vÃ  AWS Config khÃ´ng relevant cho Lambda error troubleshooting</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/invocation-async-retain-records.html\">Capturing records of Lambda asynchronous invocations</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/blogs/compute/implementing-aws-lambda-error-handling-patterns/\">Implementing AWS Lambda error handling patterns</a></p></li></ul>",
            "correctAnswer": [
                "<p>Configure Dead Letter Queues by sending events to Amazon SQS for investigation.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure AWS CloudTrail logging to investigate the invocation failures.</p>",
                "<p>Configure Dead Letter Queues by sending events to Amazon SQS for investigation.</p>",
                "<p>Configure Amazon Simple Workflow Service to process any direct unprocessed events.</p>",
                "<p>Configure AWS Config to process any direct unprocessed events.</p>"
            ],
            "answersPos": "[1,0,2,3]",
            "pos": 41
        },
        {
            "attemptAnswerId": 329703,
            "questionId": 7579,
            "questionText": "<p>A company needs to distribute firmware updates to its customers around the world.<br><br>Which service will allow easy and secure control of the access to the downloads at the lowest cost?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company cáº§n <strong>distribute cÃ¡c báº£n cáº­p nháº­t pháº§n má»m</strong> Ä‘áº¿n customers <strong>around the world</strong></p></li><li><p>Requirements:</p><ul><li><p><strong>Easy and secure control</strong> cá»§a access to downloads</p></li><li><p><strong>Lowest cost</strong></p></li></ul></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use Amazon CloudFront with signed URLs for Amazon S3.</strong></p><ul><li><p><strong>CloudFront</strong> distribute content globally vá»›i low latency (edge locations worldwide)</p></li><li><p><strong>Signed URLs</strong> provide <strong>secure, time-limited access</strong> to private content</p></li><li><p>Control access: chá»‰ users cÃ³ signed URL má»›i download Ä‘Æ°á»£c</p></li><li><p><strong>Lowest cost</strong>: CloudFront + S3 standard pricing, no additional compute</p></li><li><p>Easy to implement: generate signed URLs programmatically</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a dedicated Amazon CloudFront Distribution for each customer.</strong></p><ul><li><p><strong>Separate distribution cho má»—i customer</strong> = cá»±c ká»³ expensive vÃ  complex</p></li><li><p>Hard to manage multiple distributions</p></li><li><p>KhÃ´ng scalable</p></li><li><p>KhÃ´ng pháº£i lowest cost</p></li></ul><p></p><p>âŒ <strong>Use Amazon CloudFront with AWS Lambda@Edge.</strong></p><ul><li><p><strong>Lambda@Edge</strong> adds <strong>compute cost</strong> cho má»—i request</p></li><li><p>More complex so vá»›i signed URLs</p></li><li><p>Overkill khi signed URLs Ä‘Ã£ Ä‘á»§ cho access control</p></li><li><p>KhÃ´ng pháº£i lowest cost</p></li></ul><p></p><p>âŒ <strong>Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket.</strong></p><ul><li><p><strong>API Gateway + Lambda</strong> adds thÃª chi phÃ­ (per request charges)</p></li><li><p>More complex architecture</p></li><li><p>API Gateway cÃ³ <strong>payload size limits</strong> (10 MB), khÃ´ng tá»‘t cho large firmware files</p></li><li><p>CloudFront better cho content distribution</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Global distribution + secure access + lowest cost\"</strong> â†’ <strong>CloudFront with Signed URLs</strong></p></li><li><p><strong>CloudFront signed URLs:</strong></p><ul><li><p>Time-limited access to private content</p></li><li><p>Control who can access vÃ  when</p></li><li><p>No additional compute cost</p></li></ul></li><li><p><strong>CloudFront vs API Gateway cho file distribution:</strong></p><ul><li><p>CloudFront = optimized cho static content, lower cost</p></li><li><p>API Gateway = API requests, cÃ³ payload limits</p></li></ul></li><li><p>Lambda@Edge adds compute cost, overkill cho simple access control</p></li><li><p>Separate distributions per customer = khÃ´ng scalable</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-signed-urls.html\">CloudFront signed URLs</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.html\">Serving private content with CloudFront</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use Amazon CloudFront with signed URLs for Amazon S3.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use Amazon CloudFront with signed URLs for Amazon S3.</p>",
                "<p>Create a dedicated Amazon CloudFront Distribution for each customer.</p>",
                "<p>Use Amazon CloudFront with AWS Lambda@Edge.</p>",
                "<p>Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 42
        },
        {
            "attemptAnswerId": 329704,
            "questionId": 7580,
            "questionText": "<p>A company has an ecommerce application. To track product reviews, the companyâ€™s development team uses an Amazon DynamoDB table.<br><br>Every record includes the following:</p><p></p><ul><li><p>A Review ID, a 16-digit universally unique identifier (UUID)</p></li><li><p>A Product ID and User ID, 16-digit UUIDs that reference other tables</p></li><li><p>A Product Rating on a scale of 1-5</p></li><li><p>An optional comment from the user</p></li></ul><p></p><p>The table partition key is the Review ID. The most performed query against the table is to find the 10 reviews with the highest rating for a given product.<br><br>Which index will provide the FASTEST response for this query?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>DynamoDB table tracking <strong>product reviews</strong></p></li><li><p>Table schema:</p><ul><li><p><strong>Review ID</strong> (16-digit UUID) = <strong>partition key</strong></p></li><li><p>Product ID, User ID (16-digit UUIDs)</p></li><li><p>Product Rating (1-5)</p></li><li><p>Optional comment</p></li></ul></li><li><p><strong>Most performed query</strong>: find <strong>10 reviews with highest rating</strong> for a <strong>given product</strong></p></li><li><p>TÃ¬m index provide <strong>FASTEST response</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>A global secondary index (GSI) with Product ID as the partition key and Product Rating as the sort key</strong></p><ul><li><p>Query pattern: filter by <strong>Product ID</strong> + sort by <strong>Product Rating</strong> (highest first)</p></li><li><p><strong>GSI vá»›i Product ID partition key</strong> cho phÃ©p query all reviews cá»§a product chá»‰ Ä‘á»‹nh</p></li><li><p><strong>Product Rating sort key</strong> cho phÃ©p sort vÃ  retrieve top 10 highest ratings hiá»‡u quáº£</p></li><li><p>Query: <code>Query(ProductID = \"xxx\", SortKeyCondition: ProductRating desc, Limit: 10)</code></p></li><li><p>Fastest response vÃ¬ query directly trÃªn indexed attributes</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>A global secondary index (GSI) with Product ID as the partition key and Review ID as the sort key</strong></p><ul><li><p>Product ID partition key Ä‘Ãºng cho query by product</p></li><li><p>NhÆ°ng <strong>Review ID sort key KHÃ”NG giÃºp</strong> sort by rating</p></li><li><p>Pháº£i scan all reviews rá»“i má»›i sort by rating trong application code</p></li><li><p>KhÃ´ng efficient</p></li></ul><p></p><p>âŒ <strong>A local secondary index (LSI) with Product ID as the partition key and Product Rating as the sort key</strong></p><ul><li><p><strong>LSI PHáº¢I share partition key</strong> vá»›i base table</p></li><li><p>Base table partition key = <strong>Review ID</strong>, khÃ´ng pháº£i Product ID</p></li><li><p><strong>KHÃ”NG THá»‚</strong> dÃ¹ng Product ID lÃ m partition key trong LSI</p></li><li><p>Sai vá» LSI concept</p></li></ul><p></p><p>âŒ <strong>A local secondary index (LSI) with Review ID as the partition key and Product ID as the sort key</strong></p><ul><li><p>Review ID partition key = same as base table</p></li><li><p>LSI nÃ y khÃ´ng giÃºp query by Product ID</p></li><li><p>Pháº£i biáº¿t Review ID trÆ°á»›c â†’ khÃ´ng phÃ¹ há»£p vá»›i query pattern</p></li><li><p>Product Rating khÃ´ng cÃ³ trong index â†’ cannot sort by rating</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Query by X + sort by Y\"</strong> â†’ <strong>GSI vá»›i X = partition key, Y = sort key</strong></p></li><li><p><strong>LSI vs GSI:</strong></p><ul><li><p><strong>LSI</strong> = PHáº¢I share <strong>same partition key</strong> vá»›i base table, different sort key only</p></li><li><p><strong>GSI</strong> = completely different partition key vÃ  sort key</p></li></ul></li><li><p><strong>Query pattern analysis:</strong></p><ul><li><p>\"Find reviews for product X\" â†’ Product ID = partition key</p></li><li><p>\"With highest rating\" â†’ Product Rating = sort key (desc order)</p></li></ul></li><li><p>LSI khÃ´ng thá»ƒ change partition key</p></li><li><p>Sort key cho phÃ©p range queries vÃ  sorting</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html\">DynamoDB Global Secondary Indexes</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-indexes.html\">Best practices for using secondary indexes</a></p></li></ul>",
            "correctAnswer": [
                "<p>A global secondary index (GSI) with Product ID as the partition key and Product Rating as the sort key</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>A global secondary index (GSI) with Product ID as the partition key and Product Rating as the sort key</p>",
                "<p>A global secondary index (GSI) with Product ID as the partition key and Review ID as the sort key</p>",
                "<p>A local secondary index (LSI) with Product ID as the partition key and Product Rating as the sort key</p>",
                "<p>A local secondary index (LSI) with Review ID as the partition key and Product ID as the sort key</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 43
        },
        {
            "attemptAnswerId": 329705,
            "questionId": 7581,
            "questionText": "<p>A developer is storing sensitive data generated by an application in Amazon S3. The developer wants to encrypt the data at rest. A company policy requires an audit trail of when the AWS Key Management Service (AWS KMS) key was used and by whom.<br><br>Which encryption option will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer storing <strong>sensitive data</strong> trong S3</p></li><li><p>Developer muá»‘n <strong>encrypt data at rest</strong></p></li><li><p><strong>Company policy</strong> requires:</p><ul><li><p><strong>Audit trail</strong> of when KMS key was used</p></li><li><p><strong>Audit trail</strong> of who used the key</p></li></ul></li><li><p>TÃ¬m encryption option Ä‘Ã¡p á»©ng requirements</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Server-side encryption with AWS KMS managed keys (SSE-KMS)</strong></p><ul><li><p><strong>SSE-KMS</strong> encrypt data at rest báº±ng AWS KMS keys</p></li><li><p><strong>CloudTrail automatically logs</strong> all KMS key usage:</p><ul><li><p>When key was used</p></li><li><p>Who used the key (IAM principal)</p></li><li><p>Which S3 operations triggered encryption/decryption</p></li></ul></li><li><p>Provides complete <strong>audit trail</strong> nhÆ° company policy yÃªu cáº§u</p></li><li><p>Centralized key management vá»›i KMS</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Server-side encryption with Amazon S3 managed keys (SSE-S3)</strong></p><ul><li><p><strong>SSE-S3</strong> encrypt data at rest nhÆ°ng S3 fully manage keys</p></li><li><p><strong>KHÃ”NG cÃ³ detailed audit trail</strong> of key usage</p></li><li><p>Cannot track who used keys hoáº·c when</p></li><li><p>KhÃ´ng Ä‘Ã¡p á»©ng audit trail requirement</p></li></ul><p></p><p>âŒ <strong>Server-side encryption with customer-provided keys (SSE-C)</strong></p><ul><li><p><strong>SSE-C</strong> requires customer provide encryption key vá»›i má»—i request</p></li><li><p>Keys <strong>KHÃ”NG managed by AWS KMS</strong></p></li><li><p><strong>NO audit trail</strong> from AWS services</p></li><li><p>Customer pháº£i tá»± manage keys vÃ  audit trail</p></li></ul><p></p><p>âŒ <strong>Server-side encryption with self-managed keys</strong></p><ul><li><p><strong>Self-managed keys</strong> = customer fully manage encryption keys outside AWS</p></li><li><p><strong>NO integration</strong> vá»›i AWS KMS</p></li><li><p><strong>NO automatic audit trail</strong> from AWS</p></li><li><p>Customer pháº£i build custom audit solution</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Audit trail of key usage\"</strong> â†’ <strong>SSE-KMS</strong></p></li><li><p><strong>S3 encryption options:</strong></p><ul><li><p><strong>SSE-S3</strong> = S3-managed keys, <strong>NO detailed audit</strong></p></li><li><p><strong>SSE-KMS</strong> = KMS-managed keys, <strong>full audit trail via CloudTrail</strong></p></li><li><p><strong>SSE-C</strong> = customer-provided keys, <strong>NO AWS audit</strong></p></li></ul></li><li><p><strong>SSE-KMS audit capabilities:</strong></p><ul><li><p>CloudTrail logs: kms:Decrypt, kms:GenerateDataKey</p></li><li><p>Track who accessed objects (IAM principal)</p></li><li><p>Track when keys used</p></li></ul></li><li><p>Company compliance/audit requirements â†’ SSE-KMS</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingKMSEncryption.html\">Using server-side encryption with AWS KMS keys (SSE-KMS)</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/kms/latest/developerguide/logging-using-cloudtrail.html\">Logging AWS KMS API calls with CloudTrail</a></p></li></ul>",
            "correctAnswer": [
                "<p>Server-side encryption with AWS KMS managed keys (SSE-KMS)</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Server-side encryption with Amazon S3 managed keys (SSE-S3)</p>",
                "<p>Server-side encryption with AWS KMS managed keys (SSE-KMS)</p>",
                "<p>Server-side encryption with customer-provided keys (SSE-C)</p>",
                "<p>Server-side encryption with self-managed keys</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 44
        },
        {
            "attemptAnswerId": 329706,
            "questionId": 7599,
            "questionText": "<p>A development team maintains a web application by using a single AWS RDS, template. The template defines web servers and an Amazon RDS database. The team uses the CloudFormation template to deploy the CloudFormation stack to different environments.<br><br>During a recent application deployment, a developer caused the primary development database to be dropped and recreated. The result of this incident was a loss of data. The team needs to avoid accidental database deletion in the future.<br><br>Which solutions will meet these requirements? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Team dÃ¹ng <strong>single CloudFormation template</strong> deploy web servers vÃ  <strong>RDS database</strong> to different environments</p></li><li><p>Recent incident: developer <strong>accidentally dropped vÃ  recreated</strong> primary development database â†’ <strong>loss of data</strong></p></li><li><p>Requirement: <strong>avoid accidental database deletion</strong> in future</p></li><li><p>Chá»n <strong>2 solutions</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Add a CloudFormation DeletionPolicy attribute with the Retain value to the database resource.</strong></p><ul><li><p><strong>DeletionPolicy: Retain</strong> ngÄƒn cháº·n CloudFormation tá»« deleting database khi stack deleted hoáº·c resource replaced</p></li><li><p>Database Ä‘Æ°á»£c <strong>retained</strong> thay vÃ¬ deleted</p></li><li><p>Protect against accidental deletion during stack updates</p></li><li><p>Apply directly trÃªn RDS database resource</p></li></ul><p></p><p><strong>Update the CloudFormation stack policy to prevent updates to the database.</strong></p><ul><li><p><strong>Stack policy</strong> ngÄƒn cháº·n cÃ¡c <strong>cáº­p nháº­t khÃ´ng mong muá»‘n</strong> Ä‘áº¿n resources cá»¥ thá»ƒ</p></li><li><p>Define policy Ä‘á»ƒ <strong>deny updates</strong> to database resource</p></li><li><p>Require explicit permission override Ä‘á»ƒ update database</p></li><li><p>ThÃªm <strong>protection layer</strong> chá»‘ng láº¡i accidental modifications</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Modify the database to use a Multi-AZ deployment.</strong></p><ul><li><p><strong>Multi-AZ</strong> provide <strong>high availability vÃ  failover</strong>, khÃ´ng pháº£i deletion protection</p></li><li><p>Multi-AZ khÃ´ng prevent accidental database deletion</p></li><li><p>KhÃ´ng address root cause cá»§a incident</p></li></ul><p></p><p>âŒ <strong>Create a CloudFormation stack set for the web application and database deployments.</strong></p><ul><li><p><strong>Stack sets</strong> dÃ¹ng Ä‘á»ƒ deploy <strong>same stack across multiple accounts/regions</strong></p></li><li><p>KhÃ´ng prevent accidental deletion</p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n deletion protection</p></li></ul><p></p><p>âŒ <strong>Add a CloudFormation DeletionPolicy attribute with the Retain value to the stack.</strong></p><ul><li><p>DeletionPolicy pháº£i apply trÃªn <strong>individual resource</strong> (database), khÃ´ng pháº£i entire stack</p></li><li><p>Apply trÃªn stack level khÃ´ng protect specific resources</p></li><li><p>Sai implementation</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Prevent accidental deletion\"</strong> â†’ <strong>DeletionPolicy: Retain + Stack Policy</strong></p></li><li><p><strong>CloudFormation DeletionPolicy:</strong></p><ul><li><p><strong>Retain</strong> = keep resource khi stack deleted/updated</p></li><li><p><strong>Snapshot</strong> = create snapshot before deletion (cho RDS/EBS)</p></li><li><p><strong>Delete</strong> = default, delete resource</p></li></ul></li><li><p><strong>Stack policy</strong> prevent updates/deletes to specific resources</p></li><li><p>DeletionPolicy apply trÃªn <strong>resource level</strong>, khÃ´ng pháº£i stack level</p></li><li><p>Multi-AZ = availability, khÃ´ng pháº£i deletion protection</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-attribute-deletionpolicy.html\">CloudFormation DeletionPolicy attribute</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html\">Prevent updates to stack resources with stack policies</a></p></li></ul>",
            "correctAnswer": [
                "<p>Update the CloudFormation stack policy to prevent updates to the database.</p>",
                "<p>Add a CloudFormation DeletionPolicy attribute with the Retain value to the database resource.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add a CloudFormation DeletionPolicy attribute with the Retain value to the database resource.</p>",
                "<p>Update the CloudFormation stack policy to prevent updates to the database.</p>",
                "<p>Modify the database to use a Multi-AZ deployment.</p>",
                "<p>Create a CloudFormation stack set for the web application and database deployments.</p>",
                "<p>Add a CloudFormation DeletionPolicy attribute with the Retain value to the stack.</p>"
            ],
            "answersPos": "[2,1,4,0,3]",
            "pos": 45
        },
        {
            "attemptAnswerId": 329707,
            "questionId": 7582,
            "questionText": "<p>A developer needs to deploy an application running on AWS Fargate using Amazon ECS. The application has environment variables that must be passed to a container for the application to initialize.<br><br>How should the environment variables be passed to the container?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer cáº§n deploy application trÃªn <strong>AWS Fargate using ECS</strong></p></li><li><p>Application cÃ³ <strong>environment variables</strong> cáº§n pass to container Ä‘á»ƒ initialize (khá»Ÿi táº¡o)</p></li><li><p>TÃ¬m cÃ¡ch pass environment variables to container</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Define an array that includes the environment variables under the environment parameter within the task definition.</strong></p><ul><li><p><strong>Task definition</strong> define container configuration, bao gá»“m environment variables</p></li><li><p><strong>environment parameter</strong> trong task definition cho phÃ©p specify key-value pairs</p></li><li><p>Format: <code>\"environment\": [{\"name\": \"KEY\", \"value\": \"VALUE\"}]</code></p></li><li><p>Container automatically receive environment variables khi start</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Define an array that includes the environment variables under the environment parameter within the service definition.</strong></p><ul><li><p><strong>Service definition</strong> define deployment configuration (desired count, load balancer, etc.)</p></li><li><p>Service definition <strong>KHÃ”NG chá»©a</strong> environment parameters</p></li><li><p>Environment variables pháº£i define trong <strong>task definition</strong>, khÃ´ng pháº£i service definition</p></li></ul><p></p><p>âŒ <strong>Define an array that includes the environment variables under the entryPoint parameter within the task definition.</strong></p><ul><li><p><strong>entryPoint</strong> parameter define <strong>command to run</strong> khi container starts</p></li><li><p>entryPoint <strong>KHÃ”NG dÃ¹ng</strong> Ä‘á»ƒ pass environment variables</p></li><li><p>Sai parameter</p></li></ul><p></p><p>âŒ <strong>Define an array that includes the environment variables under the entryPoint parameter within the service definition.</strong></p><ul><li><p>Service definition khÃ´ng cÃ³ entryPoint parameter</p></li><li><p>entryPoint khÃ´ng dÃ¹ng cho environment variables</p></li><li><p>Sai cáº£ location vÃ  parameter</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Pass environment variables to ECS container\"</strong> â†’ <strong>environment parameter trong task definition</strong></p></li><li><p><strong>ECS concepts:</strong></p><ul><li><p><strong>Task definition</strong> = blueprint cho container (image, CPU, memory, <strong>environment variables</strong>)</p></li><li><p><strong>Service definition</strong> = deployment config (desired count, load balancer)</p></li></ul></li><li><p><strong>Task definition environment format:</strong> </p><pre><code class=\"language-json\">\"environment\": [\n    {\"name\": \"DB_HOST\", \"value\": \"localhost\"},\n    {\"name\": \"PORT\", \"value\": \"3000\"}\n  ]</code></pre></li><li><p><strong>entryPoint</strong> = container command, khÃ´ng pháº£i environment variables</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/taskdef-envfiles.html\">ECS task definition - environment variables</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/use-environment-file.html\">Passing environment variables to containers</a></p></li></ul><p></p><p><em>ÄÃ¢y lÃ  vÃ­ dá»¥ vá» ECS task definition file vá»›i environment variables:</em></p><pre><code>{\n  \"family\": \"my-app-task\",\n  \"networkMode\": \"awsvpc\",\n  \"requiresCompatibilities\": [\"FARGATE\"],\n  \"cpu\": \"256\",\n  \"memory\": \"512\",\n  \"containerDefinitions\": [\n    {\n      \"name\": \"my-app-container\",\n      \"image\": \"my-app:latest\",\n      \"essential\": true,\n      \"portMappings\": [\n        {\n          \"containerPort\": 3000,\n          \"protocol\": \"tcp\"\n        }\n      ],\n      \"environment\": [\n        {\n          \"name\": \"NODE_ENV\",\n          \"value\": \"production\"\n        },\n        {\n          \"name\": \"DB_HOST\",\n          \"value\": \"mydb.example.com\"\n        },\n        {\n          \"name\": \"DB_PORT\",\n          \"value\": \"5432\"\n        },\n        {\n          \"name\": \"APP_PORT\",\n          \"value\": \"3000\"\n        }\n      ],\n      \"secrets\": [\n        {\n          \"name\": \"DB_PASSWORD\",\n          \"valueFrom\": \"arn:aws:secretsmanager:region:account:secret:db-password\"\n        }\n      ],\n      \"logConfiguration\": {\n        \"logDriver\": \"awslogs\",\n        \"options\": {\n          \"awslogs-group\": \"/ecs/my-app\",\n          \"awslogs-region\": \"us-east-1\",\n          \"awslogs-stream-prefix\": \"ecs\"\n        }\n      }\n    }\n  ],\n  \"executionRoleArn\": \"arn:aws:iam::account:role/ecsTaskExecutionRole\",\n  \"taskRoleArn\": \"arn:aws:iam::account:role/ecsTaskRole\"\n}</code></pre>",
            "correctAnswer": [
                "<p>Define an array that includes the environment variables under the environment parameter within the task definition.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Define an array that includes the environment variables under the environment parameter within the service definition.</p>",
                "<p>Define an array that includes the environment variables under the environment parameter within the task definition.</p>",
                "<p>Define an array that includes the environment variables under the entryPoint parameter within the task definition.</p>",
                "<p>Define an array that includes the environment variables under the entryPoint parameter within the service definition.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 46
        },
        {
            "attemptAnswerId": 329708,
            "questionId": 7583,
            "questionText": "<p>A developer has been asked to create an AWS Lambda function that is invoked any time updates are made to items in an Amazon DynamoDB table. The function has been created, and appropriate permissions have been added to the Lambda execution role. Amazon DynamoDB streams have been enabled for the table, but the function is still not being invoked.<br><br>Which option would enable DynamoDB table updates to invoke the Lambda function?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Lambda function cáº§n Ä‘Æ°á»£c invoked khi <strong>updates made to DynamoDB table</strong></p></li><li><p>Setup hiá»‡n táº¡i:</p><ul><li><p>Lambda function Ä‘Ã£ created</p></li><li><p><strong>Appropriate permissions</strong> added to Lambda execution role</p></li><li><p><strong>DynamoDB Streams enabled</strong> for table</p></li></ul></li><li><p>Issue: function <strong>still NOT being invoked</strong></p></li><li><p>TÃ¬m option Ä‘á»ƒ enable DynamoDB updates invoke Lambda</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Configure event source mapping for the Lambda function.</strong></p><ul><li><p><strong>Event source mapping</strong> lÃ  link giá»¯a DynamoDB stream vÃ  Lambda function</p></li><li><p>Event source mapping tell Lambda <strong>poll DynamoDB stream</strong> vÃ  invoke function khi cÃ³ new records</p></li><li><p>Required step Ä‘á»ƒ connect stream vá»›i Lambda</p></li><li><p>Missing piece trong current setup</p></li></ul><p></p><p><em>Kiáº¿n trÃºc tham kháº£o</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1761377626193-tyzoe057-image.png\" alt=\"\" title=\"\" width=\"514\" height=\"215.398125\" style=\"max-width: 514px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Change the StreamViewType parameter value to NEW_AND_OLD_IMAGES for the DynamoDB table.</strong></p><ul><li><p><strong>StreamViewType</strong> define data included trong stream records (KEYS_ONLY, NEW_IMAGE, OLD_IMAGE, NEW_AND_OLD_IMAGES)</p></li><li><p>Changing StreamViewType <strong>KHÃ”NG enable invocation</strong> náº¿u thiáº¿u event source mapping</p></li><li><p>StreamViewType chá»‰ áº£nh hÆ°á»Ÿng Ä‘áº¿n data content, khÃ´ng pháº£i cÆ¡ cháº¿ invocation</p></li></ul><p></p><p>âŒ <strong>Map an Amazon Simple Notification Service (Amazon SNS) topic to the DynamoDB streams.</strong></p><ul><li><p><strong>DynamoDB Streams KHÃ”NG directly integrate</strong> vá»›i SNS</p></li><li><p>Lambda cÃ³ thá»ƒ directly poll DynamoDB Streams, khÃ´ng cáº§n SNS intermediate</p></li><li><p>Adds unnecessary complexity</p></li></ul><p></p><p>âŒ <strong>Increase the maximum runtime (timeout) setting of the Lambda function.</strong></p><ul><li><p><strong>Timeout setting</strong> áº£nh hÆ°á»Ÿng Ä‘áº¿n execution duration, khÃ´ng pháº£i invocation trigger</p></li><li><p>Function khÃ´ng Ä‘Æ°á»£c invoked â†’ timeout khÃ´ng relevant</p></li><li><p>KhÃ´ng giáº£i quyáº¿t missing trigger issue</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"DynamoDB Streams + Lambda\"</strong> â†’ cáº§n <strong>Event Source Mapping</strong></p></li><li><p><strong>DynamoDB Streams integration steps:</strong></p><ol><li><p>Enable DynamoDB Streams on table âœ“</p></li><li><p>Grant Lambda permissions (execution role) âœ“</p></li><li><p><strong>Create event source mapping</strong> â† Missing step</p></li></ol></li><li><p><strong>Event source mapping</strong> = connection giá»¯a stream vÃ  Lambda</p></li><li><p>StreamViewType = data content, khÃ´ng pháº£i trigger mechanism</p></li><li><p>DynamoDB Streams â†’ Lambda direct integration, khÃ´ng cáº§n SNS</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventsourcemapping.html\">How Lambda processes records from stream and queue-based event sources</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html\">Event source mapping for DynamoDB</a></p></li></ul>",
            "correctAnswer": [
                "<p>Configure event source mapping for the Lambda function.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Change the StreamViewType parameter value to NEW_AND_OLD_IMAGES for the DynamoDB table.</p>",
                "<p>Configure event source mapping for the Lambda function.</p>",
                "<p>Map an Amazon Simple Notification Service (Amazon SNS) topic to the DynamoDB streams.</p>",
                "<p>Increase the maximum runtime (timeout) setting of the Lambda function.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 47
        },
        {
            "attemptAnswerId": 329709,
            "questionId": 7584,
            "questionText": "<p>A company is using AWS CloudFormation to deploy a two-tier application. The application will use Amazon RDS as its backend database. The company wants a solution that will randomly generate the database password during deployment. The solution also must automatically rotate the database password without requiring changes to the application.<br><br>What is the MOST operationally efficient solution that meets these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company dÃ¹ng <strong>CloudFormation</strong> deploy two-tier application vá»›i <strong>RDS backend</strong></p></li><li><p>Requirements:</p><ul><li><p><strong>Randomly generate</strong> database password during deployment</p></li><li><p><strong>Automatically rotate</strong> password without application changes</p></li><li><p><strong>MOST operationally efficient</strong></p></li></ul></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use an AWS Secrets Manager resource to generate and rotate the password.</strong></p><ul><li><p><strong>Secrets Manager</strong> cÃ³ thá»ƒ <strong>generate random password</strong> khi create secret</p></li><li><p><strong>Built-in automatic rotation</strong> cho RDS databases vá»›i rotation templates</p></li><li><p><strong>CloudFormation native support</strong>: <code>AWS::SecretsManager::Secret</code> resource</p></li><li><p>Rotation automatically update password trong <strong>cáº£ Secrets Manager vÃ  RDS</strong></p></li><li><p>Application retrieve password tá»« Secrets Manager â†’ no code changes needed</p></li><li><p>Most operationally efficient: fully managed, no custom code</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use an AWS Lambda function as a CloudFormation custom resource to generate and rotate the password.</strong></p><ul><li><p>Pháº£i <strong>write custom Lambda code</strong> cho generation vÃ  rotation</p></li><li><p>More operational overhead so vá»›i Secrets Manager</p></li><li><p>Pháº£i maintain custom rotation logic</p></li><li><p>KhÃ´ng pháº£i most operationally efficient</p></li></ul><p></p><p>âŒ <strong>Use an AWS Systems Manager Parameter Store resource with the SecureString data type to generate and rotate the password.</strong></p><ul><li><p>Parameter Store cÃ³ thá»ƒ store encrypted passwords</p></li><li><p>NhÆ°ng <strong>KHÃ”NG cÃ³ built-in automatic rotation</strong></p></li><li><p>Pháº£i build custom rotation logic</p></li><li><p>KhÃ´ng operationally efficient</p></li></ul><p></p><p>âŒ <strong>Use a cron daemon on the application's host to generate and rotate the password.</strong></p><ul><li><p><strong>Cron daemon</strong> = manual implementation, high operational overhead</p></li><li><p>Pháº£i manage cron jobs, handle failures</p></li><li><p>Requires application host access</p></li><li><p>Least operationally efficient</p></li><li><p>Not CloudFormation-native</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Generate + automatically rotate password + CloudFormation\"</strong> â†’ <strong>Secrets Manager</strong></p></li><li><p><strong>Secrets Manager trong CloudFormation:</strong></p><ul><li><p><code>AWS::SecretsManager::Secret</code> = create secret</p></li><li><p><code>GenerateSecretString</code> = auto-generate random password</p></li><li><p>Built-in rotation for RDS/DocumentDB/Aurora</p></li></ul></li><li><p><strong>Secrets Manager vs Parameter Store:</strong></p><ul><li><p>Secrets Manager = <strong>automatic rotation</strong> + versioning</p></li><li><p>Parameter Store = <strong>NO automatic rotation</strong></p></li></ul></li><li><p>Cron daemon = manual, not managed, not efficient</p></li><li><p>Custom Lambda = more code to maintain</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-resource-secretsmanager-secret.html\">AWS::SecretsManager::Secret</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use an AWS Secrets Manager resource to generate and rotate the password.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use an AWS Lambda function as a CloudFormation custom resource to generate and rotate the password.</p>",
                "<p>Use an AWS Systems Manager Parameter Store resource with the SecureString data type to generate and rotate the password.</p>",
                "<p>Use a cron daemon on the applicationâ€™s host to generate and rotate the password.</p>",
                "<p>Use an AWS Secrets Manager resource to generate and rotate the password.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 48
        },
        {
            "attemptAnswerId": 329710,
            "questionId": 7600,
            "questionText": "<p>A company is building a microservices application that consists of many AWS Lambda functions. The development team wants to use AWS Serverless Application Model (AWS SAM) templates to automatically test the Lambda functions. The development team plans to test a small percentage of traffic that is directed to new updates before the team commits to a full deployment of the application.<br><br>Which combination of steps will meet these requirements in the MOST operationally efficient way? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Microservices application vá»›i nhiá»u <strong>Lambda functions</strong></p></li><li><p>Development team dÃ¹ng <strong>AWS SAM templates</strong> Ä‘á»ƒ automatically test Lambda</p></li><li><p>Requirements:</p><ul><li><p>Test <strong>small percentage of traffic</strong> directed to new updates</p></li><li><p><strong>Before committing</strong> to full deployment</p></li><li><p><strong>MOST operationally efficient</strong></p></li></ul></li><li><p>Chá»n <strong>2 solutions</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Enable gradual deployments through AWS SAM templates.</strong></p><ul><li><p><strong>Gradual deployments</strong> (canary/linear deployments) trong SAM cho phÃ©p shift traffic incrementally (tÄƒng dáº§n)</p></li><li><p>Configure trong SAM template vá»›i <code>DeploymentPreference</code></p></li><li><p>SAM automatically integrate vá»›i <strong>CodeDeploy</strong> Ä‘á»ƒ manage traffic shifting</p></li><li><p>Operationally efficient: cáº¥u hÃ¬nh <strong>declarative</strong> (khai bÃ¡o) trong template</p></li></ul><p></p><p><strong>Set the deployment preference type to Canary10Percent30Minutes. Use hooks to test the deployment.</strong></p><ul><li><p><strong>Canary10Percent30Minutes</strong> = shift <strong>10% traffic first</strong>, wait 30 minutes, then shift remaining 90%</p></li><li><p>Test <strong>small percentage of traffic</strong> nhÆ° requirement</p></li><li><p><strong>Hooks</strong> (PreTraffic, PostTraffic) cho phÃ©p run automated tests before full deployment</p></li><li><p>Fast validation: 30 minutes Ä‘á»ƒ test 10% traffic, then commit to full deployment</p></li><li><p>Operationally efficient: built-in SAM deployment preference</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use AWS SAM CLI commands in AWS CodeDeploy to invoke the Lambda functions to test the deployment.</strong></p><ul><li><p>SAM CLI dÃ¹ng Ä‘á»ƒ <strong>build/deploy</strong>, khÃ´ng pháº£i invoke functions trong CodeDeploy</p></li><li><p>KhÃ´ng pháº£i declarative approach trong templates</p></li><li><p>Manual invocation khÃ´ng pháº£i gradual deployment</p></li></ul><p></p><p>âŒ <strong>Declare the EventInvokeConfig on the Lambda functions in the AWS SAM templates with OnSuccess and OnFailure configurations.</strong></p><ul><li><p><strong>EventInvokeConfig</strong> configure <strong>asynchronous invocation behavior</strong> (retry, DLQ)</p></li><li><p><strong>KHÃ”NG liÃªn quan</strong> Ä‘áº¿n gradual deployments hoáº·c traffic shifting</p></li><li><p>OnSuccess/OnFailure dÃ¹ng cho destination configuration, khÃ´ng pháº£i deployment strategy</p></li></ul><p></p><p>âŒ <strong>Set the deployment preference type to Linear10PercentEvery10Minutes. Use hooks to test the deployment.</strong></p><ul><li><p><strong>Linear10PercentEvery10Minutes</strong> = shift 10% every 10 minutes (10 increments total = <strong>100 minutes</strong>)</p></li><li><p>Requirement lÃ  \"test small percentage <strong>before committing</strong> to full deployment\"</p></li><li><p><strong>Canary pattern</strong> phÃ¹ há»£p hÆ¡n: test 10% â†’ validate â†’ commit 90%</p></li><li><p>Linear deployment máº¥t nhiá»u thá»i gian hÆ¡n (100 minutes vs 30 minutes)</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Test small percentage before full deployment\"</strong> â†’ <strong>Canary deployment</strong></p></li><li><p><strong>SAM deployment preferences:</strong></p><ul><li><p><strong>Canary10Percent30Minutes</strong> = 10% traffic for 30 min â†’ then 90%</p></li><li><p><strong>Linear10PercentEvery10Minutes</strong> = 10% â†’ 20% â†’ ... â†’ 100% (100 min total)</p></li><li><p><strong>AllAtOnce</strong> = immediate full deployment</p></li></ul></li><li><p><strong>Canary vs Linear:</strong></p><ul><li><p><strong>Canary</strong> = test small percentage â†’ validate â†’ commit rest (faster validation)</p></li><li><p><strong>Linear</strong> = gradual incremental rollout (slower, more conservative)</p></li></ul></li><li><p><strong>Hooks</strong> = PreTraffic vÃ  PostTraffic Lambda functions Ä‘á»ƒ run automated tests</p></li><li><p>EventInvokeConfig = async invocation settings, khÃ´ng pháº£i deployment</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/automating-updates-to-serverless-apps.html\">Deploying serverless applications gradually with AWS SAM</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-property-function-deploymentpreference.html\">Deployment preference types in SAM</a></p></li></ul>",
            "correctAnswer": [
                "<p>Set the deployment preference type to Canary10Percent30Minutes. Use hooks to test the deployment.</p>",
                "<p>Enable gradual deployments through AWS SAM templates.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use AWS SAM CLI commands in AWS CodeDeploy to invoke the Lambda functions to test the deployment.</p>",
                "<p>Declare the EventInvokeConfig on the Lambda functions in the AWS SAM templates with OnSuccess and OnFailure configurations.</p>",
                "<p>Enable gradual deployments through AWS SAM templates.</p>",
                "<p>Set the deployment preference type to Canary10Percent30Minutes. Use hooks to test the deployment.</p>",
                "<p>Set the deployment preference type to Linear10PercentEvery10Minutes. Use hooks to test the deployment.</p>"
            ],
            "answersPos": "[3,2,1,0,4]",
            "pos": 49
        },
        {
            "attemptAnswerId": 329711,
            "questionId": 7585,
            "questionText": "<p>A company developed an API application on AWS by using Amazon CloudFront, Amazon API Gateway, and AWS Lambda. The API has a minimum of four requests every second. A developer notices that many API users run the same query by using the POST method. The developer wants to cache the POST request to optimize the API resources.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>API application: <strong>CloudFront + API Gateway + Lambda</strong></p></li><li><p>API cÃ³ minimum <strong>4 requests má»—i giÃ¢y</strong></p></li><li><p>Issue: many users run <strong>same query using POST method</strong></p></li><li><p>Developer muá»‘n <strong>cache POST request</strong> Ä‘á»ƒ optimize API resources</p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Override the cache method in the selected stage of API Gateway. Select the POST method.</strong></p><ul><li><p><strong>API Gateway</strong> há»— trá»£ <strong>caching responses</strong> cho API methods</p></li><li><p>Default: API Gateway <strong>chá»‰ cache GET requests</strong></p></li><li><p>CÃ³ thá»ƒ <strong>override cache settings</strong> Ä‘á»ƒ enable caching cho <strong>POST method</strong></p></li><li><p>Configure cache key parameters Ä‘á»ƒ cache identical POST requests</p></li><li><p>Direct solution táº¡i API Gateway layer</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure the CloudFront cache. Update the application to return cached content based upon the default request headers.</strong></p><ul><li><p><strong>CloudFront default</strong> KHÃ”NG cache <strong>POST requests</strong> (chá»‰ cache GET/HEAD)</p></li><li><p>CloudFront designed cho static content caching, khÃ´ng pháº£i API POST caching</p></li><li><p>KhÃ´ng giáº£i quyáº¿t POST caching requirement</p></li></ul><p></p><p>âŒ <strong>Save the latest request response in Lambda /tmp directory. Update the Lambda function to check the /tmp directory.</strong></p><ul><li><p><strong>/tmp directory</strong> chá»‰ available trong <strong>single Lambda execution environment</strong></p></li><li><p>KHÃ”NG shared across multiple Lambda invocations/instances</p></li><li><p>KhÃ´ng work cho distributed requests tá»« multiple users</p></li><li><p>Not a caching solution</p></li></ul><p></p><p>âŒ <strong>Save the latest request in AWS Systems Manager Parameter Store. Modify the Lambda function to take the latest request response from Parameter Store.</strong></p><ul><li><p><strong>Parameter Store</strong> KHÃ”NG designed cho <strong>high-frequency caching</strong></p></li><li><p>API calls to Parameter Store add latency</p></li><li><p>Rate limits trÃªn Parameter Store API</p></li><li><p>KhÃ´ng hiá»‡u quáº£ cho 4+ requests/second</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Cache POST requests in API Gateway\"</strong> â†’ <strong>Override cache method settings</strong></p></li><li><p><strong>API Gateway caching:</strong></p><ul><li><p>Default: cache <strong>GET requests only</strong></p></li><li><p>Can enable caching cho <strong>POST/PUT/PATCH</strong> by overriding method</p></li><li><p>Configure cache key from request body/headers/query strings</p></li></ul></li><li><p><strong>CloudFront</strong> KHÃ”NG cache POST requests by default</p></li><li><p><strong>Lambda /tmp</strong> = NOT shared across invocations</p></li><li><p>Parameter Store = NOT designed for high-frequency caching</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html\">Cache settings for REST APIs in API Gateway</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html#override-api-gateway-stage-cache-for-method-cache\">Override API Gateway stage-level caching for method-level caching</a></p></li></ul>",
            "correctAnswer": [
                "<p>Override the cache method in the selected stage of API Gateway. Select the POST method.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure the CloudFront cache. Update the application to return cached content based upon the default request headers.</p>",
                "<p>Override the cache method in the selected stage of API Gateway. Select the POST method.</p>",
                "<p>Save the latest request response in Lambda /tmp directory. Update the Lambda function to check the /tmp directory.</p>",
                "<p>Save the latest request in AWS Systems Manager Parameter Store. Modify the Lambda function to take the latest request response from Parameter Store.</p>"
            ],
            "answersPos": "[0,1,3,2]",
            "pos": 50
        },
        {
            "attemptAnswerId": 329712,
            "questionId": 7586,
            "questionText": "<p>A developer is troubleshooting an Amazon API Gateway API. Clients are receiving HTTP 400 response errors when the clients try to access an endpoint of the API.<br><br>How can the developer determine the cause of these errors?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Clients receiving <strong>HTTP 400 errors</strong> khi access <strong>API Gateway endpoint</strong></p></li><li><p>Developer cáº§n <strong>determine the cause</strong> of errors</p></li><li><p>TÃ¬m solution Ä‘á»ƒ troubleshoot</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Turn on execution logging and access logging in Amazon CloudWatch Logs for the API stage. Create a CloudWatch Logs log group. Specify the Amazon Resource Name (ARN) of the log group for the API stage.</strong></p><ul><li><p><strong>Execution logging</strong> capture detailed logs vá» <strong>request/response data, errors, API Gateway processing</strong></p></li><li><p><strong>Access logging</strong> capture <strong>who accessed API vÃ  when</strong></p></li><li><p>CloudWatch Logs contain <strong>error details, request parameters, validation errors</strong> â†’ identify cause of 400 errors</p></li><li><p>Direct solution cho API Gateway troubleshooting</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create an Amazon Kinesis Data Firehose delivery stream to receive API call logs from API Gateway. Configure Amazon CloudWatch Logs as the delivery stream's destination.</strong></p><ul><li><p><strong>API Gateway KHÃ”NG directly send logs</strong> to Kinesis Firehose</p></li><li><p>Firehose dÃ¹ng cho streaming data delivery, khÃ´ng pháº£i API Gateway logging</p></li><li><p>Unnecessary complexity</p></li></ul><p></p><p>âŒ <strong>Turn on AWS CloudTrail Insights and create a trail. Specify the Amazon Resource Name (ARN) of the trail for the stage of the API.</strong></p><ul><li><p><strong>CloudTrail</strong> logs <strong>AWS API calls</strong> (management events), khÃ´ng pháº£i application-level API requests</p></li><li><p>CloudTrail KHÃ”NG capture <strong>HTTP 400 errors</strong> tá»« API Gateway endpoints</p></li><li><p>CloudTrail Insights detect unusual API activity, khÃ´ng pháº£i troubleshoot individual requests</p></li></ul><p></p><p>âŒ <strong>Turn on AWS X-Ray for the API stage. Create an Amazon CloudWatch Logs log group. Specify the Amazon Resource Name (ARN) of the log group for the API stage.</strong></p><ul><li><p><strong>X-Ray</strong> dÃ¹ng cho <strong>distributed tracing</strong>, track requests across services</p></li><li><p>X-Ray tá»‘t cho <strong>performance analysis</strong>, khÃ´ng pháº£i detailed error troubleshooting</p></li><li><p><strong>Execution logging</strong> better cho examining HTTP 400 validation/request errors</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Troubleshoot API Gateway errors\"</strong> â†’ <strong>Enable execution logging + access logging</strong></p></li><li><p><strong>API Gateway logging types:</strong></p><ul><li><p><strong>Execution logging</strong> = detailed request/response, errors, transformations</p></li><li><p><strong>Access logging</strong> = who accessed, when, response codes</p></li></ul></li><li><p><strong>CloudTrail</strong> = AWS API calls audit, khÃ´ng pháº£i application API requests</p></li><li><p><strong>X-Ray</strong> = distributed tracing, performance, khÃ´ng pháº£i detailed error logs</p></li><li><p>Kinesis Firehose khÃ´ng integrate directly vá»›i API Gateway logs</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-logging.html\">Set up CloudWatch logging for REST APIs in API Gateway</a></p></li></ul>",
            "correctAnswer": [
                "<p>Turn on execution logging and access logging in Amazon CloudWatch Logs for the API stage. Create a CloudWatch Logs log group. Specify the Amazon Resource Name (ARN) of the log group for the API stage.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an Amazon Kinesis Data Firehose delivery stream to receive API call logs from API Gateway. Configure Amazon CloudWatch Logs as the delivery streamâ€™s destination.</p>",
                "<p>Turn on AWS CloudTrail Insights and create a trail. Specify the Amazon Resource Name (ARN) of the trail for the stage of the API.</p>",
                "<p>Turn on AWS X-Ray for the API stage. Create an Amazon CloudWatch Logs log group. Specify the Amazon Resource Name (ARN) of the log group for the API stage.</p>",
                "<p>Turn on execution logging and access logging in Amazon CloudWatch Logs for the API stage. Create a CloudWatch Logs log group. Specify the Amazon Resource Name (ARN) of the log group for the API stage.</p>"
            ],
            "answersPos": "[1,0,3,2]",
            "pos": 51
        },
        {
            "attemptAnswerId": 329713,
            "questionId": 7587,
            "questionText": "<p>A company has an application that runs as a series of AWS Lambda functions. Each Lambda function receives data from an Amazon Simple Notification Service (Amazon SNS) topic and writes the data to an Amazon Aurora DB instance.<br><br>To comply with an information security policy, the company must ensure that the Lambda functions all use a single securely encrypted database connection string to access Aurora.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application: <strong>Lambda functions</strong> receive data tá»« <strong>SNS</strong> vÃ  write to <strong>Aurora DB</strong></p></li><li><p>Information security policy requirements:</p><ul><li><p>All Lambda functions use <strong>single securely encrypted database connection string</strong></p></li><li><p><strong>Secure access</strong> to Aurora</p></li></ul></li><li><p>TÃ¬m solution Ä‘Ã¡p á»©ng requirements</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Store the credentials in AWS Systems Manager Parameter Store as a secure string parameter.</strong></p><ul><li><p><strong>Parameter Store SecureString</strong> encrypt credentials at rest vá»›i AWS KMS</p></li><li><p><strong>Single source of truth</strong>: all Lambda functions retrieve tá»« same parameter</p></li><li><p>Lambda functions cÃ³ thá»ƒ securely retrieve credentials at runtime</p></li><li><p>Cost-effective vÃ  simple solution</p></li><li><p>Centralized credential management</p></li></ul><p></p><p><em>Kiáº¿n trÃºc tham kháº£o</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1761462983323-vamh3mz9-image.png\" alt=\"\" title=\"\" width=\"561\" height=\"479.33359375\" style=\"max-width: 561px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use IAM database authentication for Aurora to enable secure database connections for all the Lambda functions.</strong></p><ul><li><p><strong>IAM database authentication</strong> dÃ¹ng <strong>temporary tokens</strong>, khÃ´ng pháº£i <strong>connection string</strong></p></li><li><p>Requirement specify \"<strong>database connection string</strong>\" â†’ IAM auth khÃ´ng dÃ¹ng connection string</p></li><li><p>KhÃ´ng meet specific requirement vá» connection string</p></li></ul><p></p><p>âŒ <strong>Store the credentials and read the credentials from an encrypted Amazon RDS DB instance.</strong></p><ul><li><p>Store credentials <strong>trong database</strong> = circular dependency (cáº§n credentials Ä‘á»ƒ access database chá»©a credentials)</p></li><li><p>Bad practice: credentials khÃ´ng nÃªn store trong database</p></li><li><p>KhÃ´ng logical solution</p></li></ul><p></p><p>âŒ <strong>Use Lambda environment variables with a shared AWS Key Management Service (AWS KMS) key for encryption.</strong></p><ul><li><p><strong>Environment variables</strong> pháº£i define <strong>tá»«ng Lambda function</strong></p></li><li><p>KhÃ´ng pháº£i <strong>single shared credential</strong> across all functions</p></li><li><p>Náº¿u update credentials, pháº£i update <strong>all Lambda functions individually</strong></p></li><li><p>KhÃ´ng operationally efficient</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Shared credentials across Lambda functions\"</strong> â†’ <strong>Parameter Store SecureString</strong></p></li><li><p><strong>Parameter Store benefits:</strong></p><ul><li><p>Centralized credential storage</p></li><li><p>Encrypted at rest vá»›i KMS</p></li><li><p>All Lambda functions retrieve tá»« single source</p></li><li><p>Easy credential rotation</p></li></ul></li><li><p><strong>IAM database authentication</strong> = temporary tokens, khÃ´ng pháº£i connection strings</p></li><li><p>Lambda environment variables = per-function, khÃ´ng shared</p></li><li><p>NEVER store credentials trong database itself</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/ps-integration-lambda-extensions.html\">Using Parameter Store parameters in AWS Lambda functions</a></p></li></ul>",
            "correctAnswer": [
                "<p>Store the credentials in AWS Systems Manager Parameter Store as a secure string parameter.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use IAM database authentication for Aurora to enable secure database connections for all the Lambda functions.</p>",
                "<p>Store the credentials and read the credentials from an encrypted Amazon RDS DB instance.</p>",
                "<p>Store the credentials in AWS Systems Manager Parameter Store as a secure string parameter.</p>",
                "<p>Use Lambda environment variables with a shared AWS Key Management Service (AWS KMS) key for encryption.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 52
        },
        {
            "attemptAnswerId": 329714,
            "questionId": 7601,
            "questionText": "<p>A developer is working on a Python application that runs on Amazon EC2 instances. The developer wants to enable tracing of application requests to debug performance issues in the code.</p><p></p><p>Which combination of actions should the developer take to achieve this goal? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer working on <strong>Python application</strong> trÃªn <strong>EC2 instances</strong></p></li><li><p>Muá»‘n enable <strong>tracing of application requests</strong> Ä‘á»ƒ debug performance issues</p></li><li><p>Chá»n <strong>2 actions</strong> Ä‘á»ƒ achieve goal</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Install the AWS X-Ray daemon on the EC2 instances.</strong></p><ul><li><p><strong>X-Ray daemon</strong> lÃ  agent cháº¡y trÃªn EC2 Ä‘á»ƒ <strong>collect trace data</strong> tá»« application</p></li><li><p>Daemon listen for trace data vÃ  forward to X-Ray service</p></li><li><p>Required component Ä‘á»ƒ send traces to X-Ray</p></li></ul><p></p><p><strong>Install and configure the AWS X-Ray SDK for Python in the application.</strong></p><ul><li><p><strong>X-Ray SDK</strong> instrument application code Ä‘á»ƒ <strong>generate trace data</strong></p></li><li><p>SDK capture request/response data, subsegments, annotations</p></li><li><p>Required Ä‘á»ƒ application cÃ³ thá»ƒ create vÃ  send traces</p></li><li><p>Python SDK: <code>import aws_xray_sdk</code></p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Install the Amazon CloudWatch agent on the EC2 instances.</strong></p><ul><li><p><strong>CloudWatch agent</strong> collect <strong>metrics vÃ  logs</strong>, khÃ´ng pháº£i traces</p></li><li><p>CloudWatch khÃ´ng pháº£i distributed tracing service</p></li><li><p>KhÃ´ng giÃºp debug performance vá»›i request tracing</p></li></ul><p></p><p>âŒ <strong>Configure the application to write JSON-formatted logs to /var/log/cloudwatch.</strong></p><ul><li><p>Writing logs to <code>/var/log/cloudwatch</code> KHÃ”NG automatically send to CloudWatch</p></li><li><p>Logs khÃ´ng pháº£i <strong>distributed tracing</strong></p></li><li><p>KhÃ´ng provide request flow visualization nhÆ° X-Ray</p></li></ul><p></p><p>âŒ <strong>Configure the application to write trace data to /var/log/xray.</strong></p><ul><li><p><strong>KHÃ”NG cÃ³</strong> <code>/var/log/xray</code> directory cho X-Ray</p></li><li><p>X-Ray daemon listen on <strong>UDP port 2000</strong>, khÃ´ng Ä‘á»c tá»« log files</p></li><li><p>Application send traces to daemon qua SDK, khÃ´ng pháº£i write to files</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Application tracing on EC2\"</strong> â†’ <strong>X-Ray daemon + X-Ray SDK</strong></p></li><li><p><strong>X-Ray architecture:</strong></p><ol><li><p><strong>X-Ray SDK</strong> = instrument application code (generate traces)</p></li><li><p><strong>X-Ray daemon</strong> = collect vÃ  forward traces to X-Ray service</p></li></ol></li><li><p><strong>CloudWatch</strong> = metrics vÃ  logs, khÃ´ng pháº£i distributed tracing</p></li><li><p>X-Ray traces sent to daemon via <strong>UDP port 2000</strong>, khÃ´ng pháº£i log files</p></li><li><p>Both daemon vÃ  SDK required cho X-Ray tracing</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-python.html\">AWS X-Ray SDK for Python</a></p></li></ul>",
            "correctAnswer": [
                "<p>Install the AWS X-Ray daemon on the EC2 instances.</p>",
                "<p>Install and configure the AWS X-Ray SDK for Python in the application.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Install the Amazon CloudWatch agent on the EC2 instances.</p>",
                "<p>Install the AWS X-Ray daemon on the EC2 instances.</p>",
                "<p>Configure the application to write JSON-formatted logs to <code>/var/log/cloudwatch</code>.</p>",
                "<p>Configure the application to write trace data to <code>/var/log/xray</code>.</p>",
                "<p>Install and configure the AWS X-Ray SDK for Python in the application.</p>"
            ],
            "answersPos": "[0,1,2,3,4]",
            "pos": 53
        },
        {
            "attemptAnswerId": 329715,
            "questionId": 7588,
            "questionText": "<p>A company is building an application for stock trading. The application needs sub-millisecond latency for processing trade requests. The company uses Amazon DynamoDB to store all the trading data that is used to process each trading request.<br><br>A development team performs load testing on the application and finds that the data retrieval time is higher than expected. The development team needs a solution that reduces the data retrieval time with the least possible effort.<br><br>Which solution meets these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Stock trading application cáº§n <strong>sub-millisecond latency</strong> Ä‘á»ƒ process trade requests</p></li><li><p>DÃ¹ng <strong>DynamoDB</strong> store all trading data</p></li><li><p>Issue: <strong>data retrieval time higher than expected</strong> during load testing</p></li><li><p>Requirement: reduce data retrieval time vá»›i <strong>least possible effort</strong></p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use DynamoDB Accelerator (DAX) to cache the trading data.</strong></p><ul><li><p><strong>DAX</strong> lÃ  <strong>in-memory cache</strong> cho DynamoDB vá»›i <strong>microsecond latency</strong></p></li><li><p>Transparent caching: <strong>no application code changes</strong> needed (chá»‰ Ä‘á»•i endpoint)</p></li><li><p>DAX automatically cache read queries vÃ  invalidate cache on writes</p></li><li><p><strong>Least effort</strong>: fully managed, minimal configuration</p></li><li><p>Perfect cho use case cáº§n <strong>sub-millisecond latency</strong></p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Add local secondary indexes (LSIs) for the trading data.</strong></p><ul><li><p><strong>LSIs</strong> improve query flexibility, KHÃ”NG reduce latency Ä‘Ã¡ng ká»ƒ láº¯m</p></li><li><p>LSIs váº«n query tá»« DynamoDB tables (same performance characteristics)</p></li><li><p>KhÃ´ng provide caching hoáº·c sub-millisecond improvement</p></li><li><p>LSIs pháº£i táº¡o <strong>at table creation time</strong> (khÃ´ng thá»ƒ thÃªm sau)</p></li></ul><p></p><p>âŒ <strong>Store the trading data in Amazon S3, and use S3 Transfer Acceleration.</strong></p><ul><li><p><strong>S3</strong> KHÃ”NG designed cho <strong>low-latency queries</strong> nhÆ° DynamoDB</p></li><li><p>S3 latency <strong>higher</strong> than DynamoDB</p></li><li><p>Transfer Acceleration optimize uploads, khÃ´ng pháº£i query latency</p></li><li><p>Migration to S3 = tá»‘n khÃ¡ nhiá»u effort, khÃ´ng pháº£i least effort</p></li></ul><p></p><p>âŒ <strong>Add retries with exponential backoff for DynamoDB queries.</strong></p><ul><li><p><strong>Exponential backoff</strong> dÃ¹ng cho <strong>handling throttling errors</strong>, khÃ´ng pháº£i improve latency</p></li><li><p>Retries <strong>TÄ‚NG</strong> latency, khÃ´ng giáº£m</p></li><li><p>KhÃ´ng address root cause cá»§a high retrieval time</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"DynamoDB + sub-millisecond latency\"</strong> â†’ <strong>DynamoDB Accelerator (DAX)</strong></p></li><li><p><strong>LSIs</strong> = query flexibility, KHÃ”NG improve latency significantly</p></li><li><p>S3 latency cao hÆ¡n DynamoDB</p></li><li><p>Exponential backoff = retry logic, khÃ´ng improve performance</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/dynamodbaccelerator/\">DynamoDB Accelerator (DAX)</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use DynamoDB Accelerator (DAX) to cache the trading data.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add local secondary indexes (LSIs) for the trading data.</p>",
                "<p>Store the trading data in Amazon S3, and use S3 Transfer Acceleration.</p>",
                "<p>Add retries with exponential backoff for DynamoDB queries.</p>",
                "<p>Use DynamoDB Accelerator (DAX) to cache the trading data.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 54
        },
        {
            "attemptAnswerId": 329716,
            "questionId": 7589,
            "questionText": "<p>A company is expanding the compatibility of its photo-sharing mobile app to hundreds of additional devices with unique screen dimensions and resolutions. Photos are stored in Amazon S3 in their original format and resolution. The company uses an Amazon CloudFront distribution to serve the photos. The app includes the dimension and resolution of the display as GET parameters with every request.<br><br>A developer needs to implement a solution that optimizes the photos that are served to each device to reduce load time and increase photo quality.<br><br>Which solution will meet these requirements MOST cost-effectively?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Photo-sharing mobile app má»Ÿ rá»™ng Ä‘áº¿n <strong>hundreds of devices</strong> vá»›i nhiá»u <strong>kÃ­ch thÆ°á»›c mÃ n hÃ¬nh vÃ  Ä‘á»™ phÃ¢n giáº£i</strong></p></li><li><p>Photos stored trong <strong>S3 original format/resolution</strong></p></li><li><p>DÃ¹ng <strong>CloudFront</strong> serve photos</p></li><li><p>App includes <strong>dimension (kÃ­ch thÆ°á»›c) vÃ  resolution (Ä‘á»™ phÃ¢ n giáº£i) as GET parameters</strong> vá»›i má»—i request</p></li><li><p>Requirements:</p><ul><li><p><strong>Optimize photos</strong> served to each device</p></li><li><p><strong>Reduce load time</strong> vÃ  increase photo quality</p></li><li><p><strong>MOST cost-effectively</strong></p></li></ul></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create a Lambda@Edge function that optimizes the photos upon request and returns the photos as a response. In the same function, store a copy of the processed photos on Amazon S3 for subsequent requests.</strong></p><ul><li><p><strong>Lambda@Edge</strong> process photos <strong>on-demand</strong> at CloudFront edge locations</p></li><li><p><strong>First request</strong>: optimize photo theo kÃ­ch thÆ°á»›c device, return vÃ  <strong>store processed copy trong S3</strong></p></li><li><p><strong>Subsequent requests</strong>: serve tá»« S3 (cached processed photos), khÃ´ng reprocess</p></li><li><p><strong>Most cost-effective</strong>: chá»‰ process má»—i biáº¿n thá»ƒ 1 láº§n, tÃ¡i sá»­ dá»¥ng cho future requests</p></li><li><p>No need pre-generate all biáº¿n thá»ƒ (hundreds of devices)</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use S3 Batch Operations to invoke an AWS Lambda function to create new variants of the photos with the required dimensions and resolutions. Create a dynamic CloudFront origin that automatically maps the request of each device to the corresponding photo variant.</strong></p><ul><li><p><strong>Pre-generate all biáº¿n thá»ƒ</strong> cho hundreds of devices = <strong>chi phÃ­ storage lá»›n</strong></p></li><li><p>S3 Batch Operations + Lambda = high compute cost</p></li><li><p><strong>KhÃ´ng cÃ³ \"dynamic CloudFront origin\"</strong> feature nhÆ° described</p></li><li><p>Not cost-effective</p></li></ul><p></p><p>âŒ <strong>Use S3 Batch Operations to invoke an AWS Lambda function to create new variants of the photos with the required dimensions and resolutions. Create a Lambda@Edge function to route requests to the corresponding photo variant by using request headers.</strong></p><ul><li><p>Pre-generate all biáº¿n thá»ƒ = <strong>high storage cost</strong></p></li><li><p>Maintain hundreds of variants per photo</p></li><li><p>S3 Batch Operations + Lambda cost high</p></li><li><p>Not cost-effective</p></li></ul><p></p><p>âŒ <strong>Create a Lambda@Edge function that optimizes the photos upon request and returns the photos as a response. Change the CloudFront TTL cache policy to the maximum value possible.</strong></p><ul><li><p>Optimize <strong>on every request</strong> náº¿u khÃ´ng store processed photos</p></li><li><p><strong>KHÃ”NG lÆ°u cÃ¡c biáº¿n thá»ƒ Ä‘Ã£ processed </strong> = reprocess nhiá»u láº§n</p></li><li><p>High Lambda invocation cost</p></li><li><p>CloudFront TTL cache at edge, nhÆ°ng váº«n pháº£i process láº§n Ä‘áº§u cho má»—i edge location</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Hundreds of device variants + cost-effective\"</strong> â†’ <strong>On-demand processing + cache results</strong></p></li><li><p><strong>Cost optimization strategy:</strong></p><ul><li><p>TrÃ¡nh pre-generating táº¥t cáº£ biáº¿n thá»ƒ (storage cost)</p></li><li><p>Process <strong>on-demand</strong> (chá»‰ biáº¿n thá»ƒ thá»±c sá»± cáº§n)</p></li><li><p><strong>Cache/store biáº¿n thá»ƒ Ä‘Ã£ processed</strong> (trÃ¡nh reprocessing)</p></li></ul></li><li><p>Pre-generating táº¥t cáº£ biáº¿n thá»ƒ = expensive vá»›i hundreds of combinations</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/blogs/networking-and-content-delivery/image-optimization-using-amazon-cloudfront-and-aws-lambda/\">Image Optimization using Amazon CloudFront and AWS Lambda</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a Lambda@Edge function that optimizes the photos upon request and returns the photos as a response. In the same function, store a copy of the processed photos on Amazon S3 for subsequent requests.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use S3 Batch Operations to invoke an AWS Lambda function to create new variants of the photos with the required dimensions and resolutions. Create a dynamic CloudFront origin that automatically maps the request of each device to the corresponding photo variant.</p>",
                "<p>Use S3 Batch Operations to invoke an AWS Lambda function to create new variants of the photos with the required dimensions and resolutions. Create a Lambda@Edge function to route requests to the corresponding photo variant by using request headers.</p>",
                "<p>Create a Lambda@Edge function that optimizes the photos upon request and returns the photos as a response. Change the CloudFront TTL cache policy to the maximum value possible.</p>",
                "<p>Create a Lambda@Edge function that optimizes the photos upon request and returns the photos as a response. In the same function, store a copy of the processed photos on Amazon S3 for subsequent requests.</p>"
            ],
            "answersPos": "[0,2,3,1]",
            "pos": 55
        },
        {
            "attemptAnswerId": 329717,
            "questionId": 7590,
            "questionText": "<p>When a developer tries to run an AWS CodeBuild project, it raises an error because the length of all environment variables exceeds the limit for the combined maximum of characters.<br><br>What is the recommended solution?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer cháº¡y <strong>AWS CodeBuild project</strong></p></li><li><p>Error: <strong>length of all environment variables exceeds the combined maximum limit</strong></p></li><li><p>TÃ¬m <strong>recommended solution</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use AWS Systems Manager Parameter Store to store large numbers of environment variables.</strong></p><ul><li><p><strong>Parameter Store</strong> integrate natively vá»›i <strong>CodeBuild</strong></p></li><li><p>Store environment variables externally, <strong>khÃ´ng tÃ­nh vÃ o</strong> CodeBuild character limit</p></li><li><p>CodeBuild automatically retrieve parameters at build time</p></li><li><p>Support SecureString cho sensitive values</p></li><li><p>Cost-effective vÃ  recommended practice</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Add the export LC_ALL=\"en_US.utf8\" command to the pre_build section to ensure POSIX localization.</strong></p><ul><li><p><strong>LC_ALL</strong> setting cho <strong>locale configuration</strong>, khÃ´ng liÃªn quan Ä‘áº¿n environment variable limits</p></li><li><p>KhÃ´ng giáº£i quyáº¿t character limit issue</p></li><li><p>Sai solution hoÃ n toÃ n</p></li></ul><p></p><p>âŒ <strong>Use Amazon Cognito to store key-value pairs for large numbers of environment variables.</strong></p><ul><li><p><strong>Cognito</strong> dÃ¹ng cho <strong>user authentication/authorization</strong>, khÃ´ng pháº£i configuration management</p></li><li><p>KhÃ´ng integrate vá»›i CodeBuild cho environment variables</p></li><li><p>Sai use case</p></li></ul><p></p><p>âŒ <strong>Update the settings for the build project to use an Amazon S3 bucket for large numbers of environment variables.</strong></p><ul><li><p>CodeBuild <strong>KHÃ”NG cÃ³ native feature</strong> Ä‘á»ƒ store environment variables trong S3</p></li><li><p>Pháº£i manually download vÃ  parse tá»« S3 trong build script</p></li><li><p>Parameter Store lÃ  recommended approach, khÃ´ng pháº£i S3</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"CodeBuild environment variables limit\"</strong> â†’ <strong>AWS Systems Manager Parameter Store</strong></p></li><li><p><strong>Parameter Store vá»›i CodeBuild:</strong></p><ul><li><p>Native integration</p></li><li><p>Reference parameters: <code>parameter-store:parameter-name</code></p></li><li><p>KhÃ´ng count vÃ o character limit</p></li><li><p>Support encrypted values (SecureString)</p></li></ul></li><li><p>Cognito = authentication, khÃ´ng pháº£i config storage</p></li><li><p>S3 khÃ´ng cÃ³ native CodeBuild env var integration</p></li><li><p>LC_ALL = locale setting, khÃ´ng liÃªn quan</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html\">Build specification reference for CodeBuild</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-env-vars.html\">Environment variables in CodeBuild</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use AWS Systems Manager Parameter Store to store large numbers of environment variables.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add the export LC_ALL=\"en_US.utf8\" command to the pre_build section to ensure POSIX localization.</p>",
                "<p>Use Amazon Cognito to store key-value pairs for large numbers of environment variables.</p>",
                "<p>Update the settings for the build project to use an Amazon S3 bucket for large numbers of environment variables.</p>",
                "<p>Use AWS Systems Manager Parameter Store to store large numbers of environment variables.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 56
        },
        {
            "attemptAnswerId": 329718,
            "questionId": 7602,
            "questionText": "<p>An application that is deployed to Amazon EC2 is using Amazon DynamoDB. The application calls the DynamoDB REST API. Periodically, the application receives a ProvisionedThroughputExceededException error when the application writes to a DynamoDB table.<br><br>Which solutions will mitigate this error MOST cost-effectively? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application trÃªn <strong>EC2</strong> dÃ¹ng <strong>DynamoDB</strong>, calls <strong>DynamoDB REST API</strong></p></li><li><p>Äá»‹nh ká»³ receive <strong>ProvisionedThroughputExceededException</strong> khi write to table</p></li><li><p>Requirement: giáº£m error <strong>MOST cost-effectively</strong></p></li><li><p>Chá»n <strong>2 solutions</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Modify the application code to perform exponential backoff when the error is received.</strong></p><ul><li><p><strong>Exponential backoff</strong> retry logic giáº£m request rate khi throttled</p></li><li><p>AWS best practice cho handling throttling errors</p></li><li><p><strong>No additional cost</strong> - chá»‰ code changes</p></li><li><p>GiÃºp spread requests over time, reduce throttling</p></li></ul><p></p><p><strong>Modify the application to use the AWS SDKs for DynamoDB.</strong></p><ul><li><p><strong>AWS SDKs</strong> cÃ³ <strong>built-in exponential backoff vÃ  retry logic</strong></p></li><li><p>Automatically handle throttling errors</p></li><li><p><strong>No additional cost</strong> - chá»‰ code refactor tá»« REST API sang SDK</p></li><li><p>Better error handling vÃ  performance so vá»›i direct REST API calls</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Increase the read and write throughput of the DynamoDB table.</strong></p><ul><li><p>TÄƒng throughput = <strong>tÄƒng cost</strong> (pay for provisioned capacity)</p></li><li><p>CÃ³ thá»ƒ giáº£i quyáº¿t issue nhÆ°ng <strong>KHÃ”NG cost-effective</strong></p></li><li><p>NÃªn implement retry logic trÆ°á»›c khi tÄƒng capacity</p></li></ul><p></p><p>âŒ <strong>Create a DynamoDB Accelerator (DAX) cluster for the DynamoDB table.</strong></p><ul><li><p><strong>DAX</strong> dÃ¹ng cho <strong>caching reads</strong>, khÃ´ng giáº£i quyáº¿t <strong>write throttling</strong></p></li><li><p>DAX cÃ³ <strong>additional cost</strong> (cluster charges)</p></li><li><p>KhÃ´ng address root cause cá»§a ProvisionedThroughputExceededException on writes</p></li></ul><p></p><p>âŒ <strong>Create a second DynamoDB table. Distribute the reads and writes between the two tables.</strong></p><ul><li><p><strong>2 tables = double cost</strong> (2Ã— provisioned capacity)</p></li><li><p>Complex application logic Ä‘á»ƒ distribute data</p></li><li><p>KHÃ”NG cost-effective</p></li><li><p>Overkill solution</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"ProvisionedThroughputExceededException + cost-effective\"</strong> â†’ <strong>Exponential backoff + AWS SDK</strong></p></li><li><p><strong>Handling DynamoDB throttling:</strong></p><ol><li><p>Implement <strong>exponential backoff</strong> (free, code change)</p></li><li><p>Use <strong>AWS SDKs</strong> vá»›i built-in retry (free, better than REST API)</p></li><li><p>Increase capacity (costs money, phÆ°Æ¡ng Ã¡n cuá»‘i cÃ¹ng)</p></li></ol></li><li><p><strong>AWS SDK benefits:</strong></p><ul><li><p>Built-in exponential backoff</p></li><li><p>Automatic retries</p></li><li><p>Better error handling</p></li></ul></li><li><p>DAX = read caching, khÃ´ng help vá»›i write throttling</p></li><li><p>Multiple tables = expensive vÃ  complex</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://www.hackerone.com/blog/retrying-and-exponential-backoff-smart-strategies-robust-software\">Error retries and exponential backoff</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.html\">Using AWS SDKs with DynamoDB</a></p></li></ul>",
            "correctAnswer": [
                "<p>Modify the application code to perform exponential backoff when the error is received.</p>",
                "<p>Modify the application to use the AWS SDKs for DynamoDB.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Modify the application code to perform exponential backoff when the error is received.</p>",
                "<p>Modify the application to use the AWS SDKs for DynamoDB.</p>",
                "<p>Increase the read and write throughput of the DynamoDB table.</p>",
                "<p>Create a DynamoDB Accelerator (DAX) cluster for the DynamoDB table.</p>",
                "<p>Create a second DynamoDB table. Distribute the reads and writes between the two tables.</p>"
            ],
            "answersPos": "[0,1,4,3,2]",
            "pos": 57
        },
        {
            "attemptAnswerId": 329719,
            "questionId": 7591,
            "questionText": "<p>A developer is creating an AWS Lambda function that searches for items from an Amazon DynamoDB table that contains customer contact information. The DynamoDB table items have the customerâ€™s email_address as the partition key and additional properties such as customer_type, name and job_title.</p><p></p><p>The Lambda function runs whenever a user types a new character into the customer_type text input.The developer wants the search to return partial matches of all the email_address property of a particular customer_type. The developer does not want to recreate the DynamoDB table.</p><p></p><p>What should the developer do to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>DynamoDB table stores <strong>customer contact information</strong></p></li><li><p><strong>Table schema:</strong></p></li></ul><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/3/1761465839395-g9xv65ng-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"175.91666666666666\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><ul><li><p>Lambda function search khi user types vÃ o <strong>customer_type text input</strong></p></li><li><p>Requirements:</p><ul><li><p>Return <strong>partial matches</strong> (káº¿t quáº£ khá»›p má»™t pháº§n) cá»§a <strong>email_address</strong> property</p></li><li><p>Filter by <strong>particular customer_type</strong></p></li><li><p><strong>NOT recreate</strong> DynamoDB table</p></li></ul></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Add a global secondary index (GSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the GSI by using the begins_with key condition expression with the email_address property.</strong></p><ul><li><p><strong>GSI vá»›i customer_type partition key</strong> cho phÃ©p query by customer_type</p></li><li><p><strong>email_address sort key</strong> cho phÃ©p dÃ¹ng <strong>begins_with</strong> condition cho partial matching</p></li><li><p>Query: <code>Query(customer_type = \"VIP\", begins_with(email_address, \"john\"))</code></p></li><li><p><strong>GSI cÃ³ thá»ƒ add</strong> sau khi table created (khÃ´ng cáº§n recreate table)</p></li><li><p>ÄÃ¡p á»©ng Ä‘áº§y Ä‘á»§ requirements</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Add a global secondary index (GSI) to the DynamoDB table with email_address as the partition key and customer_type as the sort key. Perform a query operation on the GSI by using the begins_with key condition expression with the email_address property.</strong></p><ul><li><p><strong>email_address partition key</strong> = pháº£i biáº¿t chÃ­nh xÃ¡c email Ä‘á»ƒ query</p></li><li><p><strong>KHÃ”NG thá»ƒ</strong> dÃ¹ng begins_with trÃªn partition key</p></li><li><p>begins_with chá»‰ work trÃªn <strong>sort key</strong></p></li><li><p>KhÃ´ng filter Ä‘Æ°á»£c by customer_type trÆ°á»›c</p></li></ul><p></p><p>âŒ <strong>Add a local secondary index (LSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the LSI by using the begins_with key condition expression with the email_address property.</strong></p><ul><li><p><strong>LSI PHáº¢I share partition key</strong> vá»›i base table</p></li><li><p>Base table partition key = <strong>email_address</strong>, khÃ´ng pháº£i customer_type</p></li><li><p><strong>KHÃ”NG THá»‚</strong> dÃ¹ng customer_type lÃ m partition key trong LSI</p></li><li><p>Sai vá» LSI concept</p></li></ul><p></p><p>âŒ <strong>Add a local secondary index (LSI) to the DynamoDB table with job_title as the partition key and email_address as the sort key. Perform a query operation on the LSI by using the begins_with key condition expression with the email_address property.</strong></p><ul><li><p>LSI khÃ´ng thá»ƒ change partition key</p></li><li><p><strong>job_title</strong> khÃ´ng liÃªn quan Ä‘áº¿n requirement (cáº§n filter by customer_type)</p></li><li><p>Sai logic</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Query by X + partial match on Y\"</strong> â†’ <strong>GSI vá»›i X = partition key, Y = sort key + begins_with</strong></p></li><li><p><strong>begins_with</strong> chá»‰ work trÃªn <strong>sort key</strong>, KHÃ”NG work trÃªn partition key</p></li><li><p><strong>LSI vs GSI:</strong></p><ul><li><p><strong>LSI</strong> = same partition key, different sort key, <strong>cannot add after table creation</strong></p></li><li><p><strong>GSI</strong> = different partition key vÃ  sort key, <strong>can add after creation</strong></p></li></ul></li><li><p>Pattern: customer_type partition key â†’ email_address sort key â†’ begins_with query</p></li><li><p>GSI khÃ´ng require table recreation</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html\">Using Global Secondary Indexes in DynamoDB</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/example_dynamodb_Scenarios_QueryWithBeginsWithCondition_section.html\">DynamoDB begins_with key condition</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add a global secondary index (GSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the GSI by using the begins_with key condition expression with the email_address property.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add a global secondary index (GSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the GSI by using the begins_with key condition expression with the email_address property.</p>",
                "<p>Add a global secondary index (GSI) to the DynamoDB table with email_address as the partition key and customer_type as the sort key. Perform a query operation on the GSI by using the begins_with key condition expression with the email_address property.</p>",
                "<p>Add a local secondary index (LSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the LSI by using the begins_with key condition expression with the email_address property.</p>",
                "<p>Add a local secondary index (LSI) to the DynamoDB table with job_title as the partition key and email_address as the sort key. Perform a query operation on the LSI by using the begins_with key condition expression with the email_address property.</p>"
            ],
            "answersPos": "[1,3,0,2]",
            "pos": 58
        },
        {
            "attemptAnswerId": 329720,
            "questionId": 7592,
            "questionText": "<p>A developer is modifying an existing AWS Lambda function. While checking the code, the developer notices hardcoded parameter values for an Amazon RDS for SQL Server user name, password, database, host, and port. There are also hardcoded parameter values for an Amazon DynamoDB table, an Amazon S3 bucket, and an Amazon Simple Notification Service (Amazon SNS) topic.<br><br>The developer wants to securely store the parameter values outside the code in an encrypted format and wants to turn on rotation for the credentials. The developer also wants to be able to reuse the parameter values from other applications and to update the parameter values without modifying code.<br><br>Which solution will meet these requirements with the LEAST operational overhead?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Lambda function cÃ³ <strong>hardcoded parameters</strong>:</p><ul><li><p><strong>RDS SQL Server</strong>: username, password, database, host, port</p></li><li><p><strong>DynamoDB table, S3 bucket, SNS topic</strong> names</p></li></ul></li><li><p>Requirements:</p><ul><li><p>Store parameters <strong>outside code</strong>, <strong>encrypted</strong></p></li><li><p><strong>Turn on rotation</strong> for credentials</p></li><li><p><strong>Reuse</strong> parameters from other applications</p></li><li><p><strong>Update parameters without modifying code</strong></p></li><li><p><strong>LEAST operational overhead</strong></p></li></ul></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create an RDS database secret in AWS Secrets Manager. Set the user name, password, database, host, and port. Turn on secret rotation. Create SecureString parameters in AWS Systems Manager Parameter Store for the DynamoDB table, S3 bucket, and SNS topic.</strong></p><ul><li><p><strong>Secrets Manager</strong> cho RDS credentials vá»›i <strong>built-in automatic rotation</strong></p></li><li><p><strong>Parameter Store SecureString</strong> cho DynamoDB/S3/SNS names (khÃ´ng cáº§n rotation)</p></li><li><p>Both services integrate tá»‘t vá»›i Lambda</p></li><li><p><strong>Least overhead</strong>: managed services, no custom rotation logic</p></li><li><p>Parameters reusable across applications</p></li><li><p>Update without code changes</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create an RDS database secret in AWS Secrets Manager. Set the user name, password, database, host, and port. Turn on secret rotation. Create encrypted Lambda environment variables for the DynamoDB table, S3 bucket, and SNS topic.</strong></p><ul><li><p>Secrets Manager cho RDS credentials Ä‘Ãºng</p></li><li><p><strong>Lambda environment variables</strong> = per-function, <strong>KHÃ”NG reusable</strong> across applications</p></li><li><p>Pháº£i update Lambda function configuration Ä‘á»ƒ change values</p></li><li><p>KhÃ´ng meet \"reuse from other applications\" requirement</p></li></ul><p></p><p>âŒ <strong>Create RDS database parameters in AWS Systems Manager Parameter Store for the user name, password, database, host, and port. Create encrypted Lambda environment variables for the DynamoDB table, S3 bucket, and SNS topic. Create a Lambda function and set the logic for the credentials rotation task. Schedule the credentials rotation task in Amazon EventBridge.</strong></p><ul><li><p><strong>Parameter Store KHÃ”NG cÃ³ built-in rotation</strong></p></li><li><p>Pháº£i <strong>build custom rotation logic</strong> vá»›i Lambda + EventBridge</p></li><li><p>High operational overhead</p></li><li><p>Lambda env vars khÃ´ng reusable</p></li></ul><p></p><p>âŒ <strong>Create RDS database parameters in AWS Systems Manager Parameter Store for the user name, password, database, host, and port. Store the DynamoDB table, S3 bucket, and SNS topic in Amazon S3. Create a Lambda function and set the logic for the credentials rotation. Invoke the Lambda function on a schedule.</strong></p><ul><li><p>Parameter Store khÃ´ng cÃ³ built-in rotation</p></li><li><p><strong>Store config trong S3</strong> = phá»©c táº¡p khÃ´ng cáº§n thiáº¿t</p></li><li><p>Custom rotation logic = high overhead</p></li><li><p>KhÃ´ng pháº£i least operational overhead</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Database credentials + automatic rotation\"</strong> â†’ <strong>AWS Secrets Manager</strong></p></li><li><p><strong>\"Non-sensitive config values\"</strong> â†’ <strong>Parameter Store</strong></p></li><li><p><strong>Secrets Manager vs Parameter Store:</strong></p><ul><li><p>Secrets Manager = credentials + <strong>automatic rotation</strong></p></li><li><p>Parameter Store = config data, <strong>NO automatic rotation</strong></p></li></ul></li><li><p><strong>Lambda environment variables</strong> = NOT reusable across applications</p></li><li><p>Custom rotation logic = high operational overhead</p></li><li><p>S3 khÃ´ng pháº£i optimal cho storing simple config values</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/ps-integration-lambda-extensions.html\">Using Parameter Store parameters in AWS Lambda functions</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an RDS database secret in AWS Secrets Manager. Set the user name, password, database, host, and port. Turn on secret rotation. Create SecureString parameters in AWS Systems Manager Parameter Store for the DynamoDB table, S3 bucket, and SNS topic.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an RDS database secret in AWS Secrets Manager. Set the user name, password, database, host, and port. Turn on secret rotation. Create encrypted Lambda environment variables for the DynamoDB table, S3 bucket, and SNS topic.</p>",
                "<p>Create an RDS database secret in AWS Secrets Manager. Set the user name, password, database, host, and port. Turn on secret rotation. Create SecureString parameters in AWS Systems Manager Parameter Store for the DynamoDB table, S3 bucket, and SNS topic.</p>",
                "<p>Create RDS database parameters in AWS Systems Manager Parameter Store for the user name, password, database, host, and port. Create encrypted Lambda environment variables for the DynamoDB table, S3 bucket, and SNS topic. Create a Lambda function and set the logic for the credentials rotation task. Schedule the credentials rotation task in Amazon EventBridge.</p>",
                "<p>Create RDS database parameters in AWS Systems Manager Parameter Store for the user name, password, database, host, and port. Store the DynamoDB table, S3 bucket, and SNS topic in Amazon S3. Create a Lambda function and set the logic for the credentials rotation. Invoke the Lambda function on a schedule.</p>"
            ],
            "answersPos": "[0,2,1,3]",
            "pos": 59
        },
        {
            "attemptAnswerId": 329721,
            "questionId": 7593,
            "questionText": "<p>A mobile app stores blog posts in an Amazon DynamoDB table. Millions of posts are added every day, and each post represents a single item in the table. The mobile app requires only recent posts. Any post that is older than 48 hours can be removed.<br><br>What is the MOST cost-effective way to delete posts that are older than 48 hours?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Mobile app stores <strong>blog posts</strong> trong <strong>DynamoDB table</strong></p></li><li><p><strong>Millions of posts added daily</strong></p></li><li><p>Má»—i post = single item trong table</p></li><li><p>Requirement: remove posts <strong>older than 48 hours</strong></p></li><li><p>TÃ¬m <strong>MOST cost-effective</strong> way to delete old posts</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>For each item, add a new attribute of type Number that has a timestamp that is set to 48 hours after the blog post creation time. Configure the DynamoDB table with a TTL that references the new attribute.</strong></p><ul><li><p><strong>DynamoDB TTL (Time To Live)</strong> automatically delete expired items</p></li><li><p><strong>No cost</strong> cho TTL deletions (free feature)</p></li><li><p><strong>No operational overhead</strong>: fully managed, no scripts/Lambda needed</p></li><li><p>TTL attribute = Unix epoch timestamp (Number type)</p></li><li><p>Set TTL = creation_time + 48 hours</p></li><li><p>Most cost-effective: zero cost, zero maintenance</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>For each item, add a new attribute of type String that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the BatchWriteItem API operation. Schedule a cron job on an Amazon EC2 instance once an hour to start the script.</strong></p><ul><li><p><strong>EC2 instance</strong> running 24/7 = <strong>continuous cost</strong></p></li><li><p><strong>Table scan</strong> = expensive, consume read capacity</p></li><li><p>High operational overhead: maintain EC2, scripts</p></li><li><p>Not cost-effective</p></li></ul><p></p><p>âŒ <strong>For each item, add a new attribute of type String that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the BatchWriteItem API operation. Place the script in a container image. Schedule an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate that invokes the container every 5 minutes.</strong></p><ul><li><p><strong>Fargate tasks</strong> every 5 minutes = recurring cost</p></li><li><p>Table scan = expensive</p></li><li><p>Operational overhead: maintain container, ECS tasks</p></li><li><p>More expensive than EC2 option</p></li></ul><p></p><p>âŒ <strong>For each item, add a new attribute of type Date that has a timestamp that is set to 48 hours after the blog post creation time. Create a global secondary index (GSI) that uses the new attribute as a sort key. Create an AWS Lambda function that references the GSI and removes expired items by using the BatchWriteItem API operation. Schedule the function with an Amazon CloudWatch event every minute.</strong></p><ul><li><p><strong>GSI</strong> = additional cost (storage + throughput)</p></li><li><p><strong>Lambda invocations</strong> every minute = cost</p></li><li><p><strong>BatchWriteItem</strong> = write capacity cost</p></li><li><p>Operational overhead</p></li><li><p>Complex so vá»›i TTL</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Automatically delete old DynamoDB items\"</strong> â†’ <strong>DynamoDB TTL</strong></p></li><li><p><strong>DynamoDB TTL:</strong></p><ul><li><p><strong>Free feature</strong> (no additional cost)</p></li><li><p>Automatic deletion based on timestamp</p></li><li><p>TTL attribute must be <strong>Number type</strong> (Unix epoch timestamp)</p></li><li><p>Deletions typically within 48 hours of expiration</p></li></ul></li><li><p><strong>TTL attribute calculation</strong>: <code>current_time + retention_period</code></p></li><li><p>Table scans = expensive, consume capacity</p></li><li><p>EC2/Fargate/Lambda = ongoing costs</p></li><li><p>TTL = most cost-effective cho time-based deletion</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html\">DynamoDB Time To Live (TTL)</a></p></li></ul>",
            "correctAnswer": [
                "<p>For each item, add a new attribute of type Number that has a timestamp that is set to 48 hours after the blog post creation time. Configure the DynamoDB table with a TTL that references the new attribute.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>For each item, add a new attribute of type String that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the BatchWriteItem API operation. Schedule a cron job on an Amazon EC2 instance once an hour to start the script.</p>",
                "<p>For each item, add a new attribute of type String that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the BatchWriteItem API operation. Place the script in a container image. Schedule an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate that invokes the container every 5 minutes.</p>",
                "<p>For each item, add a new attribute of type Date that has a timestamp that is set to 48 hours after the blog post creation time. Create a global secondary index (GSI) that uses the new attribute as a sort key. Create an AWS Lambda function that references the GSI and removes expired items by using the BatchWriteItem API operation. Schedule the function with an Amazon CloudWatch event every minute.</p>",
                "<p>For each item, add a new attribute of type Number that has a timestamp that is set to 48 hours after the blog post creation time. Configure the DynamoDB table with a TTL that references the new attribute.</p>"
            ],
            "answersPos": "[1,0,2,3]",
            "pos": 60
        },
        {
            "attemptAnswerId": 329722,
            "questionId": 7594,
            "questionText": "<p>A developer has an application that is composed of many different AWS Lambda functions. The Lambda functions all use some of the same dependencies. To avoid security issues, the developer is constantly updating the dependencies of all of the Lambda functions. The result is duplicated effort for each function.<br><br>How can the developer keep the dependencies of the Lambda functions up to date with the LEAST additional complexity?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application vá»›i <strong>many Lambda functions</strong></p></li><li><p>Lambda functions <strong>share some dependencies</strong></p></li><li><p>Developer liÃªn tá»¥c updating dependencies cho <strong>all functions</strong> (duplicated effort)</p></li><li><p>Requirement: keep dependencies up to date vá»›i <strong>LEAST additional complexity</strong></p></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Define a Lambda layer that contains all of the shared dependencies.</strong></p><ul><li><p><strong>Lambda layer</strong> = reusable package chá»©a libraries/dependencies</p></li><li><p><strong>Single update</strong>: update layer má»™t láº§n, all functions using layer get updated dependencies</p></li><li><p>No need update functions riÃªng láº»</p></li><li><p>Functions reference layer, khÃ´ng duplicate dependencies</p></li><li><p>Least complexity: centralized dependency management</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Define a maintenance window for the Lambda functions to ensure that the functions get updated copies of the dependencies.</strong></p><ul><li><p><strong>Maintenance window</strong> = scheduled time cho updates, khÃ´ng pháº£i automated solution</p></li><li><p>Váº«n pháº£i <strong>manually update</strong> má»—i function</p></li><li><p>KhÃ´ng giáº£m duplicated effort</p></li><li><p>KhÃ´ng address root cause</p></li></ul><p></p><p>âŒ <strong>Upgrade the Lambda functions to the most recent runtime version.</strong></p><ul><li><p><strong>Runtime version upgrade</strong> update Lambda runtime (Node.js, Python version)</p></li><li><p><strong>KHÃ”NG update application dependencies</strong> (libraries, packages)</p></li><li><p>Sai solution hoÃ n toÃ n</p></li></ul><p></p><p>âŒ <strong>Use an AWS CodeCommit repository to host the dependencies in a centralized location.</strong></p><ul><li><p>CodeCommit centralize source code nhÆ°ng <strong>KHÃ”NG eliminate duplicated packaging effort</strong></p></li><li><p>Váº«n pháº£i <strong>package dependencies</strong> vÃ o má»—i function deployment</p></li><li><p>KhÃ´ng giáº£m complexity</p></li><li><p>Lambda layers better solution</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Shared dependencies across Lambda functions\"</strong> â†’ <strong>Lambda Layers</strong></p></li><li><p><strong>Lambda Layer benefits:</strong></p><ul><li><p>Share code/dependencies across functions</p></li><li><p>Update once, apply to all functions</p></li><li><p>Reduce deployment package size</p></li><li><p>Centralized dependency management</p></li></ul></li><li><p><strong>Layer use cases:</strong> shared libraries, custom runtimes, configuration files</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/chapter-layers.html\">AWS Lambda Layers</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/serverlessrepo/latest/devguide/sharing-lambda-layers.html\">Creating and sharing Lambda layers</a></p></li></ul>",
            "correctAnswer": [
                "<p>Define a Lambda layer that contains all of the shared dependencies.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Define a maintenance window for the Lambda functions to ensure that the functions get updated copies of the dependencies.</p>",
                "<p>Upgrade the Lambda functions to the most recent runtime version.</p>",
                "<p>Define a Lambda layer that contains all of the shared dependencies.</p>",
                "<p>Use an AWS CodeCommit repository to host the dependencies in a centralized location.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 61
        },
        {
            "attemptAnswerId": 329723,
            "questionId": 7603,
            "questionText": "<p>A companyâ€™s website runs on an Amazon EC2 instance and uses Auto Scaling to scale the environment during peak times. Website users across the world are experiencing high latency due to static content on the EC2 instance, even during non-peak hours.</p><p></p><p>Which combination of steps will resolve the latency issue? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company website runs trÃªn <strong>EC2 instance vá»›i Auto Scaling</strong></p></li><li><p>Issue: users <strong>across the world</strong> experiencing <strong>high latency</strong> for <strong>static content</strong></p></li><li><p>Latency occurs <strong>even during non-peak hours</strong> (khÃ´ng pháº£i capacity issue)</p></li><li><p>Requirement: resolve latency issue</p></li><li><p>Chá»n <strong>2 solutions</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create an Amazon CloudFront distribution to cache the static content.</strong></p><ul><li><p><strong>CloudFront</strong> = global CDN vá»›i <strong>edge locations worldwide</strong></p></li><li><p>Cache static content at edge locations <strong>closer to users</strong></p></li><li><p>Dramatically reduce latency cho global users</p></li><li><p>Giáº£m táº£i traffic tá»« EC2 instances</p></li></ul><p></p><p><strong>Store the application's static content in Amazon S3.</strong></p><ul><li><p><strong>S3</strong> designed cho storing static content (images, CSS, JS, videos)</p></li><li><p>CloudFront cÃ³ thá»ƒ dÃ¹ng <strong>S3 as origin</strong></p></li><li><p>Decouple static content tá»« EC2 instances</p></li><li><p>S3 highly available vÃ  scalable</p></li><li><p>Pattern: S3 (origin) â†’ CloudFront (CDN) â†’ Users</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Double the Auto Scaling group's maximum number of servers.</strong></p><ul><li><p>Issue xáº£y ra <strong>even during non-peak hours</strong> â†’ khÃ´ng pháº£i capacity problem</p></li><li><p>More EC2 instances <strong>KHÃ”NG giáº£i quyáº¿t geographic latency</strong></p></li><li><p>Users xa EC2 region váº«n cÃ³ high latency</p></li><li><p>TÄƒng cost khÃ´ng cáº§n thiáº¿t</p></li></ul><p></p><p>âŒ <strong>Host the application code on AWS Lambda.</strong></p><ul><li><p>Lambda cho <strong>application logic</strong>, khÃ´ng pháº£i static content delivery</p></li><li><p><strong>KHÃ”NG giáº£i quyáº¿t latency</strong> cho static content</p></li><li><p>Migration to Lambda = major rewrite, khÃ´ng address root cause</p></li></ul><p></p><p>âŒ <strong>Scale vertically by resizing the EC2 instances.</strong></p><ul><li><p>Larger instances <strong>KHÃ”NG giáº£m network latency</strong> to global users</p></li><li><p>Issue lÃ  <strong>geographic distance</strong>, khÃ´ng pháº£i server capacity</p></li><li><p>Vertical scaling khÃ´ng help vá»›i latency</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Global users + high latency + static content\"</strong> â†’ <strong>CloudFront + S3</strong></p></li><li><p><strong>CloudFront benefits:</strong></p><ul><li><p>Global edge locations</p></li><li><p>Cache static content close to users</p></li><li><p>Reduce latency dramatically</p></li></ul></li><li><p><strong>Pattern cho static content:</strong></p><ul><li><p>Store trong <strong>S3</strong></p></li><li><p>Distribute qua <strong>CloudFront</strong></p></li><li><p>EC2 chá»‰ serve dynamic content</p></li></ul></li><li><p>Auto Scaling = capacity, khÃ´ng fix geographic latency</p></li><li><p>Vertical/horizontal scaling khÃ´ng solve network distance issue</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/getting-started-cloudfront-overview.html\">Amazon CloudFront for static content</a></p></li></ul>",
            "correctAnswer": [
                "<p>Store the applicationâ€™s static content in Amazon S3.</p>",
                "<p>Create an Amazon CloudFront distribution to cache the static content.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Double the Auto Scaling groupâ€™s maximum number of servers.</p>",
                "<p>Host the application code on AWS Lambda.</p>",
                "<p>Scale vertically by resizing the EC2 instances.</p>",
                "<p>Create an Amazon CloudFront distribution to cache the static content.</p>",
                "<p>Store the applicationâ€™s static content in Amazon S3.</p>"
            ],
            "answersPos": "[0,1,2,3,4]",
            "pos": 62
        },
        {
            "attemptAnswerId": 329724,
            "questionId": 7595,
            "questionText": "<p>A company is using Amazon RDS as the backend database for its application. After a recent marketing campaign, a surge of read requests to the database increased the latency of data retrieval from the database. The company has decided to implement a caching layer in front of the database. The cached content must be encrypted and must be highly available.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company dÃ¹ng <strong>Amazon RDS</strong> as backend database</p></li><li><p><strong>Surge of read requests</strong> (lÆ°á»£ng read requests tÄƒng Ä‘á»™t biáº¿n) increased <strong>latency</strong> of data retrieval</p></li><li><p>Company wants implement <strong>caching layer</strong> in front of database</p></li><li><p>Requirements:</p><ul><li><p><strong>Cached content must be encrypted</strong></p></li><li><p>Must be <strong>highly available</strong></p></li></ul></li><li><p>TÃ¬m solution phÃ¹ há»£p</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Amazon ElastiCache for Redis in cluster mode</strong></p><ul><li><p><strong>Redis</strong> há»— trá»£ <strong>encryption at rest vÃ  in transit</strong></p></li><li><p><strong>Cluster mode</strong> provide <strong>high availability</strong> vá»›i automatic failover</p></li><li><p>Multi-AZ deployment vá»›i replication</p></li><li><p>Redis persistence options (AOF, RDB) cho durability</p></li><li><p>Perfect cho caching RDS data vá»›i encryption vÃ  HA requirements</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Amazon CloudFront</strong></p><ul><li><p><strong>CloudFront</strong> = CDN cho <strong>static content</strong> (images, videos, files)</p></li><li><p>KHÃ”NG phÃ¹ há»£p cho caching <strong>database queries/results</strong></p></li><li><p>CloudFront cache HTTP responses, khÃ´ng pháº£i database data</p></li><li><p>Sai use case</p></li></ul><p></p><p>âŒ <strong>Amazon ElastiCache for Memcached</strong></p><ul><li><p><strong>Memcached KHÃ”NG há»— trá»£ encryption at rest</strong></p></li><li><p>Memcached cÃ³ <strong>limited high availability</strong> (no automatic failover)</p></li><li><p>No data persistence</p></li><li><p>KhÃ´ng meet encryption requirement</p></li></ul><p></p><p>âŒ <strong>Amazon DynamoDB Accelerator (DAX)</strong></p><ul><li><p><strong>DAX</strong> chá»‰ work vá»›i <strong>DynamoDB</strong>, khÃ´ng pháº£i RDS</p></li><li><p>DAX KHÃ”NG cache cho RDS databases</p></li><li><p>Sai use case hoÃ n toÃ n</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"RDS caching + encryption + high availability\"</strong> â†’ <strong>ElastiCache Redis cluster mode</strong></p></li><li><p><strong>Redis vs Memcached:</strong></p><ul><li><p><strong>Redis</strong> = encryption, persistence, HA, advanced data structures</p></li><li><p><strong>Memcached</strong> = simple key-value, <strong>NO encryption</strong>, limited HA</p></li></ul></li><li><p><strong>Redis cluster mode:</strong></p><ul><li><p>Automatic failover</p></li><li><p>Multi-AZ deployment</p></li><li><p>Data sharding</p></li></ul></li><li><p><strong>DAX</strong> = DynamoDB only, khÃ´ng work vá»›i RDS</p></li><li><p>CloudFront = static content CDN, khÃ´ng pháº£i database caching</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonElastiCache/latest/dg/at-rest-encryption.html\">ElastiCache for Redis with encryption</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonElastiCache/latest/dg/Replication.html\">Redis cluster mode for high availability</a></p></li></ul>",
            "correctAnswer": [
                "<p>Amazon ElastiCache for Redis in cluster mode</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Amazon CloudFront</p>",
                "<p>Amazon ElastiCache for Memcached</p>",
                "<p>Amazon ElastiCache for Redis in cluster mode</p>",
                "<p>Amazon DynamoDB Accelerator (DAX)</p>"
            ],
            "answersPos": "[3,1,0,2]",
            "pos": 63
        },
        {
            "attemptAnswerId": 329725,
            "questionId": 7596,
            "questionText": "<p>A developer is building a serverless application that is based on AWS Lambda. The developer initializes the AWS software development kit (SDK) outside of the Lambda handler function.<br><br>What is the PRIMARY benefit of this action?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Developer building <strong>serverless application</strong> based on <strong>AWS Lambda</strong></p></li><li><p>Developer <strong>initializes AWS SDK outside of Lambda handler function</strong></p></li><li><p>TÃ¬m <strong>PRIMARY benefit</strong> cá»§a action nÃ y</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Takes advantage of runtime environment reuse</strong></p><ul><li><p>Lambda <strong>tÃ¡i sá»­ dá»¥ng execution environment</strong> across multiple invocations (warm starts)</p></li><li><p>Code <strong>outside handler</strong> executed <strong>once per execution environment</strong> (initialization phase)</p></li><li><p>Code <strong>inside handler</strong> executed <strong>every invocation</strong></p></li><li><p>Initialize SDK outside handler = <strong>reuse SDK client</strong> across invocations</p></li><li><p>Benefits: <strong>reduce latency</strong>, save initialization time, reuse connections</p></li><li><p>Best practice cho Lambda performance optimization</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Improves legibility and stylistic convention</strong></p><ul><li><p>Legibility khÃ´ng pháº£i PRIMARY benefit</p></li><li><p>Main benefit lÃ  <strong>performance</strong>, khÃ´ng pháº£i code style</p></li><li><p>Lá»£i Ã­ch nhá» so vá»›i runtime reuse</p></li></ul><p></p><p>âŒ <strong>Provides better error handling</strong></p><ul><li><p>SDK initialization location <strong>KHÃ”NG affect error handling</strong></p></li><li><p>Error handling quality depends on try-catch implementation</p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n initialization location</p></li></ul><p></p><p>âŒ <strong>Creates a new SDK instance for each invocation</strong></p><ul><li><p><strong>SAI</strong> - initialize outside handler = <strong>REUSE</strong> SDK instance</p></li><li><p>Inside handler = new instance má»—i invocation</p></li><li><p>Opposite cá»§a actual behavior</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Initialize outside Lambda handler\"</strong> â†’ <strong>Reuse across invocations</strong></p></li><li><p><strong>Lambda execution lifecycle:</strong></p><ul><li><p><strong>Init phase</strong> (cold start): code outside handler runs <strong>once</strong></p></li><li><p><strong>Invoke phase</strong>: handler code runs <strong>every invocation</strong></p></li></ul></li><li><p><strong>Best practices:</strong></p><ul><li><p>Initialize SDK clients <strong>outside handler</strong></p></li><li><p>Database connections <strong>outside handler</strong></p></li><li><p>Heavy computations <strong>outside handler</strong> (if possible)</p></li></ul></li><li><p><strong>Benefits:</strong> reduce latency, reuse connections, improve performance</p></li><li><p>Lambda reuses execution environment khi cÃ³ thá»ƒ (warm starts)</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html\">Best practices for working with AWS Lambda functions</a></p></li></ul>",
            "correctAnswer": [
                "<p>Takes advantage of runtime environment reuse</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Improves legibility and stylistic convention</p>",
                "<p>Takes advantage of runtime environment reuse</p>",
                "<p>Provides better error handling</p>",
                "<p>Creates a new SDK instance for each invocation</p>"
            ],
            "answersPos": "[2,0,1,3]",
            "pos": 64
        }
    ],
    "statistics": {
        "correctCount": 0,
        "incorrectCount": 0,
        "skippedCount": 65,
        "flaggedCount": 0
    },
    "examName": "Practice Test 6",
    "courseName": "Practice Exams | AWS Certified Developer - Associate",
    "slug": "practice-exams-aws-certified-developer-associate"
}