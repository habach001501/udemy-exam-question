export const exam2 = {
    "attemptAnswers": [
        {
            "attemptAnswerId": 329141,
            "questionId": 6365,
            "questionText": "<p>A company wants to store sensitive financial data within Amazon S3 buckets. The company has a corporate policy that does not allow public read or write access to the buckets. A SysOps administrator must create a solution to automatically remove S3 permissions that allow public read or write access.<br><br>Which AWS service should the SysOps administrator use to meet these requirements in the MOST operationally efficient manner?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company mu·ªën store <strong>sensitive financial data</strong> trong S3 buckets</p></li><li><p>Corporate policy KH√îNG cho ph√©p <strong>public read ho·∫∑c write access</strong></p></li><li><p>SysOps admin c·∫ßn solution ƒë·ªÉ <strong>t·ª± ƒë·ªông remove (automatically remove)</strong> S3 permissions cho ph√©p public access</p></li><li><p>Y√™u c·∫ßu: <strong>most operationally efficient</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>AWS Config</strong></p><ul><li><p>AWS Config c√≥ managed rules ƒë·ªÉ detect S3 public access violations: <code>s3-bucket-public-read-prohibited</code> v√† <code>s3-bucket-public-write-prohibited</code></p></li><li><p>H·ªó tr·ª£ Auto Remediation v·ªõi SSM Automation documents ƒë·ªÉ t·ª± ƒë·ªông fix non-compliant S3 buckets</p></li><li><p>Built-in remediation action c√≥ th·ªÉ automatically remove public access permissions khi detect vi ph·∫°m</p></li><li><p>Most operationally efficient v√¨ kh√¥ng c·∫ßn vi·∫øt custom code, ch·ªâ c·∫ßn enable Config rules v√† auto remediation</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>AWS Security Hub</strong></p><ul><li><p>Security Hub aggregate security findings t·ª´ nhi·ªÅu services</p></li><li><p>KH√îNG c√≥ built-in automatic remediation capability</p></li><li><p>Ch·ªâ l√† centralized dashboard cho security findings</p></li><li><p>C·∫ßn custom automation ƒë·ªÉ remediate</p></li></ul><p></p><p>‚ùå <strong>AWS Trusted Advisor</strong></p><ul><li><p>Trusted Advisor c√≥ security checks cho S3 bucket permissions</p></li><li><p>Ch·ªâ l√† advisory service, kh√¥ng c√≥ automatic remediation</p></li><li><p>Ch·ªâ detect v√† notify, kh√¥ng t·ª± ƒë·ªông fix</p></li></ul><p></p><p>‚ùå <strong>Amazon Inspector</strong></p><ul><li><p>Inspector focus v√†o EC2 instances, container images, v√† Lambda functions</p></li><li><p>Kh√¥ng monitor ho·∫∑c remediate S3 bucket permissions</p></li><li><p>Kh√¥ng ph√π h·ª£p cho use case n√†y</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Automatically remove/fix violations\"</strong> ‚Üí <strong>AWS Config</strong> v·ªõi <strong>Auto Remediation</strong> l√† only choice</p></li><li><p><strong>\"Most operationally efficient\"</strong> ‚Üí <strong>Managed remediation</strong> thay v√¨ custom Lambda/automation</p></li><li><p><strong>\"S3 compliance enforcement\"</strong> ‚Üí <strong>AWS Config managed rules</strong> cho S3 permissions</p></li><li><p><strong>Inspector</strong> scope ‚Üí EC2/containers/Lambda only, KH√îNG cover S3 permissions</p></li><li><p><strong>Auto Remediation pattern</strong> ‚Üí AWS Config rules + SSM Automation = zero-touch compliance</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/config/latest/developerguide/remediation.html\">Remediating Noncompliant AWS Resources by AWS Config Rules</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-soa/introduction-aws-config\">https://blog.cloudmentor.pro/blog/aws-soa/introduction-aws-config</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-soa/aws-config-automation-revoke-unused-iam-user-credentials\">https://blog.cloudmentor.pro/blog/aws-soa/aws-config-automation-revoke-unused-iam-user-credentials</a></p></li></ul>",
            "correctAnswer": [
                "<p>AWS Config</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>AWS Config</p>",
                "<p>AWS Security Hub</p>",
                "<p>AWS Trusted Advisor</p>",
                "<p>Amazon Inspector</p>"
            ],
            "answersPos": "[3,1,2,0]",
            "pos": 0
        },
        {
            "attemptAnswerId": 329142,
            "questionId": 6366,
            "questionText": "<p>A SysOps administrator receives an alert that a production Auto Scaling group has been scaled down to two Amazon EC2 instances. The Auto Scaling group was originally configured with a minimum capacity of three instances. However, the SysOps administrator confirms that the configuration now reflects a minimum capacity of two instances.<br><br>Which AWS service will help identify who made the change?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Production <strong>Auto Scaling group</strong> b·ªã scaled down t·ª´ 3 xu·ªëng 2 EC2 instances</p></li><li><p>Auto Scaling group ban ƒë·∫ßu configured v·ªõi <strong>minimum capacity</strong> l√† 3 instances</p></li><li><p>Configuration hi·ªán t·∫°i ƒë√£ thay ƒë·ªïi th√†nh <strong>minimum capacity</strong> l√† 2 instances</p></li><li><p>C·∫ßn <strong>identify who made the change</strong> (ai ƒë√£ thay ƒë·ªïi configuration)</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>AWS Config</strong></p><ul><li><p><strong>AWS Config</strong> track <strong>configuration changes</strong> c·ªßa AWS resources theo th·ªùi gian</p></li><li><p><strong>Configuration Timeline</strong> trong Config show history c·ªßa resource changes</p></li><li><p>Config integrate v·ªõi <strong>CloudTrail</strong> ƒë·ªÉ capture <strong>WHO made changes</strong> (user/role information)</p></li><li><p>C√≥ th·ªÉ xem chi ti·∫øt configuration changes, th·ªùi gian thay ƒë·ªïi, v√† <strong>identity c·ªßa ng∆∞·ªùi th·ª±c hi·ªán</strong></p></li><li><p>Best service ƒë·ªÉ <strong>audit</strong> v√† track <strong>resource configuration changes</strong></p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Amazon Inspector</strong></p><ul><li><p>Inspector l√† <strong>security assessment service</strong> cho EC2 instances, containers, v√† Lambda functions</p></li><li><p>Focus v√†o <strong>vulnerability scanning</strong> v√† security findings</p></li><li><p><strong>Kh√¥ng track configuration changes</strong> ho·∫∑c identify users</p></li><li><p>Kh√¥ng ph√π h·ª£p cho <strong>auditing use case</strong></p></li></ul><p></p><p>‚ùå <strong>Amazon Macie</strong></p><ul><li><p>Macie l√† <strong>data security service</strong> specialized cho <strong>S3</strong></p></li><li><p>Ph√°t hi·ªán v√† protect <strong>sensitive data</strong> trong S3 buckets</p></li><li><p><strong>Kh√¥ng track infrastructure configuration changes</strong></p></li><li><p>Kh√¥ng li√™n quan ƒë·∫øn Auto Scaling group changes</p></li></ul><p></p><p>‚ùå <strong>Amazon CloudWatch Logs</strong></p><ul><li><p>CloudWatch Logs collect v√† monitor <strong>application/system logs</strong></p></li><li><p><strong>Kh√¥ng c√≥ built-in capability</strong> ƒë·ªÉ track WHO made configuration changes</p></li><li><p>C·∫ßn <strong>CloudTrail integration</strong> ƒë·ªÉ c√≥ audit trail information</p></li><li><p><strong>Kh√¥ng ph·∫£i tool ch√≠nh</strong> cho change tracking</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Identify who made the change\"</strong> ‚Üí <strong>AWS Config</strong> v·ªõi <strong>CloudTrail integration</strong></p></li><li><p><strong>\"Configuration change tracking\"</strong> ‚Üí <strong>AWS Config Configuration Timeline</strong></p></li><li><p><strong>\"Who/When/What changed\"</strong> ‚Üí <strong>Config</strong> cho resources, <strong>CloudTrail</strong> cho API calls</p></li><li><p><strong>Inspector</strong> ‚Üí Vulnerability scanning, kh√¥ng ph·∫£i change tracking</p></li><li><p><strong>Macie</strong> ‚Üí S3 data security, kh√¥ng ph·∫£i infrastructure auditing</p></li><li><p><strong>CloudWatch Logs</strong> ‚Üí Application logs, kh√¥ng ph·∫£i configuration auditing</p></li><li><p><strong>Config</strong> vs <strong>CloudTrail</strong> ‚Üí Config track resource states, CloudTrail track API calls (combine c√πng nhau)</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p>Viewing Configuration Details in the AWS Config Console</p></li></ul><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763860443673-w4oub8fl-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"394.95312499999994\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p>",
            "correctAnswer": [
                "<p>AWS Config</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>AWS Config</p>",
                "<p>Amazon Inspector</p>",
                "<p>Amazon Macie</p>",
                "<p>Amazon Cloud Watch Logs</p>"
            ],
            "answersPos": "[3,0,1,2]",
            "pos": 1
        },
        {
            "attemptAnswerId": 329143,
            "questionId": 6367,
            "questionText": "<p>A company is running an application on a group of Amazon EC2 instances behind an Application Load Balancer. The EC2 instances run across three Availability Zones. The company needs to provide the customers with a maximum of two static IP addresses for their applications.<br><br>How should a SysOps administrator meet these requirement?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company ch·∫°y application tr√™n EC2 instances ƒë·∫±ng sau <strong>Application Load Balancer (ALB)</strong></p></li><li><p>EC2 instances ch·∫°y tr√™n <strong>three Availability Zones</strong></p></li><li><p>C·∫ßn cung c·∫•p customers <strong>maximum of two static IP addresses</strong></p></li><li><p>H·ªèi: l√†m sao ƒë√°p ·ª©ng requirement?</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Add AWS Global Accelerator in front of the Application Load Balancer.</strong></p><ul><li><p><strong>AWS Global Accelerator</strong> cung c·∫•p <strong>2 static anycast IP addresses</strong></p></li><li><p>Route traffic t·ª´ static IPs n√†y ƒë·∫øn ALB endpoints</p></li><li><p><strong>ALB kh√¥ng h·ªó tr·ª£ static IPs natively</strong>, c·∫ßn Global Accelerator ƒë·ªÉ c√≥ static IPs</p></li><li><p>Global Accelerator improve performance v√† availability v·ªõi AWS global network</p></li><li><p>ƒê√°p ·ª©ng ch√≠nh x√°c requirement: <strong>maximum 2 static IPs</strong> cho customers</p></li></ul><p></p><p><em>Hinh minh ho·∫°:</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763861061348-esbm0xy3-image.png\" alt=\"\" title=\"\" width=\"645\" height=\"508.37841796875006\" style=\"max-width: 645px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Add an internal Network Load Balancer behind the Application Load Balancer.</strong></p><ul><li><p>Architecture <strong>kh√¥ng h·ª£p l√Ω</strong>: internal NLB ·ªü ph√≠a sau ALB kh√¥ng c√≥ √Ω nghƒ©a</p></li><li><p><strong>Internal NLB</strong> l√† internal-facing, <strong>kh√¥ng public-facing</strong> cho external customers</p></li><li><p><strong>Kh√¥ng gi·∫£i quy·∫øt</strong> v·∫•n ƒë·ªÅ static IPs cho external access</p></li><li><p>TƒÉng complexity kh√¥ng c·∫ßn thi·∫øt</p></li></ul><p></p><p>‚ùå <strong>Configure the Application Load Balancer in only two Availability Zones.</strong></p><ul><li><p><strong>ALB v·∫´n kh√¥ng c√≥ static IPs</strong> d√π ch·ªâ configure ·ªü 2 AZs</p></li><li><p><strong>Gi·∫£m high availability</strong> (t·ª´ 3 AZs xu·ªëng 2 AZs)</p></li><li><p><strong>Kh√¥ng gi·∫£i quy·∫øt requirement</strong> v·ªÅ static IP addresses</p></li><li><p>Vi ph·∫°m best practice v·ªÅ multi-AZ deployment</p></li></ul><p></p><p>‚ùå <strong>Create two Elastic IP addresses and assign them to the Application Load Balancer.</strong></p><ul><li><p><strong>ALB KH√îNG h·ªó tr·ª£</strong> g√°n Elastic IPs</p></li><li><p>Ch·ªâ <strong>Network Load Balancer (NLB)</strong> m·ªõi c√≥ th·ªÉ g√°n Elastic IPs</p></li><li><p><strong>Kh√¥ng th·ªÉ implement</strong> solution n√†y v·ªõi ALB</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Static IP addresses\"</strong> + <strong>\"Application Load Balancer\"</strong> ‚Üí <strong>AWS Global Accelerator</strong></p></li><li><p><strong>ALB</strong> ‚Üí Kh√¥ng h·ªó tr·ª£ static IPs, ch·ªâ c√≥ dynamic DNS name</p></li><li><p><strong>NLB</strong> ‚Üí H·ªó tr·ª£ Elastic IPs (static IPs per AZ)</p></li><li><p><strong>Global Accelerator</strong> ‚Üí Provides exactly 2 static anycast IPs</p></li><li><p><strong>Static IPs for ALB</strong> ‚Üí Only solution l√† add Global Accelerator in front</p></li><li><p><strong>Internal NLB</strong> ‚Üí Kh√¥ng d√πng cho external static IPs</p></li><li><p>Load balancer IP types ‚Üí ALB (dynamic), NLB (static per AZ), Global Accelerator (2 anycast IPs)</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/global-accelerator/latest/dg/what-is-global-accelerator.html\">What is AWS Global Accelerator?</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/global-accelerator/latest/dg/about-accelerators.alb-accelerator.html\">Adding an accelerator when you create a load balancer</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add AWS Global Accelerator in front of the Application Load Balancer.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add AWS Global Accelerator in front of the Application Load Balancer.</p>",
                "<p>Add an internal Network Load Balancer behind the Application Load Balancer.</p>",
                "<p>Configure the Application Load Balancer in only two Availability Zones.</p>",
                "<p>Create two Elastic IP addresses and assign them to the Application Load Balancer.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 2
        },
        {
            "attemptAnswerId": 329144,
            "questionId": 6368,
            "questionText": "<p>A company hosts a continuous integration and continuous delivery (CI/CD) environment on AWS. The CI/CD environment includes a Jenkins server that is hosted on an Amazon EC2 instance. A 500 GB General Purpose SSD (gp2) Amazon Elastic Block Store (Amazon EBS) volume is attached to the EC2 instance.<br><br>Because of disk throughput limitations, the Jenkins server reports performance issues that are resulting in slower builds on the server. The EBS volume needs to sustain 3,000 IOPS while performing nightly build tasks.<br><br>A SysOps administrator examines the server's history in Amazon CloudWatch. The BurstBalance metric has had a value of 0 during nightly builds. The SysOps administrator needs to improve the performance and meet the sustained throughput requirements.<br><br>Which solution will meet these requirements MOST cost-effectively?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Jenkins server tr√™n EC2 v·ªõi <strong>500 GB gp2 EBS volume</strong></p></li><li><p><strong>Disk throughput limitations</strong> g√¢y performance issues v√† slower builds</p></li><li><p>C·∫ßn sustain <strong>3,000 IOPS</strong> cho nightly build tasks</p></li><li><p><strong>BurstBalance metric = 0</strong> trong nightly builds (ƒë√£ h·∫øt burst credits)</p></li><li><p>C·∫ßn improve performance v√† meet <strong>sustained throughput requirements</strong></p></li><li><p>Y√™u c·∫ßu: <strong>MOST cost-effectively</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Change the volume type from gp2 to General Purpose SSD (gp3).</strong></p><ul><li><p><strong>gp3 baseline performance</strong>: <strong>3,000 IOPS</strong> v√† 125 MB/s throughput (b·∫•t k·ªÉ volume size)</p></li><li><p>500 GB gp3 v·∫´n c√≥ <strong>3,000 IOPS sustained</strong> m√† kh√¥ng c·∫ßn burst credits</p></li><li><p><strong>gp3 cheaper than gp2</strong> per GB (kho·∫£ng 20% r·∫ª h∆°n)</p></li><li><p><strong>Kh√¥ng c·∫ßn tƒÉng storage size</strong>, v·∫´n gi·ªØ 500 GB</p></li><li><p><strong>Most cost-effective</strong> solution: ƒë√°p ·ª©ng performance requirement v·ªõi chi ph√≠ th·∫•p nh·∫•t</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Double the gp2 EBS volume size from 500 GB to 1,000 GB.</strong></p><ul><li><p>gp2 baseline: <strong>3 IOPS/GB</strong> ‚Üí 1,000 GB = 3,000 baseline IOPS ƒë√°p ·ª©ng requirement</p></li><li><p>Nh∆∞ng <strong>ph·∫£i pay cho 1,000 GB storage</strong> kh√¥ng c·∫ßn thi·∫øt, <strong>kh√¥ng cost-effective</strong> so v·ªõi gp3</p></li></ul><p></p><p>‚ùå <strong>Change the volume type from gp2 to Throughput Optimized HDD (st1).</strong></p><ul><li><p><strong>st1 l√† HDD</strong> optimized cho sequential throughput, kh√¥ng ph·∫£i IOPS</p></li><li><p><strong>Kh√¥ng ph√π h·ª£p</strong> cho CI/CD workloads c·∫ßn high random IOPS, performance s·∫Ω t·ªá h∆°n</p></li></ul><p></p><p>‚ùå <strong>Change the volume type from gp2 to Provisioned IOPS SSD (io2).</strong></p><ul><li><p><strong>io2 l√† most expensive</strong> EBS volume type</p></li><li><p><strong>Overkill</strong> cho Jenkins workload, <strong>kh√¥ng cost-effective</strong></p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"BurstBalance = 0\"</strong> ‚Üí gp2 ƒë√£ h·∫øt burst credits, ch·ªâ c√≤n baseline IOPS</p></li><li><p><strong>\"3,000 IOPS sustained\"</strong> + <strong>\"cost-effectively\"</strong> ‚Üí <strong>gp3</strong> l√† best choice</p></li><li><p><strong>gp2 baseline</strong>: 3 IOPS/GB (min 100, max 16,000 IOPS)</p></li><li><p><strong>gp3 baseline</strong>: 3,000 IOPS v√† 125 MB/s (b·∫•t k·ªÉ size, c√≥ th·ªÉ provision th√™m n·∫øu c·∫ßn)</p></li><li><p><strong>gp3 vs gp2</strong>: gp3 cheaper v√† predictable performance</p></li><li><p><strong>st1/sc1 (HDD)</strong> ‚Üí Kh√¥ng d√πng cho high IOPS workloads (Jenkins, databases)</p></li><li><p><strong>io1/io2</strong> ‚Üí Expensive, d√πng cho mission-critical workloads c·∫ßn &gt; 16,000 IOPS</p></li><li><p><strong>Cost optimization pattern</strong>: gp2 ‚Üí gp3 migration saves cost v·ªõi better baseline performance</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html\">Amazon EBS volume types</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/general-purpose.html\">General Purpose SSD volumes (gp2 and gp3)</a></p></li></ul>",
            "correctAnswer": [
                "<p>Change the volume type from gp2 to General Purpose SSD (gp3).</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Double the gp2 EBS volume size from 500 GB to 1,000 GB.</p>",
                "<p>Change the volume type from gp2 to General Purpose SSD (gp3).</p>",
                "<p>Change the volume type from gp2 to Throughput Optimized HDD (st1).</p>",
                "<p>Change the volume type from gp2 to Provisioned IOPS SSD (io2).</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 3
        },
        {
            "attemptAnswerId": 329145,
            "questionId": 6369,
            "questionText": "<p>A SysOps administrator wants to share a copy of a production database with a migration account. The production database is hosted on an Amazon RDS DB instance and is encrypted at rest with an AWS Key Management Service (AWS KMS) key that has an alias of production-rds-key.<br><br>What must the SysOps administrator do to meet these requirements with the LEAST administrative overhead?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>SysOps admin mu·ªën share copy c·ªßa <strong>production database</strong> v·ªõi migration account</p></li><li><p>Production database host tr√™n <strong>RDS DB instance</strong></p></li><li><p>Database <strong>encrypted at rest</strong> v·ªõi <strong>AWS KMS key</strong> (alias: production-rds-key)</p></li><li><p>Y√™u c·∫ßu: <strong>LEAST administrative overhead</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Take a snapshot of the RDS DB instance in the production account. Amend the KMS key policy of the production-rds-key KMS key to give access to the migration account's root user. Share the snapshot with the migration account.</strong></p><ul><li><p><strong>Cross-account encrypted snapshot sharing</strong> y√™u c·∫ßu sharing c·∫£ <strong>snapshot</strong> V√Ä <strong>KMS key access</strong></p></li><li><p>Update <strong>KMS key policy</strong> ƒë·ªÉ grant <strong>kms:Decrypt</strong> v√† <strong>kms:CreateGrant</strong> cho migration account</p></li><li><p><strong>Share snapshot</strong> v·ªõi migration account th√¥ng qua RDS console/API</p></li><li><p>Migration account c√≥ th·ªÉ <strong>copy snapshot</strong> v√† decrypt v·ªõi shared KMS key</p></li><li><p><strong>Least overhead</strong>: ch·ªâ 3 b∆∞·ªõc - snapshot, update KMS policy, share snapshot</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create an RDS read replica in the migration account. Configure the KMS key policy to replicate the production-rds-key KMS key to the migration account.</strong></p><ul><li><p><strong>KH√îNG TH·ªÇ</strong> create cross-account read replica directly cho RDS</p></li><li><p><strong>KMS keys kh√¥ng replicate</strong> across accounts, KMS keys are region and account specific</p></li></ul><p></p><p>‚ùå <strong>Take a snapshot of the RDS DB instance in the production account. Share the snapshot with the migration account. In the migration account, create a new KMS key that has an identical alias.</strong></p><ul><li><p>Migration account <strong>KH√îNG TH·ªÇ decrypt</strong> snapshot v·ªõi KMS key kh√°c</p></li><li><p><strong>Thi·∫øu b∆∞·ªõc grant KMS access</strong> ho·∫∑c re-encrypt snapshot, snapshot v·∫´n encrypted v·ªõi production KMS key</p></li></ul><p></p><p>‚ùå <strong>Use native database toolsets to export the RDS DB instance to Amazon S3. Create an S3 bucket and an S3 bucket policy for cross account access between the production account and the migration account. Use native database toolsets to import the database from Amazon S3 to a new RDS DB instance.</strong></p><ul><li><p>Works nh∆∞ng <strong>MOST overhead</strong>: export ‚Üí S3 setup ‚Üí cross-account policy ‚Üí import</p></li><li><p>Ph·ª©c t·∫°p v√† time-consuming, <strong>kh√¥ng ph·∫£i least overhead</strong></p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Share encrypted RDS snapshot\"</strong> ‚Üí Must share c·∫£ <strong>snapshot</strong> V√Ä <strong>KMS key access</strong></p></li><li><p><strong>\"Cross-account KMS\"</strong> ‚Üí Update <strong>KMS key policy</strong> to grant target account permissions</p></li><li><p><strong>\"LEAST overhead\"</strong> ‚Üí Snapshot + KMS policy update (kh√¥ng c·∫ßn export/import)</p></li><li><p><strong>RDS read replica</strong> ‚Üí KH√îNG support cross-account replication</p></li><li><p><strong>KMS key replication</strong> ‚Üí KMS keys KH√îNG replicate across accounts</p></li><li><p><strong>Encrypted snapshot sharing</strong> ‚Üí 3 steps: snapshot, KMS policy, share snapshot</p></li><li><p><strong>Cross-account pattern</strong>: Share resource + Share encryption key access</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-soa/share-encrypted-rds-snapshot-kms-key\">Share RDS snapshots across AWS account</a></p></li></ul><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763862012700-klwpiavg-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"281.25\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p>",
            "correctAnswer": [
                "<p>Take a snapshot of the RDS DB instance in the production account. Amend the KMS key policy of the production-rds-key KMS key to give access to the migration account's root user. Share the snapshot with the migration account.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Take a snapshot of the RDS DB instance in the production account. Amend the KMS key policy of the production-rds-key KMS key to give access to the migration account's root user. Share the snapshot with the migration account.</p>",
                "<p>Create an RDS read replica in the migration account. Configure the KMS key policy to replicate the production-rds-key KMS key to the migration account.</p>",
                "<p>Take a snapshot of the RDS DB instance in the production account. Share the snapshot with the migration account. In the migration account, create a new KMS key that has an identical alias.</p>",
                "<p>Use native database toolsets to export the RDS DB instance to Amazon S3. Create an S3 bucket and an S3 bucket policy for cross account access between the production account and the migration account. Use native database toolsets to import the database from Amazon S3 to a new RDS DB instance.</p>"
            ],
            "answersPos": "[2,1,3,0]",
            "pos": 4
        },
        {
            "attemptAnswerId": 329146,
            "questionId": 6370,
            "questionText": "<p>A company is running Amazon RDS for PostgreSQL Multi-AZ DB clusters. The company uses an AWS CloudFormation template to create the databases individually with a default size of 100 GB. The company creates the databases every Monday and deletes the databases every Friday.<br><br>Occasionally, the databases run low on disk space and initiate an Amazon CloudWatch alarm. A SysOps administrator must prevent the databases from running low on disk space in the future.<br><br>Which solution will meet these requirements with the FEWEST changes to the application?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company ch·∫°y <strong>RDS for PostgreSQL Multi-AZ DB clusters</strong></p></li><li><p>D√πng <strong>CloudFormation template</strong> ƒë·ªÉ create databases v·ªõi <strong>default size 100 GB</strong></p></li><li><p>Databases created <strong>every Monday</strong>, deleted <strong>every Friday</strong></p></li><li><p><strong>Occasionally (th·ªânh tho·∫£ng) run low on disk space</strong> ‚Üí trigger CloudWatch alarm</p></li><li><p>C·∫ßn prevent databases t·ª´ running low on disk space</p></li><li><p>Y√™u c·∫ßu: <strong>FEWEST changes to the application</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Modify the CloudFormation template to activate storage auto scaling on the existing DB instances.</strong></p><ul><li><p><strong>RDS storage auto scaling</strong> automatically increase storage capacity khi free space th·∫•p</p></li><li><p>Ch·ªâ c·∫ßn <strong>enable feature trong CloudFormation template</strong> (parameter: MaxAllocatedStorage)</p></li><li><p><strong>Kh√¥ng c·∫ßn change application code</strong> ho·∫∑c database engine</p></li><li><p>Auto scaling trigger khi free space &lt; threshold (default 10%)</p></li><li><p><strong>Fewest changes</strong>: ch·ªâ modify CloudFormation template, kh√¥ng touch application</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Modify the CloudFormation template to use Amazon Aurora PostgreSQL as the DB engine.</strong></p><ul><li><p>Aurora c√≥ auto scaling storage nh∆∞ng ƒë√¢y l√† <strong>change DB engine</strong></p></li><li><p>C√≥ th·ªÉ require <strong>application modifications</strong> (connection strings, features compatibility)</p></li><li><p><strong>Not fewest changes</strong> compared to just enabling storage auto scaling</p></li></ul><p></p><p>‚ùå <strong>Modify the CloudFormation template to use Amazon DynamoDB as the database. Activate storage auto scaling during creation of the tables.</strong></p><ul><li><p>DynamoDB l√† <strong>NoSQL database</strong>, ho√†n to√†n kh√°c PostgreSQL</p></li><li><p>Requires <strong>major application rewrite</strong> ƒë·ªÉ change t·ª´ SQL sang NoSQL</p></li><li><p><strong>Most changes</strong>, kh√¥ng ph·∫£i fewest changes</p></li></ul><p></p><p>‚ùå <strong>Create a CloudWatch alarm to monitor DB instance storage space. Configure the alarm to invoke the VACUUM command.</strong></p><ul><li><p><strong>VACUUM command c·∫£i thi·ªán space</strong>, kh√¥ng tƒÉng storage capacity</p></li><li><p><strong>Kh√¥ng gi·∫£i quy·∫øt</strong> v·∫•n ƒë·ªÅ c·∫ßn more storage space</p></li><li><p>VACUUM optimize existing space, kh√¥ng add new space</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Run low on disk space\"</strong> + <strong>\"FEWEST changes\"</strong> ‚Üí <strong>RDS storage auto scaling</strong></p></li><li><p><strong>\"FEWEST changes to application\"</strong> ‚Üí Infrastructure/configuration changes, kh√¥ng change code ho·∫∑c database type</p></li><li><p><strong>Storage auto scaling</strong> ‚Üí Automatic, no manual intervention needed</p></li><li><p><strong>VACUUM</strong> ‚Üí Reclaims space, kh√¥ng tƒÉng storage size</p></li><li><p><strong>Engine migration</strong> (RDS ‚Üí Aurora, SQL ‚Üí NoSQL) ‚Üí Requires application changes</p></li><li><p><strong>RDS storage auto scaling</strong> ‚Üí Set MaxAllocatedStorage parameter trong CloudFormation</p></li><li><p><strong>Auto scaling vs Migration</strong> ‚Üí Auto scaling = zero application changes, migration = code changes</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.Autoscaling.html\">Managing capacity automatically with Amazon RDS storage autoscaling</a></p></li></ul>",
            "correctAnswer": [
                "<p>Modify the CloudFormation template to activate storage auto scaling on the existing DB instances.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Modify the CloudFormation template to use Amazon Aurora PostgreSQL as the DB engine.</p>",
                "<p>Modify the CloudFormation template to use Amazon DynamoDB as the database. Activate storage auto scaling during creation of the tables.</p>",
                "<p>Modify the CloudFormation template to activate storage auto scaling on the existing DB instances.</p>",
                "<p>Create a CloudWatch alarm to monitor DB instance storage space. Configure the alarm to invoke the VACUUM command.</p>"
            ],
            "answersPos": "[2,1,3,0]",
            "pos": 5
        },
        {
            "attemptAnswerId": 329147,
            "questionId": 6371,
            "questionText": "<p>A SysOps administrator is responsible for a company's disaster recovery procedures. The company has a source Amazon S3 bucket in a production account, and it wants to replicate objects from the source to a destination S3 bucket in a nonproduction account. The SysOps administrator configures S3 cross-Region, cross-account replication to copy the source S3 bucket to the destination S3 bucket. When the SysOps administrator attempts to access objects in the destination S3 bucket, they receive an Access Denied error.<br><br>Which solution will resolve this problem?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Source <strong>S3 bucket</strong> ·ªü <strong>production account</strong></p></li><li><p>Destination <strong>S3 bucket</strong> ·ªü <strong>nonproduction account</strong></p></li><li><p>Configure <strong>S3 cross-Region, cross-account replication</strong></p></li><li><p>SysOps admin access objects ·ªü destination bucket ‚Üí <strong>Access Denied error</strong></p></li><li><p>H·ªèi: gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y?</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Modify the replication configuration to change object ownership to the destination S3 bucket owner.</strong></p><ul><li><p>Trong <strong>cross-account replication</strong>, m·∫∑c ƒë·ªãnh <strong>replicated objects v·∫´n owned by source account</strong></p></li><li><p>Destination account <strong>KH√îNG c√≥ permission</strong> ƒë·ªÉ access objects do source account owns</p></li><li><p>Solution: Enable <strong>\"Change object ownership to destination\"</strong> trong replication configuration</p></li><li><p>Sau khi change ownership, destination account c√≥ <strong>full control</strong> over replicated objects</p></li><li><p>Resolve Access Denied v√¨ destination account tr·ªü th√†nh owner c·ªßa objects</p></li></ul><p></p><p><em>Setting</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763863085386-pcoyn981-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"498.87500000000006\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Ensure that the replication rule applies to all objects in the source S3 bucket and is not scoped to a single prefix.</strong></p><ul><li><p>Replication scope (prefix/filter) <strong>KH√îNG li√™n quan</strong> ƒë·∫øn Access Denied issue</p></li><li><p>Ch·ªâ ·∫£nh h∆∞·ªüng ƒë·∫øn objects n√†o ƒë∆∞·ª£c replicate, kh√¥ng ·∫£nh h∆∞·ªüng permissions</p></li></ul><p></p><p>‚ùå <strong>Retry the request when the S3 Replication Time Control (S3 RTC) has elapsed.</strong></p><ul><li><p><strong>S3 RTC</strong> v·ªÅ replication timing/SLA (replicate trong 15 minutes)</p></li><li><p><strong>KH√îNG gi·∫£i quy·∫øt</strong> permission/ownership issue, retry c≈©ng v·∫´n Access Denied</p></li></ul><p></p><p>‚ùå <strong>Verify that the storage class for the replicated objects did not change between the source S3 bucket and the destination S3 bucket.</strong></p><ul><li><p>Storage class <strong>KH√îNG ·∫£nh h∆∞·ªüng</strong> ƒë·∫øn access permissions</p></li><li><p>Storage class ch·ªâ ·∫£nh h∆∞·ªüng cost v√† retrieval time</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Cross-account replication\"</strong> + <strong>\"Access Denied\"</strong> ‚Üí <strong>Object ownership issue</strong></p></li><li><p><strong>Default cross-account replication</strong> ‚Üí Objects owned by source account</p></li><li><p><strong>\"Change object ownership\"</strong> ‚Üí Destination account becomes owner, c√≥ full permissions</p></li><li><p><strong>S3 RTC</strong> ‚Üí Replication timing SLA, kh√¥ng ph·∫£i permission fix</p></li><li><p><strong>Replication scope/prefix</strong> ‚Üí Controls which objects replicate, kh√¥ng ·∫£nh h∆∞·ªüng permissions</p></li><li><p><strong>Storage class</strong> ‚Üí Cost/performance feature, kh√¥ng li√™n quan access control</p></li><li><p><strong>Cross-account S3 pattern</strong> ‚Üí Must explicitly change ownership ho·∫∑c grant permissions</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication-change-owner.html\">Changing the replica owner</a></p></li></ul>",
            "correctAnswer": [
                "<p>Modify the replication configuration to change object ownership to the destination S3 bucket owner.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Modify the replication configuration to change object ownership to the destination S3 bucket owner.</p>",
                "<p>Ensure that the replication rule applies to all objects in the source S3 bucket and is not scoped to a single prefix.</p>",
                "<p>Retry the request when the S3 Replication Time Control (S3 RTC) has elapsed.</p>",
                "<p>Verify that the storage class for the replicated objects did not change between the source S3 bucket and the destination S3 bucket.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 6
        },
        {
            "attemptAnswerId": 329148,
            "questionId": 6372,
            "questionText": "<p>A company uses Amazon CloudFront to serve static content to end users. The company's marketing team recently deployed updates to 150 images on the company's website. However, the website is not displaying some of the new images.<br><br>A SysOps administrator reviews the CloudFront distribution's cache settings. The default TTL for the distribution is set to 1 week (604,800 seconds).<br><br>What should the SysOps administrator do to refresh the cache with the new images in the MOST operationally efficient way?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company d√πng <strong>CloudFront</strong> ƒë·ªÉ serve <strong>static content</strong></p></li><li><p>Marketing team deployed updates to <strong>150 images</strong></p></li><li><p>Website <strong>kh√¥ng display m·ªôt s·ªë new images</strong> (still showing old cached images)</p></li><li><p>CloudFront distribution's <strong>default TTL = 1 week (604,800 seconds)</strong></p></li><li><p>C·∫ßn <strong>refresh cache</strong> v·ªõi new images</p></li><li><p>Y√™u c·∫ßu: <strong>MOST operationally efficient way</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Issue a CloudFront invalidation request to immediately expire the new images from the marketing team's update.</strong></p><ul><li><p><strong>CloudFront invalidation</strong> force remove objects from edge cache ngay l·∫≠p t·ª©c</p></li><li><p>C√≥ th·ªÉ invalidate <strong>specific paths</strong> ho·∫∑c use <strong>wildcard patterns</strong> (e.g., /images/*)</p></li><li><p>Next request s·∫Ω fetch <strong>new version</strong> t·ª´ origin</p></li><li><p><strong>Most efficient</strong>: tr·ª±c ti·∫øp gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ, kh√¥ng c·∫ßn infrastructure changes</p></li><li><p>AWS Free Tier: first 1,000 invalidation paths/month free</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a new CloudFront distribution that has the same origin. Set the default TTL to 1 minute (60 seconds). Switch Amazon Route 53 DNS records to use the new distribution.</strong></p><ul><li><p><strong>Complex qu√° m·ª©c</strong>: t·∫°o new distribution, update DNS, manage multiple distributions</p></li><li><p><strong>DNS propagation delay</strong>, kh√¥ng ph·∫£i immediate solution</p></li><li><p><strong>Not operationally efficient</strong>, tƒÉng management overhead</p></li></ul><p></p><p>‚ùå <strong>Instruct the marketing team to upload the new images to a different location. When the new images are uploaded, update the website to locate the new images.</strong></p><ul><li><p>Requires <strong>change website code</strong> ƒë·ªÉ point to new image paths</p></li><li><p><strong>Application deployment</strong> needed, kh√¥ng ph·∫£i infrastructure fix</p></li><li><p><strong>Not efficient</strong>, marketing team ph·∫£i re-upload v√† track multiple versions</p></li></ul><p></p><p>‚ùå <strong>Update the existing CloudFront distribution to reconfigure the default TTL to 1 minute (60 seconds). During submission of the new configuration, include the flag to invalidate objects in the specified path.</strong></p><ul><li><p><strong>Changing TTL</strong> ch·ªâ affect <strong>future caching</strong>, kh√¥ng clear existing cache</p></li><li><p><strong>Existing cached objects</strong> (with 1 week TTL) v·∫´n kh√¥ng refresh</p></li><li><p>TTL 1 minute qu√° th·∫•p, increase origin load v√† latency</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Not displaying new images\"</strong> + <strong>\"cached content\"</strong> ‚Üí <strong>CloudFront invalidation</strong></p></li><li><p><strong>\"Immediately refresh cache\"</strong> ‚Üí <strong>Invalidation request</strong> l√† only solution</p></li><li><p><strong>\"MOST operationally efficient\"</strong> ‚Üí Direct action (invalidation), kh√¥ng c·∫ßn infrastructure changes</p></li><li><p><strong>CloudFront invalidation</strong> ‚Üí First 1,000 paths/month free, charged after that</p></li><li><p><strong>TTL change</strong> ‚Üí Only affects future requests, kh√¥ng clear existing cache</p></li><li><p><strong>Invalidation vs Versioned filenames</strong> ‚Üí Invalidation for immediate fix, versioning for long-term strategy</p></li><li><p><strong>Wildcard invalidation</strong> ‚Üí /images/* invalidates all objects trong path</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Invalidation.html\">Invalidating files</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://repost.aws/questions/QUG__vuLtlS-Wf_z2iNxOFtw/cloudfront-continues-to-serve-old-content-after-invalidation-and-s3-update\">Choose when CloudFront serves an outdated object</a></p></li></ul>",
            "correctAnswer": [
                "<p>Issue a CloudFront invalidation request to immediately expire the new images from the marketing team's update.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a new CloudFront distribution that has the same origin. Set the default TTL to 1 minute (60 seconds). Switch Amazon Route 53 DNS records to use the new distribution.</p>",
                "<p>Instruct the marketing team to upload the new images to a different location. When the new images are uploaded, update the website to locate the new images.</p>",
                "<p>Issue a CloudFront invalidation request to immediately expire the new images from the marketing team's update.</p>",
                "<p>Update the existing CloudFront distribution to reconfigure the default TTL to 1 minute (60 seconds). During submission of the new configuration, include the flag to invalidate objects in the specified path.</p>"
            ],
            "answersPos": "[1,3,0,2]",
            "pos": 7
        },
        {
            "attemptAnswerId": 329149,
            "questionId": 6373,
            "questionText": "<p>A company is transitioning away from applications that are hosted on Amazon EC2 instances. The company wants to implement a serverless architecture that uses Amazon S3, Amazon API Gateway, AWS Lambda, and Amazon CloudFront. As part of this transition, the company has Elastic IP addresses that are unassociated with any EC2 instances after the EC2 instances are terminated.<br><br>A SysOps administrator needs to automate the process of releasing all unassociated Elastic IP addresses that remain after the EC2 instances are terminated.<br><br>Which solution will meet this requirement in the MOST operationally efficient way?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company chuy·ªÉn t·ª´ EC2 sang <strong>serverless architecture</strong></p></li><li><p>Sau khi <strong>terminate EC2 instances</strong>, c√≤n l·∫°i <strong>unassociated Elastic IP addresses</strong></p></li><li><p>C·∫ßn <strong>automate process</strong> release all unassociated Elastic IPs</p></li><li><p>Y√™u c·∫ßu: <strong>MOST operationally efficient way</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Activate the eip-attached AWS Config managed rule to run automatically when resource changes occur in the AWS account. Configure automatic remediation for the rule. Specify the AWS-ReleaseElasticIP AWS Systems Manager Automation runbook for remediation. Specify an appropriate role that has permission for the remediation.</strong></p><ul><li><p><strong>AWS Config managed rule </strong><code>eip-attached</code> check if Elastic IPs are associated v·ªõi resources</p></li><li><p><strong>Automatic remediation</strong> v·ªõi <strong>AWS-ReleaseElasticIP SSM Automation runbook</strong> (built-in)</p></li><li><p><strong>No custom code needed</strong>, fully managed solution</p></li><li><p>Runs automatically khi resource changes occur (config change detection)</p></li><li><p><strong>Most operationally efficient</strong>: zero-touch automation, no Lambda development/maintenance</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a custom Lambda function that calls the EC2 ReleaseAddress API operation and specifies the Elastic IP address AllocationId. Invoke the Lambda function by using an Amazon EventBridge rule. Specify AWS services as the event source, All Events as the event type, and AWS Trusted Advisor as the target.</strong></p><ul><li><p><strong>AWS Trusted Advisor kh√¥ng ph·∫£i appropriate target</strong> cho EventBridge rule n√†y</p></li><li><p>Requires <strong>custom Lambda code</strong>, more maintenance overhead</p></li></ul><p></p><p>‚ùå <strong>Create an Amazon EventBridge rule. Specify AWS services as the event source, Instance State-change Notification as the event type, and Amazon EC2 as the service. Invoke a Lambda function that extracts the Elastic IP address from the notification. Use AWS CloudFormation to release the address by specifying the AllocationId as an input parameter.</strong></p><ul><li><p><strong>CloudFormation kh√¥ng ph·∫£i tool</strong> ƒë·ªÉ dynamically release EIPs</p></li><li><p><strong>Overly complex</strong>: EventBridge + Lambda + CloudFormation</p></li><li><p>Not operationally efficient</p></li></ul><p></p><p>‚ùå <strong>Create a custom Lambda function that calls the EC2 ReleaseAddress API operation and specifies the Elastic IP address AllocationId. Invoke the Lambda function by using an Amazon EventBridge rule. Specify AWS services as the event source, Instance State-change Notification as the event type, and Amazon EC2 as the service.</strong></p><ul><li><p>Works nh∆∞ng requires <strong>custom Lambda code</strong> development v√† maintenance</p></li><li><p><strong>Not as efficient</strong> as managed Config rule v·ªõi built-in remediation</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Unassociated Elastic IPs\"</strong> + <strong>\"automate release\"</strong> ‚Üí <strong>AWS Config eip-attached rule</strong></p></li><li><p><strong>\"MOST operationally efficient\"</strong> ‚Üí <strong>Managed services</strong> (Config + SSM Automation) over custom code</p></li><li><p><strong>AWS Config auto remediation</strong> ‚Üí Zero-touch compliance enforcement</p></li><li><p><strong>eip-attached rule</strong> ‚Üí AWS Config managed rule specifically cho Elastic IP compliance</p></li><li><p><strong>Custom Lambda</strong> ‚Üí More development/maintenance overhead</p></li><li><p><strong>Instance State-change</strong> ‚Üí Triggers on EC2 events, nh∆∞ng c·∫ßn custom logic ƒë·ªÉ handle EIPs</p></li><li><p><strong>Automation pattern</strong> ‚Üí Config rules + SSM Automation runbooks = no-code remediation</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/config/latest/developerguide/eip-attached.html\">eip-attached</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-aws-releaseelasticip.html\">AWS-ReleaseElasticIP</a></p></li></ul>",
            "correctAnswer": [
                "<p>Activate the eip-attached AWS Config managed rule to run automatically when resource changes occur in the AWS account. Configure automatic remediation for the rule. Specify the AWS-ReleaseElasticIP AWS Systems Manager Automation runbook for remediation. Specify an appropriate role that has permission for the remediation.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Activate the eip-attached AWS Config managed rule to run automatically when resource changes occur in the AWS account. Configure automatic remediation for the rule. Specify the AWS-ReleaseElasticIP AWS Systems Manager Automation runbook for remediation. Specify an appropriate role that has permission for the remediation.</p>",
                "<p>Create a custom Lambda function that calls the EC2 ReleaseAddress API operation and specifies the Elastic IP address AllocationId. Invoke the Lambda function by using an Amazon EventBridge rule. Specify AWS services as the event source, All Events as the event type, and AWS Trusted Advisor as the target.</p>",
                "<p>Create an Amazon EventBridge rule. Specify AWS services as the event source, Instance State-change Notification as the event type, and Amazon EC2 as the service. Invoke a Lambda function that extracts the Elastic IP address from the notification. Use AWS CloudFormation to release the address by specifying the AllocationId as an input parameter.</p>",
                "<p>Create a custom Lambda function that calls the EC2 ReleaseAddress API operation and specifies the Elastic IP address AllocationId. Invoke the Lambda function by using an Amazon EventBridge rule. Specify AWS services as the event source, Instance State-change Notification as the event type, and Amazon EC2 as the service.</p>"
            ],
            "answersPos": "[1,0,2,3]",
            "pos": 8
        },
        {
            "attemptAnswerId": 329150,
            "questionId": 6374,
            "questionText": "<p>A company has several member accounts that are in an organization in AWS Organizations. The company recently discovered that administrators have been using account root user credentials. The company must prevent the administrators from using root user credentials to perform any actions on Amazon EC2 instances.<br><br>What should a SysOps administrator do to meet this requirement?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company c√≥ multiple <strong>member accounts</strong> trong <strong>AWS Organizations</strong></p></li><li><p>Admins ƒëang s·ª≠ d·ª•ng <strong>account root user credentials</strong></p></li><li><p>C·∫ßn <strong>prevent root user</strong> t·ª´ performing <strong>any actions on EC2 instances</strong></p></li><li><p>H·ªèi: solution to meet requirement?</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>In the organization's management account, create a service control policy (SCP) to deny actions on EC2 instances by the root user in all member accounts.</strong></p><ul><li><p><strong>SCPs</strong> l√† <strong>ONLY mechanism</strong> c√≥ th·ªÉ restrict <strong>root user permissions</strong> trong member accounts</p></li><li><p>SCPs apply t·∫°i <strong>organization/OU/account level</strong> v√† override t·∫•t c·∫£ permissions</p></li><li><p>C√≥ th·ªÉ create <strong>SCP with Deny effect</strong> specifically cho root user principal</p></li><li><p>Centralized management t·ª´ <strong>management account</strong>, apply to all member accounts</p></li><li><p><strong>Most effective</strong> cho organization-wide policy enforcement</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create an identity-based IAM policy in each member account to deny actions on EC2 instances by the root user.</strong></p><ul><li><p><strong>IAM policies KH√îNG √ÅP D·ª§NG cho root user</strong> - root user bypasses IAM policies</p></li><li><p>Root user c√≥ full permissions, kh√¥ng th·ªÉ restrict b·∫±ng identity-based IAM policies</p></li></ul><p></p><p>‚ùå <strong>Use AWS Config to prevent any actions on EC2 instances by the root user.</strong></p><ul><li><p>AWS Config l√† <strong>detective control</strong>, ch·ªâ detect v√† report compliance</p></li><li><p><strong>KH√îNG PH·∫¢I preventive control</strong>, kh√¥ng prevent actions real-time</p></li></ul><p></p><p>‚ùå <strong>Use Amazon Inspector in each member account to scan for root user logins and to prevent any actions on EC2 instances by the root user.</strong></p><ul><li><p>Inspector l√† <strong>vulnerability scanning tool</strong> cho EC2/containers/Lambda</p></li><li><p><strong>KH√îNG monitor</strong> root user activities ho·∫∑c prevent actions</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Prevent root user\"</strong> + <strong>\"member accounts\"</strong> ‚Üí <strong>Service Control Policies (SCPs)</strong></p></li><li><p><strong>\"Organization-wide restriction\"</strong> ‚Üí SCPs l√† only solution</p></li><li><p><strong>IAM policies vs SCPs</strong> ‚Üí IAM policies KH√îNG affect root user, SCPs C√ì TH·ªÇ restrict root user</p></li><li><p><strong>SCPs scope</strong> ‚Üí Apply to all principals including root user in member accounts</p></li><li><p><strong>Config vs SCPs</strong> ‚Üí Config = detective (detect), SCPs = preventive (prevent)</p></li><li><p><strong>Inspector</strong> ‚Üí Security assessment, kh√¥ng ph·∫£i access control</p></li><li><p><strong>Root user restriction pattern</strong> ‚Üí SCPs trong Organizations l√† only way</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html\">Service control policies (SCPs)</a></p></li></ul>",
            "correctAnswer": [
                "<p>In the organization's management account, create a service control policy (SCP) to deny actions on EC2 instances by the root user in all member accounts.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an identity-based IAM policy in each member account to deny actions on EC2 instances by the root user.</p>",
                "<p>In the organization's management account, create a service control policy (SCP) to deny actions on EC2 instances by the root user in all member accounts.</p>",
                "<p>Use AWS Config to prevent any actions on EC2 instances by the root user.</p>",
                "<p>Use Amazon Inspector in each member account to scan for root user logins and to prevent any actions on EC2 instances by the root user.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 9
        },
        {
            "attemptAnswerId": 329151,
            "questionId": 6375,
            "questionText": "<p>A company has an Amazon EC2 instance that supports a production system. The EC2 instance is backed by an Amazon Elastic Block Store (Amazon EBS) volume. The EBS volume's drive has filled to 100% capacity, which is causing the application on the EC2 instance to experience errors.<br><br>Which solution will remediate these errors in the LEAST amount of time?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>EC2 instance support <strong>production system</strong>, backed by <strong>EBS volume</strong></p></li><li><p><strong>EBS volume's drive filled to 100% capacity</strong></p></li><li><p>Causing <strong>application errors</strong></p></li><li><p>C·∫ßn kh·∫Øc ph·ª•c errors</p></li><li><p>Y√™u c·∫ßu: <strong>LEAST amount of time</strong> (nhanh nh·∫•t)</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Modify the EBS volume by adding additional drive space. Log on to the EC2 instance. Use the file system-specific commands to extend the file system.</strong></p><ul><li><p><strong>Elastic Volumes</strong> cho ph√©p <strong>modify EBS volume size online</strong> (no downtime)</p></li><li><p>Increase volume size c√≥ th·ªÉ th·ª±c hi·ªán <strong>while instance is running</strong></p></li><li><p>Sau khi modify volume, ch·ªâ c·∫ßn <strong>extend file system</strong> v·ªõi OS commands (resize2fs, xfs_growfs)</p></li><li><p><strong>FASTEST solution</strong>: no snapshot creation, no detach/attach, minimal downtime</p></li><li><p>Production system c√≥ th·ªÉ continue running during volume modification</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a snapshot of the existing EBS volume. When the snapshot is complete, create an EBS volume of a larger size from the snapshot in the same Availability Zone as the EC2 instance. Attach the new EBS volume to the EC2 instance. Mount the file system.</strong></p><ul><li><p><strong>T·ªën kh√° nhi·ªÅu th·ªùi gian</strong>: snapshot creation + volume creation + attach + mount</p></li><li><p>Requires <strong>downtime</strong> ƒë·ªÉ switch volumes</p></li><li><p><strong>Not the fastest</strong> approach</p></li></ul><p></p><p>‚ùå <strong>Create a new EBS volume of a larger size in the same Availability Zone as the EC2 instance. Attach the EBS volume to the EC2 instance. Copy the data from the existing EBS volume to the new EBS volume.</strong></p><ul><li><p>Requires <strong>copying all data</strong> from old to new volume - m·∫•t kh√° nhi·ªÅu th·ªùi gian</p></li><li><p><strong>Additional complexity</strong> v·ªõi data migration</p></li><li><p><strong>Longest time</strong> trong s·ªë t·∫•t c·∫£ options</p></li></ul><p></p><p>‚ùå <strong>Stop the EC2 instance. Change the EC2 instance to a larger instance size that includes additional drive space. Start the EC2 instance.</strong></p><ul><li><p><strong>Instance size KH√îNG ·∫£nh h∆∞·ªüng EBS volume size</strong> - sai concept</p></li><li><p>Requires <strong>downtime</strong> (stop/start instance)</p></li><li><p><strong>Kh√¥ng gi·∫£i quy·∫øt</strong> v·∫•n ƒë·ªÅ EBS capacity</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"EBS full\"</strong> + <strong>\"LEAST time\"</strong> ‚Üí <strong>Elastic Volumes modification</strong> (online resize)</p></li><li><p><strong>Elastic Volumes</strong> ‚Üí Modify size, type, IOPS <strong>without downtime</strong></p></li><li><p><strong>Instance size vs EBS size</strong> ‚Üí Ho√†n to√†n ƒë·ªôc l·∫≠p, changing instance type kh√¥ng tƒÉng EBS capacity</p></li><li><p><strong>Volume modification</strong> ‚Üí Online operation, no detach needed</p></li><li><p><strong>File system extension</strong> ‚Üí Must run after volume resize (resize2fs, xfs_growfs)</p></li><li><p><strong>Snapshot approach</strong> ‚Üí Slower, requires recreation v√† reattachment</p></li><li><p><strong>Fast remediation pattern</strong> ‚Üí Elastic Volumes &gt; Snapshot-based &gt; Data copy</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/ebs-modify-volume.html\">Amazon EBS Elastic Volumes</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/recognize-expanded-volume-linux.html\">Extend a Linux file system after resizing a volume</a></p></li></ul>",
            "correctAnswer": [
                "<p>Modify the EBS volume by adding additional drive space. Log on to the EC2 instance. Use the file system-specific commands to extend the file system.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Modify the EBS volume by adding additional drive space. Log on to the EC2 instance. Use the file system-specific commands to extend the file system.</p>",
                "<p>Create a snapshot of the existing EBS volume. When the snapshot is complete, create an EBS volume of a larger size from the snapshot in the same Availability Zone as the EC2 instance. Attach the new EBS volume to the EC2 instance. Mount the file system.</p>",
                "<p>Create a new EBS volume of a larger size in the same Availability Zone as the EC2 instance. Attach the EBS volume to the EC2 instance. Copy the data from the existing EBS volume to the new EBS volume.</p>",
                "<p>Stop the EC2 instance. Change the EC2 instance to a larger instance size that includes additional drive space. Start the EC2 instance.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 10
        },
        {
            "attemptAnswerId": 329152,
            "questionId": 6376,
            "questionText": "<p>A company stores data in Amazon S3 buckets that are provisioned in three separate AWS Regions. The data is copied from the S3 buckets to the data center over the public internet using a VPN. The SysOps administrator notices that, occasionally, the transfers take longer than usual, and determines the issue is congestion within the company's ISP network.<br><br>What is the MOST cost-effective approach the administrator can take to ensure consistent transfer times from S3 to the data center?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company stores data trong <strong>S3 buckets</strong> ·ªü <strong>3 separate AWS Regions</strong></p></li><li><p>Data copied to data center qua <strong>public internet using VPN</strong></p></li><li><p><strong>Vi·ªác chuy·ªÉn d·ªØ li·ªáu ƒë√¥i khi m·∫•t nhi·ªÅu th·ªùi gian h∆°n do t·∫Øc ngh·∫Ωn m·∫°ng ISP</strong></p></li><li><p>C·∫ßn ensure <strong>consistent transfer times</strong> from S3 to data center</p></li><li><p>Y√™u c·∫ßu: <strong>MOST cost-effective approach</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Establish an AWS Direct Connect link to one of the Regions. Create a public virtual interface over that link.</strong></p><ul><li><p><strong>Public Virtual Interface (VIF)</strong> ƒë∆∞·ª£c d√πng ƒë·ªÉ access <strong>AWS public services</strong> (S3, DynamoDB, etc.)</p></li><li><p><strong>One public VIF</strong> c√≥ th·ªÉ access <strong>S3 in ALL regions</strong>, kh√¥ng c·∫ßn separate links per region</p></li><li><p><strong>Bypass ISP congestion</strong> v·ªõi dedicated network connection</p></li><li><p><strong>Most cost-effective</strong>: ch·ªâ c·∫ßn <strong>1 Direct Connect link</strong> instead of 3</p></li><li><p>Consistent transfer times v·ªõi dedicated bandwidth</p></li></ul><p></p><p><em>Hinh minh ho·∫°</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763866575992-t6sx2o0v-image.png\" alt=\"\" title=\"\" width=\"768\" height=\"399.6\" style=\"max-width: 768px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Establish an AWS Direct Connect link to each Region. Create a private virtual interface over each link.</strong></p><ul><li><p><strong>Private VIF</strong> d√πng cho <strong>VPC resources</strong>, KH√îNG d√πng cho S3 (public service)</p></li><li><p><strong>3 Direct Connect links</strong> r·∫•t expensive, kh√¥ng cost-effective</p></li></ul><p></p><p>‚ùå <strong>Establish an AWS Direct Connect link to each Region. Create a public virtual interface over each link.</strong></p><ul><li><p>Public VIF ƒë√∫ng cho S3 nh∆∞ng <strong>3 Direct Connect links kh√¥ng c·∫ßn thi·∫øt</strong></p></li><li><p><strong>One public VIF</strong> c√≥ th·ªÉ access S3 across all regions</p></li><li><p><strong>Not cost-effective</strong> v·ªõi 3 links</p></li></ul><p></p><p>‚ùå <strong>Establish an AWS Direct Connect link to one of the Regions. Create a private virtual interface over that link.</strong></p><ul><li><p><strong>Private VIF KH√îNG access ƒë∆∞·ª£c S3</strong> - S3 l√† public service</p></li><li><p>Private VIF ch·ªâ cho VPC resources v·ªõi private IP addresses</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"S3 access\"</strong> + <strong>\"Direct Connect\"</strong> ‚Üí <strong>Public Virtual Interface</strong></p></li><li><p><strong>\"Cost-effective\"</strong> + <strong>\"multiple regions\"</strong> ‚Üí <strong>One Direct Connect link</strong> v·ªõi public VIF</p></li><li><p><strong>Public VIF</strong> ‚Üí Access AWS public services (S3, DynamoDB) <strong>across ALL regions</strong></p></li><li><p><strong>Private VIF</strong> ‚Üí Access VPC resources only (EC2, RDS trong VPC)</p></li><li><p><strong>VPN vs Direct Connect</strong> ‚Üí Direct Connect = dedicated, consistent bandwidth</p></li><li><p><strong>Direct Connect pricing</strong> ‚Üí Per port + data transfer, minimize s·ªë l∆∞·ª£ng links</p></li><li><p><strong>Public services pattern</strong> ‚Üí Public VIF can reach all regions, private VIF cannot</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html\">AWS Direct Connect virtual interfaces</a></p></li></ul>",
            "correctAnswer": [
                "<p>Establish an AWS Direct Connect link to one of the Regions. Create a public virtual interface over that link.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Establish an AWS Direct Connect link to each Region. Create a private virtual interface over each link.</p>",
                "<p>Establish an AWS Direct Connect link to each Region. Create a public virtual interface over each link.</p>",
                "<p>Establish an AWS Direct Connect link to one of the Regions. Create a private virtual interface over that link.</p>",
                "<p>Establish an AWS Direct Connect link to one of the Regions. Create a public virtual interface over that link.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 11
        },
        {
            "attemptAnswerId": 329153,
            "questionId": 6377,
            "questionText": "<p>A company has scientists who upload large data objects to an Amazon S3 bucket. The scientists upload the objects as multipart uploads. The multipart uploads often fail because of poor end-client connectivity.<br><br>The company wants to optimize storage costs that are associated with the data. A SysOps administrator must implement a solution that presents metrics for incomplete uploads. The solution also must automatically delete any incomplete uploads after 7 days.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Scientists upload <strong>large data objects</strong> to S3 bucket as <strong>multipart uploads</strong></p></li><li><p>Multipart uploads <strong>often fail</strong> do <strong>poor end-client connectivity</strong></p></li><li><p>C·∫ßn <strong>optimize storage costs</strong> associated v·ªõi incomplete uploads</p></li><li><p>Y√™u c·∫ßu solution:</p><ul><li><p>Present <strong>metrics for incomplete uploads</strong></p></li><li><p><strong>Automatically delete incomplete uploads after 7 days</strong></p></li></ul></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Review the Incomplete Multipart Upload Bytes metric in the S3 Storage Lens dashboard. Create an S3 Lifecycle policy to automatically delete any incomplete multipart uploads after 7 days.</strong></p><ul><li><p><strong>S3 Storage Lens</strong> provides <strong>Incomplete Multipart Upload Bytes metric</strong> ƒë·ªÉ monitor storage consumed</p></li><li><p><strong>S3 Lifecycle policy</strong> c√≥ <strong>AbortIncompleteMultipartUpload</strong> action</p></li><li><p>Lifecycle rule c√≥ th·ªÉ set <strong>DaysAfterInitiation</strong> parameter (7 days)</p></li><li><p><strong>Fully automated</strong>: no custom code, built-in S3 features</p></li><li><p>ƒê√°p ·ª©ng c·∫£ 2 requirements: metrics dashboard + automatic cleanup</p></li></ul><p></p><p><em>Incomplete Multipart Upload Bytes metric</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763870626403-zogtsmep-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"377.41666666666663\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p></p><p><em>S3 Lifecycle policy</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763870706552-pi0yq9le-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"545.4583333333334\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Implement S3 Intelligent-Tiering to move data into lower-cost storage classes after 7 days. Create an S3 Storage Lens policy to automatically delete any incomplete multipart uploads after 7 days.</strong></p><ul><li><p><strong>Intelligent-Tiering</strong> cho completed objects, kh√¥ng handle incomplete uploads</p></li><li><p><strong>S3 Storage Lens KH√îNG c√≥ deletion policies</strong> - ch·ªâ l√† monitoring/analytics tool</p></li></ul><p></p><p>‚ùå <strong>Access the S3 console. Review the Metrics tab to check the storage that incomplete multipart uploads are consuming. Create an AWS Lambda function to delete any incomplete multipart uploads after 7 days.</strong></p><ul><li><p><strong>Manual console review</strong> kh√¥ng ph·∫£i automated metrics solution</p></li><li><p>Lambda works nh∆∞ng requires <strong>custom code development v√† maintenance</strong></p></li></ul><p></p><p>‚ùå <strong>Use the S3 analytics storage class analysis tool to identify and measure incomplete multipart uploads. Configure an S3 bucket policy to enforce restrictions on multipart uploads to delete incomplete multipart uploads after 7 days.</strong></p><ul><li><p><strong>S3 analytics</strong> focus on storage class optimization, kh√¥ng track incomplete uploads</p></li><li><p><strong>S3 bucket policy KH√îNG th·ªÉ delete objects</strong> based on time/age</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Incomplete multipart uploads\"</strong> + <strong>\"metrics\"</strong> ‚Üí <strong>S3 Storage Lens</strong></p></li><li><p><strong>\"Automatically delete\"</strong> + <strong>\"incomplete uploads\"</strong> ‚Üí <strong>S3 Lifecycle AbortIncompleteMultipartUpload</strong></p></li><li><p><strong>S3 Storage Lens</strong> ‚Üí Monitoring v√† analytics, KH√îNG c√≥ deletion capability</p></li><li><p><strong>S3 Lifecycle</strong> ‚Üí Automated object management including incomplete multipart cleanup</p></li><li><p><strong>Intelligent-Tiering</strong> ‚Üí Storage class optimization, kh√¥ng li√™n quan incomplete uploads</p></li><li><p><strong>Bucket policy</strong> ‚Üí Access control, kh√¥ng th·ªÉ delete based on time</p></li><li><p><strong>Cost optimization pattern</strong> ‚Üí Lifecycle rules cleanup incomplete uploads to save storage costs</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens_metrics_glossary.html\">S3 Storage Lens metrics glossary</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpu-abort-incomplete-mpu-lifecycle-config.html\">Configuring a bucket lifecycle configuration to delete incomplete multipart uploads</a></p></li></ul>",
            "correctAnswer": [
                "<p>Review the Incomplete Multipart Upload Bytes metric in the S3 Storage Lens dashboard. Create an S3 Lifecycle policy to automatically delete any incomplete multipart uploads after 7 days.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Review the Incomplete Multipart Upload Bytes metric in the S3 Storage Lens dashboard. Create an S3 Lifecycle policy to automatically delete any incomplete multipart uploads after 7 days.</p>",
                "<p>Implement S3 Intelligent-Tiering to move data into lower-cost storage classes after 7 days. Create an S3 Storage Lens policy to automatically delete any incomplete multipart uploads after 7 days.</p>",
                "<p>Access the S3 console. Review the Metrics tab to check the storage that incomplete multipart uploads are consuming. Create an AWS Lambda function to delete any incomplete multipart uploads after 7 days.</p>",
                "<p>Use the S3 analytics storage class analysis tool to identify and measure incomplete multipart uploads. Configure an S3 bucket policy to enforce restrictions on multipart uploads to delete incomplete multipart uploads after 7 days.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 12
        },
        {
            "attemptAnswerId": 329154,
            "questionId": 6378,
            "questionText": "<p>A company deployed a new web application on multiple Amazon EC2 instances behind an Application Load Balancer (ALB). The EC2 instances run in an Auto Scaling group. Users report that they are frequently being prompted to log in.<br><br>What should a SysOps administrator do to resolve this issue?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Web application deployed tr√™n <strong>multiple EC2 instances</strong> behind <strong>Application Load Balancer (ALB)</strong></p></li><li><p>EC2 instances ch·∫°y trong <strong>Auto Scaling group</strong></p></li><li><p>Users report <strong>frequently being prompted to log in (th∆∞·ªùng xuy√™n b·ªã nh·∫Øc ƒëƒÉng nh·∫≠p)</strong></p></li><li><p>H·ªèi: resolve issue n√†y?</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Enable sticky sessions (session affinity) for the target group of EC2 instances.</strong></p><ul><li><p>Issue x·∫£y ra v√¨ <strong>ALB route requests to different instances</strong>, m·ªói instance <strong>kh√¥ng share session data</strong></p></li><li><p><strong>Sticky sessions</strong> bind user session to <strong>specific EC2 instance</strong> trong duration-based period</p></li><li><p>ALB uses <strong>cookies</strong> ƒë·ªÉ track v√† route subsequent requests to c√πng instance</p></li><li><p>Ensure user <strong>kh√¥ng ph·∫£i re-login</strong> khi requests ƒë·∫øn different instances</p></li><li><p>Quick fix cho session persistence without architecture changes</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Configure an Amazon CloudFront distribution with the ALB as the origin.</strong></p><ul><li><p>CloudFront cache <strong>static content</strong>, kh√¥ng gi·∫£i quy·∫øt <strong>session persistence issue</strong></p></li><li><p>Requests v·∫´n ƒë∆∞·ª£c distributed across multiple instances</p></li></ul><p></p><p>‚ùå <strong>Redeploy the EC2 instances in a spread placement group.</strong></p><ul><li><p><strong>Spread placement group</strong> v·ªÅ physical placement strategy ƒë·ªÉ reduce correlated failures</p></li><li><p><strong>KH√îNG li√™n quan</strong> ƒë·∫øn session management ho·∫∑c login issues</p></li></ul><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763943614920-7d0f8rra-image.png\" alt=\"\" title=\"\" width=\"760\" height=\"412.93528505392914\" style=\"max-width: 760px\" data-keep-ratio=\"true\"></span></span></p><p></p><p>‚ùå <strong>Replace the ALB with a Network Load Balancer.</strong></p><ul><li><p>NLB c≈©ng distribute traffic across instances, <strong>kh√¥ng automatically solve session persistence</strong></p></li><li><p>V·∫´n c·∫ßn sticky sessions ho·∫∑c external session store</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Frequently prompted to log in\"</strong> ‚Üí <strong>Session state kh√¥ng persist</strong> across instances</p></li><li><p><strong>\"Multiple instances\"</strong> + <strong>\"login issues\"</strong> ‚Üí <strong>Sticky sessions</strong> ho·∫∑c <strong>external session store (ElastiCache ho·∫∑c DynamoDB)</strong></p></li><li><p><strong>Sticky sessions</strong> ‚Üí Quick fix, bind user to specific instance</p></li><li><p><strong>Better long-term solution</strong> ‚Üí External session store (ElastiCache, DynamoDB) cho true stateless architecture</p></li><li><p><strong>CloudFront</strong> ‚Üí Static content caching, kh√¥ng ph·∫£i session management</p></li><li><p><strong>Placement groups</strong> ‚Üí Physical placement strategy, kh√¥ng ·∫£nh h∆∞·ªüng sessions</p></li><li><p><strong>ALB vs NLB</strong> ‚Üí Both need session handling mechanism</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/load-balancer-stickiness/app-cookies-stickiness.html\">Sticky sessions for your Application Load Balancer</a></p></li></ul>",
            "correctAnswer": [
                "<p>Enable sticky sessions (session affinity) for the target group of EC2 instances.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure an Amazon CloudFront distribution with the ALB as the origin.</p>",
                "<p>Enable sticky sessions (session affinity) for the target group of EC2 instances.</p>",
                "<p>Redeploy the EC2 instances in a spread placement group.</p>",
                "<p>Replace the ALB with a Network Load Balancer.</p>"
            ],
            "answersPos": "[1,2,3,0]",
            "pos": 13
        },
        {
            "attemptAnswerId": 329155,
            "questionId": 6379,
            "questionText": "<p>An ecommerce company uses an Amazon ElastiCache for Redis cluster for in-memory caching of popular product queries on a shopping website. The cache eviction policy is randomly evicting keys whether or not a TTL is set. A SysOps administrator must improve the cache hit ratio without increasing costs.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Ecommerce company d√πng <strong>ElastiCache for Redis</strong> cho <strong>in-memory caching</strong> c·ªßa popular product queries</p></li><li><p>Current <strong>cache eviction policy</strong> ƒëang <strong>randomly evicting keys</strong> (b·∫•t k·ªÉ TTL)</p></li><li><p>C·∫ßn <strong>improve cache hit ratio</strong></p></li><li><p>Constraint: <strong>without increasing costs</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Change the eviction policy to evict the least frequently used keys.</strong></p><ul><li><p><strong>evict</strong> = tr·ª•c xu·∫•t / gi·∫£i ph√≥ng</p></li><li><p><strong>LFU (Least Frequently Used)</strong> eviction policy evict <strong>keys √≠t ƒë∆∞·ª£c access nh·∫•t</strong></p></li><li><p><strong>Keep popular/frequently accessed items</strong> trong cache - perfect cho \"popular product queries\"</p></li><li><p><strong>Improve cache hit ratio</strong> v√¨ popular products (most likely to be requested again) ƒë∆∞·ª£c gi·ªØ l·∫°i</p></li><li><p><strong>No cost increase</strong> - ch·ªâ change configuration parameter</p></li><li><p>Smart eviction strategy thay v√¨ random</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Add another node to the ElastiCache cluster.</strong></p><ul><li><p>TƒÉng memory capacity gi·∫£m evictions</p></li><li><p>NH∆ØNG <strong>increase costs</strong> - vi ph·∫°m requirement \"without increasing costs\"</p></li></ul><p></p><p>‚ùå <strong>Increase the ElastiCache TTL value.</strong></p><ul><li><p>TTL cao h∆°n gi·ªØ keys l√¢u h∆°n</p></li><li><p>NH∆ØNG <strong>kh√¥ng address root cause</strong> - eviction policy v·∫´n random</p></li><li><p>Keys v·∫´n c√≥ th·ªÉ b·ªã randomly evicted tr∆∞·ªõc khi TTL expires</p></li></ul><p></p><p>‚ùå <strong>Change the eviction policy to randomly evict keys that have a TTL set.</strong></p><ul><li><p>V·∫´n l√† <strong>random eviction</strong>, kh√¥ng intelligent</p></li><li><p><strong>Kh√¥ng optimize</strong> cache hit ratio effectively</p></li><li><p>Popular items v·∫´n c√≥ th·ªÉ b·ªã evicted randomly</p></li></ul><p></p><p>üîë Tips and tricks:</p><ul><li><p><strong>\"Popular product queries\"</strong> + <strong>\"improve cache hit ratio\"</strong> ‚Üí <strong>LFU eviction policy</strong></p></li><li><p><strong>\"Without increasing costs\"</strong> ‚Üí Configuration change, kh√¥ng add capacity</p></li><li><p><strong>Redis eviction policies</strong>:</p><ul><li><p><strong>allkeys-lfu</strong> ‚Üí Evict least frequently used (best cho popular content)</p></li><li><p><strong>allkeys-lru</strong> ‚Üí Evict least recently used</p></li><li><p><strong>allkeys-random</strong> ‚Üí Random eviction (current issue)</p></li></ul></li><li><p><strong>LFU vs LRU</strong> ‚Üí LFU tracks access frequency (th∆∞·ªùng xuy√™n), LRU tracks access recency (g·∫ßn ƒë√¢y)</p></li><li><p><strong>Ecommerce pattern</strong> ‚Üí Popular products accessed frequently = LFU keeps them cached</p></li><li><p><strong>Random eviction</strong> ‚Üí Worst for cache hit ratio, kh√¥ng intelligent selection</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://redis.io/glossary/lru-cache/\">Using Redis as an LRU cache</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/whitepapers/latest/database-caching-strategies-using-redis/evictions.html\">Evictions</a></p></li></ul>",
            "correctAnswer": [
                "<p>Change the eviction policy to evict the least frequently used keys.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add another node to the ElastiCache cluster.</p>",
                "<p>Increase the ElastiCache TTL value.</p>",
                "<p>Change the eviction policy to randomly evict keys that have a TTL set.</p>",
                "<p>Change the eviction policy to evict the least frequently used keys.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 14
        },
        {
            "attemptAnswerId": 329156,
            "questionId": 8830,
            "questionText": "<p>A company needs to monitor the disk utilization of Amazon Elastic Block Store (Amazon EBS) volumes. The EBS volumes are attached to Amazon EC2 Linux instances. A SysOps administrator must set up an Amazon CloudWatch alarm that provides an alert when disk utilization increases to more than 80%.</p><p></p><p>Which combination of steps must the SysOps administrator take to meet these requirements? (Choose three.)</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company c·∫ßn monitor <strong>disk utilization</strong> c·ªßa <strong>EBS volumes</strong> attached to <strong>EC2 Linux instances</strong></p></li><li><p>C·∫ßn setup <strong>CloudWatch alarm</strong> alert khi <strong>disk utilization &gt; 80%</strong></p></li><li><p>Ch·ªçn <strong>3 steps</strong> ƒë·ªÉ meet requirements</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create an IAM role that includes the CloudWatchAgentServerPolicy AWS managed policy. Attach the role to the instances.</strong></p><ul><li><p><strong>CloudWatchAgentServerPolicy</strong> grant permissions cho CloudWatch agent <strong>push metrics v√† logs</strong> to CloudWatch</p></li><li><p>IAM role ph·∫£i attached to EC2 instances ƒë·ªÉ agent c√≥ credentials</p></li></ul><p></p><p><strong>Install and start the CloudWatch agent by using AWS Systems Manager or the command line.</strong></p><ul><li><p><strong>CloudWatch agent</strong> required ƒë·ªÉ collect <strong>custom metrics</strong> (disk utilization kh√¥ng ph·∫£i default EC2 metric)</p></li><li><p>C√≥ th·ªÉ install via <strong>Systems Manager Run Command</strong> ho·∫∑c <strong>manual command line</strong></p></li></ul><p></p><p><strong>Configure a CloudWatch alarm to enter ALARM state when the disk_used_percent CloudWatch metric is greater than 80%.</strong></p><ul><li><p><strong>disk_used_percent</strong> l√† metric ƒë∆∞·ª£c CloudWatch agent collect specifically cho disk utilization <strong>percentage</strong></p></li><li><p>Alarm trigger khi value &gt; 80% ƒë√°p ·ª©ng ch√≠nh x√°c requirement</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create an IAM role that includes the CloudWatchApplicationInsightsReadOnlyAccess AWS managed policy. Attach the role to the instances.</strong></p><ul><li><p><strong>CloudWatchApplicationInsightsReadOnlyAccess</strong> l√† <strong>read-only policy</strong> cho Application Insights</p></li><li><p><strong>KH√îNG ph·∫£i policy</strong> cho CloudWatch agent, agent c·∫ßn <strong>write permissions</strong></p></li></ul><p></p><p>‚ùå <strong>Install and start the CloudWatch agent by using an IAM role. Attach the CloudWatchAgentServerPolicy AWS managed policy to the role.</strong></p><ul><li><p>T·ª´ ng·ªØ kh√≥ hi·ªÉu, kh√¥ng ch√≠nh x√°c</p></li><li><p><strong>KH√îNG install agent \"by using IAM role\"</strong> - IAM role l√† prerequisite, agent install via Systems Manager ho·∫∑c CLI</p></li></ul><p></p><p>‚ùå <strong>Configure a CloudWatch alarm to enter ALARM state when the disk_used CloudWatch metric is greater than 80% or when the disk_free CloudWatch metric is less than 20%.</strong></p><ul><li><p><strong>disk_used</strong> metric l√† <strong>bytes used</strong>, KH√îNG ph·∫£i percentage</p></li><li><p><strong>KH√îNG th·ªÉ compare</strong> disk_used &gt; 80% (v√¨ n√≥ l√† valua tuy·ªát ƒë·ªëi -  bytes, kh√¥ng ph·∫£i %)</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Disk utilization\"</strong> + <strong>\"EC2 Linux\"</strong> ‚Üí <strong>CloudWatch agent</strong> required (kh√¥ng ph·∫£i default metric)</p></li><li><p><strong>CloudWatch agent permissions</strong> ‚Üí <strong>CloudWatchAgentServerPolicy</strong> managed policy</p></li><li><p><strong>Disk metrics t·ª´ agent</strong>:</p><ul><li><p><strong>disk_used_percent</strong> ‚Üí Percentage (d√πng cho % thresholds)</p></li><li><p><strong>disk_used</strong> ‚Üí Bytes used (absolute value)</p></li><li><p><strong>disk_free</strong> ‚Üí Bytes free (absolute value)</p></li></ul></li><li><p><strong>Agent installation methods</strong> ‚Üí Systems Manager Run Command ho·∫∑c manual CLI</p></li><li><p><strong>Default EC2 metrics</strong> ‚Üí CPU, Network, Disk I/O (KH√îNG include disk utilization %)</p></li><li><p><strong>Custom metrics pattern</strong> ‚Üí Agent install + IAM role + metric configuration</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-soa/cloudwatch-agent-cai-dat-cau-hinh-amazon-linux-2023-ec2\">CloudWatch Agent - C√†i ƒë·∫∑t v√† c·∫•u h√¨nh tr√™n Amazon Linux 2023 - Thu th·∫≠p Logs v√† Metrics t·ª´ EC2</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html\">Collect metrics and logs from Amazon EC2 instances with the CloudWatch agent</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/metrics-collected-by-CloudWatch-agent.html\">Metrics collected by the CloudWatch agent</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an IAM role that includes the CloudWatchAgentServerPolicy AWS managed policy. Attach the role to the instances.</p>",
                "<p>Install and start the CloudWatch agent by using AWS Systems Manager or the command line.</p>",
                "<p>Configure a CloudWatch alarm to enter ALARM state when the disk_used_percent CloudWatch metric is greater than 80%.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an IAM role that includes the CloudWatchAgentServerPolicy AWS managed policy. Attach the role to the instances.</p>",
                "<p>Create an IAM role that includes the CloudWatchApplicationInsightsReadOnlyAccess AWS managed policy. Attach the role to the instances.</p>",
                "<p>Install and start the CloudWatch agent by using AWS Systems Manager or the command line.</p>",
                "<p>Install and start the CloudWatch agent by using an IAM role. Attach the CloudWatchAgentServerPolicy AWS managed policy to the role.</p>",
                "<p>Configure a CloudWatch alarm to enter ALARM state when the disk_used_percent CloudWatch metric is greater than 80%.</p>",
                "<p>Configure a CloudWatch alarm to enter ALARM state when the disk_used CloudWatch metric is greater than 80% or when the disk_free CloudWatch metric is less than 20%.</p>"
            ],
            "answersPos": "[5,4,3,2,1,0]",
            "pos": 15
        },
        {
            "attemptAnswerId": 329157,
            "questionId": 6381,
            "questionText": "<p>A company's web application runs on Amazon EC2 instances in a single AWS Region. The infrastructure must be designed so the application remains available with no performance degradation in the event of an Availability Zone (AZ) failure. To ensure optimal performance, the application must maintain a minimum of 12 instances at all times.<br><br>Which solution will meet the requirements with the fewest running instances possible?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Web application ch·∫°y tr√™n <strong>EC2 instances</strong> trong <strong>single AWS Region</strong></p></li><li><p>Ph·∫£i remain available v·ªõi <strong>kh√¥ng suy gi·∫£m performance</strong> khi c√≥ <strong>AZ failure</strong></p></li><li><p>Must maintain <strong>minimum of 12 instances at all times</strong> (k·ªÉ c·∫£ khi AZ fails)</p></li><li><p>Y√™u c·∫ßu: <strong>fewest running instances possible</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>3 AZs with 6 instances in each AZ</strong></p><ul><li><p>Total: <strong>18 instances</strong> running normally</p></li><li><p>Khi <strong>1 AZ fails</strong>: c√≤n <strong>2 AZs √ó 6 instances = 12 instances</strong> ‚úì</p></li><li><p><strong>Meets requirement</strong>: 12 instances minimum maintained after failure</p></li><li><p><strong>Fewest instances</strong>: ch·ªâ c·∫ßn 18 instances ƒë·ªÉ ƒë·∫£m b·∫£o 12 sau khi 1 AZ fail</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>2 AZs with 6 instances in each AZ</strong></p><ul><li><p>Total: <strong>12 instances</strong> running normally</p></li><li><p>Khi <strong>1 AZ fails</strong>: c√≤n <strong>6 instances</strong> ‚úó (kh√¥ng ƒë·ªß 12 instances minimum)</p></li></ul><p></p><p>‚ùå <strong>2 AZs with 12 instances in each AZ</strong></p><ul><li><p>Total: <strong>24 instances</strong> running normally</p></li><li><p>Khi <strong>1 AZ fails</strong>: c√≤n <strong>12 instances</strong> ‚úì</p></li><li><p>Meets requirement nh∆∞ng <strong>NOT fewest</strong> (24 instances &gt; 18 instances)</p></li></ul><p></p><p>‚ùå <strong>3 AZs with 4 instances in each AZ</strong></p><ul><li><p>Total: <strong>12 instances</strong> running normally</p></li><li><p>Khi <strong>1 AZ fails</strong>: c√≤n <strong>8 instances</strong> ‚úó (kh√¥ng ƒë·ªß 12 instances minimum)</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Minimum X instances at all times\"</strong> ‚Üí Must have X instances <strong>AFTER</strong> AZ failure</p></li><li><p><strong>N+1 redundancy</strong> ‚Üí Capacity ph·∫£i ƒë·ªß sau khi lose 1 AZ</p></li><li><p><strong>Formula</strong>: Total instances = (Minimum required) / (Number of AZs - 1) √ó Number of AZs</p></li><li><p><strong>3 AZs</strong> ‚Üí 12 / 2 √ó 3 = 18 instances</p></li><li><p><strong>2 AZs</strong> ‚Üí 12 / 1 √ó 2 = 24 instances</p></li><li><p><strong>More AZs = fewer total instances</strong> needed cho same redundancy</p></li><li><p><strong>High availability pattern</strong> ‚Üí Spread across multiple AZs v·ªõi capacity planning cho AZ failures</p></li></ul>",
            "correctAnswer": [
                "<p>3 AZs with 6 instances in each AZ</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>2 AZs with 6 instances in each AZ</p>",
                "<p>2 AZs with 12 instances in each AZ</p>",
                "<p>3 AZs with 4 instances in each AZ</p>",
                "<p>3 AZs with 6 instances in each AZ</p>"
            ],
            "answersPos": "[1,0,3,2]",
            "pos": 16
        },
        {
            "attemptAnswerId": 329158,
            "questionId": 8831,
            "questionText": "<p>A company has developed a service that is deployed on a fleet of Linux-based Amazon EC2 instances that are in an Auto Scaling group. The service occasionally fails unexpectedly because of an error in the application code. The company's engineering team determines that resolving the underlying cause of the service failure could take several weeks.<br><br>A SysOps administrator needs to create a solution to automate recovery if the service crashes on any of the EC2 instances.<br><br>Which solutions will meet this requirement? (Choose two.)</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Service deployed tr√™n <strong>fleet of Linux EC2 instances</strong> trong <strong>Auto Scaling group</strong></p></li><li><p>Service <strong>th·ªânh tho·∫£ng fails unexpectedly</strong> do application code error</p></li><li><p>Fixing underlying cause s·∫Ω m·∫•t <strong>several weeks</strong></p></li><li><p>C·∫ßn <strong>automate recovery</strong> if service crashes on any EC2 instances</p></li><li><p>Ch·ªçn <strong>2 solutions</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Install the Amazon CloudWatch agent on the EC2 instances. Configure the CloudWatch agent to monitor the service. Set the CloudWatch action to restart if the service health check fails.</strong></p><ul><li><p><strong>CloudWatch agent</strong> c√≥ th·ªÉ <strong>monitor process/service status</strong> tr√™n Linux instances</p></li><li><p>Agent c√≥ capability <strong>restart service</strong> khi detect failure</p></li><li><p><strong>Automated real-time monitoring</strong> v√† recovery</p></li><li><p>Kh√¥ng c·∫ßn redeploy instances, ch·ªâ install agent</p></li></ul><p></p><p><strong>Tag the EC2 instances. Use AWS Systems Manager State Manager to create an association that uses the AWS-RunShellScript document. Configure the association command with a script that checks if the service is running and that starts the service if the service is not running. For targets, specify the EC2 instance tag. Schedule the association to run every 5 minutes.</strong></p><ul><li><p><strong>State Manager associations</strong> run scheduled commands tr√™n managed instances</p></li><li><p><strong>AWS-RunShellScript</strong> c√≥ th·ªÉ check service status v√† restart if needed</p></li><li><p><strong>Tag-based targeting</strong> apply to all instances trong Auto Scaling group</p></li><li><p><strong>Scheduled execution</strong> (every 5 minutes) ensure continuous monitoring</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Tag the EC2 instances. Create an AWS Lambda function that uses AWS Systems Manager Session Manager to log in to the tagged EC2 instances and restart the service. Schedule the Lambda function to run every 5 minutes.</strong></p><ul><li><p><strong>Overly complex</strong>: Lambda + Session Manager login kh√¥ng ph·∫£i best practice</p></li><li><p>Session Manager designed cho interactive sessions, kh√¥ng ph·∫£i automation</p></li><li><p>State Manager approach simpler v√† more appropriate</p></li></ul><p></p><p>‚ùå <strong>Update the EC2 user data that is specified in the Auto Scaling group's launch template to include a script that runs on a cron schedule every 5 minutes. Configure the script to check if the service is running and to start the service if the service is not running. Redeploy all the EC2 instances in the Auto Scaling group with the updated launch template.</strong></p><ul><li><p><strong>Requires redeploy ALL instances</strong> - disruptive v√† m·∫•t nhi·ªÅu time</p></li><li><p>Complex implementation so v·ªõi CloudWatch agent ho·∫∑c State Manager</p></li></ul><p></p><p>‚ùå <strong>Update the EC2 user data that is specified in the Auto Scaling group's launch template to ensure that the service runs during startup. Redeploy all the EC2 instances in the Auto Scaling group with the updated launch template.</strong></p><ul><li><p>Ch·ªâ ensure service starts <strong>during instance launch</strong></p></li><li><p><strong>KH√îNG handle</strong> service crashes AFTER instance is running</p></li><li><p>Kh√¥ng meet requirement v·ªÅ automated recovery</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Automate recovery\"</strong> + <strong>\"service crashes\"</strong> ‚Üí <strong>Automated monitoring + restart</strong></p></li><li><p><strong>CloudWatch agent</strong> ‚Üí Can monitor processes v√† trigger actions</p></li><li><p><strong>State Manager</strong> ‚Üí Scheduled automation tr√™n fleet of instances</p></li><li><p><strong>AWS-RunShellScript</strong> ‚Üí Execute shell commands via Systems Manager</p></li><li><p><strong>User data</strong> ‚Üí Only runs at instance launch, kh√¥ng ph·∫£i ongoing monitoring</p></li><li><p><strong>Session Manager</strong> ‚Üí Interactive sessions, kh√¥ng ph·∫£i automation tool</p></li><li><p><strong>Tag-based targeting</strong> ‚Üí Easy management of dynamic Auto Scaling fleets</p></li><li><p><strong>Recovery pattern</strong> ‚Üí Continuous monitoring + automatic restart actions</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-procstat-process-metrics.html\">Collect process metrics with the procstat plugin</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-state.html\">AWS Systems Manager State Manager</a></p></li></ul>",
            "correctAnswer": [
                "<p>Install the Amazon CloudWatch agent on the EC2 instances. Configure the CloudWatch agent to monitor the service. Set the CloudWatch action to restart if the service health check fails.</p>",
                "<p>Tag the EC2 instances. Use AWS Systems Manager State Manager to create an association that uses the AWS-RunShellScript document. Configure the association command with a script that checks if the service is running and that starts the service if the service is not running. For targets, specify the EC2 instance tag. Schedule the association to run every 5 minutes.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Install the Amazon CloudWatch agent on the EC2 instances. Configure the CloudWatch agent to monitor the service. Set the CloudWatch action to restart if the service health check fails.</p>",
                "<p>Tag the EC2 instances. Create an AWS Lambda function that uses AWS Systems Manager Session Manager to log in to the tagged EC2 instances and restart the service. Schedule the Lambda function to run every 5 minutes.</p>",
                "<p>Tag the EC2 instances. Use AWS Systems Manager State Manager to create an association that uses the AWS-RunShellScript document. Configure the association command with a script that checks if the service is running and that starts the service if the service is not running. For targets, specify the EC2 instance tag. Schedule the association to run every 5 minutes.</p>",
                "<p>Update the EC2 user data that is specified in the Auto Scaling group's launch template to include a script that runs on a cron schedule every 5 minutes. Configure the script to check if the service is running and to start the service if the service is not running. Redeploy all the EC2 instances in the Auto Scaling group with the updated launch template.</p>",
                "<p>Update the EC2 user data that is specified in the Auto Scaling group's launch template to ensure that the service runs during startup. Redeploy all the EC2 instances in the Auto Scaling group with the updated launch template.</p>"
            ],
            "answersPos": "[4,3,2,1,0]",
            "pos": 17
        },
        {
            "attemptAnswerId": 329159,
            "questionId": 6383,
            "questionText": "<p>A company has a stateless application that is hosted on a fleet of 10 Amazon EC2 On-Demand Instances in an Auto Scaling group. A minimum of 6 instances are needed to meet service requirements.<br><br>Which action will maintain uptime for the application MOST cost-effectively?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p><strong>Stateless application</strong> hosted tr√™n <strong>10 EC2 On-Demand Instances</strong> trong Auto Scaling group</p></li><li><p><strong>Minimum 6 instances</strong> needed ƒë·ªÉ meet service requirements</p></li><li><p>Y√™u c·∫ßu: maintain uptime <strong>MOST cost-effectively</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Use a Spot Fleet with an On-Demand capacity of 6 instances.</strong></p><ul><li><p><strong>Spot Fleet</strong> cho ph√©p combine <strong>On-Demand</strong> v√† <strong>Spot instances</strong></p></li><li><p><strong>6 On-Demand instances</strong> l√†m <strong>base capacity</strong> guarantee minimum requirements</p></li><li><p><strong>Spot instances</strong> c√≥ th·ªÉ add ƒë·ªÉ scale beyond 6 v·ªõi <strong>up to 90% cost savings</strong></p></li><li><p><strong>Stateless application</strong> tolerate Spot interruptions t·ªët (no state loss)</p></li><li><p><strong>Most cost-effective</strong>: ƒë·∫£m b·∫£o uptime v·ªõi On-Demand base, optimize cost v·ªõi Spot for additional capacity</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Update the Auto Scaling group with a minimum of 6 On-Demand Instances and a maximum of 10 On-Demand Instances.</strong></p><ul><li><p><strong>All On-Demand instances</strong> - expensive</p></li><li><p><strong>Kh√¥ng t·∫≠n d·ª•ng Spot instances</strong> ƒë·ªÉ save costs cho stateless workload</p></li></ul><p></p><p>‚ùå <strong>Update the Auto Scaling group with a minimum of 1 On-Demand Instance and a maximum of 6 On-Demand Instances.</strong></p><ul><li><p><strong>Minimum 1 instance</strong> KH√îNG meet requirement (need minimum 6 instances)</p></li><li><p>Maximum 6 v·∫´n kh√¥ng ƒë·∫£m b·∫£o c√≥ 6 instances running</p></li></ul><p></p><p>‚ùå <strong>Use a Spot Fleet with a target capacity of 6 instances.</strong></p><ul><li><p><strong>ALL Spot instances</strong> - no guaranteed capacity</p></li><li><p><strong>Risk</strong>: All Spot instances c√≥ th·ªÉ b·ªã interrupted simultaneously</p></li><li><p><strong>Cannot guarantee uptime</strong> khi Spot capacity unavailable</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Stateless application\"</strong> ‚Üí <strong>Good candidate for Spot instances</strong></p></li><li><p><strong>\"Maintain uptime\"</strong> + <strong>\"cost-effective\"</strong> ‚Üí <strong>Mix of On-Demand + Spot</strong></p></li><li><p><strong>Spot Fleet best practice</strong> ‚Üí On-Demand base capacity + Spot for scaling</p></li><li><p><strong>Minimum required capacity</strong> ‚Üí Use On-Demand to guarantee</p></li><li><p><strong>Additional capacity</strong> ‚Üí Use Spot to optimize costs</p></li><li><p><strong>All On-Demand</strong> ‚Üí Most expensive, not cost-effective</p></li><li><p><strong>All Spot</strong> ‚Üí Cheapest but risky for uptime</p></li><li><p><strong>Hybrid approach</strong> ‚Üí Balance cost v√† availability</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Fleets.html\">Spot Fleet</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html\">Auto Scaling groups with multiple instance types and purchase options</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use a Spot Fleet with an On-Demand capacity of 6 instances.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use a Spot Fleet with an On-Demand capacity of 6 instances.</p>",
                "<p>Update the Auto Scaling group with a minimum of 6 On-Demand Instances and a maximum of 10 On-Demand Instances.</p>",
                "<p>Update the Auto Scaling group with a minimum of 1 On-Demand Instance and a maximum of 6 On-Demand Instances.</p>",
                "<p>Use a Spot Fleet with a target capacity of 6 instances.</p>"
            ],
            "answersPos": "[2,1,3,0]",
            "pos": 18
        },
        {
            "attemptAnswerId": 329160,
            "questionId": 6384,
            "questionText": "<p>A company has a high performance computing (HPC) application that runs on Amazon EC2 instances. The application requires minimum latency and maximum network throughput between nodes.<br><br>How should a SysOps administrator deploy the EC2 instances to meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p><strong>High performance computing (HPC) application</strong> ch·∫°y tr√™n EC2 instances</p></li><li><p>Requires <strong>minimum latency</strong> gi·ªØa nodes</p></li><li><p>Requires <strong>maximum network throughput</strong> gi·ªØa nodes</p></li><li><p>H·ªèi: c√°ch deploy EC2 instances?</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Use a cluster placement group in a single Availability Zone.</strong></p><ul><li><p><strong>Cluster placement group</strong> packs instances <strong>physically close together</strong> trong single AZ</p></li><li><p>Provides <strong>lowest latency</strong> (sub-millisecond) v√† <strong>highest network throughput</strong> (up to 100 Gbps)</p></li><li><p>Optimized cho <strong>tightly-coupled node-to-node communication</strong> c·ªßa HPC workloads</p></li><li><p><strong>Enhanced networking</strong> v·ªõi single-digit microsecond latencies</p></li><li><p>Perfect cho applications requiring high-bandwidth, low-latency network</p></li></ul><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763945889792-zull7l14-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"434.6666666666667\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Use a cluster placement group across multiple Availability Zones.</strong></p><ul><li><p><strong>Cluster placement groups CANNOT span multiple AZs</strong></p></li><li><p>Cluster placement groups <strong>MUST be in single AZ</strong> ƒë·ªÉ achieve low latency</p></li><li><p>Technically not possible</p></li></ul><p></p><p>‚ùå <strong>Use a partition placement group in a single Availability Zone.</strong></p><ul><li><p><strong>Partition placement groups</strong> designed cho <strong>distributed workloads</strong> (Hadoop, Cassandra, Kafka)</p></li><li><p>Spread instances across <strong>logical partitions</strong> tr√™n different hardware racks</p></li><li><p><strong>KH√îNG optimize</strong> cho low latency v√† high throughput gi·ªØa nodes</p></li></ul><p></p><p>‚ùå <strong>Use a partition placement group across multiple Availability Zones.</strong></p><ul><li><p>Partition groups c√≥ th·ªÉ span multiple AZs</p></li><li><p>Nh∆∞ng <strong>KH√îNG optimize</strong> cho HPC requirements (latency v√† throughput)</p></li><li><p>Focus on fault isolation, kh√¥ng ph·∫£i performance</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"HPC\"</strong> + <strong>\"minimum latency\"</strong> + <strong>\"maximum throughput\"</strong> ‚Üí <strong>Cluster placement group</strong></p></li><li><p><strong>Placement group types</strong>:</p><ul><li><p><strong>Cluster</strong> ‚Üí Low latency, high throughput (HPC, ML training)</p></li><li><p><strong>Spread</strong> ‚Üí High availability, reduce correlated failures</p></li><li><p><strong>Partition</strong> ‚Üí Distributed systems (Hadoop, Cassandra)</p></li></ul></li><li><p><strong>Cluster placement group</strong> ‚Üí Always <strong>single AZ</strong></p></li><li><p><strong>Spread/Partition</strong> ‚Üí Can span multiple AZs</p></li><li><p><strong>HPC workload pattern</strong> ‚Üí Cluster placement group + enhanced networking</p></li><li><p><strong>Network performance</strong> ‚Üí Cluster &gt; Partition &gt; Spread</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html\">Placement groups</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use a cluster placement group in a single Availability Zone.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use a cluster placement group in a single Availability Zone.</p>",
                "<p>Use a cluster placement group across multiple Availability Zones.</p>",
                "<p>Use a partition placement group in a single Availability Zone.</p>",
                "<p>Use a partition placement group across multiple Availability Zones.</p>"
            ],
            "answersPos": "[2,1,3,0]",
            "pos": 19
        },
        {
            "attemptAnswerId": 329161,
            "questionId": 6385,
            "questionText": "<p>A company stores its internal data within an Amazon S3 bucket. All existing data within the S3 bucket is protected by using server-side encryption with Amazon S3 managed encryption keys (SSE-S3). S3 Versioning is enabled. A SysOps administrator must replicate the internal data to another S3 bucket in a different AWS account for disaster recovery. All the existing data is copied from the source S3 bucket to the destination S3 bucket.<br><br>Which replication solution is MOST operationally efficient?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company stores internal data trong <strong>S3 bucket</strong> v·ªõi <strong>SSE-S3 encryption</strong></p></li><li><p><strong>S3 Versioning enabled</strong></p></li><li><p>C·∫ßn <strong>replicate data to another S3 bucket</strong> trong <strong>different AWS account</strong> cho disaster recovery</p></li><li><p><strong>All existing data ƒë√£ ƒë∆∞·ª£c copied</strong></p></li><li><p>Y√™u c·∫ßu: <strong>MOST operationally efficient</strong> replication solution</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Add a replication rule to the source bucket and specify the destination bucket. Create a bucket policy for the destination bucket to allow the owner of the source bucket to replicate objects.</strong></p><ul><li><p><strong>S3 Replication</strong> (CRR/SRR) l√† <strong>native AWS feature</strong> cho cross-account replication</p></li><li><p><strong>Automatic replication</strong> c·ªßa new objects v√† changes</p></li><li><p><strong>No custom code</strong>, no infrastructure management</p></li><li><p>Supports <strong>versioned objects</strong> automatically</p></li><li><p>Ch·ªâ c·∫ßn configure: replication rule + destination bucket policy + IAM role</p></li><li><p><strong>Most operationally efficient</strong>: fully managed, zero-maintenance</p></li></ul><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Schedule an AWS Batch job with Amazon EventBridge to copy new objects from the source bucket to the destination bucket. Create a Batch Operations IAM role in the destination account.</strong></p><ul><li><p><strong>AWS Batch overkill</strong> cho simple object replication</p></li><li><p>Requires managing compute resources, job definitions, scheduling</p></li><li><p><strong>Not operationally efficient</strong> compared to native S3 replication</p></li></ul><p></p><p>‚ùå <strong>Configure an Amazon S3 event notification for the source bucket to invoke an AWS Lambda function to copy new objects to the destination bucket. Ensure that the Lambda function has cross-account access permissions.</strong></p><ul><li><p>Requires <strong>custom Lambda code</strong> development v√† maintenance</p></li><li><p>Lambda c√≥ limitations (timeout, payload size)</p></li><li><p><strong>More complex</strong> than native S3 replication</p></li></ul><p></p><p>‚ùå <strong>Run a scheduled script on an Amazon EC2 instance to copy new objects from the source bucket to the destination bucket. Assign cross-account access permissions to the EC2 instance's role.</strong></p><ul><li><p>Requires <strong>EC2 instance management</strong> (patching, monitoring, costs)</p></li><li><p><strong>Manual scripting</strong> - maintenance overhead</p></li><li><p><strong>Least operationally efficient</strong></p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Cross-account replication\"</strong> + <strong>\"operationally efficient\"</strong> ‚Üí <strong>S3 Replication</strong> v·ªõi bucket policy</p></li><li><p><strong>S3 Replication types</strong>: CRR (cross-region), SRR (same-region)</p></li><li><p><strong>S3 Replication requirements</strong>: Versioning enabled ‚úì, IAM role, destination bucket policy</p></li><li><p><strong>Replication scope</strong>: Only NEW objects after replication enabled (existing objects ƒë√£ copied)</p></li><li><p><strong>Native AWS features</strong> ‚Üí Always more operationally efficient than custom solutions</p></li><li><p><strong>Lambda/EC2/Batch</strong> ‚Üí Custom solutions, higher operational overhead</p></li><li><p><strong>Cross-account pattern</strong>: Replication rule + destination bucket policy granting source account permissions</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html\">Replicating objects</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add a replication rule to the source bucket and specify the destination bucket. Create a bucket policy for the destination bucket to allow the owner of the source bucket to replicate objects.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add a replication rule to the source bucket and specify the destination bucket. Create a bucket policy for the destination bucket to allow the owner of the source bucket to replicate objects.</p>",
                "<p>Schedule an AWS Batch job with Amazon EventBridge to copy new objects from the source bucket to the destination bucket. Create a Batch Operations IAM role in the destination account.</p>",
                "<p>Configure an Amazon S3 event notification for the source bucket to invoke an AWS Lambda function to copy new objects to the destination bucket. Ensure that the Lambda function has cross-account access permissions.</p>",
                "<p>Run a scheduled script on an Amazon EC2 instance to copy new objects from the source bucket to the destination bucket. Assign cross-account access permissions to the EC2 instance's role.</p>"
            ],
            "answersPos": "[3,0,1,2]",
            "pos": 20
        },
        {
            "attemptAnswerId": 329162,
            "questionId": 6386,
            "questionText": "<p>A SysOps administrator is troubleshooting a VPC with public and private subnets that leverage custom network ACLs. Instances in the private subnet are unable to access the internet. There is an internet gateway attached to the public subnet. The private subnet has a route to a NAT gateway that is also attached to the public subnet. The Amazon EC2 instances are associated with the default security group for the VPC.<br><br>What is causing the issue in this scenario?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>VPC c√≥ <strong>public v√† private subnets</strong> v·ªõi <strong>custom network ACLs</strong></p></li><li><p>Instances trong <strong>private subnet unable to access internet</strong></p></li><li><p><strong>Internet gateway</strong> attached to public subnet </p></li><li><p>Private subnet c√≥ <strong>route to NAT gateway</strong> (NAT gateway trong public subnet) </p></li><li><p>EC2 instances d√πng <strong>default security group</strong> cho VPC</p></li><li><p>H·ªèi: <strong>What is causing the issue?</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>There is a network ACL on the private subnet set to deny all outbound traffic.</strong></p><ul><li><p><strong>Custom Network ACLs</strong> th∆∞·ªùng ƒë∆∞·ª£c t·∫°o v·ªõi <strong>deny all by default</strong> (kh√°c default NACL allow all)</p></li><li><p>N·∫øu NACL <strong>deny outbound traffic</strong>, instances kh√¥ng th·ªÉ initiate connections to internet</p></li><li><p><strong>NACLs are stateless</strong> - c·∫ßn explicit rules cho c·∫£ outbound requests V√Ä inbound responses</p></li><li><p>Ngay c·∫£ khi NAT gateway configured ƒë√∫ng, NACL blocking outbound traffic prevents internet access</p></li><li><p>ƒê√¢y l√† <strong>common misconfiguration</strong> v·ªõi custom NACLs</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>There is no NAT gateway deployed in the private subnet of the VPC.</strong></p><ul><li><p><strong>NAT gateway PH·∫¢I ·ªü public subnet</strong>, KH√îNG ph·∫£i private subnet</p></li><li><p>ƒê·ªÅ b√†i n√≥i \"NAT gateway attached to public subnet\" - ƒë√¢y l√† <strong>correct configuration</strong></p></li><li><p>Sai concept v·ªÅ NAT gateway placement</p></li></ul><p></p><p>‚ùå <strong>The default security group for the VPC blocks all inbound traffic to the EC2 instances.</strong></p><ul><li><p>Default SG block unsolicited inbound traffic nh∆∞ng allow <strong>return traffic</strong> (stateful)</p></li><li><p><strong>KH√îNG affect outbound internet access</strong> - return traffic automatically allowed</p></li><li><p>Security groups are stateful</p></li></ul><p></p><p>‚ùå <strong>The default security group for the VPC blocks all outbound traffic from the EC2 instances.</strong></p><ul><li><p><strong>Default security group ALLOW all outbound traffic</strong> (0.0.0.0/0)</p></li><li><p>ƒê√¢y kh√¥ng ph·∫£i default behavior c·ªßa SG</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Custom network ACLs\"</strong> ‚Üí Th∆∞·ªùng <strong>deny all by default</strong>, c·∫ßn explicit allow rules</p></li><li><p><strong>\"Unable to access internet\"</strong> + <strong>\"custom NACLs\"</strong> ‚Üí Check NACL outbound rules</p></li><li><p><strong>NAT gateway location</strong> ‚Üí MUST be in <strong>public subnet</strong>, private subnet routes to it</p></li><li><p><strong>NACLs are stateless</strong> ‚Üí Need rules for both request (outbound) AND response (inbound)</p></li><li><p><strong>Security groups are stateful</strong> ‚Üí Return traffic automatically allowed</p></li><li><p><strong>Default SG</strong> ‚Üí Block unsolicited inbound, allow all outbound</p></li><li><p><strong>Default NACL</strong> ‚Üí Allow all, custom NACL ‚Üí Deny all by default</p></li><li><p><strong>Troubleshooting pattern</strong> ‚Üí Check NACLs first when using custom NACLs</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html\">Network ACLs</a></p></li></ul>",
            "correctAnswer": [
                "<p>There is a network ACL on the private subnet set to deny all outbound traffic.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>There is a network ACL on the private subnet set to deny all outbound traffic.</p>",
                "<p>There is no NAT gateway deployed in the private subnet of the VPC.</p>",
                "<p>The default security group for the VPC blocks all inbound traffic to the EC2 instances.</p>",
                "<p>The default security group for the VPC blocks all outbound traffic from the EC2 instances.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 21
        },
        {
            "attemptAnswerId": 329163,
            "questionId": 6387,
            "questionText": "<p>A company is running an ecommerce application on AWS. The application maintains many open but idle connections to an Amazon Aurora DB cluster. During times of peak usage, the database produces the following error message: \"Too many connections.\" The database clients are also experiencing errors.<br><br>Which solution will resolve these errors?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Ecommerce application ch·∫°y tr√™n AWS</p></li><li><p>Application maintains <strong>many open but idle connections (nhi·ªÅu k·∫øt n·ªëi nh∆∞ng kh√¥ng ho·∫°t ƒë·ªông)</strong> to <strong>Amazon Aurora DB cluster</strong></p></li><li><p>During peak usage: database error <strong>\"Too many connections\"</strong></p></li><li><p>Database clients also experiencing errors</p></li><li><p>H·ªèi: <strong>solution to resolve these errors?</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Configure RDS Proxy. Update the application with the RDS Proxy endpoint.</strong></p><ul><li><p><strong>RDS Proxy</strong> provides <strong>connection pooling</strong> v√† <strong>connection reuse</strong></p></li><li><p>Gi·∫£m s·ªë database connections b·∫±ng c√°ch <strong>multiplex application connections</strong> onto fewer database connections</p></li><li><p><strong>Idle connections</strong> ƒë∆∞·ª£c reused thay v√¨ gi·ªØ open connections to database</p></li><li><p>NgƒÉn ch·∫∑n <strong>\"Too many connections\" error</strong> b·∫±ng c√°ch manage connection limits efficiently</p></li><li><p>Application ch·ªâ c·∫ßn update endpoint to RDS Proxy - <strong>no code changes</strong> needed</p></li></ul><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763947293732-ilw0lj25-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"322.5416666666667\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Increase the read capacity units (RCUs) and the write capacity units (WCUs) on the database.</strong></p><ul><li><p><strong>RCUs/WCUs l√† DynamoDB concepts</strong>, KH√îNG ph·∫£i Aurora/RDS</p></li><li><p>Aurora kh√¥ng s·ª≠ d·ª•ng RCU/WCU metrics</p></li></ul><p></p><p>‚ùå <strong>Turn on enhanced networking for the DB instances.</strong></p><ul><li><p><strong>Enhanced networking</strong> improve network throughput v√† latency</p></li><li><p><strong>KH√îNG gi·∫£i quy·∫øt</strong> connection limit issue - v·∫´n hit max_connections</p></li></ul><p></p><p>‚ùå <strong>Modify the DB cluster to use a burstable instance type.</strong></p><ul><li><p><strong>Burstable instances</strong> (T-series) v·ªÅ CPU performance bursting</p></li><li><p><strong>KH√îNG tƒÉng max_connections</strong> limit - connection limit based on instance memory</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Too many connections\"</strong> + <strong>\"idle connections\"</strong> ‚Üí <strong>RDS Proxy</strong> v·ªõi connection pooling</p></li><li><p><strong>\"Many open but idle connections\"</strong> ‚Üí Connection pooling l√† best solution</p></li><li><p><strong>RDS Proxy benefits</strong> ‚Üí Connection pooling, reuse, reduce overhead, improve scalability</p></li><li><p><strong>max_connections</strong> ‚Üí Based on instance memory (formula varies by engine)</p></li><li><p><strong>RCU/WCU</strong> ‚Üí DynamoDB only, KH√îNG ph·∫£i RDS/Aurora</p></li><li><p><strong>Enhanced networking</strong> ‚Üí Network performance, kh√¥ng ph·∫£i connection management</p></li><li><p><strong>Instance type</strong> ‚Üí CPU/memory, kh√¥ng direct affect connection pooling</p></li><li><p><strong>Connection management pattern</strong> ‚Üí RDS Proxy &gt; increasing instance size</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html\">Using Amazon RDS Proxy</a></p></li></ul>",
            "correctAnswer": [
                "<p>Configure RDS Proxy. Update the application with the RDS Proxy endpoint.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Increase the read capacity units (RCUs) and the write capacity units (WCUs) on the database.</p>",
                "<p>Configure RDS Proxy. Update the application with the RDS Proxy endpoint.</p>",
                "<p>Turn on enhanced networking for the DB instances.</p>",
                "<p>Modify the DB cluster to use a burstable instance type.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 22
        },
        {
            "attemptAnswerId": 329164,
            "questionId": 6388,
            "questionText": "<p>A SysOps administrator wants to securely share an object from a private Amazon S3 bucket with a group of users who do not have an AWS account.<br><br>What is the MOST operationally efficient solution that will meet this requirement?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>SysOps admin mu·ªën securely share object t·ª´ <strong>private Amazon S3 bucket</strong></p></li><li><p>Share v·ªõi group of <strong>users who do NOT have AWS account</strong></p></li><li><p>Y√™u c·∫ßu: <strong>MOST operationally efficient</strong> solution</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Generate a presigned URL for the object. Share the URL with the users.</strong></p><ul><li><p><strong>Presigned URL</strong> cung c·∫•p <strong>temporary access</strong> to private S3 objects</p></li><li><p><strong>KH√îNG c·∫ßn AWS account</strong> - users ch·ªâ c·∫ßn URL ƒë·ªÉ download</p></li><li><p>URL c√≥ <strong>expiration time</strong> (configurable t·ª´ seconds ƒë·∫øn days)</p></li><li><p><strong>Most operationally efficient</strong>: ch·ªâ generate URL v√† share, no infrastructure setup</p></li><li><p><strong>Secure</strong>: time-limited access, URL contains authentication information</p></li><li><p>Can revoke access b·∫±ng c√°ch URL expire ho·∫∑c change object permissions</p></li></ul><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763947558099-y5ibla8e-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"405.83333333333337\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Attach an S3 bucket policy that only allows object downloads from the users' IP addresses.</strong></p><ul><li><p>C·∫ßn <strong>track v√† maintain IP addresses</strong> c·ªßa all users</p></li><li><p><strong>IP addresses c√≥ th·ªÉ change</strong> (mobile, different locations)</p></li><li><p><strong>Not scalable</strong> cho large group of users</p></li></ul><p></p><p>‚ùå <strong>Create an IAM role that has access to the object. Instruct the users to assume the role.</strong></p><ul><li><p>Users <strong>KH√îNG c√≥ AWS account</strong> ‚Üí <strong>CANNOT assume IAM roles</strong></p></li><li><p>Assume role requires AWS credentials (STS AssumeRole API)</p></li><li><p><strong>Kh√¥ng kh·∫£ thi</strong> cho users without AWS accounts</p></li></ul><p></p><p>‚ùå <strong>Create an IAM user that has access to the object. Share the credentials with the users.</strong></p><ul><li><p><strong>Sharing IAM credentials</strong> vi ph·∫°m <strong>AWS security best practices</strong></p></li><li><p><strong>Security risk</strong>: credentials c√≥ th·ªÉ b·ªã leaked ho·∫∑c misused</p></li><li><p><strong>Operational overhead</strong>: manage IAM users, credential rotation</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Users without AWS account\"</strong> ‚Üí <strong>Presigned URL</strong> l√† only practical solution</p></li><li><p><strong>\"Share private S3 object\"</strong> + <strong>\"operationally efficient\"</strong> ‚Üí Presigned URL</p></li><li><p><strong>Presigned URL</strong> ‚Üí Temporary, secure, no AWS account needed</p></li><li><p><strong>IAM role/user</strong> ‚Üí Requires AWS credentials, kh√¥ng ph√π h·ª£p cho external users</p></li><li><p><strong>Bucket policy with IP</strong> ‚Üí Difficult to manage, IPs change frequently</p></li><li><p><strong>Credential sharing</strong> ‚Üí Security anti-pattern, never recommended</p></li><li><p><strong>Access control pattern</strong> ‚Üí Presigned URL for temporary external access</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html\">Sharing objects with presigned URLs</a></p></li></ul>",
            "correctAnswer": [
                "<p>Generate a presigned URL for the object. Share the URL with the users.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Attach an S3 bucket policy that only allows object downloads from the users' IP addresses.</p>",
                "<p>Create an IAM role that has access to the object. Instruct the users to assume the role.</p>",
                "<p>Create an IAM user that has access to the object. Share the credentials with the users.</p>",
                "<p>Generate a presigned URL for the object. Share the URL with the users.</p>"
            ],
            "answersPos": "[1,2,3,0]",
            "pos": 23
        },
        {
            "attemptAnswerId": 329165,
            "questionId": 6389,
            "questionText": "<p>A custom application must be installed on all Amazon EC2 instances. The application is small, updated frequently, and can be installed automatically.<br><br>How can the application be deployed on new EC2 instances?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p><strong>Custom application</strong> ph·∫£i installed tr√™n <strong>all EC2 instances</strong></p></li><li><p>Application l√† <strong>small</strong>, <strong>updated frequently</strong></p></li><li><p>Can be <strong>installed automatically</strong></p></li><li><p>H·ªèi: <strong>How to deploy application on new EC2 instances?</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Launch a script that downloads and installs the application using Amazon EC2 user data.</strong></p><ul><li><p><strong>EC2 user data</strong> executes scripts automatically <strong>at instance launch</strong></p></li><li><p>Script c√≥ th·ªÉ <strong>download latest version</strong> of application m·ªói l·∫ßn instance starts</p></li><li><p><strong>Updated frequently</strong> ‚Üí downloading ensures always get latest version</p></li><li><p><strong>Simple v√† automatic</strong> - no manual intervention needed</p></li><li><p>Built-in EC2 feature, <strong>no additional infrastructure</strong> required</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a custom API using Amazon API Gateway to call an installation executable from an AWS CloudFormation template.</strong></p><ul><li><p><strong>Overly complex</strong> - API Gateway kh√¥ng ph·∫£i tool cho software installation</p></li><li><p>CloudFormation orchestrates infrastructure, kh√¥ng ph·∫£i application installation automation</p></li></ul><p></p><p>‚ùå <strong>Use AWS Systems Manager to inject the application into an AMI.</strong></p><ul><li><p><strong>AMI approach inflexible</strong> cho frequently updated applications</p></li><li><p>Ph·∫£i <strong>rebuild v√† redistribute AMI</strong> m·ªói khi application updates</p></li><li><p><strong>Not efficient</strong> cho frequent updates</p></li></ul><p></p><p>‚ùå <strong>Configure AWS CodePipeline to deploy code changes and updates.</strong></p><ul><li><p>CodePipeline designed cho <strong>CI/CD deployment to running infrastructure</strong></p></li><li><p><strong>KH√îNG ph·∫£i bootstrap tool</strong> cho new instances</p></li><li><p>Kh√¥ng automatically install on new instances at launch</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"New EC2 instances\"</strong> + <strong>\"automatic installation\"</strong> ‚Üí <strong>EC2 user data</strong></p></li><li><p><strong>\"Updated frequently\"</strong> ‚Üí Download approach &gt; baked-into-AMI approach</p></li><li><p><strong>User data</strong> ‚Üí Runs once at first boot (or every boot if configured)</p></li><li><p><strong>Small application</strong> ‚Üí Perfect for user data script download</p></li><li><p><strong>AMI approach</strong> ‚Üí Good for large, stable software, bad for frequent updates</p></li><li><p><strong>Systems Manager</strong> ‚Üí Better for ongoing management of running instances</p></li><li><p><strong>CodePipeline</strong> ‚Üí CI/CD for application updates, not instance bootstrap</p></li><li><p><strong>Bootstrap pattern</strong> ‚Üí User data script downloads latest version at launch</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html\">Run commands on your Linux instance at launch</a></p></li></ul>",
            "correctAnswer": [
                "<p>Launch a script that downloads and installs the application using Amazon EC2 user data.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Launch a script that downloads and installs the application using Amazon EC2 user data.</p>",
                "<p>Create a custom API using Amazon API Gateway to call an installation executable from an AWS CloudFormation template.</p>",
                "<p>Use AWS Systems Manager to inject the application into an AMI.</p>",
                "<p>Configure AWS CodePipeline to deploy code changes and updates.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 24
        },
        {
            "attemptAnswerId": 329166,
            "questionId": 8832,
            "questionText": "<p>A SysOps administrator notices that the cache hit ratio for an Amazon CloudFront distribution is less than 10%. The SysOps administrator needs to increase the cache hit ratio for the distribution, improve network performance, and reduce the load on the origin.<br><br>Which combination of actions should the SysOps administrator take to meet these requirements? (Choose two.)</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p><strong>CloudFront distribution</strong> c√≥ <strong>cache hit ratio &lt; 10%</strong> (very low)</p></li><li><p>C·∫ßn:</p><ul><li><p><strong>Increase cache hit ratio</strong></p></li><li><p><strong>Improve network performance</strong></p></li><li><p><strong>Reduce load on origin</strong></p></li></ul></li><li><p>Ch·ªçn <strong>2 actions</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Enable CloudFront Origin Shield for the required AWS Regions.</strong></p><ul><li><p><strong>Origin Shield</strong> l√† <strong>additional caching layer</strong> between edge locations v√† origin</p></li><li><p>Consolidate requests t·ª´ multiple edge locations th√†nh <strong>single request to origin</strong></p></li><li><p><strong>Increase cache hit ratio</strong> v√¨ nhi·ªÅu edge locations share cached content from Origin Shield</p></li><li><p><strong>Reduce origin load</strong> significantly v·ªõi centralized caching</p></li><li><p>Improve network performance v·ªõi optimized routes to origin</p></li></ul><p></p><p><strong>Increase the CloudFront TTL values in the cache behavior settings.</strong></p><ul><li><p><strong>Longer TTL</strong> = objects stay in cache longer before expiring</p></li><li><p><strong>Fewer requests to origin</strong> ƒë·ªÉ revalidate content</p></li><li><p><strong>Increase cache hit ratio</strong> v√¨ objects served from cache instead of origin</p></li><li><p>Reduce origin load ƒë√°ng k·ªÉ</p></li><li><p>Simple configuration change, t√°c ƒë·ªông nhanh ch√≥ng</p></li></ul><p></p><p><em>Use Amazon CloudFront Origin Shield</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1763948133761-o4crib7q-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"424.5\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Change the viewer protocol policy to use HTTPS only.</strong></p><ul><li><p><strong>Security feature</strong>, kh√¥ng ·∫£nh h∆∞·ªüng cache hit ratio</p></li><li><p>Kh√¥ng improve caching behavior</p></li></ul><p></p><p>‚ùå <strong>Add a second origin. Create an origin group that includes both origins. Activate CloudFront origin failover.</strong></p><ul><li><p><strong>Origin failover</strong> cho high availability</p></li><li><p><strong>KH√îNG c·∫£i thi·ªán cache hit ratio</strong> ho·∫∑c reduce origin load</p></li><li><p>Focus on availability, kh√¥ng ph·∫£i caching optimization</p></li></ul><p></p><p>‚ùå <strong>Turn on automatic compression of objects in the cache behavior settings.</strong></p><ul><li><p>Compression gi·∫£m transfer size, improve bandwidth efficiency</p></li><li><p>NH∆ØNG <strong>KH√îNG tƒÉng cache hit ratio</strong> - objects v·∫´n expire at same rate</p></li><li><p>Kh√¥ng address root cause c·ªßa low cache hit ratio</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Low cache hit ratio\"</strong> ‚Üí Check <strong>TTL settings</strong> v√† <strong>Origin Shield</strong></p></li><li><p><strong>\"Reduce origin load\"</strong> ‚Üí Increase TTL + Origin Shield combination</p></li><li><p><strong>Origin Shield</strong> ‚Üí Additional caching layer, consolidates requests</p></li><li><p><strong>Longer TTL</strong> ‚Üí Objects cached longer, fewer origin requests</p></li><li><p><strong>Compression</strong> ‚Üí Transfer optimization, kh√¥ng ph·∫£i cache optimization</p></li><li><p><strong>Origin failover</strong> ‚Üí High availability, kh√¥ng ph·∫£i caching</p></li><li><p><strong>HTTPS policy</strong> ‚Üí Security, kh√¥ng ·∫£nh h∆∞·ªüng caching</p></li><li><p><strong>Cache optimization pattern</strong> ‚Üí TTL tuning + Origin Shield = best combination</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/origin-shield.html\">Using Amazon CloudFront Origin Shield</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html\">Managing how long content stays in the cache (expiration)</a></p></li></ul>",
            "correctAnswer": [
                "<p>Increase the CloudFront TTL values in the cache behavior settings.</p>",
                "<p>Enable CloudFront Origin Shield for the required AWS Regions.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Enable CloudFront Origin Shield for the required AWS Regions.</p>",
                "<p>Change the viewer protocol policy to use HTTPS only.</p>",
                "<p>Add a second origin. Create an origin group that includes both origins. Activate CloudFront origin failover.</p>",
                "<p>Turn on automatic compression of objects in the cache behavior settings.</p>",
                "<p>Increase the CloudFront TTL values in the cache behavior settings.</p>"
            ],
            "answersPos": "[2,4,1,0,3]",
            "pos": 25
        },
        {
            "attemptAnswerId": 329167,
            "questionId": 6391,
            "questionText": "<p>A SysOps administrator configured VPC flow logs by using the default format. The SysOps administrator specified Amazon CloudWatch Logs as the destination. This solution has worked successfully for several months. However, because of additional troubleshooting requirements, the SysOps administrator needs to include the tcp-flags field on the flow logs.<br><br>What should the SysOps administrator do to meet this requirement?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>VPC flow logs configured v·ªõi <strong>default format</strong></p></li><li><p>Destination l√† <strong>Amazon CloudWatch Logs</strong></p></li><li><p>Solution ho·∫°t ƒë·ªông t·ªët trong several months</p></li><li><p>C·∫ßn th√™m <strong>tcp-flags field</strong> v√†o flow logs cho additional troubleshooting</p></li><li><p>H·ªèi: <strong>What to do to meet requirement?</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create a new flow log. Include the tcp-flags field in the custom log format. Delete the original flow log.</strong></p><ul><li><p><strong>KH√îNG TH·ªÇ modify existing flow log format</strong> sau khi created</p></li><li><p>Ph·∫£i <strong>create new flow log</strong> v·ªõi <strong>custom log format</strong> ƒë·ªÉ include additional fields</p></li><li><p>Custom format cho ph√©p specify exactly which fields to capture (including <strong>tcp-flags</strong>)</p></li><li><p>Delete original flow log ƒë·ªÉ avoid duplicate logging v√† unnecessary costs</p></li><li><p>tcp-flags field provides TCP flag information for troubleshooting</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>In the CloudWatch Logs log group, modify the filter to include the tcp-flags field and the type field.</strong></p><ul><li><p><strong>CloudWatch Logs filters</strong> ch·ªâ filter existing log data, <strong>KH√îNG thay ƒë·ªïi</strong> flow log format</p></li><li><p>Kh√¥ng th·ªÉ add fields th√¥ng qua log group filters</p></li></ul><p></p><p>‚ùå <strong>In CloudWatch Metrics, modify the metric configuration to include the tcp-flags field.</strong></p><ul><li><p><strong>CloudWatch Metrics</strong> l√† separate service t·ª´ flow logs</p></li><li><p><strong>KH√îNG li√™n quan</strong> ƒë·∫øn flow log format configuration</p></li></ul><p></p><p>‚ùå <strong>Modify the existing flow log. Include the tcp-flags field and the type field in the custom log format. Save the configuration.</strong></p><ul><li><p><strong>Flow log format CANNOT be modified</strong> after creation</p></li><li><p>This is a <strong>limitation</strong> c·ªßa VPC Flow Logs service</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Add field to flow log\"</strong> ‚Üí <strong>Create new flow log</strong>, cannot modify existing</p></li><li><p><strong>VPC Flow Log limitation</strong> ‚Üí Format immutable after creation</p></li><li><p><strong>Custom format</strong> ‚Üí Specify exactly which fields to capture</p></li><li><p><strong>tcp-flags field</strong> ‚Üí Contains TCP flag information for detailed troubleshooting</p></li><li><p><strong>Default format</strong> ‚Üí Fixed set of fields, cannot customize</p></li><li><p><strong>Flow log recreation</strong> ‚Üí Create new + delete old to avoid duplicates</p></li><li><p><strong>Cost consideration</strong> ‚Üí Delete old flow log to prevent double logging costs</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/vpc/latest/userguide/flow-log-records.html\">Flow log records</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a new flow log. Include the tcp-flags field in the custom log format. Delete the original flow log.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a new flow log. Include the tcp-flags field in the custom log format. Delete the original flow log.</p>",
                "<p>In the CloudWatch Logs log group, modify the filter to include the tcp-flags field and the type field.</p>",
                "<p>In CloudWatch Metrics, modify the metric configuration to include the tcp-flags field.</p>",
                "<p>Modify the existing flow log. Include the tcp-flags field and the type field in the custom log format. Save the configuration.</p>"
            ],
            "answersPos": "[3,0,1,2]",
            "pos": 26
        },
        {
            "attemptAnswerId": 329168,
            "questionId": 8833,
            "questionText": "<p>A company deploys a new application to Amazon EC2 instances. The application code is stored in an AWS CodeCommit repository. The company uses an AWS CodePipeline pipeline to deploy the code to the EC2 instances through a continuous integration and continuous delivery (CI/CD) process.<br><br>A SysOps administrator needs to ensure that sensitive database information is configured properly on the EC2 instances to prevent accidental leakage of credentials.<br><br>Which solutions will store and retrieve the sensitive information in the MOST secure manner? (Choose two.)</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company deploys application to <strong>EC2 instances</strong> v·ªõi <strong>CI/CD pipeline</strong> (CodePipeline, CodeCommit)</p></li><li><p>C·∫ßn ensure <strong>sensitive database information</strong> configured ƒë√∫ng c√°ch</p></li><li><p>Prevent <strong>accidental leakage of credentials</strong></p></li><li><p>Y√™u c·∫ßu: store v√† retrieve sensitive information <strong>MOST secure manner</strong></p></li><li><p>Ch·ªçn <strong>2 solutions</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Store the values in AWS Secrets Manager. Update the code to retrieve these values when the application starts. Store the values as environmental variables that the application can use.</strong></p><ul><li><p><strong>Secrets Manager</strong> designed specifically cho <strong>database credentials v√† secrets</strong></p></li><li><p><strong>Automatic rotation</strong> support cho credentials</p></li><li><p><strong>Encryption at rest</strong> v·ªõi KMS v√† <strong>in transit</strong></p></li><li><p><strong>Audit logging</strong> v·ªõi CloudTrail</p></li><li><p><strong>Retrieve at runtime</strong> = kh√¥ng store plaintext tr√™n instances</p></li></ul><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-saa-dva/aws-secrets-manager-integration-with-amazon-rds\"><em>AWS Secrets Manager Integration with Amazon RDS</em></a></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/undefined/1763948631268-n858x0l4-image.png\" alt=\"\" title=\"\" width=\"699\" height=\"606.56453125\" style=\"max-width: 699px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><strong>Store the values in AWS Systems Manager Parameter Store as secret strings. Update the code to retrieve these values when the application starts. Store the values as environmental variables that the application can use.</strong></p><ul><li><p><strong>Parameter Store SecureString</strong> encrypted v·ªõi <strong>AWS KMS</strong></p></li><li><p><strong>Built-in versioning</strong> v√† audit capabilities</p></li><li><p><strong>Lower cost</strong> alternative to Secrets Manager</p></li><li><p><strong>IAM-based access control</strong></p></li><li><p><strong>Retrieve at runtime</strong> ensures security</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Store the values in an AWS Lambda function. Update the code to invoke the Lambda function when the application starts. Configure the Lambda function to inject the values as environmental variables that the application can use.</strong></p><ul><li><p><strong>Lambda KH√îNG ph·∫£i n∆°i store secrets</strong> - Lambda needs to retrieve secrets t·ª´ Secrets Manager/Parameter Store</p></li><li><p>Architecture kh√¥ng ƒë√∫ng, Lambda c≈©ng c·∫ßn secrets management service</p></li></ul><p></p><p>‚ùå <strong>Store the configuration information in a file on the EC2 instances. Ensure that the underlying drives are encrypted by AWS Key Management Service (AWS KMS). Update the application to read the file when the application starts. Store the values as environmental variables.</strong></p><ul><li><p><strong>File tr√™n EC2 instance = less secure</strong> even with encryption</p></li><li><p>Khi instance b·ªã x√¢m nh·∫≠p, file credentials c√≥ th·ªÉ b·ªã ƒë·ªçc</p></li><li><p><strong>Static credentials</strong> tr√™n disk = security risk</p></li></ul><p></p><p>‚ùå <strong>Store the values in a text file in an Amazon S3 bucket. In the CI/CD pipeline, copy the file to the EC2 instance in an appropriate location on a disk that the application can read.</strong></p><ul><li><p><strong>Text file approach = very insecure</strong></p></li><li><p>Credentials exposed trong S3 v√† copied to instances</p></li><li><p><strong>Accidental leakage risk</strong> cao n·∫øu S3 misconfigured</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Sensitive database information\"</strong> + <strong>\"credentials\"</strong> ‚Üí <strong>Secrets Manager</strong> ho·∫∑c <strong>Parameter Store SecureString</strong></p></li><li><p><strong>\"MOST secure\"</strong> ‚Üí AWS managed secrets services, KH√îNG ph·∫£i files/S3</p></li><li><p><strong>Secrets Manager</strong> vs <strong>Parameter Store</strong>:</p><ul><li><p>Secrets Manager: automatic rotation, higher cost, designed for DB credentials</p></li><li><p>Parameter Store: lower cost, manual rotation, good for configs v√† secrets</p></li></ul></li><li><p><strong>Never store credentials in</strong>: Plaintext files, S3 text files, hardcoded, Lambda code</p></li><li><p><strong>Retrieve at runtime</strong> &gt; Baked into AMI/container images</p></li><li><p><strong>Best practices</strong>: Dynamic retrieval + encryption + audit + rotation</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html\">What is AWS Secrets Manager?</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html\">AWS Systems Manager Parameter Store</a></p></li></ul>",
            "correctAnswer": [
                "<p>Store the values in AWS Secrets Manager. Update the code to retrieve these values when the application starts. Store the values as environmental variables that the application can use.</p>",
                "<p>Store the values in AWS Systems Manager Parameter Store as secret strings. Update the code to retrieve these values when the application starts. Store the values as environmental variables that the application can use.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Store the values in AWS Secrets Manager. Update the code to retrieve these values when the application starts. Store the values as environmental variables that the application can use.</p>",
                "<p>Store the values in AWS Systems Manager Parameter Store as secret strings. Update the code to retrieve these values when the application starts. Store the values as environmental variables that the application can use.</p>",
                "<p>Store the values in an AWS Lambda function. Update the code to invoke the Lambda function when the application starts. Configure the Lambda function to inject the values as environmental variables that the application can use.</p>",
                "<p>Store the configuration information in a file on the EC2 instances. Ensure that the underlying drives are encrypted by AWS Key Management Service (AWS KMS). Update the application to read the file when the application starts. Store the values as environmental variables.</p>",
                "<p>Store the values in a text file in an Amazon S3 bucket. In the CI/CD pipeline, copy the file to the EC2 instance in an appropriate location on a disk that the application can read.</p>"
            ],
            "answersPos": "[3,0,1,4,2]",
            "pos": 27
        },
        {
            "attemptAnswerId": 329169,
            "questionId": 6393,
            "questionText": "<p>A company has implemented a Kubernetes cluster on Amazon Elastic Kubernetes Service (Amazon EKS) to host a microservices-based application. The company expects application traffic to increase significantly for the next month and wants to prevent the application from crashing because of the high number of requests.<br><br>Which solution will meet these requirements with the LEAST administrative overhead?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company c√≥ <strong>Kubernetes cluster</strong> tr√™n <strong>Amazon EKS</strong> hosting <strong>microservices application</strong></p></li><li><p>Expect <strong>application traffic increase significantly</strong> trong next month</p></li><li><p>C·∫ßn <strong>prevent application crashes</strong> do <strong>high number of requests</strong></p></li><li><p>Y√™u c·∫ßu: <strong>LEAST administrative overhead</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Implement the Kubernetes Horizontal Pod Autoscaler. Set a target CPU utilization percentage.</strong></p><ul><li><p><strong>HPA (Horizontal Pod Autoscaler)</strong> automatically <strong>scale number of pods</strong> based on metrics (CPU, memory, custom)</p></li><li><p><strong>Scale OUT</strong> (add more pods) khi traffic tƒÉng ƒë·ªÉ handle more requests</p></li><li><p><strong>Scale IN</strong> (reduce pods) khi traffic gi·∫£m ƒë·ªÉ optimize costs</p></li><li><p><strong>Built-in Kubernetes feature</strong> - no additional infrastructure needed</p></li><li><p><strong>Minimal administrative overhead</strong> - ch·ªâ c·∫ßn configure target metrics, HPA t·ª± ƒë·ªông manage</p></li><li><p>Perfect cho <strong>handling traffic spikes</strong> trong microservices architecture</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a second EKS cluster. Load balance the workload between the two clusters.</strong></p><ul><li><p><strong>Very high administrative overhead</strong> - manage 2 separate clusters</p></li><li><p><strong>Expensive</strong> v√† overly complex</p></li><li><p><strong>Kh√¥ng c·∫ßn thi·∫øt</strong> khi c√≥ autoscaling</p></li></ul><p></p><p>‚ùå <strong>Migrate the application from Amazon EKS to Amazon EC2 for the next month. Migrate the application back to Amazon EKS when the month ends.</strong></p><ul><li><p><strong>Extremely high overhead</strong> - migrate twice trong 1 th√°ng</p></li><li><p><strong>Disruptive</strong> v√† risky cho production application</p></li><li><p><strong>Worst option</strong> v·ªÅ administrative effort</p></li></ul><p></p><p>‚ùå <strong>Implement the Kubernetes Vertical Pod Autoscaler. Set a target CPU utilization percentage.</strong></p><ul><li><p><strong>VPA scales pod RESOURCES</strong> (CPU/memory limits), KH√îNG scale number of pods</p></li><li><p><strong>KH√îNG gi·∫£i quy·∫øt</strong> \"high number of requests\" - c·∫ßn MORE pods, kh√¥ng ph·∫£i BIGGER pods</p></li><li><p>VPA d√πng cho right-sizing resources, kh√¥ng ph·∫£i handling traffic increases</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"High number of requests\"</strong> + <strong>\"prevent crashes\"</strong> ‚Üí <strong>Horizontal scaling</strong> (more replicas)</p></li><li><p><strong>\"LEAST overhead\"</strong> + <strong>\"Kubernetes\"</strong> ‚Üí <strong>Use built-in autoscalers</strong></p></li><li><p><strong>HPA (Horizontal Pod Autoscaler)</strong> ‚Üí Scale number of pods (replicas)</p></li><li><p><strong>VPA (Vertical Pod Autoscaler)</strong> ‚Üí Scale pod resources (CPU/memory)</p></li><li><p><strong>Traffic increase</strong> ‚Üí HPA scales OUT with more pods</p></li><li><p><strong>Resource optimization</strong> ‚Üí VPA adjusts pod sizing</p></li><li><p><strong>Microservices pattern</strong> ‚Üí HPA perfect cho handle variable load</p></li><li><p><strong>Autoscaling pattern</strong> ‚Üí HPA for traffic, VPA for resource optimization</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/\">Horizontal Pod Autoscaler</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/eks/latest/userguide/horizontal-pod-autoscaler.html\">Autoscaling in Amazon EKS</a></p></li></ul>",
            "correctAnswer": [
                "<p>Implement the Kubernetes Horizontal Pod Autoscaler. Set a target CPU utilization percentage.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a second EKS cluster. Load balance the workload between the two clusters.</p>",
                "<p>Implement the Kubernetes Horizontal Pod Autoscaler. Set a target CPU utilization percentage.</p>",
                "<p>Migrate the application from Amazon EKS to Amazon EC2 for the next month. Migrate the application back to Amazon EKS when the month ends.</p>",
                "<p>Implement the Kubernetes Vertical Pod Autoscaler. Set a target CPU utilization percentage.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 28
        },
        {
            "attemptAnswerId": 329170,
            "questionId": 6394,
            "questionText": "<p>A company has a multi-account environment. Account A has a production application that is hosted on an Amazon EC2 instance. The application needs to query data in an Amazon DynamoDB table that is hosted in Account B.<br><br>A SysOps administrator needs to provide the EC2 instance in Account A with access to the DynamoDB table in Account B.<br><br>What is the MOST secure solution that will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Multi-account environment: <strong>Account A</strong> v√† <strong>Account B</strong></p></li><li><p><strong>EC2 instance</strong> trong <strong>Account A</strong> ch·∫°y production application</p></li><li><p>Application c·∫ßn <strong>query DynamoDB table</strong> trong <strong>Account B</strong></p></li><li><p>C·∫ßn provide EC2 instance access to DynamoDB table</p></li><li><p>Y√™u c·∫ßu: <strong>MOST secure solution</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>In Account B, create an IAM role that has permission to query the DynamoDB table. Add the EC2 instance's IAM role to the trust policy on the newly created IAM role in Account B. Update the IAM policy that is attached to the EC2 instance's IAM role to allow the sts:AssumeRole permission on the newly created IAM role in Account B.</strong></p><ul><li><p><strong>Standard cross-account access pattern</strong> v·ªõi <strong>AssumeRole</strong></p></li><li><p>Account B creates IAM role v·ªõi DynamoDB query permissions</p></li><li><p><strong>Trust policy</strong> trong Account B role allows Account A's EC2 role to assume it</p></li><li><p>EC2 instance assumes Account B's role ƒë·ªÉ temporary access DynamoDB</p></li><li><p><strong>Most secure</strong>: temporary credentials, no static keys, full audit trail v·ªõi CloudTrail</p></li><li><p><strong>Principle of least privilege</strong> - ch·ªâ grant specific permissions needed</p></li></ul><p><em>Architectture:</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1764072826816-rfoq9hl5-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"364.9166666666667\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Update the IAM policy that is attached to the EC2 instance's IAM role to allow the dynamodb:Query permission on the DynamoDB table in Account B. Add a policy in Account A to allow the DynamoDB service principal to use the PassRole action to pass the role to Account B.</strong></p><ul><li><p><strong>KH√îNG th·ªÉ</strong> directly grant permissions on resources trong another account ch·ªâ b·∫±ng IAM policy</p></li><li><p><strong>PassRole action kh√¥ng d√πng</strong> cho cross-account resource access pattern n√†y</p></li></ul><p></p><p>‚ùå <strong>Update the IAM policy that is attached to the EC2 instance's IAM role to allow the dynamodb:Query permission on the DynamoDB table in Account B. Update the DynamoDB table's resource policy to allow the query action from the EC2 instance's IAM role.</strong></p><ul><li><p><strong>DynamoDB KH√îNG c√≥ resource-based policies</strong> nh∆∞ S3 bucket policies</p></li><li><p>DynamoDB ch·ªâ support IAM identity-based policies</p></li></ul><p></p><p>‚ùå <strong>In Account B, create a static IAM key that has the appropriate permissions to query the DynamoDB table. Embed these credentials into the credentials file on the EC2 instance. Reference the credentials every time the application needs to query the table.</strong></p><ul><li><p><strong>Static credentials = r·ªßi ro security l·ªõn</strong></p></li><li><p>Credentials c√≥ th·ªÉ b·ªã leaked ho·∫∑c compromised</p></li><li><p><strong>Vi ph·∫°m AWS security best practices</strong> - never nh√∫ng credentials</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Cross-account access\"</strong> + <strong>\"most secure\"</strong> ‚Üí <strong>AssumeRole pattern</strong></p></li><li><p><strong>Cross-account IAM role steps</strong>:</p><ol><li><p>Create role in destination account (Account B)</p></li><li><p>Add trust policy allowing source account's principal</p></li><li><p>Grant sts:AssumeRole permission in source account</p></li></ol></li><li><p><strong>DynamoDB</strong> ‚Üí KH√îNG c√≥ resource-based policies (kh√°c S3, SNS, SQS)</p></li><li><p><strong>Static credentials</strong> ‚Üí Never embed, always use temporary credentials</p></li><li><p><strong>PassRole</strong> ‚Üí Used for passing roles to AWS services, kh√¥ng ph·∫£i cross-account access</p></li><li><p><strong>Cross-account pattern</strong> ‚Üí AssumeRole &gt; Resource policies &gt; Static credentials (worst)</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html\">Tutorial: Delegate access across AWS accounts using IAM roles</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_aws-accounts.html\">Providing access to an IAM user in another AWS account</a></p></li></ul>",
            "correctAnswer": [
                "<p>In Account B, create an IAM role that has permission to query the DynamoDB table. Add the EC2 instance's IAM role to the trust policy on the newly created IAM role in Account B. Update the IAM policy that is attached to the EC2 instance's IAM role to allow the sts:AssumeRole permission on the newly created IAM role in Account B.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Update the IAM policy that is attached to the EC2 instance's IAM role to allow the dynamodb:Query permission on the DynamoDB table in Account B. Add a policy in Account A to allow the DynamoDB service principal to use the PassRole action to pass the role to Account B.</p>",
                "<p>In Account B, create an IAM role that has permission to query the DynamoDB table. Add the EC2 instance's IAM role to the trust policy on the newly created IAM role in Account B. Update the IAM policy that is attached to the EC2 instance's IAM role to allow the sts:AssumeRole permission on the newly created IAM role in Account B.</p>",
                "<p>Update the IAM policy that is attached to the EC2 instance's IAM role to allow the dynamodb:Query permission on the DynamoDB table in Account B. Update the DynamoDB table's resource policy to allow the query action from the EC2 instance's IAM role.</p>",
                "<p>In Account B, create a static IAM key that has the appropriate permissions to query the DynamoDB table. Embed these credentials into the credentials file on the EC2 instance. Reference the credentials every time the application needs to query the table.</p>"
            ],
            "answersPos": "[2,1,3,0]",
            "pos": 29
        },
        {
            "attemptAnswerId": 329171,
            "questionId": 6395,
            "questionText": "<p>A SysOps administrator has many Windows Amazon EC2 instances that need to share a file system between nodes. The SysOps administrator creates an Amazon Elastic File System (Amazon EFS) file share. After creation of the file share, the SysOps administrator is having trouble mounting the file share to the EC2 instances.<br><br>Which action should the SysOps administrator take so that the EC2 instances can share the files?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>SysOps admin c√≥ nhi·ªÅu <strong>Windows EC2 instances</strong> c·∫ßn <strong>share file system</strong> between nodes</p></li><li><p>Admin t·∫°o <strong>Amazon EFS file share</strong></p></li><li><p><strong>C√≥ v·∫•n ƒë·ªÅ mounting</strong> EFS to EC2 instances</p></li><li><p>H·ªèi: <strong>What action to take</strong> ƒë·ªÉ EC2 instances c√≥ th·ªÉ share files?</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Delete the EFS file share. Create an Amazon FSx for Windows File Server file share for the EC2 instances.</strong></p><ul><li><p><strong>Amazon EFS designed cho Linux instances</strong>, s·ª≠ d·ª•ng <strong>NFS protocol</strong></p></li><li><p><strong>Windows instances KH√îNG natively support EFS</strong> - wrong file system choice</p></li><li><p><strong>Amazon FSx for Windows File Server</strong> l√† correct solution cho <strong>Windows workloads</strong></p></li><li><p>FSx for Windows supports <strong>SMB protocol</strong> m√† Windows native support</p></li><li><p><strong>Fully managed Windows file system</strong> v·ªõi Active Directory integration</p></li><li><p>Built on Windows Server, optimized cho Windows applications</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Use the correct IAM credentials to mount the EFS file share.</strong></p><ul><li><p><strong>EFS mounting KH√îNG require IAM credentials</strong></p></li><li><p>EFS s·ª≠ d·ª•ng NFS protocol v·ªõi network-based access control</p></li><li><p>Kh√¥ng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ Windows compatibility</p></li></ul><p></p><p>‚ùå <strong>Configure NFSv4 support on the Windows operating system that is running on the EC2 instances.</strong></p><ul><li><p>Windows c√≥ th·ªÉ enable NFS client nh∆∞ng <strong>NOT recommended</strong> v√† <strong>not supported by AWS</strong></p></li><li><p>Performance issues v√† compatibility problems (v·∫•n ƒë·ªÅ kh·∫£ nƒÉng t∆∞∆°ng th√≠ch)</p></li><li><p><strong>Amazon KH√îNG recommend</strong> EFS cho Windows instances</p></li></ul><p></p><p>‚ùå <strong>Allow the correct port for NFS through the security group and network ACL.</strong></p><ul><li><p>Security group/NACL rules c√≥ th·ªÉ l√† issue v·ªõi Linux instances</p></li><li><p>NH∆ØNG <strong>KH√îNG gi·∫£i quy·∫øt root cause</strong> - EFS kh√¥ng ph·∫£i right choice cho Windows</p></li><li><p>Port 2049 (NFS) open v·∫´n kh√¥ng make Windows work properly v·ªõi EFS</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Windows instances\"</strong> + <strong>\"file share\"</strong> ‚Üí <strong>Amazon FSx for Windows File Server</strong></p></li><li><p><strong>\"Linux instances\"</strong> + <strong>\"file share\"</strong> ‚Üí <strong>Amazon EFS</strong></p></li><li><p><strong>EFS</strong> ‚Üí NFS protocol, Linux only</p></li><li><p><strong>FSx for Windows</strong> ‚Üí SMB protocol, Windows native</p></li><li><p><strong>Protocol mapping</strong>:</p><ul><li><p>Windows ‚Üí SMB/CIFS ‚Üí FSx for Windows File Server</p></li><li><p>Linux ‚Üí NFS ‚Üí Amazon EFS</p></li><li><p>Both ‚Üí SMB ‚Üí FSx for Windows (Linux c√≥ th·ªÉ mount SMB)</p></li></ul></li><li><p><strong>Wrong file system choice</strong> ‚Üí Recreate v·ªõi correct service</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/fsx/windows/\">Amazon FSx for Windows File Server</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/efs/when-to-choose-efs/\">When to choose Amazon EFS</a></p></li></ul>",
            "correctAnswer": [
                "<p>Delete the EFS file share. Create an Amazon FSx for Windows File Server file share for the EC2 instances.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Delete the EFS file share. Create an Amazon FSx for Windows File Server file share for the EC2 instances.</p>",
                "<p>Use the correct IAM credentials to mount the EFS file share.</p>",
                "<p>Configure NFSv4 support on the Windows operating system that is running on the EC2 instances.</p>",
                "<p>Allow the correct port for NFS through the security group and network ACL.</p>"
            ],
            "answersPos": "[1,0,2,3]",
            "pos": 30
        },
        {
            "attemptAnswerId": 329172,
            "questionId": 6396,
            "questionText": "<p>A company has users that deploy Amazon EC2 instances that have more disk performance capacity than is required. A SysOps administrator needs to review all Amazon Elastic Block Store (Amazon EBS) volumes that are associated with the instances and create cost optimization recommendations based on IOPS and throughput.<br><br>What should the SysOps administrator do to meet these requirements in the MOST operationally efficient way?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Users deploy <strong>EC2 instances</strong> c√≥ <strong>more disk performance capacity than required</strong> (over-provisioned)</p></li><li><p>SysOps admin c·∫ßn <strong>review all EBS volumes</strong> associated v·ªõi instances</p></li><li><p>Create <strong>cost optimization recommendations</strong> based on <strong>IOPS v√† throughput</strong></p></li><li><p>Y√™u c·∫ßu: <strong>MOST operationally efficient way</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Opt in to AWS Compute Optimizer. Allow sufficient time for metrics to be gathered. Review the Compute Optimizer findings for EBS volumes.</strong></p><ul><li><p><strong>AWS Compute Optimizer</strong> automatically analyze <strong>EBS volume utilization</strong> metrics (IOPS, throughput)</p></li><li><p>Provides <strong>specific recommendations</strong> cho volume type v√† size optimization</p></li><li><p><strong>Machine learning-based</strong> analysis c·ªßa CloudWatch metrics</p></li><li><p><strong>Zero manual effort</strong> - fully automated analysis</p></li><li><p>Recommendations include <strong>cost savings estimates</strong></p></li><li><p><strong>Most operationally efficient</strong> - no manual review, no tool installation</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Use the monitoring graphs in the EC2 console to view metrics for EBS volumes. Review the consumed space against the provisioned space on each volume. Identify any volumes that have low utilization.</strong></p><ul><li><p><strong>Manual review</strong> kh√¥ng scalable cho many volumes</p></li><li><p>\"Consumed space vs provisioned space\" l√† <strong>storage capacity</strong>, KH√îNG ph·∫£i IOPS/throughput</p></li><li><p>KH√îNG operationally efficient</p></li></ul><p></p><p>‚ùå <strong>Stop the EC2 instances from the EC2 console. Change the EC2 instance type for Amazon EBS-optimized. Start the EC2 instances.</strong></p><ul><li><p><strong>EBS-optimized instance type</strong> KH√îNG gi·∫£i quy·∫øt EBS volume over-provisioning</p></li><li><p><strong>G√¢y gi·∫£n ƒëo·∫°n</strong> - requires stop/start</p></li><li><p>KH√îNG li√™n quan ƒë·∫øn IOPS/throughput optimization c·ªßa volumes</p></li></ul><p></p><p>‚ùå <strong>Install the fio tool onto EC2 instances and create a .cfg file to approximate the required workloads. Use the benchmark results to gauge whether the provisioned EBS volumes are of the most appropriate type.</strong></p><ul><li><p><strong>C√¥ng c·ª• ƒë√°nh gi√° th·ªß c√¥ng</strong> - high operational overhead</p></li><li><p>Requires <strong>fio expertise</strong> v√† configuration</p></li><li><p><strong>M·∫•t th·ªùi gian </strong>cho multiple instances</p></li><li><p>KH√îNG operationally efficient</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Cost optimization\"</strong> + <strong>\"IOPS/throughput\"</strong> ‚Üí <strong>AWS Compute Optimizer</strong></p></li><li><p><strong>\"MOST operationally efficient\"</strong> ‚Üí <strong>Managed services</strong> &gt; Manual tools</p></li><li><p><strong>Compute Optimizer</strong> analyze:</p><ul><li><p>EC2 instance types</p></li><li><p>EBS volumes (IOPS, throughput utilization)</p></li><li><p>Lambda functions</p></li><li><p>Auto Scaling groups</p></li></ul></li><li><p><strong>Storage capacity</strong> ‚â† <strong>IOPS/throughput</strong> - different metrics</p></li><li><p><strong>EBS-optimized instances</strong> ‚Üí Dedicated bandwidth to EBS, kh√¥ng ph·∫£i volume optimization</p></li><li><p><strong>fio tool</strong> ‚Üí Manual benchmarking, good for specific testing but not scalable</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/compute-optimizer/\">AWS Compute Optimizer</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/compute-optimizer/latest/ug/viewing-dashboard.html\">Viewing the AWS Compute Optimizer dashboard</a></p></li></ul>",
            "correctAnswer": [
                "<p>Opt in to AWS Compute Optimizer. Allow sufficient time for metrics to be gathered. Review the Compute Optimizer findings for EBS volumes.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use the monitoring graphs in the EC2 console to view metrics for EBS volumes. Review the consumed space against the provisioned space on each volume. Identify any volumes that have low utilization.</p>",
                "<p>Stop the EC2 instances from the EC2 console. Change the EC2 instance type for Amazon EBS-optimized. Start the EC2 instances.</p>",
                "<p>Opt in to AWS Compute Optimizer. Allow sufficient time for metrics to be gathered. Review the Compute Optimizer findings for EBS volumes.</p>",
                "<p>Install the fio tool onto the EC2 instances and create a .cfg file to approximate the required workloads. Use the benchmark results to gauge whether the provisioned EBS volumes are of the most appropriate type.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 31
        },
        {
            "attemptAnswerId": 329173,
            "questionId": 6397,
            "questionText": "<p>A SysOps administrator manages policies for many AWS member accounts in an AWS Organizations structure. Administrators on other teams have access to the account root user credentials of the member accounts. The SysOps administrator must prevent all teams, including their administrators, from using Amazon DynamoDB. The solution must not affect the ability of the teams to access other AWS services.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>SysOps admin manages policies cho <strong>many AWS member accounts</strong> trong <strong>AWS Organizations</strong></p></li><li><p>Administrators c√≥ access to <strong>root user credentials</strong> c·ªßa member accounts</p></li><li><p>Must <strong>prevent ALL teams (including admins) from using DynamoDB</strong></p></li><li><p>Must <strong>NOT affect</strong> ability to access <strong>other AWS services</strong></p></li><li><p>H·ªèi: <strong>solution to meet requirements?</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create a service control policy (SCP) in the management account to deny all DynamoDB actions. Apply the SCP to the root of the organization.</strong></p><ul><li><p><strong>SCPs l√† ONLY way</strong> to restrict <strong>root user</strong> trong member accounts</p></li><li><p>Deny DynamoDB actions at <strong>organization root level</strong> applies to <strong>all accounts v√† all principals</strong></p></li><li><p>SCPs ·∫£nh h∆∞·ªüng <strong>all users including root user</strong> - IAM policies kh√¥ng th·ªÉ l√†m ƒë∆∞·ª£c</p></li><li><p>Other AWS services <strong>kh√¥ng b·ªã ·∫£nh h∆∞·ªüng</strong> v√¨ SCP ch·ªâ deny DynamoDB</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>In all member accounts, configure IAM policies that deny access to all DynamoDB resources for all users, including the root user.</strong></p><ul><li><p><strong>IAM policies CANNOT restrict root user</strong> - root user bypasses IAM policies</p></li><li><p>Root user credentials v·∫´n c√≥ full DynamoDB access</p></li></ul><p></p><p>‚ùå <strong>In all member accounts, configure IAM policies that deny AmazonDynamoDBFullAccess to all users, including the root user.</strong></p><ul><li><p><strong>IAM policies kh√¥ng apply cho root user</strong></p></li><li><p>Cannot deny managed policy to root user via IAM</p></li></ul><p></p><p>‚ùå <strong>Remove the default service control policy (SCP) in the management account. Create a replacement SCP that includes a single statement that denies all DynamoDB actions.</strong></p><ul><li><p><strong>Removing default FullAWSAccess SCP</strong> s·∫Ω block ALL services by default</p></li><li><p>C·∫ßn ph·∫£i <strong>keep FullAWSAccess v√† ADD</strong> deny DynamoDB SCP b·∫°n c·∫°nh n√≥</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Root user\"</strong> + <strong>\"prevent access\"</strong> ‚Üí <strong>SCPs</strong> l√† only solution</p></li><li><p><strong>\"All teams including admins\"</strong> ‚Üí SCPs affect everyone including root</p></li><li><p><strong>IAM policies</strong> ‚Üí CANNOT restrict root user</p></li><li><p><strong>SCPs</strong> ‚Üí CAN restrict root user</p></li><li><p><strong>SCP strategy</strong> ‚Üí Keep FullAWSAccess, ADD deny-specific-service SCPs</p></li><li><p><strong>Organization root</strong> ‚Üí SCP applies to all OUs v√† accounts</p></li><li><p><strong>Root user restriction pattern</strong> ‚Üí SCPs only, IAM policies kh√¥ng work</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html\">Service control policies (SCPs)</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a service control policy (SCP) in the management account to deny all DynamoDB actions. Apply the SCP to the root of the organization</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>In all member accounts, configure IAM policies that deny access to all DynamoDB resources for all users, including the root user.</p>",
                "<p>Create a service control policy (SCP) in the management account to deny all DynamoDB actions. Apply the SCP to the root of the organization</p>",
                "<p>In all member accounts, configure IAM policies that deny AmazonDynamoDBFullAccess to all users, including the root user.</p>",
                "<p>Remove the default service control policy (SCP) in the management account. Create a replacement SCP that includes a single statement that denies all DynamoDB actions.</p>"
            ],
            "answersPos": "[3,0,2,1]",
            "pos": 32
        },
        {
            "attemptAnswerId": 329174,
            "questionId": 6398,
            "questionText": "<p>A SysOps administrator needs to create an Amazon S3 bucket as a resource in an AWS CloudFormation template. The bucket name must be randomly generated, and the bucket must be encrypted. Other resources in the template will reference the bucket.<br><br>Which CloudFormation resource definition should the SysOps administrator use to meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>C·∫ßn create <strong>S3 bucket</strong> trong <strong>CloudFormation template</strong></p></li><li><p>Bucket name must be <strong>randomly generated</strong> (kh√¥ng hardcode)</p></li><li><p>Bucket must be <strong>encrypted</strong></p></li><li><p><strong>Other resources</strong> trong template s·∫Ω reference bucket</p></li><li><p>H·ªèi: <strong>Which CloudFormation resource definition?</strong></p></li></ul><p></p><p>‚úÖ ƒê√°p √°n ƒë√∫ng:</p><pre><code class=\"language-yaml\">Bucket:\n  Type: AWS::S3::Bucket\n  Properties:\n    BucketEncryption:\n      ServerSideEncryptionConfiguration:\n        - ServerSideEncryptionByDefault:\n            SSEAlgorithm: AES256\n</code></pre><ul><li><p><strong>KH√îNG specify BucketName</strong> ‚Üí CloudFormation <strong>auto-generate random bucket name</strong></p></li><li><p><strong>BucketEncryption configured</strong> v·ªõi <strong>SSE-S3 (AES256)</strong></p></li><li><p>Other resources c√≥ th·ªÉ reference b·∫±ng <strong>!Ref Bucket</strong> ho·∫∑c <strong>!GetAtt</strong></p></li><li><p>Meets all requirements: random name + encryption + referenceable</p></li></ul><p></p><p><strong>C√°c ƒë√°p √°n sai:</strong></p><p>‚ùå</p><pre><code class=\"language-yaml\">Bucket:\n  Type: AWS::S3::Bucket\n  Properties:\n    BucketName: \"DOC-EXAMPLE-BUCKET\"\n    BucketEncryption:\n      ServerSideEncryptionConfiguration:\n        - ServerSideEncryptionByDefault:\n            SSEAlgorithm: AES256\n</code></pre><ul><li><p><strong>BucketName hardcoded</strong> \"DOC-EXAMPLE-BUCKET\" - KH√îNG random</p></li><li><p>C√≥ encryption nh∆∞ng vi ph·∫°m \"randomly generated\" requirement</p></li></ul><p></p><p>‚ùå</p><pre><code class=\"language-yaml\">Bucket:\n  Type: AWS::S3::Bucket\n  Properties:\n    BucketName: \"DOC-EXAMPLE-BUCKET\"\n</code></pre><ul><li><p><strong>BucketName hardcoded</strong> - kh√¥ng random</p></li><li><p><strong>KH√îNG c√≥ encryption</strong> configuration</p></li></ul><p></p><p>‚ùå</p><pre><code class=\"language-yaml\">Bucket:\n  Type: AWS::S3::Bucket\n  Properties:\n</code></pre><ul><li><p><strong>KH√îNG c√≥ encryption</strong> configuration</p></li><li><p>Ch·ªâ c√≥ auto-generated name nh∆∞ng thi·∫øu encryption requirement</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Randomly generated bucket name\"</strong> ‚Üí <strong>KH√îNG specify BucketName</strong> property</p></li><li><p><strong>CloudFormation auto-naming</strong> ‚Üí If property omitted, CF generates unique name</p></li><li><p><strong>S3 bucket encryption</strong> ‚Üí BucketEncryption v·ªõi SSEAlgorithm</p></li><li><p><strong>SSE-S3</strong> ‚Üí AES256 (AWS managed keys)</p></li><li><p><strong>Reference bucket</strong> ‚Üí Use <strong>!Ref LogicalID</strong> to get bucket name</p></li><li><p><strong>Hardcoded names</strong> ‚Üí Risk of conflicts, not recommended unless necessary</p></li><li><p><strong>CloudFormation best practice</strong> ‚Üí Let CF generate names for uniqueness</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-resource-s3-bucket.html\">AWS::S3::Bucket</a></p></li></ul>",
            "correctAnswer": [
                "<pre><code>Bucket:\n  Type: AWS::S3::Bucket\n  Properties:\n    BucketEncryption:\n      ServerSideEncryptionConfiguration:\n        - ServerSideEncryptionByDefault:\n            SSEAlgorithm: AES256</code></pre>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<pre><code>Bucket:\n  Type: AWS::S3::Bucket\n  Properties:\n    BucketName: \"DOC-EXAMPLE-BUCKET\"\n    BucketEncryption:\n      ServerSideEncryptionConfiguration:\n        - ServerSideEncryptionByDefault:\n            SSEAlgorithm: AES256</code></pre>",
                "<pre><code>Bucket:\n  Type: AWS::S3::Bucket\n  Properties:\n    BucketEncryption:\n      ServerSideEncryptionConfiguration:\n        - ServerSideEncryptionByDefault:\n            SSEAlgorithm: AES256</code></pre>",
                "<pre><code>Bucket:\n  Type: AWS::S3::Bucket\n  Properties:\n    BucketName: \"DOC-EXAMPLE-BUCKET\"</code></pre>",
                "<pre><code>Bucket:\n  Type: AWS::S3::Bucket\n  Properties:</code></pre>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 33
        },
        {
            "attemptAnswerId": 329175,
            "questionId": 6399,
            "questionText": "<p>A SysOps administrator manages a company's Amazon S3 buckets. The SysOps administrator has identified 5 GB of incomplete multipart uploads in an S3 bucket in the company's AWS account. The SysOps administrator needs to reduce the number of incomplete multipart upload objects in the S3 bucket.<br><br>Which solution will meet this requirement?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>SysOps admin manages <strong>S3 buckets</strong></p></li><li><p>ƒê√£ x√°c ƒë·ªãnh <strong>5 GB of incomplete multipart uploads</strong> trong S3 bucket</p></li><li><p>C·∫ßn <strong>reduce s·ªë l∆∞·ª£ng incomplete multipart upload objects</strong></p></li><li><p>H·ªèi: <strong>solution to meet requirement?</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create an S3 Lifecycle rule on the S3 bucket to delete expired markers or incomplete multipart uploads.</strong></p><ul><li><p><strong>S3 Lifecycle</strong> c√≥ action <strong>AbortIncompleteMultipartUpload</strong></p></li><li><p>Automatically delete incomplete multipart uploads sau <strong>specified number of days</strong></p></li><li><p><strong>Best practice</strong> cho cleanup incomplete uploads v√† save storage costs</p></li><li><p>Set once, runs automatically - no manual intervention</p></li></ul><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1764074877351-x9k10af3-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"420.29166666666663\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Require users that perform uploads of files into Amazon S3 to use the S3 TransferUtility.</strong></p><ul><li><p>TransferUtility gi√∫p reliable uploads nh∆∞ng <strong>KH√îNG cleanup existing</strong> incomplete uploads</p></li><li><p>Kh√¥ng gi·∫£i quy·∫øt 5 GB incomplete uploads ƒë√£ t·ªìn t·∫°i</p></li></ul><p></p><p>‚ùå <strong>Enable S3 Versioning on the S3 bucket that contains the incomplete multipart uploads.</strong></p><ul><li><p><strong>Versioning KH√îNG li√™n quan</strong> ƒë·∫øn incomplete multipart upload cleanup</p></li><li><p>Kh√¥ng address v·∫•n ƒë·ªÅ n√†y</p></li></ul><p></p><p>‚ùå <strong>Create an S3 Object Lambda Access Point to delete incomplete multipart uploads.</strong></p><ul><li><p><strong>Object Lambda</strong> for transforming objects trong khi retrieval</p></li><li><p><strong>KH√îNG ph·∫£i cleanup tool</strong>, wrong use case</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Incomplete multipart uploads\"</strong> ‚Üí <strong>S3 Lifecycle AbortIncompleteMultipartUpload</strong> action</p></li><li><p><strong>\"Gi·∫£m incomplete uploads\"</strong> ‚Üí Lifecycle rule l√† gi·∫£i ph√°p t·ª± ƒë·ªông h√≥a</p></li><li><p><strong>S3 Lifecycle actions</strong> ‚Üí Transition, Expiration, AbortIncompleteMultipartUpload</p></li><li><p><strong>T·ªëi ∆∞u storage</strong> ‚Üí Lifecycle rules ngƒÉn chi ph√≠ t·ª´ incomplete uploads</p></li><li><p><strong>TransferUtility</strong> ‚Üí ƒê·ªô tin c·∫≠y upload, kh√¥ng ph·∫£i c√¥ng c·ª• d·ªçn d·∫πp</p></li><li><p><strong>Object Lambda</strong> ‚Üí Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu, kh√¥ng ph·∫£i c√¥ng c·ª• qu·∫£n l√Ω</p></li><li><p><strong>Pattern d·ªçn d·∫πp</strong> ‚Üí Lifecycle rules cho b·∫£o tr√¨ t·ª± ƒë·ªông</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpu-abort-incomplete-mpu-lifecycle-config.html\">Configuring a bucket lifecycle configuration to delete incomplete multipart uploads</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html\">Uploading and copying objects using multipart upload</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an S3 Lifecycle rule on the S3 bucket to delete expired markers or incomplete multipart uploads.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an S3 Lifecycle rule on the S3 bucket to delete expired markers or incomplete multipart uploads.</p>",
                "<p>Require users that perform uploads of files into Amazon S3 to use the S3 TransferUtility.</p>",
                "<p>Enable S3 Versioning on the S3 bucket that contains the incomplete multipart uploads.</p>",
                "<p>Create an S3 Object Lambda Access Point to delete incomplete multipart uploads.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 34
        },
        {
            "attemptAnswerId": 329176,
            "questionId": 6400,
            "questionText": "<p>A company has a large on-premises tape backup solution. The company has started to use AWS Storage Gateway. The company created a Tape Gateway to replace the existing on-premises hardware. The company's backup engineer noticed that some of the backup jobs that were supposed to write to AWS failed to run because of a \"Not Enough Space\" error.<br><br>The company does not want these failures to happen again. The company also wants to consistently have enough tape available on AWS.<br><br>What is the MOST operationally efficient way for a SysOps administrator to meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company c√≥ <strong>large on-premises tape backup solution</strong></p></li><li><p>ƒê√£ t·∫°o <strong>Tape Gateway</strong> ƒë·ªÉ replace on-premises hardware</p></li><li><p>M·ªôt s·ªë <strong>backup jobs failed</strong> v·ªõi l·ªói <strong>\"Not Enough Space\"</strong></p></li><li><p>C·∫ßn prevent failures v√† <strong>consistently have enough tape available</strong> tr√™n AWS</p></li><li><p>Y√™u c·∫ßu: <strong>MOST operationally efficient way</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Configure tape auto-create on the Tape Gateway. In the auto-create settings, configure a minimum number of tapes, an appropriate barcode prefix, and a tape pool.</strong></p><ul><li><p><strong>Tape auto-create</strong> l√† <strong>built-in feature</strong> c·ªßa Tape Gateway</p></li><li><p>T·ª± ƒë·ªông t·∫°o tapes m·ªõi khi s·ªë l∆∞·ª£ng tapes available <strong>d∆∞·ªõi minimum threshold</strong></p></li><li><p>Configure m·ªôt l·∫ßn: minimum tapes, barcode prefix, tape pool</p></li><li><p><strong>Zero-touch automation</strong> - kh√¥ng c·∫ßn Lambda, scripts, ho·∫∑c manual intervention</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create an AWS Lambda function that runs on an hourly basis and checks how many tapes have available space. If the available tapes are below a certain threshold, provision more.</strong></p><ul><li><p>C·∫ßn vi·∫øt v√† maintain <strong>custom Lambda code</strong></p></li><li><p>Hourly check c√≥ th·ªÉ <strong>miss timing</strong> n·∫øu tapes h·∫øt gi·ªØa c√°c l·∫ßn check</p></li></ul><p></p><p>‚ùå <strong>Install the Amazon CloudWatch agent on the on-premises system. Push the log files to a CloudWatch log group. Create an AWS Lambda function that creates more tapes when the \"Not Enough Space\" error appears. Create a metric filter and a metric alarm that launches the Lambda function.</strong></p><ul><li><p><strong>Overly complex</strong>: CloudWatch agent + logs + Lambda + metric filter + alarm</p></li><li><p><strong>Reactive approach</strong> - ch·ªâ t·∫°o tapes sau khi error ƒë√£ x·∫£y ra</p></li></ul><p></p><p>‚ùå <strong>Create an additional Tape Gateway with its own set of tapes. Configure Amazon Simple Notification Service (Amazon SNS) to send a notification to the backup engineer if the tapes that are associated with the primary Tape Gateway do not have available space.</strong></p><ul><li><p>Th√™m <strong>infrastructure complexity</strong> v·ªõi second Tape Gateway</p></li><li><p>SNS notification v·∫´n c·∫ßn <strong>manual intervention</strong> t·ª´ engineer</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Not Enough Space\"</strong> + <strong>\"Tape Gateway\"</strong> ‚Üí <strong>Tape auto-create feature</strong></p></li><li><p><strong>\"MOST operationally efficient\"</strong> ‚Üí <strong>Native features</strong> &gt; Custom solutions</p></li><li><p><strong>Tape Gateway auto-create</strong> ‚Üí Ch·ªß ƒë·ªông, automatic tape provisioning</p></li><li><p><strong>Custom Lambda/monitoring</strong> ‚Üí Higher overhead, reactive approach</p></li><li><p><strong>Tape management</strong> ‚Üí Auto-create prevents capacity issues automatically</p></li><li><p><strong>Built-in features first</strong> ‚Üí Always prefer native capabilities over custom code</p></li><li><p><strong>Proactive vs Reactive</strong> ‚Üí Auto-create is proactive, monitoring/alerting is reactive</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/storagegateway/latest/tgw/CreateTapesAutomatically.html\">Creating Tapes Automatically</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/storagegateway/latest/tgw/managing-gateway-common.html\">Managing Your Tape Gateway</a></p></li></ul>",
            "correctAnswer": [
                "<p>Configure tape auto-create on the Tape Gateway. In the auto-create settings, configure a minimum number of tapes, an appropriate barcode prefix, and a tape pool.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an AWS Lambda function that runs on an hourly basis and checks how many tapes have available space. If the available tapes are below a certain threshold, provision more.</p>",
                "<p>Install the Amazon CloudWatch agent on the on-premises system. Push the log files to a CloudWatch log group. Create an AWS Lambda function that creates more tapes when the \"Not Enough Space\" error appears. Create a metric filter and a metric alarm that launches the Lambda function.</p>",
                "<p>Create an additional Tape Gateway with its own set of tapes. Configure Amazon Simple Notification Service (Amazon SNS) to send a notification to the backup engineer if the tapes that are associated with the primary Tape Gateway do not have available space.</p>",
                "<p>Configure tape auto-create on the Tape Gateway. In the auto-create settings, configure a minimum number of tapes, an appropriate barcode prefix, and a tape pool.</p>"
            ],
            "answersPos": "[1,0,2,3]",
            "pos": 35
        },
        {
            "attemptAnswerId": 329177,
            "questionId": 6401,
            "questionText": "<p>A company has an encrypted Amazon S3 bucket that is hosted in the ap-southeast-2 Region. Users from the eu-west-2 Region access the S3 bucket over the internet. The users from eu-west-2 need faster transfers to and from the S3 bucket for large files.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company c√≥ <strong>encrypted S3 bucket</strong> trong <strong>ap-southeast-2 Region</strong></p></li><li><p>Users t·ª´ <strong>eu-west-2 Region</strong> access bucket qua <strong>internet</strong></p></li><li><p>C·∫ßn <strong>faster transfers</strong> cho <strong>large files</strong> gi·ªØa eu-west-2 v√† ap-southeast-2</p></li><li><p>H·ªèi: <strong>gi·∫£i ph√°p ƒë√°p ·ª©ng y√™u c·∫ßu?</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Enable S3 Transfer Acceleration on the S3 bucket. Use the new s3-accelerate endpoint's domain name for access.</strong></p><ul><li><p><strong>S3 Transfer Acceleration</strong> s·ª≠ d·ª•ng <strong>CloudFront edge locations</strong> ƒë·ªÉ accelerate transfers</p></li><li><p>Optimize routing qua <strong>AWS backbone network</strong> thay v√¨ public internet</p></li><li><p>ƒê·∫∑c bi·ªát hi·ªáu qu·∫£ cho <strong>long-distance transfers</strong> v√† <strong>large files</strong></p></li><li><p>Ch·ªâ c·∫ßn enable feature v√† change endpoint - kh√¥ng c·∫ßn infrastructure changes</p></li></ul><p></p><p><em>Architecture</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1764076077634-qbh2an1l-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"232.29166666666666\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Reduce the length of the S3 bucket prefixes within the S3 bucket.</strong></p><ul><li><p><strong>Prefix length KH√îNG ·∫£nh h∆∞·ªüng</strong> transfer speed</p></li><li><p>Ch·ªâ li√™n quan ƒë·∫øn object organization, kh√¥ng ph·∫£i performance</p></li></ul><p></p><p>‚ùå <strong>Change the server-side encryption on the S3 bucket from AES to RSA.</strong></p><ul><li><p><strong>Encryption type KH√îNG ·∫£nh h∆∞·ªüng</strong> transfer speed ƒë√°ng k·ªÉ</p></li><li><p>RSA c≈©ng kh√¥ng ph·∫£i encryption option cho S3 server-side encryption</p></li></ul><p></p><p>‚ùå <strong>Create a new S3 bucket that has an identical name in eu-west-2. Use the new S3 bucket endpoint's domain name for access.</strong></p><ul><li><p><strong>S3 bucket names ph·∫£i globally unique</strong> - kh√¥ng th·ªÉ t·∫°o bucket c√πng t√™n</p></li><li><p>K·ªÉ c·∫£ c√≥ th·ªÉ, v·∫´n c·∫ßn sync data gi·ªØa regions</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Cross-region transfers\"</strong> + <strong>\"large files\"</strong> ‚Üí <strong>S3 Transfer Acceleration</strong></p></li><li><p><strong>\"Faster transfers\"</strong> + <strong>\"long distance\"</strong> ‚Üí Transfer Acceleration via CloudFront edges</p></li><li><p><strong>S3 Transfer Acceleration</strong> ‚Üí Uses edge locations, optimizes routing</p></li><li><p><strong>When to use</strong> ‚Üí Long-distance uploads/downloads, large files, poor network conditions</p></li><li><p><strong>Prefix optimization</strong> ‚Üí For request rate performance, kh√¥ng ph·∫£i transfer speed</p></li><li><p><strong>Encryption type</strong> ‚Üí Security feature, minimal impact on transfer speed</p></li><li><p><strong>Cross-region pattern</strong> ‚Üí Transfer Acceleration &gt; Direct internet transfer</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/transfer-acceleration.html\">Configuring fast, secure file transfers using Amazon S3 Transfer Acceleration</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/s3/transfer-acceleration/\">Amazon S3 Transfer Acceleration</a></p></li></ul>",
            "correctAnswer": [
                "<p>Enable S3 Transfer Acceleration on the S3 bucket. Use the new s3-accelerate endpoint's domain name for access.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Reduce the length of the S3 bucket prefixes within the S3 bucket.</p>",
                "<p>Change the server-side encryption on the S3 bucket from AES to RSA.</p>",
                "<p>Create a new S3 bucket that has an identical name in eu-west-2. Use the new S3 bucket endpoint's domain name for access.</p>",
                "<p>Enable S3 Transfer Acceleration on the S3 bucket. Use the new s3-accelerate endpoint's domain name for access.</p>"
            ],
            "answersPos": "[3,1,2,0]",
            "pos": 36
        },
        {
            "attemptAnswerId": 329178,
            "questionId": 6402,
            "questionText": "<p>A company runs an application on Amazon EC2 instances behind an Application Load Balancer. The EC2 instances are in an Auto Scaling group. The application sometimes becomes slow and unresponsive. Amazon CloudWatch metrics show that some EC2 instances are experiencing high CPU load.<br><br>A SysOps administrator needs to create a CloudWatch dashboard that can automatically display CPU metrics of all the EC2 instances. The metrics must include new instances that are launched as part of the Auto Scaling group.<br><br>What should the SysOps administrator do to meet these requirements in the MOST operationally efficient way?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Application ch·∫°y tr√™n <strong>EC2 instances</strong> behind <strong>ALB</strong> trong <strong>Auto Scaling group</strong></p></li><li><p>Application ƒë√¥i khi <strong>slow v√† unresponsive</strong> do <strong>high CPU load</strong></p></li><li><p>C·∫ßn t·∫°o <strong>CloudWatch dashboard</strong> t·ª± ƒë·ªông display <strong>CPU metrics c·ªßa ALL EC2 instances</strong></p></li><li><p>Dashboard ph·∫£i <strong>include new instances</strong> ƒë∆∞·ª£c launch t·ª´ Auto Scaling group</p></li><li><p>Y√™u c·∫ßu: <strong>MOST operationally efficient way</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Use CloudWatch metrics explorer to filter by the aws:autoscaling:groupName tag and to create a visualization for the CPUUtilization metric. Add the visualization to a CloudWatch dashboard.</strong></p><ul><li><p><strong>Auto Scaling group t·ª± ƒë·ªông tag instances</strong> v·ªõi <strong>aws:autoscaling:groupName</strong> tag</p></li><li><p><strong>Metrics explorer filter by tag</strong> t·ª± ƒë·ªông include t·∫•t c·∫£ instances trong ASG</p></li><li><p><strong>New instances automatically included</strong> v√¨ ƒë∆∞·ª£c tag khi launch</p></li><li><p><strong>No custom code</strong> - fully managed solution, zero maintenance</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a CloudWatch dashboard. Use activity notifications from the Auto Scaling group to invoke a custom AWS Lambda function. Use the Lambda function to update the CloudWatch dashboard to monitor the CPUUtilization metric for the new instance IDs.</strong></p><ul><li><p>C·∫ßn vi·∫øt v√† maintain <strong>custom Lambda function</strong></p></li><li><p><strong>Operational overhead</strong> cao v·ªõi notifications + Lambda + dashboard updates</p></li></ul><p></p><p>‚ùå <strong>Create a CloudWatch dashboard. Run a custom script on each EC2 instance to stream the CPU utilization to the dashboard.</strong></p><ul><li><p><strong>Custom scripts tr√™n T·ª™NG instance</strong> = very high overhead</p></li><li><p>Ph·∫£i deploy scripts, maintain, v√† ensure ch·∫°y tr√™n new instances</p></li></ul><p></p><p>‚ùå <strong>Use CloudWatch metrics explorer to filter by instance state and to create a visualization for the CPUUtilization metric. Add the visualization to a CloudWatch dashboard.</strong></p><ul><li><p>Filter by instance state s·∫Ω show <strong>ALL running instances</strong>, kh√¥ng ch·ªâ ASG instances</p></li><li><p><strong>Kh√¥ng specific</strong> cho Auto Scaling group c·ª• th·ªÉ</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Auto Scaling group\"</strong> + <strong>\"automatic monitoring\"</strong> ‚Üí <strong>Filter by ASG tag</strong></p></li><li><p><strong>\"Include new instances automatically\"</strong> ‚Üí <strong>Tag-based filtering</strong></p></li><li><p><strong>Auto Scaling tags</strong> ‚Üí aws:autoscaling:groupName automatically applied</p></li><li><p><strong>Metrics explorer</strong> ‚Üí Dynamic metric selection, automatically includes matching resources</p></li><li><p><strong>CloudWatch dashboard best practice</strong> ‚Üí Tag-based filtering &gt; Instance ID hardcoding</p></li><li><p><strong>Custom Lambda/scripts</strong> ‚Üí High overhead, avoid when native solution exists</p></li><li><p><strong>Dynamic monitoring pattern</strong> ‚Üí Tag filters automatically scale with infrastructure</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Metrics-Explorer.html\">Using CloudWatch metrics explorer</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-tagging.html\">Tagging Auto Scaling groups and instances</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use CloudWatch metrics explorer to filter by the aws:autoscaling:groupName tag and to create a visualization for the CPUUtilization metric. Add the visualization to a CloudWatch dashboard.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a CloudWatch dashboard. Use activity notifications from the Auto Scaling group to invoke a custom AWS Lambda function. Use the Lambda function to update the CloudWatch dashboard to monitor the CPUUtilization metric for the new instance IDs.</p>",
                "<p>Create a CloudWatch dashboard. Run a custom script on each EC2 instance to stream the CPU utilization to the dashboard.</p>",
                "<p>Use CloudWatch metrics explorer to filter by the aws:autoscaling:groupName tag and to create a visualization for the CPUUtilization metric. Add the visualization to a CloudWatch dashboard.</p>",
                "<p>Use CloudWatch metrics explorer to filter by instance state and to create a visualization for the CPUUtilization metric. Add the visualization to a CloudWatch dashboard.</p>"
            ],
            "answersPos": "[1,0,2,3]",
            "pos": 37
        },
        {
            "attemptAnswerId": 329179,
            "questionId": 6403,
            "questionText": "<p>A SysOps administrator needs to deploy an application in multiple AWS Regions. The SysOps administrator must implement a solution that routes users to the Region with the lowest latency. In case of failure, the solution must automatically route requests to a Region with a healthy instance of the application. The company needs a solution with the shortest time to failover.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>C·∫ßn deploy application trong <strong>multiple AWS Regions</strong></p></li><li><p>Route users ƒë·∫øn <strong>Region with lowest latency</strong></p></li><li><p><strong>Automatic failover</strong> ƒë·∫øn healthy Region n·∫øu c√≥ failure</p></li><li><p>Y√™u c·∫ßu: <strong>shortest time to failover</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create an AWS Global Accelerator standard accelerator. Create an endpoint group for each Region. Add a listener to the accelerator. Associate the endpoint group with the listener.</strong></p><ul><li><p><strong>Global Accelerator</strong> s·ª≠ d·ª•ng <strong>AWS global network</strong> v√† <strong>anycast IPs</strong> ƒë·ªÉ optimize routing</p></li><li><p><strong>Instant health-based failover</strong> (trong seconds) - KH√îNG ph·ª• thu·ªôc DNS TTL</p></li><li><p>Routes traffic ƒë·∫øn <strong>optimal endpoint</strong> d·ª±a tr√™n health, geography, v√† routing policies</p></li><li><p><strong>Shortest failover time</strong> v√¨ kh√¥ng c√≥ DNS caching delays</p></li></ul><p></p><p><em>Tham kh·∫£o</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1764076782784-20d2rc0c-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"630.5416666666666\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create Amazon Route 53 A records that have the same name for each endpoint. Use a latency routing policy. Associate a health check with each record.</strong></p><ul><li><p>Latency routing ƒë√∫ng cho lowest latency NH∆ØNG <strong>failover ph·ª• thu·ªôc DNS TTL</strong></p></li><li><p>DNS caching delays l√†m <strong>failover ch·∫≠m h∆°n</strong> Global Accelerator</p></li></ul><p></p><p>‚ùå <strong>Create Amazon Route 53 A records that have the same name for each endpoint. Use a failover routing policy. Associate a health check with each record.</strong></p><ul><li><p><strong>Failover routing</strong> l√† primary/secondary pattern</p></li><li><p><strong>KH√îNG optimize</strong> cho lowest latency across multiple regions</p></li></ul><p></p><p>‚ùå <strong>Create Amazon Route 53 A records that have the same name for each endpoint. Use a geolocation routing policy. Associate a health check with each record.</strong></p><ul><li><p><strong>Geolocation routing</strong> based on user's geographic location</p></li><li><p><strong>KH√îNG guarantee lowest latency</strong> - c√≥ th·ªÉ route ƒë·∫øn region xa h∆°n</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Shortest time to failover\"</strong> ‚Üí <strong>AWS Global Accelerator</strong> over Route 53</p></li><li><p><strong>\"Lowest latency\"</strong> + <strong>\"fast failover\"</strong> ‚Üí Global Accelerator</p></li><li><p><strong>Global Accelerator</strong> ‚Üí Instant failover (seconds), no DNS dependency</p></li><li><p><strong>Route 53 latency routing</strong> ‚Üí Good for latency, nh∆∞ng failover c√≥ DNS TTL delay</p></li><li><p><strong>Failover routing</strong> ‚Üí Primary/secondary only, kh√¥ng multi-region latency-based</p></li><li><p><strong>Geolocation routing</strong> ‚Üí Geographic-based, kh√¥ng ph·∫£i latency-based</p></li><li><p><strong>Fastest failover pattern</strong> ‚Üí Global Accelerator &gt; Route 53 (do DNS caching)</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/global-accelerator/latest/dg/what-is-global-accelerator.html\">What is AWS Global Accelerator?</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/global-accelerator/latest/dg/introduction-how-it-works.html\">How AWS Global Accelerator works</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an AWS Global Accelerator standard accelerator. Create an endpoint group for each Region. Add a listener to the accelerator. Associate the endpoint group with the listener.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create Amazon Route 53 A records that have the same name for each endpoint. Use a latency routing policy. Associate a health check with each record.</p>",
                "<p>Create Amazon Route 53 A records that have the same name for each endpoint. Use a failover routing policy. Associate a health check with each record.</p>",
                "<p>Create an AWS Global Accelerator standard accelerator. Create an endpoint group for each Region. Add a listener to the accelerator. Associate the endpoint group with the listener.</p>",
                "<p>Create Amazon Route 53 A records that have the same name for each endpoint. Use a geolocation routing policy. Associate a health check with each record.</p>"
            ],
            "answersPos": "[1,2,0,3]",
            "pos": 38
        },
        {
            "attemptAnswerId": 329180,
            "questionId": 6404,
            "questionText": "<p>A company has an application that collects notifications from thousands of alarm systems. The notifications include alarm notifications and information notifications. The information notifications include the system arming processes, disarming processes, and sensor status.<br><br>All notifications are kept as messages in an Amazon Simple Queue Service (Amazon SQS) queue. Amazon EC2 instances that are in an Auto Scaling group process the messages. A SysOps administrator needs to implement a solution that prioritizes alarm notifications over information notifications.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Application thu th·∫≠p <strong>notifications t·ª´ thousands of alarm systems</strong></p></li><li><p>C√≥ 2 lo·∫°i: <strong>alarm notifications</strong> (quan tr·ªçng) v√† <strong>information notifications</strong> (arming, disarming, sensor status)</p></li><li><p>T·∫•t c·∫£ notifications trong <strong>1 SQS queue</strong></p></li><li><p><strong>EC2 instances trong Auto Scaling group</strong> process messages</p></li><li><p>C·∫ßn <strong>∆∞u ti√™n alarm notifications h∆°n information notifications</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create a queue for alarm notifications and a queue for information notifications. Update the application to collect messages from the alarm notifications queue first.</strong></p><ul><li><p><strong>SQS kh√¥ng c√≥ native priority support</strong> - ph·∫£i d√πng multiple queues</p></li><li><p><strong>2 separate queues</strong>: 1 cho alarm notifications (high priority), 1 cho information (low priority)</p></li><li><p>Application <strong>poll alarm queue first</strong>, ch·ªâ poll info queue khi alarm queue empty</p></li><li><p><strong>Standard pattern</strong> cho message prioritization v·ªõi SQS</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Adjust the Auto Scaling group to scale faster when a high number of messages is in the queue.</strong></p><ul><li><p>Scale faster ch·ªâ tƒÉng processing capacity</p></li><li><p><strong>KH√îNG gi·∫£i quy·∫øt prioritization</strong> - messages v·∫´n processed theo FIFO order</p></li></ul><p></p><p>‚ùå <strong>Use the Amazon Simple Notification Service (Amazon SNS) fanout feature with Amazon SQS to send the notifications in parallel to all the EC2 instances.</strong></p><ul><li><p>SNS fanout d√πng ƒë·ªÉ distribute messages song song</p></li><li><p><strong>KH√îNG implement priority</strong> - t·∫•t c·∫£ messages treated equally</p></li></ul><p></p><p>‚ùå <strong>Add an Amazon DynamoDB stream to accelerate the message processing.</strong></p><ul><li><p>DynamoDB stream <strong>kh√¥ng li√™n quan</strong> ƒë·∫øn SQS message prioritization</p></li><li><p>Kh√¥ng address priority requirement</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"SQS priority\"</strong> ‚Üí <strong>Multiple queues</strong> (SQS kh√¥ng c√≥ native priority)</p></li><li><p><strong>\"Prioritize message types\"</strong> ‚Üí Separate queues + application polling order</p></li><li><p><strong>SQS limitations</strong> ‚Üí No message priority, no message filtering (use multiple queues)</p></li><li><p><strong>Priority pattern</strong>: High-priority queue ‚Üí Low-priority queue ‚Üí Polling order</p></li><li><p><strong>SNS fanout</strong> ‚Üí Distribution, kh√¥ng ph·∫£i prioritization</p></li><li><p><strong>Auto Scaling</strong> ‚Üí Capacity, kh√¥ng ph·∫£i message ordering</p></li><li><p><strong>Message priority best practice</strong> ‚Üí Separate queues cho t·ª´ng priority level</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/sqs/features/\">Amazon SQS message priority</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-best-practices.html\">Best practices for Amazon SQS</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a queue for alarm notifications and a queue for information notifications. Update the application to collect messages from the alarm notifications queue first.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Adjust the Auto Scaling group to scale faster when a high number of messages is in the queue.</p>",
                "<p>Use the Amazon Simple Notification Service (Amazon SNS) fanout feature with Amazon SQS to send the notifications in parallel to all the C2 instances</p>",
                "<p>Add an Amazon DynamoDB stream to accelerate the message processing</p>",
                "<p>Create a queue for alarm notifications and a queue for information notifications. Update the application to collect messages from the alarm notifications queue first.</p>"
            ],
            "answersPos": "[3,0,2,1]",
            "pos": 39
        },
        {
            "attemptAnswerId": 329181,
            "questionId": 6405,
            "questionText": "<p>A company's SysOps administrator manages a fleet of hundreds of Amazon EC2 instances that run Windows-based workloads and Linux-based workloads. Each EC2 instance has a tag that identifies its operating system. All the EC2 instances run AWS Systems Manager Session Manager.<br><br>A zero-day vulnerability is reported, and no patches are available. The company's security team provides code for all the relevant operating systems to reduce the risk of the vulnerability. The SysOps administrator needs to implement the code on the EC2 instances and must provide a report that shows that the code has successfully run on all the instances.<br><br>What should the SysOps administrator do to meet these requirements as quickly as possible?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Qu·∫£n l√Ω <strong>h√†ng trƒÉm EC2 instances</strong> ch·∫°y Windows v√† Linux</p></li><li><p>M·ªói instance c√≥ <strong>tag ph√¢n lo·∫°i OS</strong></p></li><li><p>ƒê√£ c√†i <strong>Systems Manager Session Manager</strong></p></li><li><p>Ph√°t hi·ªán <strong>l·ªó h·ªïng zero-day</strong>, ch∆∞a c√≥ patch</p></li><li><p>Security team ƒë∆∞a <strong>code kh·∫©n c·∫•p</strong> ƒë·ªÉ gi·∫£m r·ªßi ro</p></li><li><p>C·∫ßn ch·∫°y code tr√™n t·∫•t c·∫£ instances v√† <strong>b√°o c√°o k·∫øt qu·∫£ th·ª±c thi</strong></p></li><li><p>Y√™u c·∫ßu: l√†m <strong>nhanh nh·∫•t c√≥ th·ªÉ</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Use Systems Manager Run Command. Choose either the AWS-RunShellScript document or the AWS-RunPowerShellScript document. Configure Run Command with the code from the security team. Specify the operating system tag in the Targets parameter. Run the command. Provide the command history's evidence to the security team.</strong></p><ul><li><p><strong>Run Command</strong> ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ th·ª±c thi l·ªánh <strong>quy m√¥ l·ªõn (at scale)</strong> tr√™n nhi·ªÅu instances</p></li><li><p><strong>Nh·∫Øm m·ª•c ti√™u theo tag (tag-based targeting)</strong> - ch·∫°y script kh√°c nhau cho Windows vs Linux d·ª±a tr√™n OS tag</p></li><li><p><strong>L·ªãch s·ª≠ l·ªánh t√≠ch h·ª£p s·∫µn (built-in command history)</strong> cung c·∫•p b·∫±ng ch·ª©ng th·ª±c thi v√† k·∫øt qu·∫£</p></li><li><p><strong>Nhanh nh·∫•t</strong> - t·ª± ƒë·ªông th·ª±c thi tr√™n h√†ng trƒÉm instances c√πng l√∫c</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create an AWS Lambda function that connects to the EC2 instances through Session Manager. Configure the Lambda function to identify the operating system, run the code from the security team, and return the results to an Amazon RDS DB instance. Query the DB instance for the results. Provide the results as evidence to the security team.</strong></p><ul><li><p><strong>Qu√° ph·ª©c t·∫°p (overly complex)</strong> - Lambda + Session Manager + RDS kh√¥ng c·∫ßn thi·∫øt</p></li><li><p>C·∫ßn vi·∫øt custom code v√† thi·∫øt l·∫≠p h·∫° t·∫ßng</p></li></ul><p></p><p>‚ùå <strong>Log on to each EC2 instance. Run the code from the security team on each EC2 instance. Copy and paste the results of each run into a single spreadsheet. Provide the spreadsheet as evidence to the security team.</strong></p><ul><li><p><strong>Manual work</strong> cho hundreds of instances - kh√¥ng quick</p></li><li><p>D·ªÖ sai s√≥t v√† t·ªën th·ªùi gian</p></li></ul><p></p><p>‚ùå <strong>Update the launch templates of the EC2 instances to include the code from the security team in the user data. Relaunch the EC2 instances by using the updated launch templates. Retrieve the EC2 instance logs of each instance. Provide the EC2 instance logs as evidence to the security team.</strong></p><ul><li><p><strong>Y√™u c·∫ßu kh·ªüi ƒë·ªông l·∫°i (requires relaunch)</strong> - g√¢y gi√°n ƒëo·∫°n v·ªõi downtime</p></li><li><p>User data ch·ªâ ch·∫°y khi kh·ªüi ƒë·ªông, kh√¥ng ph·∫£i gi·∫£i ph√°p nhanh nh·∫•t</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Hundreds of instances\" + \"quickly\"</strong> ‚Üí Systems Manager Run Command</p></li><li><p><strong>\"Tag-based targeting\"</strong> ‚Üí Run Command h·ªó tr·ª£ nh·∫Øm m·ª•c ti√™u theo tags</p></li><li><p><strong>\"Different OS types\"</strong> ‚Üí AWS-RunShellScript (Linux), AWS-RunPowerShellScript (Windows)</p></li><li><p><strong>\"Provide report/evidence\"</strong> ‚Üí Command history t√≠ch h·ª£p s·∫µn v·ªõi Run Command</p></li><li><p><strong>Run Command</strong> ‚Üí T·ª± ƒë·ªông h√≥a quy m√¥ l·ªõn, th·ª±c thi song song, b√°o c√°o t√≠ch h·ª£p</p></li><li><p><strong>Session Manager</strong> ‚Üí Phi√™n t∆∞∆°ng t√°c (interactive sessions), kh√¥ng ph·∫£i c√¥ng c·ª• t·ª± ƒë·ªông h√≥a</p></li><li><p><strong>M√¥ h√¨nh th·ª±c thi quy m√¥ l·ªõn (at-scale execution pattern)</strong> ‚Üí Run Command &gt; Lambda &gt; Manual login</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/run-command.html\">AWS Systems Manager Run Command</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use Systems Manager Run Command. Choose either the AWS-RunShellScript document or the AWS-RunPowerShellScript document. Configure Run Command with the code from the security team. Specify the operating system tag in the Targets parameter. Run the command. Provide the command history's evidence to the security team.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use Systems Manager Run Command. Choose either the AWS-RunShellScript document or the AWS-RunPowerShellScript document. Configure Run Command with the code from the security team. Specify the operating system tag in the Targets parameter. Run the command. Provide the command history's evidence to the security team.</p>",
                "<p>Create an AWS Lambda function that connects to the EC2 instances through Session Manager. Configure the Lambda function to identify the operating system, run the code from the security team, and return the results to an Amazon RDS DB instance. Query the DB instance for the results. Provide the results as evidence to the security team.</p>",
                "<p>Log on to each EC2 instance. Run the code from the security team on each EC2 instance. Copy and paste the results of each run into a single spreadsheet. Provide the spreadsheet as evidence to the security team.</p>",
                "<p>Update the launch templates of the EC2 instances to include the code from the security team in the user data. Relaunch the EC2 instances by using the updated launch templates. Retrieve the EC2 instance logs of each instance. Provide the EC2 instance logs as evidence to the security team.</p>"
            ],
            "answersPos": "[1,0,3,2]",
            "pos": 40
        },
        {
            "attemptAnswerId": 329182,
            "questionId": 6406,
            "questionText": "<p>A company needs to deploy instances of an application and associated infrastructure to multiple AWS Regions. The company wants to use a single AWS CloudFormation template to achieve this goal. The company uses AWS Organizations and wants to administer and run this template from a central administration account.<br><br>What should a SysOps administrator do to meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>C·∫ßn deploy <strong>application v√† infrastructure</strong> ƒë·∫øn <strong>nhi·ªÅu AWS Regions</strong></p></li><li><p>Mu·ªën d√πng <strong>single CloudFormation template</strong></p></li><li><p>C√¥ng ty s·ª≠ d·ª•ng <strong>AWS Organizations</strong></p></li><li><p>Mu·ªën qu·∫£n l√Ω v√† ch·∫°y template t·ª´ <strong>central administration account</strong></p></li><li><p>Y√™u c·∫ßu: deploy t·ª´ central account ƒë·∫øn nhi·ªÅu accounts v√† Regions</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create a CloudFormation stack set that includes service-managed permissions. Deploy the stack set into the required accounts and Regions from the central administration account.</strong></p><ul><li><p><strong>StackSets</strong> ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ deploy CloudFormation stacks ƒë·∫øn <strong>nhi·ªÅu accounts v√† Regions</strong> t·ª´ single template</p></li><li><p><strong>Service-managed permissions</strong> t√≠ch h·ª£p v·ªõi <strong>AWS Organizations</strong>, t·ª± ƒë·ªông qu·∫£n l√Ω quy·ªÅn gi·ªØa c√°c accounts</p></li><li><p>Deploy t·ª´ <strong>central administration account</strong> ƒë·∫øn target accounts v√† Regions m·ªôt c√°ch t·∫≠p trung</p></li><li><p>ƒê√°p ·ª©ng ch√≠nh x√°c y√™u c·∫ßu: single template + multi-account + multi-region + Organizations integration</p></li></ul><p></p><p><em>Architecture</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1764465000339-vwbu4wyf-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"448.16666666666663\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a CloudFormation template that is stored in Amazon S3. Configure Cross-Region Replication (CRR) on the S3 bucket. Reference the required accounts and remote Regions in the input template parameters.</strong></p><ul><li><p><strong>Cross-Region Replication</strong> ch·ªâ replicate template file, kh√¥ng t·ª± ƒë·ªông deploy stacks</p></li><li><p>V·∫´n ph·∫£i manually deploy template ·ªü t·ª´ng Region v√† account</p></li><li><p>Kh√¥ng c√≥ kh·∫£ nƒÉng centralized deployment</p></li></ul><p></p><p>‚ùå <strong>In the central administration account, create a CloudFormation primary template that loads CloudFormation nested stacks from Amazon S3 buckets in the target Regions.</strong></p><ul><li><p><strong>Nested stacks</strong> ch·ªâ ho·∫°t ƒë·ªông trong <strong>single account v√† single Region</strong></p></li><li><p>Kh√¥ng h·ªó tr·ª£ cross-account ho·∫∑c cross-region deployment</p></li><li><p>Kh√¥ng ph√π h·ª£p v·ªõi y√™u c·∫ßu multi-account, multi-region</p></li></ul><p></p><p>‚ùå <strong>Create CloudFormation nested stacks by using a primary template in the central administration account. Configure the required accounts and Regions for deployment of the nested stacks.</strong></p><ul><li><p><strong>Nested stacks kh√¥ng h·ªó tr·ª£</strong> deploy ƒë·∫øn multiple accounts ho·∫∑c Regions</p></li><li><p>CloudFormation nested stacks ch·ªâ d√πng ƒë·ªÉ t·ªï ch·ª©c template ph·ª©c t·∫°p trong c√πng m·ªôt stack</p></li><li><p>Sai approach cho use case n√†y</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Multiple accounts + multiple Regions + Organizations\"</strong> ‚Üí CloudFormation StackSets</p></li><li><p><strong>\"Central administration account\"</strong> ‚Üí StackSets v·ªõi service-managed permissions</p></li><li><p><strong>\"AWS Organizations\"</strong> ‚Üí Service-managed permissions (kh√¥ng c·∫ßn self-managed permissions)</p></li><li><p><strong>StackSets</strong> ‚Üí Multi-account, multi-region deployment t·ª´ single template</p></li><li><p><strong>Nested stacks</strong> ‚Üí T·ªï ch·ª©c template ph·ª©c t·∫°p trong single account/Region, kh√¥ng ph·∫£i cross-account</p></li><li><p><strong>Cross-Region Replication</strong> ‚Üí Replicate data, kh√¥ng ph·∫£i deployment automation</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/what-is-cfnstacksets.html\">AWS CloudFormation StackSets</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/security-ir/latest/userguide/working-with-stacksets.html\">Working with AWS CloudFormation StackSets</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-orgs-associate-stackset-with-org.html\">Service-managed permissions for StackSets</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a CloudFormation stack set that includes service-managed permissions. Deploy the stack set into the required accounts and Regions from the central administration account.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a CloudFormation template that is stored in Amazon S3. Configure Cross-Region Replication (CRR) on the S3 bucket. Reference the required accounts and remote Regions in the input template parameters.</p>",
                "<p>In the central administration account, create a CloudFormation primary template that loads CloudFormation nested stacks from Amazon S3 buckets in the target Regions.</p>",
                "<p>Create CloudFormation nested stacks by using a primary template in the central administration account. Configure the required accounts and Regions for deployment of the nested stacks.</p>",
                "<p>Create a CloudFormation stack set that includes service-managed permissions. Deploy the stack set into the required accounts and Regions from the central administration account.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 41
        },
        {
            "attemptAnswerId": 329183,
            "questionId": 6407,
            "questionText": "<p>A company is trying to connect two applications. One application runs in an on-premises data center that has a hostname of host1.onprem private. The other application runs on an Amazon EC2 instance that has a hostname of host1.awscloud private. An AWS Site-to-Site VPN connection is in place between the on-premises network and AWS.<br><br>The application that runs in the data center tries to connect to the application that runs on the EC2 instance, but DNS resolution fails. A SysOps administrator must implement DNS resolution between on-premises and AWS resources.<br><br>Which solution allows the on-premises application to resolve the EC2 instance hostname?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Hai applications: m·ªôt ch·∫°y <strong>on-premises</strong> (hostname: host1.onprem.private), m·ªôt ch·∫°y <strong>EC2</strong> (hostname: host1.awscloud.private)</p></li><li><p>ƒê√£ c√≥ <strong>Site-to-Site VPN</strong> k·∫øt n·ªëi on-premises v√† AWS</p></li><li><p><strong>On-premises application</strong> c·∫ßn connect ƒë·∫øn <strong>EC2 application</strong> nh∆∞ng <strong>DNS resolution fails</strong></p></li><li><p>Y√™u c·∫ßu: cho ph√©p <strong>on-premises resolve EC2 hostname</strong> (awscloud.private)</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Set up an Amazon Route 53 inbound resolver endpoint. Associate the resolver with the VPC of the EC2 instance. Configure the on-premises DNS resolver to forward awscloud.private DNS queries to the inbound resolver endpoint.</strong></p><ul><li><p><strong>Inbound resolver</strong> cho ph√©p <strong>on-premises DNS queries</strong> v√†o AWS ƒë·ªÉ resolve <strong>AWS hostnames</strong></p></li><li><p>On-premises mu·ªën resolve <strong>awscloud.private</strong> (EC2 hostname) ‚Üí c·∫ßn <strong>inbound endpoint</strong></p></li><li><p>C·∫•u h√¨nh on-premises DNS forward queries cho <strong>awscloud.private</strong> ƒë·∫øn inbound endpoint</p></li><li><p>Route 53 Resolver trong VPC s·∫Ω resolve hostname c·ªßa EC2 instance</p></li></ul><p></p><p><em>Architecture tham kh·∫£o</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1764465320706-t7ctqkbs-image.png\" alt=\"\" title=\"\" width=\"762\" height=\"614.4815625\" style=\"max-width: 762px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Set up an Amazon Route 53 inbound resolver endpoint with a forwarding rule for the onprem.private hosted zone. Associate the resolver with the VPC of the EC2 instance. Configure the on-premises DNS resolver to forward onprem.private DNS queries to the inbound resolver endpoint.</strong></p><ul><li><p><strong>Inbound endpoint ƒë√∫ng</strong> nh∆∞ng <strong>forwarding rule sai direction</strong></p></li><li><p>Forwarding rule cho onprem.private kh√¥ng li√™n quan, v√¨ on-premises ƒëang c·∫ßn resolve <strong>awscloud.private</strong></p></li><li><p>On-premises ƒë√£ t·ª± resolve ƒë∆∞·ª£c onprem.private c·ªßa ch√≠nh n√≥</p></li></ul><p></p><p>‚ùå <strong>Set up an Amazon Route 53 outbound resolver endpoint with a forwarding rule for the onprem.private hosted zone. Associate the resolver with the AWS Region of the EC2 instance. Configure the on-premises DNS resolver to forward onprem.private DNS queries to the outbound resolver endpoint.</strong></p><ul><li><p><strong>Outbound resolver</strong> d√πng khi <strong>AWS resources</strong> c·∫ßn resolve <strong>on-premises hostnames</strong></p></li><li><p>ƒê√¢y l√† chi·ªÅu ng∆∞·ª£c l·∫°i: on-premises c·∫ßn resolve AWS, kh√¥ng ph·∫£i AWS resolve on-premises</p></li><li><p>Sai direction ho√†n to√†n</p></li></ul><p></p><p>‚ùå <strong>Set up an Amazon Route 53 outbound resolver endpoint. Associate the resolver with the AWS Region of the EC2 instance. Configure the on-premises DNS resolver to forward awscloud.private DNS queries to the outbound resolver endpoint.</strong></p><ul><li><p><strong>Outbound resolver</strong> sai use case</p></li><li><p>Outbound d√πng cho AWS ‚Üí on-premises, kh√¥ng ph·∫£i on-premises ‚Üí AWS</p></li><li><p>C·∫ßn inbound resolver, kh√¥ng ph·∫£i outbound</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"On-premises resolve AWS hostnames\"</strong> ‚Üí Route 53 <strong>Inbound</strong> Resolver Endpoint</p></li><li><p><strong>\"AWS resolve on-premises hostnames\"</strong> ‚Üí Route 53 <strong>Outbound</strong> Resolver Endpoint</p></li><li><p><strong>Inbound</strong> = DNS queries ƒëi <strong>v√†o</strong> AWS t·ª´ b√™n ngo√†i</p></li><li><p><strong>Outbound</strong> = DNS queries ƒëi <strong>ra kh·ªèi</strong> AWS ƒë·∫øn external DNS</p></li><li><p><strong>Direction pattern</strong>: On-prem ‚Üí AWS = Inbound | AWS ‚Üí On-prem = Outbound</p></li><li><p>Forward queries cho <strong>domain c·∫ßn resolve</strong>, kh√¥ng ph·∫£i domain c·ªßa ch√≠nh m√¨nh</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/whitepapers/latest/hybrid-cloud-dns-options-for-vpc/route-53-resolver-endpoints-and-forwarding-rules.html\">Route 53 Resolver Endpoints</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resolver-overview-DSN-queries-to-vpc.html\">Resolving DNS queries between VPCs and your network</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resolver-forwarding-inbound-queries-managing.html\">Route 53 Resolver Inbound Endpoints</a></p></li></ul>",
            "correctAnswer": [
                "<p>Set up an Amazon Route 53 inbound resolver endpoint. Associate the resolver with the VPC of the EC2 instance. Configure the on-premises DNS resolver to forward awscloud.private DNS queries to the inbound resolver endpoint.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Set up an Amazon Route 53 inbound resolver endpoint with a forwarding rule for the onprem.private hosted zone. Associate the resolver with the VPC of the EC2 instance. Configure the on-premises DNS resolver to forward onprem.private DNS queries to the inbound resolver endpoint.</p>",
                "<p>Set up an Amazon Route 53 inbound resolver endpoint. Associate the resolver with the VPC of the EC2 instance. Configure the on-premises DNS resolver to forward awscloud.private DNS queries to the inbound resolver endpoint.</p>",
                "<p>Set up an Amazon Route 53 outbound resolver endpoint with a forwarding rule for the onprem.private hosted zone. Associate the resolver with the AWS Region of the EC2 instance. Configure the on-premises DNS resolver to forward onprem.private DNS queries to the outbound resolver endpoint.</p>",
                "<p>Set up an Amazon Route 53 outbound resolver endpoint. Associate the resolver with the AWS Region of the EC2 instance. Configure the on-premises DNS resolver to forward awscloud.private DNS queries to the outbound resolver endpoint.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 42
        },
        {
            "attemptAnswerId": 329184,
            "questionId": 6408,
            "questionText": "<p>A SysOps administrator is creating resources from an AWS. CloudFbrmation template that defines an Auto Scaling group of Amazon EC2 instances. The Auto Scaling group launch template provisions each EC2 instance by using a user data script. The creation of the Auto Scaling group resource is failing because of an error. The wait condition is not receiving the required number of signals.<br><br>How should the SysOps administrator resolve this error?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>T·∫°o <strong>Auto Scaling group</strong> t·ª´ <strong>CloudFormation template</strong></p></li><li><p>Launch template s·ª≠ d·ª•ng <strong>user data script</strong> ƒë·ªÉ provision EC2 instances</p></li><li><p>Creation <strong>failing</strong> v·ªõi l·ªói: <strong>wait condition kh√¥ng nh·∫≠n ƒë·ªß s·ªë signals</strong></p></li><li><p>Y√™u c·∫ßu: fix l·ªói ƒë·ªÉ CloudFormation nh·∫≠n ƒë·ªß success signals</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Run cfn-signal at the completion of the user data script.</strong></p><ul><li><p><strong>Wait condition</strong> trong CloudFormation c·∫ßn <strong>cfn-signal</strong> ƒë·ªÉ x√°c nh·∫≠n instance ƒë√£ provision th√†nh c√¥ng</p></li><li><p>User data script ph·∫£i <strong>g·ªçi cfn-signal</strong> khi ho√†n th√†nh ƒë·ªÉ g·ª≠i success signal v·ªÅ CloudFormation</p></li><li><p>N·∫øu kh√¥ng c√≥ cfn-signal, CloudFormation s·∫Ω timeout ch·ªù signal v√† fail</p></li><li><p>ƒê√¢y l√† <strong>best practice</strong> cho CloudFormation provisioning v·ªõi wait conditions</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Modify the EC2 instances' security group to allow outgoing traffic on port 443.</strong></p><ul><li><p>Ch·ªâ c·∫ßn thi·∫øt n·∫øu instances kh√¥ng th·ªÉ k·∫øt n·ªëi internet ƒë·ªÉ download packages</p></li><li><p>Kh√¥ng li√™n quan tr·ª±c ti·∫øp ƒë·∫øn <strong>cfn-signal</strong> mechanism</p></li><li><p>Wait condition th·∫•t b·∫°i v√¨ thi·∫øu signal call, kh√¥ng ph·∫£i network issue</p></li></ul><p></p><p>‚ùå <strong>Reduce the Auto Scaling group's DesiredCapacity value in the CloudFormation template.</strong></p><ul><li><p>Gi·∫£m s·ªë instances kh√¥ng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ <strong>thi·∫øu cfn-signal</strong></p></li><li><p>V·∫´n s·∫Ω th·∫•t b·∫°i v·ªõi s·ªë l∆∞·ª£ng instances √≠t h∆°n n·∫øu kh√¥ng g·ª≠i signal</p></li><li><p>Kh√¥ng ph·∫£i root cause c·ªßa v·∫•n ƒë·ªÅ</p></li></ul><p></p><p>‚ùå <strong>Set the AssociatePublicIpAddress property to True in the Auto Scaling group launch template.</strong></p><ul><li><p>Ch·ªâ c·∫ßn n·∫øu instances c·∫ßn public IP ƒë·ªÉ access internet</p></li><li><p>Kh√¥ng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ <strong>cfn-signal kh√¥ng ƒë∆∞·ª£c g·ªçi</strong> trong user data</p></li><li><p>Wait condition c·∫ßn signal t·ª´ cfn-signal command, kh√¥ng ph·∫£i network connectivity</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Wait condition not receiving signals\"</strong> ‚Üí Thi·∫øu <strong>cfn-signal</strong> trong user data script</p></li><li><p><strong>CloudFormation wait condition</strong> ‚Üí C·∫ßn <strong>cfn-signal</strong> ƒë·ªÉ confirm success</p></li><li><p><strong>User data script pattern</strong> ‚Üí Install/configure ‚Üí <strong>cfn-signal</strong> at the end</p></li><li><p><strong>cfn-signal</strong> g·ª≠i success/failure status v·ªÅ CloudFormation stack</p></li><li><p><strong>Best practice</strong>: Lu√¥n k·∫øt th√∫c user data v·ªõi cfn-signal khi d√πng wait conditions</p></li><li><p><strong>Common mistakes</strong>: Qu√™n g·ªçi cfn-signal ho·∫∑c g·ªçi tr∆∞·ªõc khi provisioning ho√†n t·∫•t</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/cfn-helper-scripts-reference.html\">CloudFormation cfn-signal helper script</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-resource-cloudformation-waitcondition.html\">CloudFormation Wait Conditions</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-soa/aws-cloudformation-helper-scripts#3-deploy-stack-s%E1%BB%AD-d%E1%BB%A5ng-cfn-signal\">Deploy stack s·ª≠ d·ª•ng cfn-signal</a></p></li></ul>",
            "correctAnswer": [
                "<p>Run cfn-signal at the completion of the user data script.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Run cfn-signal at the completion of the user data script.</p>",
                "<p>Modify the EC2 instances‚Äô security group to allow outgoing traffic on port 443.</p>",
                "<p>Reduce the Auto Scaling group's DesiredCapacity value in the CloudFormation template.</p>",
                "<p>Set the AssociatePublicIpAddress property to True in the Auto Scaling group launch template.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 43
        },
        {
            "attemptAnswerId": 329185,
            "questionId": 6409,
            "questionText": "<p>A developer creates a web application that runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances are in an Auto Scaling group. The developer reviews the deployment and notices some suspicious traffic to the application. The traffic is malicious and is coming from a single public IP address. A SysOps administrator must block the public IP address.<br><br>Which solution will meet this requirement?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Web application ch·∫°y tr√™n <strong>EC2 instances</strong> ƒë·∫±ng sau <strong>Application Load Balancer (ALB)</strong></p></li><li><p>Ph√°t hi·ªán <strong>suspicious malicious traffic (truy c·∫≠p ƒë·ªôc h·∫°i)</strong> t·ª´ <strong>single public IP address</strong></p></li><li><p>Y√™u c·∫ßu: <strong>block public IP address</strong> n√†y</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Add the malicious IP address to an IP set in AWS WAF. Create a web ACL. Include an IP set rule with the action set to BLOCK. Associate the web ACL with the ALB.</strong></p><ul><li><p><strong>AWS WAF</strong> ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ <strong>filter web traffic</strong> ·ªü application layer (Layer 7)</p></li><li><p><strong>IP set</strong> cho ph√©p ƒë·ªãnh nghƒ©a list c√°c IP addresses c·∫ßn block</p></li><li><p><strong>Web ACL</strong> v·ªõi BLOCK action s·∫Ω <strong>ch·∫∑n requests</strong> t·ª´ IP trong IP set</p></li><li><p>WAF integrate tr·ª±c ti·∫øp v·ªõi ALB ƒë·ªÉ filter traffic tr∆∞·ªõc khi ƒë·∫øn instances</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a security group rule to deny all inbound traffic from the suspicious IP address. Associate the security group with the ALB.</strong></p><ul><li><p><strong>Security groups ch·ªâ support ALLOW rules</strong>, kh√¥ng c√≥ DENY rules</p></li><li><p>Security groups ho·∫°t ƒë·ªông theo <strong>stateful whitelist</strong></p></li></ul><p></p><p>‚ùå <strong>Implement Amazon Detective to monitor traffic and to block malicious activity from the internet. Configure Detective to integrate with the ALB.</strong></p><ul><li><p><strong>Amazon Detective</strong> l√† <strong>investigation tool</strong> ƒë·ªÉ ph√¢n t√≠ch security findings</p></li><li><p>Detective <strong>kh√¥ng block traffic</strong>, ch·ªâ gi√∫p analyze incidents</p></li></ul><p></p><p>‚ùå <strong>Implement AWS Resource Access Manager (AWS RAM) to manage traffic rules and to block malicious activity from the internet. Associate AWS RAM with the ALB.</strong></p><ul><li><p><strong>AWS RAM</strong> d√πng ƒë·ªÉ <strong>share resources</strong> gi·ªØa c√°c AWS accounts</p></li><li><p>Kh√¥ng ph·∫£i tool ƒë·ªÉ block traffic</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Block IP address at ALB/CloudFront\"</strong> ‚Üí <strong>AWS WAF</strong> with IP set</p></li><li><p><strong>\"Application layer filtering\"</strong> ‚Üí AWS WAF (Layer 7)</p></li><li><p><strong>Security groups</strong> ‚Üí Ch·ªâ ALLOW rules, kh√¥ng c√≥ DENY (stateful whitelist)</p></li><li><p><strong>Network ACLs</strong> ‚Üí C√≥ c·∫£ ALLOW v√† DENY rules (stateless, subnet level)</p></li><li><p><strong>AWS WAF components</strong>: IP sets ‚Üí Web ACL ‚Üí Rules ‚Üí Associate v·ªõi ALB/CloudFront</p></li><li><p><strong>Amazon Detective</strong> ‚Üí Investigation tool, kh√¥ng ph·∫£i blocking tool</p></li><li><p><strong>AWS RAM</strong> ‚Üí Resource sharing, kh√¥ng ph·∫£i security filtering</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/waf/latest/developerguide/waf-ip-set-managing.html\">AWS WAF IP set rules</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/waf/latest/developerguide/classic-web-acl-working-with.html\">Working with Web ACLs</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/waf/latest/developerguide/web-acl-associating-aws-resource.html\">Associating or disassociating a Web ACL with an AWS resource</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add the malicious IP address to an IP set in AWS WAF. Create a web ACL. Include an IP set rule with the action set to BLOCK. Associate the web ACL with the ALB.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a security group rule to deny all inbound traffic from the suspicious IP address. Associate the security group with the ALB.</p>",
                "<p>Implement Amazon Detective to monitor traffic and to block malicious activity from the internet. Configure Detective to integrate with the ALB.</p>",
                "<p>Implement AWS Resource Access Manager (AWS RAM) to manage traffic rules and to block malicious activity from the internet. Associate AWS RAM with the ALB.</p>",
                "<p>Add the malicious IP address to an IP set in AWS WAF. Create a web ACL. Include an IP set rule with the action set to BLOCK. Associate the web ACL with the ALB.</p>"
            ],
            "answersPos": "[1,3,0,2]",
            "pos": 44
        },
        {
            "attemptAnswerId": 329186,
            "questionId": 6410,
            "questionText": "<p>A manufacturing company uses an Amazon RDS DB instance to store inventory of all stock items. The company maintains several AWS Lambda functions that interact with the database to add, update, and delete items. The Lambda functions use hardcoded credentials to connect to the database.<br><br>A SysOps administrator must ensure that the database credentials are never stored in plaintext and that the password is rotated every 30 days.<br><br>Which solution will meet these requirements in the MOST operationally efficient manner?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Lambda functions k·∫øt n·ªëi RDS ƒë·ªÉ add, update, delete items</p></li><li><p>Hi·ªán t·∫°i d√πng <strong>hardcoded credentials</strong></p></li><li><p>Y√™u c·∫ßu: <strong>credentials kh√¥ng l∆∞u plaintext</strong> v√† <strong>rotate password m·ªói 30 ng√†y</strong></p></li><li><p>M·ª•c ti√™u: gi·∫£i ph√°p <strong>MOST operationally efficient</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Use AWS Secrets Manager to store credentials for the database. Create a Secrets Manager secret, and select the database so that Secrets Manager will use a Lambda function to update the database password automatically. Specify an automatic rotation schedule of 30 days. Update each Lambda function to access the database password from Secrets Manager.</strong></p><ul><li><p><strong>Secrets Manager</strong> ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·∫∑c bi·ªát ƒë·ªÉ <strong>store v√† rotate database credentials</strong></p></li><li><p><strong>Automatic rotation</strong> t√≠ch h·ª£p s·∫µn cho RDS, kh√¥ng c·∫ßn vi·∫øt custom Lambda function</p></li><li><p>Secrets Manager t·ª± ƒë·ªông t·∫°o rotation Lambda, update password trong RDS v√† secret</p></li><li><p><strong>Least operational overhead</strong>: ch·ªâ c·∫ßn config rotation schedule, t·∫•t c·∫£ t·ª± ƒë·ªông</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Store the database password as an environment variable for each Lambda function. Create a new Lambda function that is named PasswordRotate. Use Amazon EventBridge to schedule the PasswordRotate function every 30 days to change the database password and update the environment variable for each Lambda function.</strong></p><ul><li><p>Environment variables <strong>l∆∞u plaintext</strong>, kh√¥ng encrypted by default</p></li><li><p>C·∫ßn manual update t·∫•t c·∫£ Lambda functions khi rotate password</p></li></ul><p></p><p>‚ùå <strong>Use AWS Key Management Service (AWS KMS) to encrypt the database password and to store the encrypted password as an environment variable for each Lambda function. Grant each Lambda function access to the KMS key so that the database password can be decrypted when required. Create a new Lambda function that is named PasswordRotate to change the password every 30 days.</strong></p><ul><li><p>C·∫ßn <strong>t·ª± vi·∫øt rotation logic</strong> v√† update environment variables</p></li><li><p><strong>More operational overhead</strong> so v·ªõi Secrets Manager built-in rotation</p></li></ul><p></p><p>‚ùå <strong>Use AWS Systems Manager Parameter Store to create a secure string to store credentials for the database. Create a new Lambda function called PasswordRotate. Use Amazon EventBridge to schedule the PasswordRotate function every 30 days to change the database password and to update the secret within Parameter Store. Update each Lambda function to access the database password from Parameter Store.</strong></p><ul><li><p>Parameter Store <strong>kh√¥ng c√≥ automatic rotation</strong> cho database credentials</p></li><li><p>C·∫ßn t·ª± build rotation mechanism v·ªõi custom Lambda + EventBridge</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Database credentials + automatic rotation\"</strong> ‚Üí <strong>AWS Secrets Manager</strong></p></li><li><p><strong>\"RDS/Aurora credentials rotation\"</strong> ‚Üí Secrets Manager built-in rotation</p></li><li><p><strong>\"Most operationally efficient + rotation\"</strong> ‚Üí Secrets Manager (fully managed)</p></li><li><p><strong>Secrets Manager</strong> ‚Üí Native support cho RDS, Redshift, DocumentDB rotation</p></li><li><p><strong>Parameter Store</strong> ‚Üí Good for config values, kh√¥ng c√≥ built-in rotation</p></li><li><p><strong>KMS</strong> ‚Üí Encryption service, kh√¥ng ph·∫£i secrets management + rotation</p></li><li><p><strong>Pattern</strong>: Secrets Manager &gt; Parameter Store khi c·∫ßn automatic rotation</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html\">AWS Secrets Manager Rotation</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotate-secrets_turn-on-for-db.html\">Rotating AWS Secrets Manager secrets for RDS</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-saa-dva/aws-secrets-manager-integration-with-amazon-rds\">https://blog.cloudmentor.pro/blog/aws-saa-dva/aws-secrets-manager-integration-with-amazon-rds</a></p></li></ul><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1764466317316-t34a3hal-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"694.2083333333333\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p>",
            "correctAnswer": [
                "<p>Use AWS Secrets Manager to store credentials for the database. Create a Secrets Manager secret, and select the database so that Secrets Manager will use a Lambda function to update the database password automatically. Specify an automatic rotation schedule of 30 days. Update each Lambda function to access the database password from Secrets Manager.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Store the database password as an environment variable for each Lambda function. Create a new Lambda function that is named PasswordRotate. Use Amazon EventBridge to schedule the PasswordRotate function every 30 days to change the database password and update the environment variable for each Lambda function.</p>",
                "<p>Use AWS Key Management Service (AWS KMS) to encrypt the database password and to store the encrypted password as an environment variable for each Lambda function. Grant each Lambda function access to the KMS key so that the database password can be decrypted when required. Create a new Lambda function that is named PasswordRotate to change the password every 30 days.</p>",
                "<p>Use AWS Secrets Manager to store credentials for the database. Create a Secrets Manager secret, and select the database so that Secrets Manager will use a Lambda function to update the database password automatically. Specify an automatic rotation schedule of 30 days. Update each Lambda function to access the database password from Secrets Manager.</p>",
                "<p>Use AWS Systems Manager Parameter Store to create a secure string to store credentials for the database. Create a new Lambda function called PasswordRotate. Use Amazon EventBridge to schedule the PasswordRotate function every 30 days to change the database password and to update the secret within Parameter Store. Update each Lambda function to access the database password from Parameter Store.</p>"
            ],
            "answersPos": "[1,3,0,2]",
            "pos": 45
        },
        {
            "attemptAnswerId": 329187,
            "questionId": 6411,
            "questionText": "<p>A company runs its entire suite of applications on Amazon EC2 instances. The company plans to move the applications to containers and AWS Fargate. Within 6 months, the company plans to retire its EC2 instances and use only Fargate. The company has been able to estimate its future Fargate costs.<br><br>A SysOps administrator needs to choose a purchasing option to help the company minimize costs. The SysOps administrator must maximize any discounts that are available and must ensure that there are no unused reservations.<br><br>Which purchasing option will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Hi·ªán ch·∫°y applications tr√™n <strong>EC2 instances</strong></p></li><li><p>S·∫Ω <strong>migrate sang containers v√† Fargate</strong> trong 6 th√°ng</p></li><li><p>Sau 6 th√°ng s·∫Ω <strong>retire EC2 ho√†n to√†n</strong>, ch·ªâ d√πng Fargate</p></li><li><p>ƒê√£ estimate ƒë∆∞·ª£c <strong>future Fargate costs</strong></p></li><li><p>Y√™u c·∫ßu: <strong>minimize costs</strong>, <strong>maximize discounts</strong>, <strong>kh√¥ng c√≥ unused reservations</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Compute Savings Plans for 1 year with the No Upfront payment option</strong></p><ul><li><p><strong>Compute Savings Plans</strong> √°p d·ª•ng cho <strong>c·∫£ EC2 v√† Fargate</strong>, ph√π h·ª£p v·ªõi migration path</p></li><li><p>Khi migrate t·ª´ EC2 sang Fargate, Compute Savings Plans <strong>t·ª± ƒë·ªông apply</strong> cho Fargate</p></li><li><p><strong>No Upfront</strong> gi√∫p <strong>avoid unused reservations</strong> n·∫øu workload change nhanh h∆°n d·ª± ki·∫øn</p></li><li><p>Flexible nh·∫•t cho scenario transition gi·ªØa compute services</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Compute Savings Plans for 1 year with the Partial Upfront payment option</strong></p><ul><li><p>Compute Savings Plans <strong>ƒë√∫ng</strong>, nh∆∞ng <strong>Partial Upfront c√≥ risk</strong> cao h∆°n</p></li><li><p>N·∫øu migrate nhanh h∆°n 6 th√°ng, upfront payment c√≥ th·ªÉ kh√¥ng t·ªëi ∆∞u</p></li></ul><p></p><p>‚ùå <strong>EC2 Instance Savings Plans for 1 year with the All Upfront payment option</strong></p><ul><li><p><strong>EC2 Instance Savings Plans ch·ªâ apply cho EC2</strong>, kh√¥ng cover Fargate</p></li><li><p>Sau khi retire EC2, savings plans n√†y s·∫Ω <strong>unused</strong> ho√†n to√†n</p></li></ul><p></p><p>‚ùå <strong>EC2 Reserved Instances for 1 year with the Partial Upfront payment option</strong></p><ul><li><p><strong>Reserved Instances ch·ªâ cho EC2</strong>, kh√¥ng apply cho Fargate</p></li><li><p>S·∫Ω c√≥ <strong>unused reservations</strong> sau khi migrate sang Fargate</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"EC2 ‚Üí Fargate migration\"</strong> ‚Üí <strong>Compute Savings Plans</strong> (covers both)</p></li><li><p><strong>\"Avoid unused reservations + workload change\"</strong> ‚Üí <strong>No Upfront</strong> payment</p></li><li><p><strong>Compute Savings Plans</strong> ‚Üí Apply cho EC2, Fargate, Lambda (most flexible)</p></li><li><p><strong>EC2 Instance Savings Plans</strong> ‚Üí Ch·ªâ EC2 instances (specific instance family)</p></li><li><p><strong>Reserved Instances</strong> ‚Üí EC2 only, less flexible</p></li><li><p><strong>Payment options discount</strong>: All Upfront &gt; Partial Upfront &gt; No Upfront (nh∆∞ng less flexible)</p></li><li><p><strong>Migration scenarios</strong> ‚Üí Compute Savings Plans &gt; EC2 Instance Savings Plans</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/savingsplans/compute-pricing/?nc1=h_ls\">AWS Compute Savings Plans</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://repost.aws/knowledge-center/savings-plans-considerations\">Savings Plans payment options</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/fargate/pricing/\">Fargate Pricing and Savings Plans</a></p></li></ul>",
            "correctAnswer": [
                "<p>Compute Savings Plans for 1 year with the No Upfront payment option</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Compute Savings Plans for 1 year with the No Upfront payment option</p>",
                "<p>Compute Savings Plans for 1 year with the Partial Upfront payment option</p>",
                "<p>EC2 Instance Savings Plans for 1 year with the All Upfront payment option</p>",
                "<p>EC2 Reserved Instances for 1 year with the Partial Upfront payment option</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 46
        },
        {
            "attemptAnswerId": 329188,
            "questionId": 6412,
            "questionText": "<p>A company has an existing public web application for www.example.com. The Application Load Balancer (ALB) is configured with a single HTTP 80 listener. A SysOps administrator must ensure that all web requests to www.example.com are encrypted between the client and the ALB.<br><br>The SysOps administrator already has requested and validated a public certificate for www.example.com in AWS Certificate Manager (ACM). Existing users of the application must not be required to change the endpoint to which they are connecting.<br><br>Which additional set of steps should the SysOps administrator take to meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Public web application: www.example.com</p></li><li><p>ALB hi·ªán c√≥ <strong>single HTTP 80 listener</strong></p></li><li><p>Y√™u c·∫ßu: <strong>encrypt traffic gi·ªØa client v√† ALB</strong></p></li><li><p>ƒê√£ c√≥ <strong>ACM certificate</strong> cho www.example.com</p></li><li><p><strong>Existing users kh√¥ng c·∫ßn change endpoint</strong> (v·∫´n d√πng ƒë∆∞·ª£c HTTP)</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Modify the ALB default rule for the HTTP port 80 listener to redirect to HTTPS on port 443. Create an additional HTTPS listener on port 443. Set the default action to forward all traffic to the target group. Specify the ACM certificate that was created for www.example.com as the default SSL certificate.</strong></p><ul><li><p><strong>Gi·ªØ HTTP listener</strong> ƒë·ªÉ existing users v·∫´n connect ƒë∆∞·ª£c</p></li><li><p><strong>Redirect HTTP ‚Üí HTTPS</strong> ƒë·∫£m b·∫£o t·∫•t c·∫£ traffic ƒë∆∞·ª£c encrypted</p></li><li><p><strong>T·∫°o HTTPS listener</strong> v·ªõi ACM certificate ƒë·ªÉ handle encrypted connections</p></li><li><p>Users kh√¥ng c·∫ßn thay ƒë·ªïi g√¨, t·ª± ƒë·ªông redirect sang HTTPS</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create an additional ALB listener for HTTPS on port 443. Set the default action to forward all traffic to the target group. Specify the ACM certificate that was created for www.example.com as the default SSL certificate.</strong></p><ul><li><p>Ch·ªâ <strong>add HTTPS listener</strong>, kh√¥ng redirect HTTP traffic</p></li><li><p>Users v·∫´n c√≥ th·ªÉ d√πng HTTP (unencrypted), kh√¥ng ƒë√°p ·ª©ng y√™u c·∫ßu encrypt <strong>all</strong> requests</p></li></ul><p></p><p>‚ùå <strong>Create an additional ALB listener for HTTPS on port 443. Set the default action to forward all traffic to the target group. Specify the ACM certificate that was created for www.example.com as the default SSL certificate. Delete the original HTTP listener on port 80.</strong></p><ul><li><p><strong>Delete HTTP listener</strong> s·∫Ω break existing users ƒëang d√πng HTTP</p></li><li><p>Vi ph·∫°m y√™u c·∫ßu \"existing users kh√¥ng c·∫ßn change endpoint\"</p></li></ul><p></p><p>‚ùå <strong>Modify the ALB default rule for the HTTP port 80 listener. Create a rule in the listener to forward all traffic for the host www.example.com to the target group. Specify the ACM certificate that was created for www.example.com as the default SSL certificate.</strong></p><ul><li><p><strong>Kh√¥ng th·ªÉ attach SSL certificate</strong> v√†o HTTP listener</p></li><li><p>HTTP listener kh√¥ng support encryption</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Encrypt all traffic + kh√¥ng break existing users\"</strong> ‚Üí <strong>HTTP redirect to HTTPS</strong></p></li><li><p><strong>\"ALB encryption\"</strong> ‚Üí HTTPS listener (port 443) + ACM certificate</p></li><li><p><strong>Best practice</strong>: Keep HTTP listener + redirect to HTTPS (user-friendly)</p></li><li><p><strong>HTTP listener</strong> ‚Üí Kh√¥ng support SSL/TLS certificate</p></li><li><p><strong>HTTPS listener</strong> ‚Üí Requires SSL certificate (ACM ho·∫∑c imported)</p></li><li><p><strong>Redirect action</strong> ‚Üí Gi·ªØ backward compatibility cho HTTP users</p></li><li><p><strong>Pattern</strong>: HTTP (80) redirect ‚Üí HTTPS (443) with certificate</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html\">Application Load Balancer HTTPS listeners</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_RedirectActionConfig.html\">Redirect actions for Application Load Balancer</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/https-listener-certificates.html\">Using AWS Certificate Manager with Application Load Balancer</a></p></li></ul>",
            "correctAnswer": [
                "<p>Modify the ALB default rule for the HTTP port 80 listener to redirect to HTTPS on port 443. Create an additional HTTPS listener on port 443. Set the default action to forward all traffic to the target group. Specify the ACM certificate that was created for www.example.com as the default SSL certificate.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an additional ALB listener for HTTPS on port 443. Set the default action to forward all traffic to the target group. Specify the ACM certificate that was created for www.example.com as the default SSL certificate.</p>",
                "<p>Create an additional ALB listener for HTTPS on port 443. Set the default action to forward all traffic to the target group. Specify the ACM certificate that was created for www.example.com as the default SSL certificate. Delete the original HTTP listener on port 80.</p>",
                "<p>Modify the ALB default rule for the HTTP port 80 listener. Create a rule in the listener to forward all traffic for the host www example.com to the target group. Specify the ACM certificate that was created for www.example.com as the default SSL certificate.</p>",
                "<p>Modify the ALB default rule for the HTTP port 80 listener to redirect to HTTPS on port 443. Create an additional HTTPS listener on port 443. Set the default action to forward all traffic to the target group. Specify the ACM certificate that was created for www.example.com as the default SSL certificate.</p>"
            ],
            "answersPos": "[3,1,0,2]",
            "pos": 47
        },
        {
            "attemptAnswerId": 329189,
            "questionId": 6413,
            "questionText": "<p>A company is using an Amazon DynamoDB table for data. A SysOps administrator must configure replication of the table to another AWS Region for disaster recovery.<br><br>What should the SysOps administrator do to meet this requirement?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>C√¥ng ty s·ª≠ d·ª•ng <strong>DynamoDB table</strong> ƒë·ªÉ l∆∞u data</p></li><li><p>Y√™u c·∫ßu: <strong>replicate table sang AWS Region kh√°c</strong> cho disaster recovery</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Enable DynamoDB Streams, and add a global table Region.</strong></p><ul><li><p><strong>DynamoDB Global Tables</strong> cung c·∫•p <strong>multi-region replication</strong> t·ª± ƒë·ªông</p></li><li><p><strong>DynamoDB Streams</strong> l√† prerequisite ƒë·ªÉ enable global tables</p></li><li><p>Th√™m <strong>global table Region</strong> s·∫Ω t·ª± ƒë·ªông replicate data sang Region m·ªõi</p></li><li><p>H·ªó tr·ª£ <strong>multi-active replication</strong> (bi-directional) cho disaster recovery</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Enable DynamoDB Accelerator (DAX).</strong></p><ul><li><p><strong>DAX</strong> l√† <strong>in-memory caching layer</strong> ƒë·ªÉ improve read performance</p></li><li><p>Kh√¥ng replicate data sang Region kh√°c, ch·ªâ cache trong c√πng Region</p></li></ul><p></p><p>‚ùå <strong>Enable DynamoDB Streams, and add a global secondary index (GSI).</strong></p><ul><li><p><strong>Global Secondary Index</strong> t·∫°o alternate query patterns trong <strong>c√πng table</strong></p></li><li><p>GSI kh√¥ng replicate data sang Region kh√°c, ch·ªâ l√† indexing mechanism</p></li></ul><p></p><p>‚ùå <strong>Enable point-in-time recovery.</strong></p><ul><li><p><strong>PITR</strong> cho ph√©p restore table ƒë·∫øn b·∫•t k·ª≥ point in time trong 35 ng√†y</p></li><li><p>Kh√¥ng replicate data sang Region kh√°c, ch·ªâ backup trong c√πng Region</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Cross-region replication + DynamoDB\"</strong> ‚Üí <strong>Global Tables</strong></p></li><li><p><strong>\"Disaster recovery across Regions\"</strong> ‚Üí Global Tables</p></li><li><p><strong>DynamoDB Global Tables</strong> ‚Üí Requires DynamoDB Streams enabled</p></li><li><p><strong>DAX</strong> ‚Üí In-memory cache, kh√¥ng ph·∫£i replication</p></li><li><p><strong>GSI</strong> ‚Üí Query optimization, kh√¥ng ph·∫£i cross-region feature</p></li><li><p><strong>PITR</strong> ‚Üí Backup/restore trong Region, kh√¥ng ph·∫£i replication</p></li><li><p><strong>Pattern</strong>: Multi-region DR cho DynamoDB = Global Tables + Streams</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/dynamodb/global-tables/\">DynamoDB Global Tables</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/V2globaltables_HowItWorks.html\">Using DynamoDB Streams with Global Tables</a></p></li></ul>",
            "correctAnswer": [
                "<p>Enable DynamoDB Streams, and add a global table Region.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Enable DynamoDB Accelerator (DAX).</p>",
                "<p>Enable DynamoDB Streams, and add a global secondary index (GSI).</p>",
                "<p>Enable DynamoDB Streams, and add a global table Region.</p>",
                "<p>Enable point-in-time recovery.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 48
        },
        {
            "attemptAnswerId": 329190,
            "questionId": 8850,
            "questionText": "<p>A company has migrated its legacy on-premises web application to an Amazon EC2 instance. The web application requires a single static public IP address to accept traffic and process requests. End users must be able to reach the web application through the example.com domain. A SysOps administrator must implement a solution that maintains the web application with the least amount of effort.<br><br>Which combination of actions will meet these requirements? (Choose two.)</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Legacy web application migrate sang <strong>EC2 instance</strong></p></li><li><p>Y√™u c·∫ßu: <strong>single static public IP address</strong></p></li><li><p>End users truy c·∫≠p qua <strong><u>example.com</u> domain</strong></p></li><li><p>M·ª•c ti√™u: maintain v·ªõi <strong>least amount of effort</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create an Elastic IP address, and associate it with the EC2 instance.</strong></p><ul><li><p><strong>Elastic IP</strong> cung c·∫•p <strong>static public IP</strong> kh√¥ng ƒë·ªïi khi stop/start instance</p></li><li><p>Associate v·ªõi EC2 instance ƒë·ªÉ ƒë·∫£m b·∫£o IP c·ªë ƒë·ªãnh</p></li><li><p>ƒê√°p ·ª©ng y√™u c·∫ßu \"single static public IP address\"</p></li></ul><p></p><p><strong>Create an Amazon Route 53 A record for the associated EC2 IP address.</strong></p><ul><li><p><strong>A record</strong> map domain name (example.com) tr·ª±c ti·∫øp t·ªõi <strong>IP address</strong> (Elastic IP)</p></li><li><p>Cho ph√©p end users truy c·∫≠p qua example.com domain</p></li><li><p>ƒê∆°n gi·∫£n nh·∫•t cho single IP scenario</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Configure an Application Load Balancer (ALB). Add the EC2 instance to a target group that is associated with the ALB.</strong></p><ul><li><p>ALB adds complexity kh√¥ng c·∫ßn thi·∫øt cho <strong>single instance</strong></p></li><li><p>Kh√¥ng ƒë√°p ·ª©ng y√™u c·∫ßu \"least amount of effort\"</p></li></ul><p></p><p>‚ùå <strong>Create an Amazon Route 53 CNAME record for the associated EC2 IP address.</strong></p><ul><li><p><strong>CNAME record maps domain to domain</strong>, kh√¥ng map domain to IP address</p></li><li><p>Kh√¥ng th·ªÉ t·∫°o CNAME cho apex domain (example.com)</p></li></ul><p></p><p>‚ùå <strong>Create an Auto Scaling group with a minimum capacity of 1 and a maximum capacity of 2.</strong></p><ul><li><p>Auto Scaling adds complexity kh√¥ng c·∫ßn thi·∫øt</p></li><li><p>C√¢u h·ªèi kh√¥ng y√™u c·∫ßu high availability hay auto scaling</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Single static IP\"</strong> ‚Üí <strong>Elastic IP</strong></p></li><li><p><strong>\"Domain to IP\"</strong> ‚Üí Route 53 <strong>A record</strong></p></li><li><p><strong>\"Domain to domain\"</strong> ‚Üí Route 53 <strong>CNAME record</strong></p></li><li><p><strong>A record</strong> ‚Üí Maps hostname to IP address</p></li><li><p><strong>CNAME</strong> ‚Üí Maps hostname to another hostname (kh√¥ng d√πng cho apex domain)</p></li><li><p><strong>Elastic IP</strong> ‚Üí Static IP persists qua stop/start instance</p></li><li><p><strong>Least effort + single instance</strong> ‚Üí Elastic IP + A record (kh√¥ng c·∫ßn ALB/Auto Scaling)</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html\">Elastic IP addresses</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/ResourceRecordTypes.html#AFormat\">Route 53 A records</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html\">Choosing between alias and non-alias records</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an Amazon Route 53 A record for the associated EC2 IP address.</p>",
                "<p>Create an Elastic IP address, and associate it with the EC2 instance.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure an Application Load Balancer (ALB). Add the EC2 instance to a target group that is associated with the ALB.</p>",
                "<p>Create an Amazon Route 53 A record for the associated EC2 IP address.</p>",
                "<p>Create an Amazon Route 53 CNAME record for the associated EC2 IP address.</p>",
                "<p>Create an Elastic IP address, and associate it with the EC2 instance.</p>",
                "<p>Create an Auto Scaling group with a minimum capacity of 1 and a maximum capacity of 2.</p>"
            ],
            "answersPos": "[3,0,1,2,4]",
            "pos": 49
        },
        {
            "attemptAnswerId": 329191,
            "questionId": 6415,
            "questionText": "<p>A company runs its applications on a large number of Amazon EC2 instances. A SysOps administrator must implement a solution to notify the operations team whenever an EC2 instance state changes.<br><br>What is the MOST operationally efficient solution that meets these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>C√¥ng ty ch·∫°y applications tr√™n <strong>large number of EC2 instances</strong></p></li><li><p>Y√™u c·∫ßu: <strong>notify operations team</strong> khi <strong>EC2 instance state changes</strong></p></li><li><p>M·ª•c ti√™u: <strong>MOST operationally efficient solution</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create an Amazon EventBridge event rule that captures EC2 instance state changes. Set an Amazon Simple Notification Service (Amazon SNS) topic as the target</strong></p><ul><li><p><strong>EventBridge</strong> t·ª± ƒë·ªông capture <strong>EC2 state change events</strong> (running, stopped, terminated...)</p></li><li><p><strong>Direct integration</strong> v·ªõi SNS topic, kh√¥ng c·∫ßn custom code</p></li><li><p><strong>Fully managed</strong>, kh√¥ng c·∫ßn maintain scripts hay Lambda functions</p></li><li><p><strong>Most efficient</strong>: ch·ªâ c·∫ßn t·∫°o event rule v√† point tr·ª±c ti·∫øp ƒë·∫øn SNS</p></li></ul><p></p><p><em>Architecture</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1764468356279-grmufu2s-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"128.125\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a script that captures instance state changes and publishes a notification to an Amazon Simple Notification Service (Amazon SNS) topic. Use AWS Systems Manager Run Command to run the script on all EC2 instances.</strong></p><ul><li><p>C·∫ßn <strong>deploy v√† maintain scripts</strong> tr√™n t·∫•t c·∫£ instances</p></li><li><p><strong>High operational overhead</strong>, ph·∫£i update script khi c√≥ instances m·ªõi</p></li></ul><p></p><p>‚ùå <strong>Create an Amazon EventBridge event rule that captures EC2 instance state changes. Set as the target an AWS Lambda function that publishes a notification to an Amazon Simple Notification Service (Amazon SNS) topic.</strong></p><ul><li><p><strong>Lambda function kh√¥ng c·∫ßn thi·∫øt</strong>, EventBridge c√≥ th·ªÉ publish tr·ª±c ti·∫øp t·ªõi SNS</p></li><li><p>Adds unnecessary complexity</p></li></ul><p></p><p>‚ùå <strong>Create an AWS Config custom rule that evaluates instance state changes with automatic remediation. Use the rule to invoke an AWS Lambda function that publishes a notification to an Amazon Simple Notification Service (Amazon SNS) topic.</strong></p><ul><li><p><strong>AWS Config</strong> d√πng cho compliance monitoring, kh√¥ng ph·∫£i event notification</p></li><li><p>Over-engineered cho simple notification requirement</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"EC2 state changes notification\"</strong> ‚Üí <strong>EventBridge</strong> event rule</p></li><li><p><strong>\"Most operationally efficient\"</strong> ‚Üí Direct integration, √≠t components nh·∫•t</p></li><li><p><strong>EventBridge native targets</strong>: SNS, SQS, Lambda, Step Functions, Systems Manager...</p></li><li><p><strong>Pattern</strong>: EventBridge ‚Üí SNS (simple) vs EventBridge ‚Üí Lambda ‚Üí SNS (th√™m processing)</p></li><li><p><strong>AWS Config</strong> ‚Üí Compliance v√† config changes evaluation</p></li><li><p><strong>EventBridge</strong> ‚Üí Event-driven automation v√† notifications</p></li><li><p><strong>Avoid</strong>: Custom scripts khi c√≥ managed service s·∫µn</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-saa-dva/create-an-eventbridge-rule-to-get-notified-on-ec2-instance-state-change\">Create an EventBridge Rule to get notified on EC2 Instance state change</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-instance-state-changes.html\">EC2 instance state change events</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-targets.html\">EventBridge targets</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an Amazon EventBridge event rule that captures EC2 instance state changes. Set an Amazon Simple Notification Service (Amazon SNS) topic as the target</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a script that captures instance state changes and publishes a notification to an Amazon Simple Notification Service (Amazon SNS) topic. Use AWS Systems Manager Run Command to run the script on all EC2 instances.</p>",
                "<p>Create an Amazon EventBridge event rule that captures EC2 instance state changes. Set an Amazon Simple Notification Service (Amazon SNS) topic as the target</p>",
                "<p>Create an Amazon EventBridge event rule that captures EC2 instance state changes. Set as the target an AWS Lambda function that publishes a notification to an Amazon Simple Notification Service (Amazon SNS) topic.</p>",
                "<p>Create an AWS Config custom rule that evaluates instance state changes with automatic remediation. Use the rule to invoke an AWS Lambda function that publishes a notification to an Amazon Simple Notification Service (Amazon SNS) topic.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 50
        },
        {
            "attemptAnswerId": 329192,
            "questionId": 6416,
            "questionText": "<p>A company asks a SysOps administrator to provision an additional environment for an application in four additional AWS Regions. The application is running on more than 100 Amazon C2 instances in the us-east-1 Region, using fully configured Amazon Machine Images (AMIs). The company has an AWS CloudFormation template to deploy resources in us-east-1.<br><br>What should the SysOps administrator do to provision the application in the MOST operationally efficient manner?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Application ch·∫°y tr√™n <strong>h∆°n 100 EC2 instances</strong> ·ªü <strong>us-east-1</strong></p></li><li><p>S·ª≠ d·ª•ng <strong>fully configured AMIs</strong></p></li><li><p>ƒê√£ c√≥ <strong>CloudFormation template</strong> ƒë·ªÉ deploy resources trong us-east-1</p></li><li><p>Y√™u c·∫ßu: provision application ·ªü <strong>4 AWS Regions m·ªõi</strong></p></li><li><p>M·ª•c ti√™u: <strong>MOST operationally efficient</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Copy the AMI to each Region by using the aws ec2 copy-image command. Update the CloudFormation template to include mappings for the copied AMIs.</strong></p><ul><li><p><strong>AMIs are Region-specific</strong>, ph·∫£i copy sang Regions kh√°c</p></li><li><p><strong>aws ec2 copy-image</strong> command ƒë∆°n gi·∫£n ƒë·ªÉ copy AMI cross-region</p></li><li><p><strong>Mappings</strong> trong CloudFormation cho ph√©p reference AMI ID kh√°c nhau per Region</p></li><li><p><strong>Most efficient</strong>: reuse existing template v·ªõi mappings, ch·ªâ thay ƒë·ªïi AMI IDs</p></li></ul><p></p><p><em>V√≠ d·ª• CloudFormation Mappings:</em></p><pre><code>Mappings:\n  RegionMap:\n    us-east-1:\n      AMI: ami-0abcdef1234567890\n    us-west-1:\n      AMI: ami-0123456789abcdef0\n    eu-west-1:\n      AMI: ami-0fedcba9876543210\n    ap-southeast-1:\n      AMI: ami-0987654321fedcba0\n\nResources:\n  MyEC2Instance:\n    Type: AWS::EC2::Instance\n    Properties:\n      ImageId: !FindInMap [RegionMap, !Ref \"AWS::Region\", AMI]\n      InstanceType: t3.medium</code></pre><p></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a snapshot of the running instance. Copy the snapshot to the other Regions. Create an AMI from the snapshots. Update the CloudFormation template for each Region to use the new AMI.</strong></p><ul><li><p><strong>Unnecessary steps</strong>: ƒë√£ c√≥ AMI s·∫µn, kh√¥ng c·∫ßn t·∫°o snapshot r·ªìi t·∫°o AMI l·∫°i</p></li><li><p>Inefficient so v·ªõi copy AMI tr·ª±c ti·∫øp</p></li></ul><p></p><p>‚ùå <strong>Run the existing CloudFormation template in each additional Region based on the success of the template that is used currently in us-east-1.</strong></p><ul><li><p><strong>S·∫Ω fail</strong> v√¨ AMI IDs trong template ch·ªâ valid ·ªü us-east-1</p></li><li><p>Kh√¥ng th·ªÉ d√πng AMI t·ª´ Region n√†y ·ªü Region kh√°c</p></li></ul><p></p><p>‚ùå <strong>Update the CloudFormation template to include the additional Regions in the Auto Scaling group. Update the existing stack in us-east-1.</strong></p><ul><li><p><strong>Auto Scaling group kh√¥ng span across Regions</strong></p></li><li><p>ASG ch·ªâ ho·∫°t ƒë·ªông trong single Region</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Deploy to multiple Regions + AMI\"</strong> ‚Üí <strong>Copy AMI</strong> + <strong>CloudFormation Mappings</strong></p></li><li><p><strong>AMIs are Region-specific</strong> ‚Üí Ph·∫£i copy sang Region kh√°c</p></li><li><p><strong>CloudFormation Mappings</strong> ‚Üí Define Region-specific values (AMI IDs, AZ names...)</p></li><li><p><strong>Auto Scaling groups</strong> ‚Üí Single Region only, kh√¥ng cross-region</p></li><li><p><strong>Pattern</strong>: Copy AMI ‚Üí Update mappings ‚Üí Deploy template per Region</p></li><li><p><strong>Avoid</strong>: Snapshot ‚Üí AMI khi ƒë√£ c√≥ AMI s·∫µn (redundant steps)</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/blogs/aws/ec2-ami-copy-between-regions/\">Copying an AMI across Regions</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/mappings-section-structure.html\">CloudFormation Mappings</a></p></li></ul>",
            "correctAnswer": [
                "<p>Copy the AMI to each Region by using the aws ec2 copy-image command. Update the CloudFormation template to include mappings for the copied AMIs.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Copy the AMI to each Region by using the aws ec2 copy-image command. Update the CloudFormation template to include mappings for the copied AMIs.</p>",
                "<p>Create a snapshot of the running instance. Copy the snapshot to the other Regions. Create an AMI from the snapshots. Update the CloudFormation template for each Region to use the new AMI.</p>",
                "<p>Run the existing CloudFormation template in each additional Region based on the success of the template that is used currently in us-east-1.</p>",
                "<p>Update the CloudF ormation template to include the additional Regions in the Auto Scaling group. Update the existing stack in us-east-1.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 51
        },
        {
            "attemptAnswerId": 329193,
            "questionId": 6417,
            "questionText": "<p>A company runs an application on Amazon EC2 instances that are in an Amazon EC2 Auto Scaling group. Scale-out actions take a long time to become complete because of long-running boot scripts. A SysOps administrator must implement a solution to reduce the required time for scale-out actions without overprovisioning the Auto Scaling group.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Application ch·∫°y tr√™n <strong>EC2 instances trong Auto Scaling group</strong></p></li><li><p><strong>Scale-out actions m·∫•t nhi·ªÅu th·ªùi gian</strong> v√¨ <strong>long-running boot scripts</strong></p></li><li><p>Y√™u c·∫ßu: gi·∫£m th·ªùi gian scale-out <strong>without overprovisioning</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Add a warm pool to the Auto Scaling group.</strong></p><ul><li><p><strong>Warm pool</strong> pre-initializes instances ·ªü <strong>stopped state</strong> v·ªõi boot scripts ƒë√£ ch·∫°y xong</p></li><li><p>Khi c·∫ßn scale-out, ch·ªâ vi·ªác <strong>start instances</strong> t·ª´ warm pool (nhanh h∆°n nhi·ªÅu so v·ªõi launch m·ªõi)</p></li><li><p><strong>Kh√¥ng overprovision</strong> v√¨ instances trong warm pool ·ªü stopped state (kh√¥ng t√≠nh ph√≠ EC2, ch·ªâ t√≠nh ph√≠ EBS)</p></li><li><p>Gi·∫£m scale-out time t·ª´ v√†i ph√∫t xu·ªëng c√≤n v√†i gi√¢y</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Change the launch configuration to use a larger instance size.</strong></p><ul><li><p><strong>Larger instance kh√¥ng gi·∫£m boot script time</strong></p></li><li><p>TƒÉng cost m√† kh√¥ng gi·∫£i quy·∫øt root cause</p></li></ul><p></p><p>‚ùå <strong>Increase the minimum number of instances in the Auto Scaling group.</strong></p><ul><li><p>ƒê√¢y ch√≠nh l√† <strong>overprovisioning</strong> - vi ph·∫°m requirement</p></li><li><p>TƒÉng cost v√¨ ch·∫°y nhi·ªÅu instances h∆°n c·∫ßn thi·∫øt</p></li></ul><p></p><p>‚ùå <strong>Add a predictive scaling policy to the Auto Scaling group.</strong></p><ul><li><p><strong>Predictive scaling</strong> d·ª± ƒëo√°n demand v√† scale proactively</p></li><li><p>V·∫´n ph·∫£i ch·ªù boot scripts ch·∫°y khi launch instances m·ªõi</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Long boot time + fast scale-out\"</strong> ‚Üí <strong>Warm pool</strong></p></li><li><p><strong>\"Without overprovisioning\"</strong> ‚Üí Warm pool (stopped instances, lower cost)</p></li><li><p><strong>Warm pool</strong> ‚Üí Pre-initialized instances s·∫µn s√†ng start nhanh</p></li><li><p><strong>Warm pool states</strong>: Stopped, Running, Hibernated</p></li><li><p><strong>Cost</strong>: Stopped instances ch·ªâ t√≠nh ph√≠ EBS storage, kh√¥ng t√≠nh compute</p></li><li><p><strong>Predictive scaling</strong> ‚Üí Forecast demand, kh√¥ng gi·∫£m boot time</p></li><li><p><strong>Pattern</strong>: Warm pool gi·∫£m launch time t·ª´ minutes xu·ªëng seconds</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-warm-pools.html\">Auto Scaling warm pools</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add a warm pool to the Auto Scaling group.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Change the launch configuration to use a larger instance size.</p>",
                "<p>Increase the minimum number of instances in the Auto Scaling group.</p>",
                "<p>Add a predictive scaling policy to the Auto Scaling group.</p>",
                "<p>Add a warm pool to the Auto Scaling group.</p>"
            ],
            "answersPos": "[0,1,3,2]",
            "pos": 52
        },
        {
            "attemptAnswerId": 329194,
            "questionId": 8851,
            "questionText": "<p>A company wants to monitor the security groups of its Amazon EC2 instances to ensure that SSH is not open to the public. If the port is opened, the company needs to close the port as soon as possible.<br><br>Which combination of actions should a SysOps administrator take to meet these requirements? (Choose two.)</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>C·∫ßn monitor <strong>security groups c·ªßa EC2 instances</strong></p></li><li><p>ƒê·∫£m b·∫£o <strong>SSH kh√¥ng open to public</strong></p></li><li><p>N·∫øu port m·ªü, c·∫ßn <strong>close port as soon as possible</strong></p></li><li><p>Y√™u c·∫ßu: detect + remediate</p></li></ul><p></p><p>‚úÖ ƒê√°p √°n ƒë√∫ng:</p><p><strong>Add an AWS Config rule to detect the security groups that allow SSH.</strong></p><ul><li><p><strong>AWS Config</strong> c√≥ managed rule <strong>restricted-ssh</strong> ƒë·ªÉ detect security groups cho ph√©p SSH t·ª´ 0.0.0.0/0</p></li><li><p>Continuous monitoring v√† evaluation c·ªßa security group configurations</p></li><li><p>T·ª± ƒë·ªông detect non-compliant security groups</p></li></ul><p></p><p><strong>Call an AWS Systems Manager Automation runbook to close the port.</strong></p><ul><li><p><strong>Systems Manager Automation</strong> c√≥ th·ªÉ t·ª± ƒë·ªông remediate b·∫±ng c√°ch modify security group rules</p></li><li><p><strong>Runbook</strong> ch·ª©a automation logic ƒë·ªÉ remove SSH rule kh·ªèi security group</p></li><li><p>Integrate v·ªõi AWS Config cho <strong>automatic remediation</strong></p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Add an Amazon CloudWatch alarm to detect the security groups that allow SSH.</strong></p><ul><li><p><strong>CloudWatch alarm</strong> monitor metrics, kh√¥ng evaluate security group rules</p></li><li><p>Kh√¥ng c√≥ built-in capability ƒë·ªÉ detect security group misconfigurations</p></li></ul><p></p><p>‚ùå <strong>Add an assessment template to Amazon Inspector to detect the security groups that allow SSH.</strong></p><ul><li><p><strong>Amazon Inspector</strong> scan vulnerabilities trong EC2 instances v√† containers</p></li><li><p>Kh√¥ng monitor ho·∫∑c evaluate security group configurations</p></li></ul><p></p><p>‚ùå <strong>Call AWS Systems Manager Run Command to close the port.</strong></p><ul><li><p><strong>Run Command</strong> ch·∫°y commands/scripts <strong>tr√™n EC2 instances</strong></p></li><li><p>Security group l√† <strong>AWS resource</strong>, kh√¥ng ph·∫£i instance-level configuration</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Detect security group violations\"</strong> ‚Üí <strong>AWS Config</strong> managed rules</p></li><li><p><strong>\"Automatic remediation of AWS resources\"</strong> ‚Üí <strong>Systems Manager Automation</strong></p></li><li><p><strong>AWS Config rules</strong>: restricted-ssh, restricted-common-ports</p></li><li><p><strong>CloudWatch</strong> ‚Üí Metrics monitoring, kh√¥ng ph·∫£i config compliance</p></li><li><p><strong>Inspector</strong> ‚Üí Vulnerability scanning, kh√¥ng ph·∫£i security group rules</p></li><li><p><strong>Run Command</strong> ‚Üí Execute tr√™n instances, kh√¥ng modify AWS resources</p></li><li><p><strong>Automation runbook</strong> ‚Üí Modify AWS resources (security groups, IAM, etc.)</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/config/latest/developerguide/restricted-ssh.html\">AWS Config restricted-ssh rule</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-automation.html\">AWS Systems Manager Automation</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/config/latest/developerguide/remediation.html\">Remediating noncompliant resources with AWS Config</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add an AWS Config rule to detect the security groups that allow SSH.</p>",
                "<p>Call an AWS Systems Manager Automation runbook to close the port.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add an Amazon CloudWatch alarm to detect the security groups that allow SSH.</p>",
                "<p>Add an AWS Config rule to detect the security groups that allow SSH.</p>",
                "<p>Add an assessment template to Amazon Inspector to detect the security groups that allow SSH.</p>",
                "<p>Call an AWS Systems Manager Automation runbook to close the port.</p>",
                "<p>Call AWS Systems Manager Run Command to close the port.</p>"
            ],
            "answersPos": "[4,3,2,1,0]",
            "pos": 53
        },
        {
            "attemptAnswerId": 329195,
            "questionId": 6419,
            "questionText": "<p>A company is managing multiple AWS accounts in AWS Organizations. The company is reviewing internal security of its AWS environment. The company‚Äôs security administrator has their own AWS account and wants to review the VPC configuration of developer AWS accounts.<br><br>Which solution will meet these requirements in the MOST secure manner?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company qu·∫£n l√Ω <strong>multiple AWS accounts</strong> trong <strong>AWS Organizations</strong></p></li><li><p><strong>Security administrator</strong> c√≥ AWS account ri√™ng</p></li><li><p>C·∫ßn <strong>review VPC configuration</strong> c·ªßa c√°c <strong>developer AWS accounts</strong></p></li><li><p>Y√™u c·∫ßu: <strong>MOST secure manner</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create an IAM policy in each developer account that has read-only access related to VPC resources. Assign the policy to a cross-account IAM role. Ask the security administrator to assume the role from their account.</strong></p><ul><li><p><strong>Cross-account IAM role</strong> l√† best practice cho cross-account access, kh√¥ng c·∫ßn share credentials</p></li><li><p><strong>Read-only access</strong> ƒë·ªß ƒë·ªÉ review configuration, tu√¢n th·ªß <strong>principle of least privilege</strong></p></li><li><p>Security administrator <strong>assume role</strong> t·ª´ account c·ªßa m√¨nh, c√≥ audit trail trong CloudTrail</p></li><li><p><strong>Most secure</strong>: kh√¥ng share credentials + minimum permissions + traceable access</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create an IAM policy in each developer account that has read-only access related to VPC resources. Assign the policy to an IAM user. Share the user credentials with the security administrator.</strong></p><ul><li><p><strong>Sharing credentials</strong> l√† security anti-pattern</p></li><li><p>Kh√¥ng th·ªÉ audit ƒë∆∞·ª£c ai ƒëang s·ª≠ d·ª•ng shared credentials</p></li></ul><p></p><p>‚ùå <strong>Create an IAM policy in each developer account that has administrator access to all Amazon EC2 actions, including VPC actions. Assign the policy to an IAM user. Share the user credentials with the security administrator.</strong></p><ul><li><p><strong>Administrator access</strong> vi ph·∫°m principle of least privilege</p></li><li><p>Sharing credentials + excessive permissions = kh√¥ng secure</p></li></ul><p></p><p>‚ùå <strong>Create an IAM policy in each developer account that has administrator access related to VPC resources. Assign the policy to a cross-account IAM role. Ask the security administrator to assume the role from their account.</strong></p><ul><li><p><strong>Administrator access</strong> qu√° r·ªông cho review task</p></li><li><p>Ch·ªâ c·∫ßn read-only ƒë·ªÉ review configuration</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Cross-account access + most secure\"</strong> ‚Üí <strong>Cross-account IAM role</strong></p></li><li><p><strong>\"Review/audit permissions\"</strong> ‚Üí <strong>Read-only access</strong> (least privilege)</p></li><li><p><strong>Never share credentials</strong> ‚Üí Use IAM roles instead</p></li><li><p><strong>Cross-account role benefits</strong>: No credential sharing, auditable, temporary credentials</p></li><li><p><strong>Principle of least privilege</strong>: Ch·ªâ c·∫•p minimum permissions c·∫ßn thi·∫øt</p></li><li><p><strong>Pattern</strong>: Cross-account role &gt; Shared credentials</p></li><li><p><strong>Administrator access</strong>: Ch·ªâ khi th·ª±c s·ª± c·∫ßn modify resources</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html\">Cross-account access with IAM roles</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://repost.aws/questions/QUB_YpztZ4QjOvkvYfFWLUEA/iam-role-best-practices-for-multi-account-architecture\">IAM best practices for cross-account access</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an IAM policy in each developer account that has read-only access related to VPC resources. Assign the policy to a cross-account IAM role. Ask the security administrator to assume the role from their account.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an IAM policy in each developer account that has read-only access related to VPC resources. Assign the policy to an IAM user. Share the user credentials with the security administrator.</p>",
                "<p>Create an IAM policy in each developer account that has administrator access to all Amazon EC2 actions, including VPC actions. Assign the policy to an IAM user. Share the user credentials with the security administrator.</p>",
                "<p>Create an IAM policy in each developer account that has administrator access related to VPC resources. Assign the policy to a cross-account IAM role. Ask the security administrator to assume the role from their account.</p>",
                "<p>Create an IAM policy in each developer account that has read-only access related to VPC resources. Assign the policy to a cross-account IAM role. Ask the security administrator to assume the role from their account.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 54
        },
        {
            "attemptAnswerId": 329196,
            "questionId": 6420,
            "questionText": "<p>A company runs a web application that users access using the name www example com. The company manages the domain name example.com using Amazon Route 53. The company created an Amazon CloudFront distribution in front of the application and would like www.example.com to access the application through CloudFront.<br><br>What is the MOST cost-effective way to achieve this?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Web application ƒë∆∞·ª£c users truy c·∫≠p qua <strong>www.example.com</strong></p></li><li><p>Domain <strong>example.com</strong> ƒë∆∞·ª£c qu·∫£n l√Ω b·ªüi <strong>Route 53</strong></p></li><li><p>ƒê√£ t·∫°o <strong>CloudFront distribution</strong> ƒë·∫∑t tr∆∞·ªõc application</p></li><li><p>Y√™u c·∫ßu: <strong>www.example.com</strong> truy c·∫≠p qua CloudFront</p></li><li><p>M·ª•c ti√™u: <strong>MOST cost-effective</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create an ALIAS record in Amazon Route 53 that points to the CloudFront distribution URL.</strong></p><ul><li><p><strong>ALIAS record</strong> l√† AWS-specific, map hostname ƒë·∫øn AWS resources (CloudFront, ALB, S3...)</p></li><li><p><strong>Free of charge</strong> cho queries ƒë·∫øn AWS resources qua ALIAS records</p></li><li><p>H·ªó tr·ª£ <strong>zone apex</strong> v√† <strong>subdomains</strong> (example.com v√† www.example.com)</p></li><li><p><strong>Most cost-effective</strong>: kh√¥ng t√≠nh ph√≠ queries nh∆∞ CNAME</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a CNAME record in Amazon Route 53 that points to the CloudFront distribution URL.</strong></p><ul><li><p>CNAME ho·∫°t ƒë·ªông ƒë∆∞·ª£c nh∆∞ng <strong>t√≠nh ph√≠ cho DNS queries</strong></p></li><li><p><strong>CNAME kh√¥ng support zone apex</strong> (example.com), ch·ªâ subdomains (www.example.com)</p></li></ul><p></p><p>‚ùå <strong>Create an A record in Amazon Route 53 that points to the public IP address of the web application.</strong></p><ul><li><p><strong>A record c·∫ßn IP address</strong>, CloudFront distribution kh√¥ng c√≥ static IP</p></li><li><p>Point tr·ª±c ti·∫øp ƒë·∫øn web application, <strong>bypass CloudFront</strong></p></li></ul><p></p><p>‚ùå <strong>Create a PTR record in Amazon Route 53 that points to the public IP address of the web application.</strong></p><ul><li><p><strong>PTR record</strong> d√πng cho <strong>reverse DNS lookup</strong> (IP ‚Üí hostname)</p></li><li><p>Kh√¥ng ph√π h·ª£p cho forward lookup (hostname ‚Üí resource)</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Route 53 to CloudFront/ALB/S3\"</strong> ‚Üí <strong>ALIAS record</strong> (cost-effective)</p></li><li><p><strong>\"Most cost-effective DNS routing\"</strong> ‚Üí ALIAS over CNAME</p></li><li><p><strong>ALIAS record benefits</strong>: Free queries, zone apex support, AWS resource integration</p></li><li><p><strong>CNAME</strong> ‚Üí Map hostname to hostname, c√≥ ph√≠ queries, kh√¥ng support zone apex</p></li><li><p><strong>A record</strong> ‚Üí Map hostname to IP address</p></li><li><p><strong>PTR record</strong> ‚Üí Reverse DNS (IP to hostname)</p></li><li><p><strong>Pattern</strong>: ALIAS (AWS resources, free) &gt; CNAME (external, c√≥ ph√≠)</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-cloudfront-distribution.html\">Route 53 ALIAS records</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html\">Choosing between alias and non-alias records</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an ALIAS record in Amazon Route 53 that points to the CloudFront distribution URL.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a CNAME record in Amazon Route 53 that points to the CloudFront distribution URL.</p>",
                "<p>Create an ALIAS record in Amazon Route 53 that points to the CloudFront distribution URL.</p>",
                "<p>Create an A record in Amazon Route 53 that points to the public IP address of the web application,</p>",
                "<p>Create a PTR record in Amazon Route 53 that points to the public IP address of the web application.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 55
        },
        {
            "attemptAnswerId": 329197,
            "questionId": 6421,
            "questionText": "<p>A company hosts a production MySQL database on an Amazon Aurora single-node DB cluster. The database is queried heavily for reporting purposes. The DB cluster is experiencing periods of performance degradation because of high CPU utilization and maximum connections errors. A SysOps administrator needs to improve the stability of the database.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Production MySQL database tr√™n <strong>Aurora single-node DB cluster</strong></p></li><li><p>Database ƒë∆∞·ª£c <strong>query heavily for reporting</strong></p></li><li><p>G·∫∑p <strong>performance degradation</strong> do <strong>high CPU utilization</strong> v√† <strong>maximum connections errors</strong></p></li><li><p>Y√™u c·∫ßu: improve database stability</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create an Aurora Replica node. Create an Auto Scaling policy to scale replicas based on CPU utilization. Ensure that all reporting requests use the read-only connection string</strong></p><ul><li><p><strong>Aurora Replicas</strong> offload (gi·∫£m t·∫£i) read traffic (reporting) kh·ªèi primary node</p></li><li><p><strong>Auto Scaling</strong> t·ª± ƒë·ªông th√™m/b·ªõt replicas d·ª±a tr√™n CPU utilization</p></li><li><p><strong>Read-only connection string</strong> t·ª± ƒë·ªông distribute reporting queries ƒë·∫øn replicas</p></li><li><p>Gi·∫£i quy·∫øt c·∫£ <strong>high CPU</strong> (ph√¢n t√°n read load) v√† <strong>max connections</strong> (th√™m connection capacity)</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a second Aurora MySQL single-node DB cluster in a second Availability Zone. Ensure that all reporting requests use the connection string for this additional node</strong></p><ul><li><p>T·∫°o <strong>separate cluster</strong> kh√¥ng replicate data t·ª± ƒë·ªông</p></li><li><p>C·∫ßn manual data sync mechanism, kh√¥ng ph·∫£i Aurora native solution</p></li></ul><p></p><p>‚ùå <strong>Create an AWS Lambda function that caches reporting requests. Ensure that all reporting requests call the Lambda function</strong></p><ul><li><p>Lambda c√≥ <strong>15 ph√∫t execution limit</strong>, kh√¥ng ph√π h·ª£p cho long-running reports</p></li><li><p>Caching logic ph·ª©c t·∫°p, kh√¥ng gi·∫£i quy·∫øt root cause</p></li></ul><p></p><p>‚ùå <strong>Create a multi-node Amazon ElastiCache cluster. Ensure that all reporting requests use the ElastiCache cluster. Use the database if the data is not in the cache.</strong></p><ul><li><p><strong>Cache-aside pattern</strong> y√™u c·∫ßu application code changes</p></li><li><p>Kh√¥ng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ khi cache miss (v·∫´n query database)</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Aurora read-heavy workload + high CPU\"</strong> ‚Üí <strong>Aurora Replicas</strong> + Read endpoint</p></li><li><p><strong>\"Reporting queries performance\"</strong> ‚Üí Offload to read replicas</p></li><li><p><strong>Aurora Replicas benefits</strong>: Up to 15 replicas, auto-scaling, separate read endpoint</p></li><li><p><strong>Read-only endpoint</strong> ‚Üí Automatically load balances across replicas</p></li><li><p><strong>Auto Scaling replicas</strong> ‚Üí Scale based on CPU, connections, ho·∫∑c custom metrics</p></li><li><p><strong>ElastiCache</strong> ‚Üí Good for caching, nh∆∞ng Aurora Replicas native solution cho Aurora</p></li><li><p><strong>Pattern</strong>: Read replicas &gt; Separate cluster &gt; Caching layer</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html\">Aurora Replicas</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html\">Aurora Auto Scaling with Aurora Replicas</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Endpoints.Reader.html\">Using Aurora Reader endpoints</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an Aurora Replica node. Create an Auto Scaling policy to scale replicas based on CPU utilization. Ensure that all reporting requests use the read-only connection string</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an Aurora Replica node. Create an Auto Scaling policy to scale replicas based on CPU utilization. Ensure that all reporting requests use the read-only connection string</p>",
                "<p>Create a second Aurora MySQL single-node DB cluster in a second Availability Zone. Ensure that all reporting requests use the connection string for this additional node</p>",
                "<p>Create an AWS Lambda function that caches reporting requests. Ensure that all reporting requests call the Lambda function</p>",
                "<p>Create a multi-node Amazon ElastiCache cluster. Ensure that all reporting requests use the ElastiCache cluster. Use the database if the data is not in the cache.</p>"
            ],
            "answersPos": "[2,0,3,1]",
            "pos": 56
        },
        {
            "attemptAnswerId": 329198,
            "questionId": 6422,
            "questionText": "<p>A company has set up an IPsec tunnel between its AWS environment and its on-premises data center. The tunnel is reporting as UP, but the Amazon EC2 instances are not able to ping any on-premises resources.<br><br>What should a SysOps administrator do to resolve this issue?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>ƒê√£ setup <strong>IPsec tunnel</strong> gi·ªØa AWS v√† <strong>on-premises data center</strong></p></li><li><p>Tunnel status l√† <strong>UP</strong></p></li><li><p><strong>EC2 instances kh√¥ng th·ªÉ ping</strong> on-premises resources</p></li><li><p>Y√™u c·∫ßu: resolve connectivity issue</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Enable route propagation for the virtual private gateway in the route table that is assigned to the subnet of the EC2 instances.</strong></p><ul><li><p>Tunnel UP nh∆∞ng kh√¥ng c√≥ connectivity th∆∞·ªùng do <strong>thi·∫øu routes</strong></p></li><li><p><strong>Route propagation</strong> t·ª± ƒë·ªông add routes t·ª´ <strong>Virtual Private Gateway (VGW)</strong> v√†o route table</p></li><li><p>Routes n√†y ch·ªâ ƒë∆∞·ªùng traffic t·ª´ VPC subnet ƒë·∫øn on-premises networks qua VPN</p></li><li><p>Enable route propagation l√† c√°ch ƒë∆°n gi·∫£n nh·∫•t ƒë·ªÉ configure routing cho VPN connections</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a new inbound rule on the EC2 instances' security groups to allow ICMP traffic from the on-premises CIDR.</strong></p><ul><li><p>Security groups control traffic <strong>ƒë·∫øn instances</strong>, kh√¥ng ·∫£nh h∆∞·ªüng routing</p></li><li><p>N·∫øu kh√¥ng c√≥ routes, traffic kh√¥ng ƒë·∫øn ƒë∆∞·ª£c security group layer</p></li></ul><p></p><p>‚ùå <strong>Create a peering connection between the IPsec tunnel and the subnet of the EC2 instances.</strong></p><ul><li><p><strong>VPC peering</strong> d√πng ƒë·ªÉ connect <strong>hai VPCs</strong>, kh√¥ng ph·∫£i VPN tunnel v·ªõi subnet</p></li><li><p>IPsec tunnel kh√¥ng ph·∫£i VPC resource c√≥ th·ªÉ peer</p></li></ul><p></p><p>‚ùå <strong>Modify the VPC's DHCP options set. Add the IPsec tunnel to the VPN section.</strong></p><ul><li><p><strong>DHCP options</strong> configure DNS, NTP, domain name cho instances</p></li><li><p>Kh√¥ng li√™n quan ƒë·∫øn routing traffic qua VPN</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"VPN tunnel UP but no connectivity\"</strong> ‚Üí <strong>Missing routes</strong> ‚Üí Enable route propagation</p></li><li><p><strong>Route propagation</strong> ‚Üí Automatically add VPN routes v√†o route table</p></li><li><p><strong>Virtual Private Gateway</strong> ‚Üí AWS-side VPN endpoint</p></li><li><p><strong>Common VPN issues</strong>: Routes missing &gt; Security groups &gt; Network ACLs</p></li><li><p><strong>Security groups/NACLs</strong> ‚Üí Control traffic flow, kh√¥ng affect routing decisions</p></li><li><p><strong>VPC Peering</strong> ‚Üí VPC-to-VPC, kh√¥ng ph·∫£i VPN-related</p></li><li><p><strong>Pattern</strong>: VPN connectivity = Tunnel UP + Routes configured + Security rules allow</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/vpn/latest/s2svpn/VPNRoutingTypes.html\">Site-to-Site VPN route propagation</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://repost.aws/knowledge-center/routing-dx-private-virtual-interface\">Virtual private gateway route propagation</a></p></li></ul>",
            "correctAnswer": [
                "<p>Enable route propagation for the virtual private gateway in the route table that is assigned to the subnet of the EC2 instances.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a new inbound rule on the EC2 instances‚Äô security groups to allow ICMP traffic from the on-premises CIDR.</p>",
                "<p>Create a peering connection between the IPsec tunnel and the subnet of the EC2 instances.</p>",
                "<p>Enable route propagation for the virtual private gateway in the route table that is assigned to the subnet of the EC2 instances.</p>",
                "<p>Modify the VPC‚Äôs DHCP options set. Add the IPsec tunnel to the VPN section.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 57
        },
        {
            "attemptAnswerId": 329199,
            "questionId": 6423,
            "questionText": "<p>A SysOps administrator is configuring Amazon CloudWatch alarms. A particular is constantly in the ALARM state.<br><br>What could be the reason for this issue?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>ƒêang configure <strong>CloudWatch alarms</strong></p></li><li><p>M·ªôt alarm <strong>constantly in ALARM state</strong></p></li><li><p>Y√™u c·∫ßu: t√¨m nguy√™n nh√¢n</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Alarms continue to evaluate metrics against configured thresholds, even after they are triggered.</strong></p><ul><li><p>CloudWatch alarms <strong>continuously evaluate metrics</strong> theo configured period</p></li><li><p>N·∫øu metric <strong>v·∫´n vi ph·∫°m threshold</strong>, alarm s·∫Ω <strong>remain in ALARM state</strong></p></li><li><p>Alarm ch·ªâ return v·ªÅ OK state khi metric value <strong>kh√¥ng c√≤n vi ph·∫°m threshold</strong></p></li><li><p>ƒê√¢y l√† <strong>normal behavior</strong> c·ªßa CloudWatch alarms - reflect actual metric state</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>After alarms are triggered, they remain in the ALARM state until they are manually disabled.</strong></p><ul><li><p>CloudWatch alarms <strong>t·ª± ƒë·ªông transition</strong> gi·ªØa OK, ALARM, INSUFFICIENT_DATA states</p></li><li><p>Kh√¥ng c·∫ßn manual intervention ƒë·ªÉ reset alarm state</p></li></ul><p></p><p>‚ùå <strong>After an alarm is triggered and an action is performed, the application logic must reset the alarm to its normal state.</strong></p><ul><li><p><strong>Application kh√¥ng reset alarm state</strong></p></li><li><p>Alarm state d·ª±a tr√™n metric evaluation, kh√¥ng ph·∫£i application control</p></li></ul><p></p><p>‚ùå <strong>The alarm is not receiving appropriate metrics.</strong></p><ul><li><p>N·∫øu kh√¥ng nh·∫≠n metrics, alarm s·∫Ω ·ªü <strong>INSUFFICIENT_DATA state</strong>, kh√¥ng ph·∫£i ALARM</p></li><li><p>ALARM state nghƒ©a l√† c√≥ metrics v√† ƒëang vi ph·∫°m threshold</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Alarm constantly in ALARM\"</strong> ‚Üí <strong>Metric v·∫´n vi ph·∫°m threshold</strong></p></li><li><p><strong>CloudWatch alarm states</strong>: OK, ALARM, INSUFFICIENT_DATA</p></li><li><p><strong>ALARM state</strong> ‚Üí Metric breaches threshold</p></li><li><p><strong>OK state</strong> ‚Üí Metric within threshold</p></li><li><p><strong>INSUFFICIENT_DATA</strong> ‚Üí Not enough data points ho·∫∑c missing metrics</p></li><li><p><strong>Alarms auto-transition</strong> based on metric evaluation, kh√¥ng c·∫ßn manual reset</p></li><li><p><strong>Pattern</strong>: Fix underlying issue (metric value) ‚Üí Alarm t·ª± ƒë·ªông return OK</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://repost.aws/knowledge-center/cloudwatch-alarm-transitions\">CloudWatch alarm states</a></p></li></ul>",
            "correctAnswer": [
                "<p>Alarms continue to evaluate metrics against configured thresholds, even after they are triggered.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Alarms continue to evaluate metrics against configured thresholds, even after they are triggered.</p>",
                "<p>After alarms are triggered, they remain in the ALARM state until they are manually disabled.</p>",
                "<p>After an alarm is triggered and an action is performed, the application logic must reset the alarm to its normal state.</p>",
                "<p>The alarm is not receiving appropriate metrics.</p>"
            ],
            "answersPos": "[3,0,2,1]",
            "pos": 58
        },
        {
            "attemptAnswerId": 329200,
            "questionId": 6424,
            "questionText": "<p>A company's security policy states that connecting to Amazon EC2 instances is not permitted through SSH and ROP. If access is required, authorized staff can connect to instances by using AWS Systems Manager Session Manager.<br><br>Users report that they are unable to connect to one specific Amazon EC2 instance that is running Ubuntu and has AWS Systems Manager Agent (SSM Agent) pre-installed. These users are able to use Session Manager to connect to other instances in the same subnet, and they are in an IAM group that has Session Manager permission for all instances.<br><br>What should a SysOps administrator do to resolve this issue?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Security policy: <strong>kh√¥ng cho ph√©p SSH v√† RDP</strong>, ch·ªâ d√πng <strong>Systems Manager Session Manager</strong></p></li><li><p>Users <strong>kh√¥ng th·ªÉ connect</strong> ƒë·∫øn <strong>m·ªôt specific Ubuntu EC2 instance</strong></p></li><li><p>Instance ƒë√£ c√≥ <strong>SSM Agent pre-installed</strong></p></li><li><p>Users <strong>c√≥ th·ªÉ connect ƒë·∫øn other instances</strong> trong c√πng subnet</p></li><li><p>Users trong <strong>IAM group c√≥ Session Manager permission</strong> cho t·∫•t c·∫£ instances</p></li><li><p>Y√™u c·∫ßu: resolve connectivity issue cho Ubuntu instance n√†y</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Assign the AmazonSSMManagedInstanceCore managed policy to the EC2 instance profile for the Ubuntu instance.</strong></p><ul><li><p>Session Manager c·∫ßn <strong>instance profile</strong> v·ªõi permissions ƒë·ªÉ communicate v·ªõi Systems Manager</p></li><li><p><strong>AmazonSSMManagedInstanceCore</strong> policy cung c·∫•p permissions cho SSM Agent</p></li><li><p>Users connect ƒë∆∞·ª£c ƒë·∫øn other instances nghƒ©a l√† <strong>instance n√†y thi·∫øu IAM role/profile</strong></p></li><li><p>Assign policy n√†y cho instance profile s·∫Ω cho ph√©p SSM Agent register v·ªõi Systems Manager</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Add an inbound rule for port 22 in the security group associated with the Ubuntu instance.</strong></p><ul><li><p><strong>Session Manager kh√¥ng c·∫ßn inbound rules</strong> trong security groups</p></li><li><p>Session Manager ho·∫°t ƒë·ªông qua <strong>outbound HTTPS (port 443)</strong> ƒë·∫øn Systems Manager endpoints</p></li></ul><p></p><p>‚ùå <strong>Configure the SSM Agent to log in with a user name of \"ubuntu\".</strong></p><ul><li><p><strong>SSM Agent kh√¥ng c·∫ßn username configuration</strong> cho Session Manager</p></li><li><p>Session Manager t·ª± ƒë·ªông handle authentication qua IAM</p></li></ul><p></p><p>‚ùå <strong>Generate a new key pair, configure Session Manager to use this new key pair, and provide the private key to the users.</strong></p><ul><li><p><strong>Session Manager kh√¥ng d√πng SSH key pairs</strong></p></li><li><p>Authentication th√¥ng qua IAM permissions, kh√¥ng ph·∫£i SSH keys</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Session Manager cannot connect to specific instance\"</strong> ‚Üí <strong>Missing IAM instance profile/role</strong></p></li><li><p><strong>\"Other instances work, one doesn't\"</strong> ‚Üí Check instance-specific configuration (IAM role)</p></li><li><p><strong>Session Manager requirements</strong>: SSM Agent + IAM instance role + Outbound HTTPS</p></li><li><p><strong>AmazonSSMManagedInstanceCore</strong> ‚Üí Required permissions cho SSM Agent</p></li><li><p><strong>Session Manager no inbound rules</strong> ‚Üí Ho·∫°t ƒë·ªông qua outbound connections</p></li><li><p><strong>No SSH keys needed</strong> ‚Üí IAM-based authentication</p></li><li><p><strong>Pattern</strong>: Session Manager = SSM Agent + Instance IAM role + User IAM permissions</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-prerequisites.html\">Session Manager prerequisites</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ja_jp/aws-managed-policy/latest/reference/AmazonSSMManagedInstanceCore.html\">AmazonSSMManagedInstanceCore policy</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-troubleshooting.html\">Troubleshooting Session Manager</a></p></li></ul>",
            "correctAnswer": [
                "<p>Assign the AmazonSSMManagedInstanceCore managed policy to the EC2 instance profile for the Ubuntu instance.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add an inbound rule for port 22 in the security group associated with the Ubuntu instance.</p>",
                "<p>Assign the AmazonSSMManagedInstanceCore managed policy to the EC2 instance profile for the Ubuntu instance.</p>",
                "<p>Configure the SSM Agent to log in with a user name of ‚Äúubuntu‚Äù.</p>",
                "<p>Generate a new key pair, configure Session Manager to use this new key pair, and provide the private key to the users.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 59
        },
        {
            "attemptAnswerId": 329201,
            "questionId": 6425,
            "questionText": "<p>A company stores files on 50 Amazon S3 buckets in the same AWS Region. The company wants to connect to the S3 buckets securely over a private connection from its Amazon EC2 instances. The company needs a solution that produces no additional cost.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company l∆∞u files tr√™n <strong>50 S3 buckets</strong> trong <strong>c√πng AWS Region</strong></p></li><li><p>C·∫ßn connect <strong>securely over private connection</strong> t·ª´ <strong>EC2 instances</strong></p></li><li><p>Y√™u c·∫ßu: solution <strong>no additional cost</strong></p></li></ul><p></p><p>‚úÖ ƒê√°p √°n ƒë√∫ng:</p><p><strong>Create one gateway VPC endpoint for all the S3 buckets. Add the gateway VPC endpoint to the VPC route table.</strong></p><ul><li><p><strong>Gateway VPC endpoint cho S3</strong> ho√†n to√†n <strong>mi·ªÖn ph√≠</strong> (no data transfer charges, no hourly charges)</p></li><li><p><strong>M·ªôt gateway endpoint</strong> c√≥ th·ªÉ handle traffic ƒë·∫øn <strong>t·∫•t c·∫£ S3 buckets</strong> trong Region</p></li><li><p>Add v√†o <strong>route table</strong> ƒë·ªÉ route S3 traffic qua private endpoint thay v√¨ internet</p></li><li><p>ƒê√°p ·ª©ng y√™u c·∫ßu: private connection + no cost</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a gateway VPC endpoint for each S3 bucket. Attach the gateway VPC endpoints to each subnet inside the VPC.</strong></p><ul><li><p><strong>Kh√¥ng c·∫ßn endpoint ri√™ng</strong> cho t·ª´ng bucket - m·ªôt endpoint cover all buckets</p></li><li><p>Gateway endpoints <strong>attach to route tables</strong>, kh√¥ng attach to subnets</p></li></ul><p></p><p>‚ùå <strong>Create an interface VPC endpoint for each S3 bucket. Attach the interface VPC endpoints to each subnet inside the VPC.</strong></p><ul><li><p><strong>Interface endpoints c√≥ hourly charge</strong> + data processing charges</p></li><li><p>Kh√¥ng ƒë√°p ·ª©ng \"no additional cost\" requirement</p></li></ul><p></p><p>‚ùå <strong>Create one interface VPC endpoint for all the S3 buckets. Add the interface VPC endpoint to the VPC route table.</strong></p><ul><li><p>Interface endpoint <strong>c√≥ ph√≠</strong>, kh√¥ng ph·∫£i no cost solution</p></li><li><p>Interface endpoints <strong>attach to subnets</strong>, kh√¥ng add to route table</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Private S3 access + no cost\"</strong> ‚Üí <strong>Gateway VPC endpoint</strong></p></li><li><p><strong>\"Private access with cost\"</strong> ‚Üí <strong>Interface VPC endpoint</strong></p></li><li><p><strong>Gateway endpoint</strong>: Free, S3 v√† DynamoDB only, attach to route tables</p></li><li><p><strong>Interface endpoint</strong>: C√≥ ph√≠, many services, attach to subnets, use PrivateLink</p></li><li><p><strong>One gateway endpoint</strong> ‚Üí Covers all S3 buckets in Region</p></li><li><p><strong>Gateway endpoints kh√¥ng attach to subnets</strong> ‚Üí Add routes to route tables</p></li><li><p><strong>Pattern</strong>: S3/DynamoDB private access = Gateway endpoint (free)</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html\">Gateway VPC endpoints for S3</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://tutorialsdojo.com/vpc-interface-endpoint-vs-gateway-endpoint-in-aws/\">Gateway endpoints vs Interface endpoints</a></p></li></ul><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1764471824986-mbmtuoxi-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"243.29166666666666\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p>",
            "correctAnswer": [
                "<p>Create one gateway VPC endpoint for all the S3 buckets. Add the gateway VPC endpoint to the VPC route table.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a gateway VPC endpoint for each S3 bucket. Attach the gateway VPC endpoints to each subnet inside the VPC.</p>",
                "<p>Create an interface VPC endpoint for each S3 bucket. Attach the interface VPC endpoints to each subnet inside the VPC.</p>",
                "<p>Create one gateway VPC endpoint for all the S3 buckets. Add the gateway VPC endpoint to the VPC route table.</p>",
                "<p>Create one interface VPC endpoint for all the S3 buckets. Add the interface VPC endpoint to the VPC route table.</p>"
            ],
            "answersPos": "[2,0,3,1]",
            "pos": 60
        },
        {
            "attemptAnswerId": 329202,
            "questionId": 6426,
            "questionText": "<p>A company has an application that runs behind an Application Load Balancer (ALB) in the us-west-2 Region. An Amazon Route 53 record set contains an alias record for app.anycompany.com that references the ALB in us-west-2 and uses a simple routing policy. The application is experiencing an increase in users from other locations in the world. These users are experiencing high latency.<br><br>Most of the new users are close to the ap-southeast-2 Region. The company deploys a copy of the application to ap-southeast-2. A SysOps administrator must implement a solution that automatically routes requests to the lowest latency endpoint for users without changing the URL.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Application ch·∫°y sau <strong>ALB ·ªü us-west-2</strong></p></li><li><p>Route 53 c√≥ <strong>alias record</strong> cho <u>app.anycompany.com</u> v·ªõi <strong>simple routing policy</strong></p></li><li><p>Users t·ª´ <strong>other locations</strong> ƒëang g·∫∑p <strong>high latency</strong></p></li><li><p>Ph·∫ßn l·ªõn users g·∫ßn <strong>ap-southeast-2 Region</strong></p></li><li><p>ƒê√£ deploy <strong>copy of application</strong> ·ªü ap-southeast-2</p></li><li><p>Y√™u c·∫ßu: t·ª± ƒë·ªông route requests ƒë·∫øn <strong>lowest latency endpoint</strong> m√† <strong>kh√¥ng change URL</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Change the existing alias record to use a latency routing policy. Create two latency records, one record that references each ALB.</strong></p><ul><li><p><strong>Latency routing policy</strong> t·ª± ƒë·ªông route users ƒë·∫øn <strong>endpoint v·ªõi lowest latency</strong></p></li><li><p>Route 53 measure latency t·ª´ user's location ƒë·∫øn t·ª´ng Region</p></li><li><p>T·∫°o <strong>latency record cho m·ªói ALB</strong> (us-west-2 v√† ap-southeast-2)</p></li><li><p><strong>Same URL</strong> (app.anycompany.com), Route 53 t·ª± ƒë·ªông ch·ªçn best endpoint based on latency</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Add a new value to the existing alias record for app.anycompany.com with the DNS name of the new ALB in ap-southeast-2.</strong></p><ul><li><p><strong>Simple routing</strong> kh√¥ng support multiple values cho alias records to ALB</p></li><li><p>Kh√¥ng c√≥ logic ƒë·ªÉ ch·ªçn endpoint based on latency</p></li></ul><p></p><p>‚ùå <strong>Change the existing alias record to use a geolocation routing policy. Create two geolocation records, one record that references each ALB. Select the location that is closest to each Region.</strong></p><ul><li><p><strong>Geolocation routing</strong> d·ª±a tr√™n <strong>geographic location</strong>, kh√¥ng ph·∫£i actual latency</p></li><li><p>Kh√¥ng guarantee <strong>lowest latency</strong>, ch·ªâ based on configured geography rules</p></li></ul><p></p><p>‚ùå <strong>Change the existing alias record to use a multivalue routing policy. Add the DNS name of each ALB to the record.</strong></p><ul><li><p><strong>Multivalue routing</strong> return <strong>random subset</strong> of healthy resources</p></li><li><p>Kh√¥ng optimize based on latency, ch·ªâ provide multiple IPs for redundancy</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Route to lowest latency endpoint\"</strong> ‚Üí <strong>Latency routing policy</strong></p></li><li><p><strong>\"Geographic-based routing\"</strong> ‚Üí <strong>Geolocation routing policy</strong></p></li><li><p><strong>Latency routing</strong> ‚Üí Route 53 measures actual latency to endpoints</p></li><li><p><strong>Geolocation routing</strong> ‚Üí Based on user's geographic location</p></li><li><p><strong>Simple routing</strong> ‚Üí No intelligence, single resource</p></li><li><p><strong>Multivalue routing</strong> ‚Üí Return multiple values randomly, kh√¥ng optimize latency</p></li><li><p><strong>Pattern</strong>: Lowest latency = Latency routing | Closest geography = Geolocation</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-latency.html\">Route 53 latency-based routing</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html\">Choosing a routing policy</a></p></li></ul>",
            "correctAnswer": [
                "<p>Change the existing alias record to use a latency routing policy. Create two latency records, one record that references each ALB.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add a new value to the existing alias record for app.anycompany.com with the DNS name of the new ALB in ap-southeast-2.</p>",
                "<p>Change the existing alias record to use a geolocation routing policy. Create two geolocation records, one record that references each ALSelect the location that is closest to each Region.</p>",
                "<p>Change the existing alias record to use a latency routing policy. Create two latency records, one record that references each ALB.</p>",
                "<p>Change the existing alias record to use a multivalue routing policy Add the DNS name of each ALB to the record.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 61
        },
        {
            "attemptAnswerId": 329203,
            "questionId": 6427,
            "questionText": "<p>A developer creates an AWS Lambda function that runs when an object is put into an Amazon S3 bucket. The function reformats the object and places the object back into the S3 bucket. During testing, the developer notices a recursive invocation loop. The developer asks a SysOps administrator to immediately stop the recursive invocations.<br><br>What should the SysOps administrator do to stop the loop without errors?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Lambda function triggered khi <strong>object ƒë∆∞·ª£c put v√†o S3 bucket</strong></p></li><li><p>Function <strong>reformats object</strong> v√† <strong>places back v√†o c√πng S3 bucket</strong></p></li><li><p>G·∫∑p v·∫•n ƒë·ªÅ <strong>recursive invocation loop (l·∫∑p ƒë·ªá quy)</strong></p></li><li><p>Y√™u c·∫ßu: <strong>immediately stop recursive invocations</strong> m√† <strong>kh√¥ng g√¢y errors</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Set the function's reserved concurrency to 0.</strong></p><ul><li><p><strong>Reserved concurrency = 0</strong> ngay l·∫≠p t·ª©c <strong>throttle t·∫•t c·∫£ invocations</strong> c·ªßa function</p></li><li><p>Lambda s·∫Ω <strong>kh√¥ng execute</strong> cho ƒë·∫øn khi concurrency ƒë∆∞·ª£c increase l·∫°i</p></li><li><p><strong>Immediate effect</strong> v√† <strong>kh√¥ng g√¢y errors</strong> cho existing objects trong bucket</p></li><li><p>Cho ph√©p dev fix code tr∆∞·ªõc khi re-enable function</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Delete all the objects from the S3 bucket.</strong></p><ul><li><p><strong>Data loss</strong> - kh√¥ng ph·∫£i gi·∫£i ph√°p an to√†n</p></li><li><p>Kh√¥ng ngƒÉn function ch·∫°y n·∫øu c√≥ objects m·ªõi ƒë∆∞·ª£c upload</p></li></ul><p></p><p>‚ùå <strong>Update the S3 bucket policy to deny access for the function.</strong></p><ul><li><p>S3 bucket policy <strong>deny s·∫Ω cause errors</strong> khi Lambda tries to write</p></li><li><p><strong>Kh√¥ng immediately stop</strong> invocations, Lambda v·∫´n ch·∫°y v√† fail</p></li></ul><p></p><p>‚ùå <strong>Publish a new version of the function.</strong></p><ul><li><p><strong>Publishing version kh√¥ng stop</strong> function execution</p></li><li><p>Function v·∫´n ti·∫øp t·ª•c invoke trong loop</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Immediately stop Lambda execution\"</strong> ‚Üí <strong>Set reserved concurrency to 0</strong></p></li><li><p><strong>\"Lambda recursive loop\"</strong> ‚Üí Throttle function + fix trigger configuration</p></li><li><p><strong>Reserved concurrency = 0</strong> ‚Üí Throttles all invocations, no execution</p></li><li><p><strong>Fix recursive S3-Lambda loops</strong>: Use prefix/suffix filters, separate buckets, ho·∫∑c conditional logic</p></li><li><p><strong>Reserved concurrency</strong> ‚Üí Controls max concurrent executions (0 = throttle all)</p></li><li><p><strong>Bucket policy deny</strong> ‚Üí Causes errors, kh√¥ng prevent invocations</p></li><li><p><strong>Pattern</strong>: Stop Lambda immediately = Concurrency 0, sau ƒë√≥ fix root cause</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html\">Lambda reserved concurrency</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/blogs/compute/avoiding-recursive-invocation-with-amazon-s3-and-aws-lambda/\">Avoiding recursive invocation loops with S3</a></p></li></ul>",
            "correctAnswer": [
                "<p>Set the function‚Äôs reserved concurrency to 0.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Delete all the objects from the S3 bucket.</p>",
                "<p>Set the function‚Äôs reserved concurrency to 0.</p>",
                "<p>Update the S3 bucket policy to deny access for the function.</p>",
                "<p>Publish a new version of the function.</p>"
            ],
            "answersPos": "[0,3,2,1]",
            "pos": 62
        },
        {
            "attemptAnswerId": 329204,
            "questionId": 6428,
            "questionText": "<p>A company runs a high performance computing (HPC) application on an Amazon EC2 instance. The company needs to scale this architecture to two or more EC2 instances. The EC2 instances will need to communicate with each other at high speeds with low latency to support the application.<br><br>The company wants to ensure that the network performance can support the required communication between the EC2 instances<br><br>What should a SysOps administrator do to meet these requirements?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>HPC application ch·∫°y tr√™n <strong>EC2 instance</strong></p></li><li><p>C·∫ßn scale sang <strong>2 ho·∫∑c nhi·ªÅu EC2 instances</strong></p></li><li><p>EC2 instances c·∫ßn <strong>communicate at high speeds with low latency</strong></p></li><li><p>Y√™u c·∫ßu: ƒë·∫£m b·∫£o <strong>network performance support high-speed communication</strong></p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create a cluster placement group. Back up the existing EC2 instance to an Amazon Machine Image (AMI). Restore the EC2 instance from the AMI into the placement group. Launch the additional EC2 instances into the placement group.</strong></p><ul><li><p><strong>Cluster placement group</strong> ƒë·∫∑t instances <strong>physically close together</strong> trong single AZ</p></li><li><p>Cung c·∫•p <strong>low latency, high throughput</strong> network performance (up to 100 Gbps)</p></li><li><p><strong>T·ªëi ∆∞u cho HPC applications</strong> c·∫ßn inter-instance communication</p></li><li><p>Instances trong cluster placement group c√≥ <strong>enhanced networking</strong> capabilities</p></li></ul><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1764473443716-q8w4kywi-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"434.6666666666667\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Back up the existing EC2 instance to an Amazon Machine Image (AMI). Create a launch template from the existing EC2 instance by specifying the AMI. Create an Auto Scaling group and configure the desired instance count.</strong></p><ul><li><p><strong>Auto Scaling group</strong> kh√¥ng guarantee low latency communication</p></li><li><p>Instances c√≥ th·ªÉ deploy ·ªü <strong>different AZs ho·∫∑c physical locations</strong></p></li></ul><p></p><p>‚ùå <strong>Create a Network Load Balancer (NLB) and a target group. Launch the new EC2 instances and register them with the target group. Register the existing EC2 instance with the target group. Pass all application traffic through the NLB.</strong></p><ul><li><p><strong>NLB</strong> d√πng cho distribute incoming traffic, kh√¥ng optimize inter-instance communication</p></li><li><p>Adds <strong>latency</strong> thay v√¨ reduce latency</p></li></ul><p></p><p>‚ùå <strong>Back up the existing EC2 instance to an Amazon Machine Image (AMI). Create additional clones of the EC2 instance from the AMI in the same Availability Zone where the existing EC2 instance is located.</strong></p><ul><li><p><strong>C√πng AZ</strong> nh∆∞ng <strong>kh√¥ng guarantee physical proximity</strong></p></li><li><p>Kh√¥ng ƒë·∫£m b·∫£o low latency nh∆∞ cluster placement group</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"HPC + low latency + high-speed inter-instance communication\"</strong> ‚Üí <strong>Cluster placement group</strong></p></li><li><p><strong>\"High network throughput between instances\"</strong> ‚Üí Cluster placement group</p></li><li><p><strong>Placement group types</strong>: Cluster (low latency), Partition (distributed), Spread (high availability)</p></li><li><p><strong>Cluster placement group</strong>: Single AZ, physical proximity, best network performance</p></li><li><p><strong>Enhanced networking</strong> ‚Üí Automatically enabled trong cluster placement groups</p></li><li><p><strong>HPC workloads</strong> ‚Üí Always use cluster placement groups</p></li><li><p><strong>Pattern</strong>: HPC/tightly-coupled apps = Cluster placement group</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html\">Placement groups</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a cluster placement group. Back up the existing EC2 instance to an Amazon Machine Image (AMI). Restore the EC2 instance from the AMI into the placement group. Launch the additional EC2 instances into the placement group.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a cluster placement group. Back up the existing EC2 instance to an Amazon Machine Image (AMI). Restore the EC2 instance from the AMI into the placement group. Launch the additional EC2 instances into the placement group.</p>",
                "<p>Back up the existing EC2 instance to an Amazon Machine Image (AMI). Create a launch template from the existing EC2 instance by specifying the AMI. Create an Auto Scaling group and configure the desired instance count.</p>",
                "<p>Create a Network Load Balancer (NLB) and a target group. Launch the new EC2 instances and register them with the target group. Register the existing EC2 instance with the target group. Pass all application traffic through the NLB.</p>",
                "<p>Back up the existing EC2 instance to an Amazon Machine Image (AMI). Create additional clones of the EC2 instance from the AMI in the same Availability Zone where the existing EC2 instance is located.</p>"
            ],
            "answersPos": "[0,3,2,1]",
            "pos": 63
        },
        {
            "attemptAnswerId": 329205,
            "questionId": 8917,
            "questionText": "<p>A company uses an Amazon Simple Queue Service (Amazon SQS) standard queue with its application. The application sends messages to the queue with unique message bodies. The company decides to switch to an SQS FIFO queue.</p><p></p><p>What must the company do to migrate to an SQS FIFO queue?</p>",
            "explanation": "<p>üìù <u>T√≥m t·∫Øt ƒë·ªÅ:</u></p><ul><li><p>Company ƒëang d√πng <strong>SQS standard queue</strong></p></li><li><p>Application g·ª≠i messages v·ªõi <strong>unique message bodies</strong></p></li><li><p>Quy·∫øt ƒë·ªãnh <strong>switch sang SQS FIFO queue</strong></p></li><li><p>Y√™u c·∫ßu: migrate t·ª´ standard sang FIFO queue</p></li></ul><p></p><p>‚úÖ <u>ƒê√°p √°n ƒë√∫ng:</u></p><p><strong>Create a new SQS FIFO queue. Turn on content-based deduplication on the new FIFO queue. Update the application to include a message group ID in the messages.</strong></p><ul><li><p><strong>Kh√¥ng th·ªÉ convert</strong> standard queue sang FIFO queue - ph·∫£i <strong>create new queue</strong></p></li><li><p><strong>Content-based deduplication</strong> s·ª≠ d·ª•ng SHA-256 hash c·ªßa message body ƒë·ªÉ deduplicate (ph√π h·ª£p v√¨ messages c√≥ unique bodies)</p></li><li><p><strong>Message group ID</strong> required cho FIFO queues ƒë·ªÉ maintain ordering within groups</p></li><li><p>ƒê√°p ·ª©ng ƒë·∫ßy ƒë·ªß FIFO requirements: ordering + deduplication</p></li></ul><p></p><p><u>C√°c ƒë√°p √°n sai:</u></p><p>‚ùå <strong>Create a new SQS FIFO queue. Update the application to include the DelaySeconds parameter in the messages.</strong></p><ul><li><p><strong>DelaySeconds</strong> kh√¥ng li√™n quan ƒë·∫øn FIFO requirements</p></li><li><p><strong>Thi·∫øu message group ID</strong> - required parameter cho FIFO queues</p></li></ul><p></p><p>‚ùå <strong>Modify the queue type from SQS standard to SQS FIFO. Turn off content-based deduplication on the queue. Update the application to include a message group ID in the messages.</strong></p><ul><li><p><strong>Kh√¥ng th·ªÉ modify</strong> queue type t·ª´ standard sang FIFO</p></li><li><p>Ph·∫£i create new queue</p></li></ul><p></p><p>‚ùå <strong>Modify the queue type from SQS standard to SQS FIFO. Update the application to send messages with identical message bodies and to include the DelaySeconds parameter in the messages.</strong></p><ul><li><p><strong>Kh√¥ng th·ªÉ modify</strong> queue type</p></li><li><p><strong>Identical message bodies</strong> kh√¥ng h·ª£p l√Ω - vi ph·∫°m unique message requirement</p></li></ul><p></p><p>üîë <u>Tips and tricks:</u></p><ul><li><p><strong>\"Migrate standard to FIFO queue\"</strong> ‚Üí <strong>Create new FIFO queue</strong> (cannot convert)</p></li><li><p><strong>\"Unique message bodies + FIFO\"</strong> ‚Üí <strong>Content-based deduplication</strong></p></li><li><p><strong>FIFO queue requirements</strong>: Message group ID (required), Deduplication ID ho·∫∑c content-based deduplication</p></li><li><p><strong>Content-based deduplication</strong>: Uses SHA-256 hash of message body</p></li><li><p><strong>Message group ID</strong>: Ensures ordering within group</p></li><li><p><strong>Cannot convert</strong>: Standard ‚Üî FIFO (must create new queue)</p></li><li><p><strong>Pattern</strong>: Standard to FIFO = New queue + Message group ID + Deduplication strategy</p></li></ul><p></p><p>üìñ <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-fifo-queues.html\">Amazon SQS FIFO queues</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/using-messagededuplicationid-property.html\">FIFO queue message deduplication</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a new SQS FIFO queue. Turn on content-based deduplication on the new FIFO queue. Update the application to include a message group ID in the messages.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a new SQS FIFO queue. Turn on content-based deduplication on the new FIFO queue. Update the application to include a message group ID in the messages.</p>",
                "<p>Create a new SQS FIFO queue. Update the application to include the DelaySeconds parameter in the messages.</p>",
                "<p>Modify the queue type from SQS standard to SQS FIFO. Turn off content-based deduplication on the queue. Update the application to include a message group ID in the messages.</p>",
                "<p>Modify the queue type from SQS standard to SQS FIFO. Update the application to send messages with identical message bodies and to include the DelaySeconds parameter in the messages.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 64
        }
    ],
    "statistics": {
        "correctCount": 0,
        "incorrectCount": 0,
        "skippedCount": 65,
        "flaggedCount": 0
    },
    "examName": "Practice Test 02",
    "courseName": "Practice Exams | AWS Certified CloudOps Engineer - SOA-C03",
    "slug": "practice-exams-aws-certified-cloudops-engineer-soa-c03"
}