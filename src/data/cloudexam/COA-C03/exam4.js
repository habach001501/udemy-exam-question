export const exam4 = {
    "attemptAnswers": [
        {
            "attemptAnswerId": 329271,
            "questionId": 10436,
            "questionText": "<p>A SysOps administrator needs to design a disaster recovery (DR) plan for an application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances are in an Auto Scaling group. The application uses an Amazon Aurora PostgreSQL database. The recovery time objective (RTO) and recovery point objective (RPO) are 15 minutes each.<br><br>Which combination of steps should the SysOps administrator take to meet these requirements MOST cost-effectively? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application cháº¡y trÃªn <strong>EC2 instances behind ALB</strong>, trong <strong>Auto Scaling group</strong></p></li><li><p>Database: <strong>Amazon Aurora PostgreSQL</strong></p></li><li><p>DR requirements: <strong>RTO = 15 minutes</strong>, <strong>RPO = 15 minutes</strong></p></li><li><p>YÃªu cáº§u: <strong>MOST cost-effective</strong> solution</p></li><li><p>Chá»n <strong>2 Ä‘Ã¡p Ã¡n</strong></p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Configure the Aurora cluster to replicate data to the DR Region by using the Aurora global database option.</strong></p><ul><li><p><strong>Aurora global database</strong> cÃ³ continuous, near real-time replication vá»›i lag <strong>&lt; 1 second</strong></p></li><li><p><strong>RPO &lt; 1 second</strong> Ä‘Ã¡p á»©ng tá»‘t requirement 15 minutes</p></li><li><p><strong>RTO nhanh</strong> (typically &lt; 1 minute) vÃ¬ chá»‰ cáº§n promote secondary region thÃ nh primary</p></li><li><p>Cost-effective vÃ¬ khÃ´ng pháº£i export/import backups, replication tá»± Ä‘á»™ng vÃ  efficient</p></li></ul><p></p><p><strong>Configure the DR Region with an ALB and an Auto Scaling group. Set the Auto Scaling group's minimum capacity, maximum capacity, and desired capacity to 1.</strong></p><ul><li><p><strong>Warm standby approach</strong> - infrastructure Ä‘Ã£ sáºµn sÃ ng vá»›i minimal capacity</p></li><li><p>Chá»‰ cháº¡y <strong>1 instance</strong> á»Ÿ DR region = <strong>cost-effective</strong></p></li><li><p><strong>RTO Ä‘á»§ 15 minutes</strong> vÃ¬ ALB vÃ  ASG Ä‘Ã£ cÃ³, chá»‰ cáº§n scale out instances khi failover</p></li><li><p>Infrastructure ready, chá»‰ cáº§n tÄƒng capacity khi cáº§n</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure Aurora backups to be exported to the DR Region.</strong></p><ul><li><p><strong>Backup export</strong> thÆ°á»ng Ä‘á»‹nh ká»³ (hourly hoáº·c daily), RPO khÃ´ng Ä‘á»§ 15 minutes</p></li><li><p><strong>RTO lÃ¢u</strong> vÃ¬ pháº£i restore database tá»« backup (cÃ³ thá»ƒ máº¥t hÃ ng giá»)</p></li><li><p>KhÃ´ng Ä‘Ã¡p á»©ng cáº£ RTO vÃ  RPO requirements</p></li></ul><p></p><p>âŒ <strong>Configure the DR Region with an ALB and an Auto Scaling group. Use the same configuration as in the primary Region.</strong></p><ul><li><p><strong>Full capacity standby</strong> = cháº¡y full infrastructure giá»‘ng primary region</p></li><li><p><strong>Chi phÃ­ cao</strong> vÃ¬ duplicate toÃ n bá»™ resources á»Ÿ DR region</p></li><li><p>KhÃ´ng pháº£i most cost-effective approach</p></li></ul><p></p><p>âŒ <strong>Manually launch a new ALB and a new Auto Scaling group by using AWS CloudFormation during a failover activity.</strong></p><ul><li><p><strong>Manual launch + CloudFormation</strong> máº¥t thá»i gian táº¡o infrastructure</p></li><li><p><strong>RTO cÃ³ thá»ƒ &gt; 15 minutes</strong> (create ALB, launch instances, configure, health checks)</p></li><li><p>Cold standby approach khÃ´ng Ä‘Ã¡p á»©ng RTO requirement</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"RPO = 15 minutes\"</strong> â†’ <strong>Aurora global database</strong> (continuous replication)</p></li><li><p><strong>\"RTO = 15 minutes\" + cost-effective</strong> â†’ <strong>Warm standby</strong> vá»›i minimal capacity</p></li><li><p><strong>\"Aurora backup export\"</strong> â†’ RPO hÃ ng giá»/ngÃ y, khÃ´ng Ä‘á»§ cho tight RPO</p></li><li><p><strong>Pattern</strong>: Tight RTO/RPO = Aurora global database + Warm standby | Looser RTO/RPO = Backups + Cold standby</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html\">Amazon Aurora global databases</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html\">Disaster recovery strategies on AWS</a></p></li></ul>",
            "correctAnswer": [
                "<p>Configure the Aurora cluster to replicate data to the DR Region by using the Aurora global database option.</p>",
                "<p>Configure the DR Region with an ALB and an Auto Scaling group. Set the Auto Scaling group's minimum capacity, maximum capacity, and desired capacity to 1.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure Aurora backups to be exported to the DR Region.</p>",
                "<p>Configure the Aurora cluster to replicate data to the DR Region by using the Aurora global database option.</p>",
                "<p>Configure the DR Region with an ALB and an Auto Scaling group. Use the same configuration as in the primary Region.</p>",
                "<p>Configure the DR Region with an ALB and an Auto Scaling group. Set the Auto Scaling group's minimum capacity, maximum capacity, and desired capacity to 1.</p>",
                "<p>Manually launch a new ALB and a new Auto Scaling group by using AWS CloudFormation during a failover activity.</p>"
            ],
            "answersPos": "[1,4,3,2,0]",
            "pos": 0
        },
        {
            "attemptAnswerId": 329272,
            "questionId": 6495,
            "questionText": "<p>A SysOps administrator needs to collect the content of log files from a custom application that is deployed across hundreds of Amazon EC2 instances running Ubuntu. The log files need to be stored in Amazon CloudWatch Logs.<br><br>How should the SysOps administrator collect the application log files with the LOWEST operational overhead?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application cháº¡y trÃªn <strong>hÃ ng trÄƒm EC2 instances (hundreds of instances)</strong> Ubuntu</p></li><li><p>Cáº§n thu tháº­p <strong>log files</strong> tá»« custom application</p></li><li><p>Äáº©y logs vá» <strong>CloudWatch Logs</strong></p></li><li><p>YÃªu cáº§u: <strong>LOWEST operational overhead</strong> (chi phÃ­ váº­n hÃ nh tháº¥p nháº¥t)</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Store a CloudWatch agent configuration in the AWS Systems Manager Parameter Store. Install the CloudWatch agent on each EC2 instance by using Systems Manager. Configure each agent to collect the application log files.</strong></p><p></p><p>ÄÃ¢y lÃ  giáº£i phÃ¡p tá»‘i Æ°u nháº¥t vÃ¬ sá»­ dá»¥ng <strong>quáº£n lÃ½ táº­p trung</strong>:</p><ul><li><p><strong>Parameter Store</strong> lÆ°u trá»¯ agent configuration á»Ÿ 1 nÆ¡i duy nháº¥t, táº¥t cáº£ instances Ä‘á»u tham chiáº¿u Ä‘áº¿n config nÃ y</p></li><li><p><strong>Systems Manager</strong> cho phÃ©p install vÃ  configure agent trÃªn hÃ ng trÄƒm instances cÃ¹ng lÃºc thÃ´ng qua Run Command hoáº·c State Manager</p></li><li><p>Khi cáº§n thay Ä‘á»•i config, chá»‰ cáº§n update Parameter Store, khÃ´ng pháº£i truy cáº­p tá»«ng instance</p></li><li><p>ÄÃ¢y lÃ  <strong>AWS best practice</strong> cho viá»‡c deploy CloudWatch agent á»Ÿ quy mÃ´ lá»›n</p></li></ul><hr><p><em>HÃ¬nh minh hoáº¡</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765271281106-hgz2sojb-image.png\" alt=\"\" title=\"\" width=\"713\" height=\"489.8904166666667\" style=\"max-width: 713px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure the syslogd service on each EC2 instance to collect and send the application log files to CloudWatch Logs.</strong></p><ul><li><p><strong>Syslogd</strong> lÃ  Linux native service nhÆ°ng khÃ´ng Ä‘Æ°á»£c thiáº¿t káº¿ tá»‘i Æ°u cho CloudWatch Logs</p></li><li><p>Pháº£i configure <strong>manually trÃªn tá»«ng instance</strong>, operational overhead ráº¥t cao vá»›i hÃ ng trÄƒm instances</p></li><li><p>KhÃ´ng pháº£i AWS best practice</p></li></ul><p></p><p>âŒ <strong>Install the CloudWatch agent by using the Amazon Linux package manager on each EC2 instance.</strong></p><ul><li><p>Instances Ä‘ang cháº¡y <strong>Ubuntu</strong>, khÃ´ng thá»ƒ dÃ¹ng <strong>Amazon Linux package manager (yum)</strong></p></li><li><p>Install manually trÃªn tá»«ng instance táº¡o operational overhead cao</p></li><li><p>Sai hoÃ n toÃ n vá» package manager</p></li></ul><p></p><p>âŒ <strong>Install the CloudWatch agent on each EC2 instance by using AWS Systems Manager. Create an agent configuration on each instance by using the CloudWatch configuration wizard.</strong></p><ul><li><p>Tuy dÃ¹ng Systems Manager Ä‘á»ƒ install nhÆ°ng váº«n pháº£i táº¡o <strong>configuration riÃªng trÃªn tá»«ng instance</strong> báº±ng wizard</p></li><li><p>Configure individually trÃªn hÃ ng trÄƒm instances = <strong>operational overhead cao</strong></p></li><li><p>KhÃ´ng pháº£i lowest overhead solution</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Hundreds/thousands of instances\"</strong> â†’ <strong>Systems Manager + Parameter Store</strong></p></li><li><p><strong>\"Lowest operational overhead\" + many instances</strong> â†’ <strong>Centralized configuration</strong></p></li><li><p><strong>CloudWatch agent at scale</strong> â†’ Parameter Store lÆ°u config, Systems Manager deploy</p></li><li><p><strong>Pattern</strong>: Centralized management = Parameter Store + Systems Manager | Manual config = High overhead</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/installing-cloudwatch-agent-ssm.html\">Install CloudWatch agent using Systems Manager</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/create-cloudwatch-agent-configuration-file.html\">Create CloudWatch agent configuration file</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-soa/cloudwatch-agent-cai-dat-cau-hinh-amazon-linux-2023-ec2#challenge-optional\">CloudWatch Agent - CÃ i Ä‘áº·t vÃ  cáº¥u hÃ¬nh trÃªn Amazon Linux 2023 - Thu tháº­p Logs vÃ  Metrics tá»« EC2</a></p></li></ul>",
            "correctAnswer": [
                "<p>Store a CloudWatch agent configuration in the AWS Systems Manager Parameter Store. Install the CloudWatch agent on each EC2 instance by using Systems Manager. Configure each agent to collect the application log files.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure the syslogd service on each EC2 instance to collect and send the application log files to CloudWatch Logs.</p>",
                "<p>Install the CloudWatch agent by using the Amazon Linux package manager on each EC2 instance. Configure each agent to collect the application log files.</p>",
                "<p>Install the CloudWatch agent on each EC2 instance by using AWS Systems Manager. Create an agent configuration on each instance by using the CloudWatch configuration wizard. Configure each agent to collect the application log files.</p>",
                "<p>Store a CloudWatch agent configuration in the AWS Systems Manager Parameter Store. Install the CloudWatch agent on each EC2 instance by using Systems Manager. Configure each agent to collect the application log files.</p>"
            ],
            "answersPos": "[2,1,0,3]",
            "pos": 1
        },
        {
            "attemptAnswerId": 329273,
            "questionId": 6496,
            "questionText": "<p>A company currently runs its infrastructure within a VPC in a single Availability Zone. The VPC is connected to the companyâ€™s on-premises data center through an AWS Site-to-Site VPN connection attached to a virtual private gateway. The on-premises route tables route all VPC networks to the VPN connection. Communication between the two environments is working correctly. A SysOps administrator created new VPC subnets within a new Availability Zone, and deployed new resources within the subnets. However, communication cannot be established between the new resources and the on-premises environment.<br><br>Which steps should the SysOps administrator take to resolve the issue?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>VPC Ä‘ang cháº¡y trong <strong>single Availability Zone</strong>, káº¿t ná»‘i vá»›i <strong>on-premises qua Site-to-Site VPN</strong></p></li><li><p>VPN attached to <strong>virtual private gateway (VGW)</strong></p></li><li><p>Communication giá»¯a VPC vÃ  on-premises Ä‘ang hoáº¡t Ä‘á»™ng tá»‘t</p></li><li><p>SysOps admin táº¡o <strong>new subnets trong new Availability Zone</strong>, deploy resources má»›i</p></li><li><p><strong>KhÃ´ng thá»ƒ communicate</strong> giá»¯a new resources vÃ  on-premises</p></li><li><p>YÃªu cáº§u: resolve connectivity issue</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Add a route to the route tables of the new subnets that send on-premises traffic to the virtual private gateway.</strong></p><ul><li><p>Khi táº¡o <strong>new subnets</strong>, chÃºng sáº½ cÃ³ <strong>route table riÃªng</strong> hoáº·c sá»­ dá»¥ng main route table</p></li><li><p><strong>Old subnets</strong> Ä‘ang hoáº¡t Ä‘á»™ng tá»‘t nghÄ©a lÃ  route tables cá»§a chÃºng Ä‘Ã£ cÃ³ route Ä‘áº¿n VGW cho on-premises traffic</p></li><li><p><strong>New subnets</strong> chÆ°a cÃ³ route nÃ y trong route table, nÃªn traffic khÃ´ng biáº¿t Ä‘Æ°á»ng Ä‘i Ä‘áº¿n on-premises</p></li><li><p>Giáº£i phÃ¡p: add route trong route table cá»§a new subnets Ä‘á»ƒ point on-premises CIDR vá» VGW</p></li><li><p><strong>Virtual Private Gateway</strong> lÃ  VPC-level resource, tá»± Ä‘á»™ng hoáº¡t Ä‘á»™ng cross-AZ, khÃ´ng cáº§n config thÃªm</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a ticket with AWS Support to request adding Availability Zones to the Site-to-Site VPN route configuration.</strong></p><ul><li><p><strong>VPN khÃ´ng hoáº¡t Ä‘á»™ng theo AZ</strong>, VPN lÃ  VPC-level resource</p></li><li><p>Virtual Private Gateway tá»± Ä‘á»™ng <strong>redundant vÃ  multi-AZ</strong>, khÃ´ng cáº§n config thÃªm AZ</p></li><li><p>KhÃ´ng cáº§n ticket vá»›i AWS Support cho váº¥n Ä‘á» routing cÆ¡ báº£n</p></li></ul><p></p><p>âŒ <strong>Establish a new Site-to-Site VPN connection between a virtual private gateway attached to the new Availability Zone and the on-premises data center.</strong></p><ul><li><p><strong>VGW khÃ´ng attach to specific AZ</strong>, VGW lÃ  VPC-level resource</p></li><li><p>Má»™t VPN connection hoáº¡t Ä‘á»™ng cho toÃ n bá»™ VPC, khÃ´ng cáº§n táº¡o VPN má»›i cho má»—i AZ</p></li><li><p>DÆ° thá»«a resources vÃ  khÃ´ng giáº£i quyáº¿t váº¥n Ä‘á» routing</p></li></ul><p></p><p>âŒ <strong>Replace the Site-to-Site VPN connection with an AWS Direct Connect connection.</strong></p><ul><li><p>Direct Connect khÃ´ng giáº£i quyáº¿t váº¥n Ä‘á» <strong>missing routes</strong> trong route table</p></li><li><p>Over-engineering vÃ  costly, khÃ´ng liÃªn quan Ä‘áº¿n root cause</p></li><li><p>Váº¥n Ä‘á» lÃ  routing configuration, khÃ´ng pháº£i VPN connection</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"New subnets + no connectivity\"</strong> â†’ <strong>Check route tables</strong></p></li><li><p><strong>Virtual Private Gateway</strong> â†’ VPC-level resource, auto multi-AZ</p></li><li><p><strong>Site-to-Site VPN</strong> â†’ Works across all AZs in VPC, khÃ´ng cáº§n configure per AZ</p></li><li><p><strong>Pattern</strong>: VPC connectivity issue = Routes missing &gt; Security groups &gt; Network ACLs</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/vpn/latest/s2svpn/VPNRoutingTypes.html\">Site-to-Site VPN route propagation</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add a route to the route tables of the new subnets that send on-premises traffic to the virtual private gateway.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add a route to the route tables of the new subnets that send on-premises traffic to the virtual private gateway.</p>",
                "<p>Create a ticket with AWS Support to request adding Availability Zones to the Site-to-Site VPN route configuration.</p>",
                "<p>Establish a new Site-to-Site VPN connection between a virtual private gateway attached to the new Availability Zone and the on-premises data center.</p>",
                "<p>Replace the Site-to-Site VPN connection with an AWS Direct Connect connection.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 2
        },
        {
            "attemptAnswerId": 329274,
            "questionId": 6497,
            "questionText": "<p>A company manages a set of accounts on AWS by using AWS Organizations. The company's security team wants to use a native AWS service to regularly scan all AWS accounts against the Center for Internet Security (CIS) AWS Foundations Benchmark.<br><br>What is the MOST operationally efficient way to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company quáº£n lÃ½ accounts qua <strong>AWS Organizations</strong></p></li><li><p>Security team muá»‘n scan táº¥t cáº£ accounts theo <strong>CIS AWS Foundations Benchmark</strong></p></li><li><p>YÃªu cáº§u: <strong>MOST operationally efficient</strong> (hiá»‡u quáº£ váº­n hÃ nh nháº¥t)</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Designate an AWS Security Hub administrator account. Configure new accounts in the organization to automatically become member accounts. Enable CIS AWS Foundations Benchmark scans.</strong></p><ul><li><p><strong>AWS Security Hub</strong> lÃ  native service Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cháº¡y <strong>CIS AWS Foundations Benchmark</strong></p></li><li><p>Khi integrate vá»›i <strong>AWS Organizations</strong>, Security Hub há»— trá»£ <strong>auto-enable</strong> cho member accounts</p></li><li><p><strong>New accounts tá»± Ä‘á»™ng</strong> trá»Ÿ thÃ nh member cá»§a Security Hub administrator account, khÃ´ng cáº§n manual invitation hay script</p></li><li><p>Enable CIS benchmark má»™t láº§n, táº¥t cáº£ accounts hiá»‡n táº¡i vÃ  má»›i sáº½ Ä‘Æ°á»£c scan tá»± Ä‘á»™ng</p></li><li><p>ÄÃ¢y lÃ  <strong>most operationally efficient</strong> vÃ¬ khÃ´ng cáº§n maintain scripts hay manual processes</p></li></ul><hr><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Designate a central security account as the AWS Security Hub administrator account. Create a script that sends an invitation from the Security Hub administrator account and accepts the invitation from the member account. Run the script every time a new account is created. Configure Security Hub to run the CIS AWS Foundations Benchmark scans.</strong></p><ul><li><p>Security Hub Ä‘Ãºng service nhÆ°ng approach <strong>khÃ´ng efficient</strong></p></li><li><p>Pháº£i <strong>táº¡o vÃ  maintain script</strong> Ä‘á»ƒ gá»­i/accept invitation má»—i khi cÃ³ account má»›i</p></li><li><p>KhÃ´ng táº­n dá»¥ng <strong>Organizations integration</strong> Ä‘á»ƒ auto-enable members</p></li></ul><p></p><p>âŒ <strong>Run the CIS AWS Foundations Benchmark across all accounts by using Amazon Inspector.</strong></p><ul><li><p><strong>Amazon Inspector</strong> lÃ  service cho <strong>vulnerability scanning</strong> cá»§a EC2 instances, container images, Lambda functions</p></li><li><p><strong>KhÃ´ng pháº£i service</strong> Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cháº¡y CIS AWS Foundations Benchmark</p></li><li><p>Sai service hoÃ n toÃ n</p></li></ul><p></p><p>âŒ <strong>Designate a central security account as the Amazon GuardDuty administrator account. Create a script that sends an invitation from the GuardDuty administrator account and accepts the invitation from the member account. Run the script every time a new account is created. Configure GuardDuty to run the CIS AWS Foundations Benchmark scans.</strong></p><ul><li><p><strong>GuardDuty</strong> lÃ  threat detection service, detect malicious activity (hoáº·t Ä‘á»™ng Ä‘á»™c háº¡i) vÃ  unauthorized behavior (hÃ nh vi trÃ¡i phÃ©p)</p></li><li><p><strong>KhÃ´ng pháº£i service</strong> Ä‘á»ƒ cháº¡y CIS compliance benchmarks</p></li><li><p>Sai service hoÃ n toÃ n</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"CIS AWS Foundations Benchmark\"</strong> â†’ <strong>AWS Security Hub</strong></p></li><li><p><strong>\"MOST operationally efficient\" + Organizations</strong> â†’ <strong>Auto-enable/auto-enrollment</strong></p></li><li><p><strong>\"Script + invitation\"</strong> â†’ NOT efficient so vá»›i Organizations integration</p></li><li><p><strong>Pattern</strong>: </p><ul><li><p>Compliance scanning = Security Hub</p></li><li><p>Vulnerability scanning = Inspector</p></li><li><p>Threat detection = GuardDuty</p></li></ul></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/organizations/latest/userguide/services-that-can-integrate-securityhub.html\">AWS Security Hub and AWS Organizations integration</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/securityhub/latest/userguide/cis-aws-foundations-benchmark.html\">CIS AWS Foundations Benchmark in Security Hub</a></p></li></ul>",
            "correctAnswer": [
                "<p>Designate an AWS Security Hub administrator account. Configure new accounts in the organization to automatically become member accounts. Enable CIS AWS Foundations Benchmark scans.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Designate a central security account as the AWS Security Hub administrator account. Create a script that sends an invitation from the Security Hub administrator account and accepts the invitation from the member account. Run the script every time a new account is created. Configure Security Hub to run the CIS AWS Foundations Benchmark scans.</p>",
                "<p>Run the CIS AWS Foundations Benchmark across all accounts by using Amazon Inspector.</p>",
                "<p>Designate a central security account as the Amazon GuardDuty administrator account. Create a script that sends an invitation from the GuardDuty administrator account and accepts the invitation from the member account. Run the script every time a new account is created. Configure GuardDuty to run the CIS AWS Foundations Benchmark scans.</p>",
                "<p>Designate an AWS Security Hub administrator account. Configure new accounts in the organization to automatically become member accounts. Enable CIS AWS Foundations Benchmark scans.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 3
        },
        {
            "attemptAnswerId": 329275,
            "questionId": 6498,
            "questionText": "<p>A company is running Amazon EC2 On-Demand Instances in an Auto Scaling group. The instances process messages from an Amazon Simple Queue Service (Amazon SQS) queue. The Auto Scaling group is set to scale based on the number of messages in the queue. Messages can take up to 12 hours to process completely. A SysOps administrator must ensure that instances are not interrupted during message processing.<br><br>What should the SysOps administrator do to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>EC2 instances trong <strong>Auto Scaling group</strong> xá»­ lÃ½ messages tá»« <strong>SQS queue</strong></p></li><li><p>Auto Scaling dá»±a trÃªn <strong>sá»‘ lÆ°á»£ng messages</strong> trong queue</p></li><li><p>Messages máº¥t tá»›i <strong>12 hours</strong> Ä‘á»ƒ xá»­ lÃ½ hoÃ n táº¥t</p></li><li><p>YÃªu cáº§u: Ä‘áº£m báº£o instances <strong>KHÃ”NG bá»‹ interrupted</strong> trong khi Ä‘ang xá»­ lÃ½ message</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Enable instance scale-in protection for the specific instance in the Auto Scaling group at the start of message processing by calling the Amazon EC2 Auto Scaling API from the processing script. Disable instance scale-in protection after message processing is complete by calling the Amazon EC2 Auto Scaling API from the processing script.</strong></p><ul><li><p><strong>Instance scale-in protection</strong> lÃ  cÆ¡ cháº¿ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ protect specific instances khá»i bá»‹ terminate</p></li><li><p>Khi message processing báº¯t Ä‘áº§u, script gá»i API Ä‘á»ƒ <strong>enable protection cho instance Ä‘Ã³</strong></p></li><li><p>Instance Ä‘Æ°á»£c protect sáº½ <strong>khÃ´ng bá»‹ terminate</strong> khi Auto Scaling scale-in, ngay cáº£ khi sá»‘ messages giáº£m</p></li><li><p>Sau khi xá»­ lÃ½ xong, script gá»i API Ä‘á»ƒ <strong>disable protection</strong>, cho phÃ©p instance cÃ³ thá»ƒ scale-in bÃ¬nh thÆ°á»ng</p></li><li><p>ÄÃ¢y lÃ  <strong>best practice</strong> cho long-running tasks, chá»‰ protect instances Ä‘ang xá»­ lÃ½ mÃ  khÃ´ng áº£nh hÆ°á»Ÿng toÃ n bá»™ group</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Set the Auto Scaling group's termination policy to OldestInstance.</strong></p><ul><li><p><strong>Termination policy</strong> chá»‰ thay Ä‘á»•i thá»© tá»± terminate instances, khÃ´ng protect chÃºng</p></li><li><p>Instance cÅ© nháº¥t váº«n cÃ³ thá»ƒ bá»‹ terminate náº¿u scale-in xáº£y ra, ká»ƒ cáº£ khi Ä‘ang xá»­ lÃ½ message 12 giá»</p></li><li><p>KhÃ´ng Ä‘áº£m báº£o message processing hoÃ n táº¥t</p></li></ul><p></p><p>âŒ <strong>Set the Auto Scaling group's termination policy to OldestLaunchConfiguration.</strong></p><ul><li><p>TÆ°Æ¡ng tá»± OldestInstance, chá»‰ thay Ä‘á»•i <strong>thá»© tá»± terminate</strong> dá»±a trÃªn launch configuration</p></li><li><p>KhÃ´ng cÃ³ cÆ¡ cháº¿ protect instances Ä‘ang xá»­ lÃ½ message</p></li><li><p>KhÃ´ng giáº£i quyáº¿t váº¥n Ä‘á» interruption</p></li></ul><p></p><p>âŒ <strong>Suspend the Launch and Terminate scaling processes for the specific instance in the Auto Scaling group at the start of message processing by calling the Amazon EC2 Auto Scaling API from the processing script. Resume the scaling processes after message processing is complete by calling the Amazon EC2 Auto Scaling API from the processing script.</strong></p><ul><li><p><strong>Scaling processes suspension</strong> Ã¡p dá»¥ng cho <strong>toÃ n bá»™ Auto Scaling group</strong>, khÃ´ng thá»ƒ suspend cho specific instance</p></li><li><p>Náº¿u suspend Terminate cho cáº£ group, táº¥t cáº£ scale-in activities sáº½ bá»‹ block</p></li><li><p>KhÃ´ng cÃ³ cÃ¡ch suspend processes cho individual instance</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Long-running tasks\" + \"prevent termination\"</strong> â†’ <strong>Instance scale-in protection</strong></p></li><li><p><strong>\"Specific instance protection\"</strong> â†’ Scale-in protection, khÃ´ng pháº£i termination policy</p></li><li><p><strong>\"Termination policy\"</strong> â†’ Chá»‰ thay Ä‘á»•i thá»© tá»±, khÃ´ng protect</p></li><li><p><strong>Pattern</strong>: Protect specific instances = Scale-in protection | Change terminate order = Termination policy</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-instance-protection.html\">Use instance scale-in protection to control instance termination</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-scale-in-protection.html\">Protect instances from scale-in during long-running tasks</a></p></li></ul>",
            "correctAnswer": [
                "<p>Enable instance scale-in protection for the specific instance in the Auto Scaling group at the start of message processing by calling the Amazon EC2 Auto Scaling API from the processing script. Disable instance scale-in protection after message processing is complete by calling the Amazon EC2 Auto Scaling API from the processing script.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Enable instance scale-in protection for the specific instance in the Auto Scaling group at the start of message processing by calling the Amazon EC2 Auto Scaling API from the processing script. Disable instance scale-in protection after message processing is complete by calling the Amazon EC2 Auto Scaling API from the processing script.</p>",
                "<p>Set the Auto Scaling group's termination policy to OldestInstance.</p>",
                "<p>Set the Auto Scaling group's termination policy to OldestLaunchConfiguration.</p>",
                "<p>Suspend the Launch and Terminate scaling processes for the specific instance in the Auto Scaling group at the start of message processing by calling the Amazon EC2 Auto Scaling API from the processing script. Resume the scaling processes after message processing is complete by calling the Amazon EC2 Auto Scaling API from the processing script.</p>"
            ],
            "answersPos": "[3,0,1,2]",
            "pos": 4
        },
        {
            "attemptAnswerId": 329276,
            "questionId": 6499,
            "questionText": "<p>A company has turned on server access logging for all of its existing Amazon S3 buckets. The company wants to implement a solution to monitor the logging settings for new and existing S3 buckets. The solution must remediate any S3 buckets that do not have logging turned on.<br><br>What should a SysOps administrator do to meet these requirements in the MOST operationally efficient way?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company Ä‘Ã£ báº­t <strong>server access logging</strong> cho táº¥t cáº£ S3 buckets hiá»‡n táº¡i</p></li><li><p>Muá»‘n <strong>monitor logging settings</strong> cho cáº£ new vÃ  existing buckets</p></li><li><p>Pháº£i <strong>remediate tá»± Ä‘á»™ng</strong> báº¥t ká»³ bucket nÃ o khÃ´ng cÃ³ logging</p></li><li><p>YÃªu cáº§u: <strong>MOST operationally efficient</strong></p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Configure automatic remediation in AWS Config by using the s3-bucket-logging-enabled rule.</strong></p><ul><li><p><strong>AWS Config</strong> cÃ³ sáºµn managed rule <code>s3-bucket-logging-enabled</code> Ä‘á»ƒ check S3 bucket logging configuration</p></li><li><p>AWS Config há»— trá»£ <strong>automatic remediation</strong> - tá»± Ä‘á»™ng trigger action Ä‘á»ƒ fix non-compliant resources</p></li><li><p>Tá»± Ä‘á»™ng <strong>evaluate cáº£ existing vÃ  new buckets</strong> khi Ä‘Æ°á»£c táº¡o hoáº·c modified</p></li><li><p>KhÃ´ng cáº§n viáº¿t code, maintain Lambda functions, hay custom logic</p></li><li><p>ÄÃ¢y lÃ  <strong>most operationally efficient</strong> vÃ¬ táº¥t cáº£ Ä‘Æ°á»£c managed bá»Ÿi AWS Config vá»›i built-in rules</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Track the logging information by using AWS CloudTrail. Launch an AWS Lambda function for remediation.</strong></p><ul><li><p><strong>CloudTrail</strong> track API calls vÃ  events, khÃ´ng pháº£i service Ä‘á»ƒ monitor configuration compliance</p></li><li><p>Pháº£i tá»± <strong>viáº¿t vÃ  maintain Lambda function</strong> cho remediation logic - not efficient</p></li><li><p>CloudTrail khÃ´ng Ä‘Æ°á»£c thiáº¿t káº¿ cho compliance monitoring vÃ  enforcement</p></li></ul><p></p><p>âŒ <strong>Configure AWS Trusted Advisor to monitor the logging configuration and to turn on access logging if necessary.</strong></p><ul><li><p><strong>Trusted Advisor</strong> chá»‰ provide recommendations vÃ  best practice checks</p></li><li><p><strong>KhÃ´ng cÃ³ tÃ­nh nÄƒng automatic remediation</strong>, chá»‰ alert vÃ  suggest</p></li><li><p>KhÃ´ng pháº£i service cho automated compliance enforcement</p></li></ul><p></p><p>âŒ <strong>Track the logging information by using Amazon CloudWatch metrics. Launch an AWS Lambda function for remediation.</strong></p><ul><li><p><strong>CloudWatch metrics</strong> khÃ´ng track S3 bucket configuration settings nhÆ° logging</p></li><li><p>Pháº£i tá»± build event-driven architecture vá»›i Lambda - <strong>more operational overhead</strong></p></li><li><p>KhÃ´ng cÃ³ built-in compliance rules nhÆ° AWS Config</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Monitor compliance + automatic remediation\"</strong> â†’ <strong>AWS Config</strong></p></li><li><p><strong>\"s3-bucket-logging-enabled\"</strong> â†’ Managed Config rule cÃ³ sáºµn</p></li><li><p><strong>\"MOST operationally efficient\" + compliance</strong> â†’ Config with auto-remediation</p></li><li><p><strong>Pattern</strong>: Compliance monitoring = AWS Config | API tracking = CloudTrail | Recommendations only = Trusted Advisor</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/config/latest/developerguide/managed-rules-by-aws-config.html\">AWS Config managed rules for S3</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/config/latest/developerguide/setup-autoremediation.html\">Automatic remediation in AWS Config</a></p></li></ul>",
            "correctAnswer": [
                "<p>Configure automatic remediation in AWS Config by using the s3-bucket-logging-enabled rule.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Track the logging information by using AWS CloudTrail. Launch an AWS Lambda function for remediation.</p>",
                "<p>Configure automatic remediation in AWS Config by using the s3-bucket-logging-enabled rule.</p>",
                "<p>Configure AWS Trusted Advisor to monitor the logging configuration and to turn on access logging if necessary.</p>",
                "<p>Track the logging information by using Amazon CloudWatch metrics. Launch an AWS Lambda function for remediation.</p>"
            ],
            "answersPos": "[2,1,0,3]",
            "pos": 5
        },
        {
            "attemptAnswerId": 329277,
            "questionId": 6500,
            "questionText": "<p>A SysOps administrator is setting up a fleet of Amazon EC2 instances in an Auto Scaling group for an application. The fleet should have 50% CPU available at all times to accommodate bursts of traffic. The load will increase significantly between the hours of 09:00 and 17:00, 7 days a week.<br><br>How should the SysOps administrator configure the scaling of the EC2 instances to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Fleet EC2 trong Auto Scaling group</p></li><li><p>YÃªu cáº§u: <strong>50% CPU available</strong> at all times (CPU utilization khÃ´ng Ä‘Æ°á»£c vÆ°á»£t quÃ¡ 50%)</p></li><li><p>Load tÄƒng máº¡nh giá»¯a <strong>09:00-17:00, 7 ngÃ y/tuáº§n</strong></p></li><li><p>Cáº§n configure scaling Ä‘á»ƒ accommodate bursts of traffic (lÆ°u lÆ°á»£ng tÄƒng Ä‘á»™t biáº¿n)</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create a target tracking scaling policy that runs when the CPU utilization is higher than 50%. Create a scheduled scaling policy that ensures that the fleet is available at 09:00. Create a second scheduled scaling policy that scales in the fleet at 17:00.</strong></p><ul><li><p><strong>Target tracking at 50% CPU</strong> Ä‘áº£m báº£o maintain requirement \"50% CPU available\" - Auto Scaling sáº½ add/remove instances Ä‘á»ƒ giá»¯ CPU á»Ÿ má»©c 50%</p></li><li><p><strong>Scheduled scaling at 09:00</strong> chá»§ Ä‘á»™ng scale-out trÆ°á»›c khi traffic tÄƒng, Ä‘áº£m báº£o cÃ³ Ä‘á»§ capacity sáºµn sÃ ng</p></li><li><p><strong>Scheduled scaling at 17:00</strong> scale-in sau giá» cao Ä‘iá»ƒm Ä‘á»ƒ optimize cost</p></li><li><p>Káº¿t há»£p <strong>proactive (scheduled) + reactive (target tracking)</strong> scaling cho best performance vÃ  cost optimization</p></li><li><p>ÄÃ¡p á»©ng cáº£ predictable pattern (09:00-17:00) vÃ  unexpected bursts</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a target tracking scaling policy that runs when the CPU utilization is higher than 90%.</strong></p><ul><li><p><strong>90% CPU</strong> vi pháº¡m requirement \"50% CPU available\"</p></li><li><p>Chá»‰ cÃ²n 10% CPU available, khÃ´ng Ä‘á»§ Ä‘á»ƒ accommodate bursts of traffic</p></li><li><p>KhÃ´ng cÃ³ scheduled scaling Ä‘á»ƒ handle predictable load pattern</p></li></ul><p></p><p>âŒ <strong>Set the Auto Scaling group to start with 2 instances by setting the desired instances, maximum instances, and minimum instances to 2. Create a scheduled scaling policy that ensures that the fleet is available at 09:00.</strong></p><ul><li><p><strong>Fix 2 instances</strong> (min=max=desired=2) khÃ´ng cÃ³ kháº£ nÄƒng scale</p></li><li><p>KhÃ´ng cÃ³ target tracking Ä‘á»ƒ respond to actual load changes</p></li><li><p>KhÃ´ng scale in sau 17:00, waste cost</p></li></ul><p></p><p>âŒ <strong>Create a scheduled scaling policy that ensures that the fleet is available at 09:00. Create a second scheduled scaling policy that scales in the fleet at 17:00.</strong></p><ul><li><p>Chá»‰ cÃ³ scheduled scaling, thiáº¿u <strong>target tracking policy</strong></p></li><li><p>KhÃ´ng thá»ƒ handle unexpected traffic bursts ngoÃ i pattern 09:00-17:00</p></li><li><p>KhÃ´ng maintain 50% CPU requirement dynamically</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"50% CPU available\"</strong> â†’ <strong>Target tracking at 50% utilization</strong></p></li><li><p><strong>\"Predictable pattern (cÃ³ thá»ƒ dá»± Ä‘oÃ¡n)\" (09:00-17:00)</strong> â†’ <strong>Scheduled scaling</strong></p></li><li><p><strong>\"Bursts of traffic\"</strong> â†’ <strong>Target tracking</strong> Ä‘á»ƒ reactive scaling</p></li><li><p><strong>Pattern</strong>: Predictable load + unpredictable bursts = Scheduled scaling + Target tracking</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-target-tracking.html\">Target tracking scaling policies for Auto Scaling</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-scheduled-scaling.html\">Scheduled scaling for Auto Scaling groups</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a target tracking scaling policy that runs when the CPU utilization is higher than 50%. Create a scheduled scaling policy that ensures that the fleet is available at 09:00. Create a second scheduled scaling policy that scales in the fleet at 17:00.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a target tracking scaling policy that runs when the CPU utilization is higher than 90%.</p>",
                "<p>Create a target tracking scaling policy that runs when the CPU utilization is higher than 50%. Create a scheduled scaling policy that ensures that the fleet is available at 09:00. Create a second scheduled scaling policy that scales in the fleet at 17:00.</p>",
                "<p>Set the Auto Scaling group to start with 2 instances by setting the desired instances, maximum instances, and minimum instances to 2. Create a scheduled scaling policy that ensures that the fleet is available at 09:00.</p>",
                "<p>Create a scheduled scaling policy that ensures that the fleet is available at 09:00. Create a second scheduled scaling policy that scales in the fleet at 17:00.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 6
        },
        {
            "attemptAnswerId": 329278,
            "questionId": 6501,
            "questionText": "<p>A company recently deployed MySQL on an Amazon EC2 instance with a default boot volume. The company intends to restore a 1.75 TB database. A SysOps administrator needs to provision the correct Amazon Elastic Block Store (Amazon EBS) volume. The database will require read performance of up to 10,000 IOPS and is not expected to grow in size.<br><br>Which solution will provide the required performance at the LOWEST cost?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>MySQL database trÃªn EC2 vá»›i <strong>1.75 TB data</strong></p></li><li><p>YÃªu cáº§u: <strong>read performance 10,000 IOPS</strong></p></li><li><p>Database <strong>khÃ´ng grow</strong> thÃªm</p></li><li><p>YÃªu cáº§u: <strong>LOWEST cost</strong> solution</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Deploy a 2 TB General Purpose SSD (gp3) volume. Set the IOPS to 10,000.</strong></p><ul><li><p><strong>gp3</strong> cho phÃ©p customize IOPS Ä‘á»™c láº­p vá»›i volume size (khÃ¡c gp2)</p></li><li><p>Baseline gp3: 3,000 IOPS free, cÃ³ thá»ƒ provision thÃªm Ä‘áº¿n 16,000 IOPS</p></li><li><p>Set IOPS to 10,000 Ä‘Ã¡p á»©ng Ä‘á»§ performance requirement</p></li><li><p><strong>Cost-effective nháº¥t</strong> trong cÃ¡c SSD options - gp3 ráº» hÆ¡n io2 Ä‘Ã¡ng ká»ƒ</p></li><li><p>PhÃ¹ há»£p cho database workloads khÃ´ng cáº§n extreme performance</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Deploy a 2 TB Cold HDD (sc1) volume.</strong></p><ul><li><p><strong>sc1</strong> lÃ  lowest cost storage nhÆ°ng designed cho <strong>infrequent access</strong></p></li><li><p>Max IOPS chá»‰ <strong>250 IOPS</strong>, khÃ´ng Ä‘á»§ 10,000 IOPS requirement</p></li><li><p>KhÃ´ng phÃ¹ há»£p cho database workloads cáº§n high IOPS</p></li></ul><p></p><p>âŒ <strong>Deploy a 2 TB Throughput Optimized HDD (st1) volume.</strong></p><ul><li><p><strong>st1</strong> designed cho <strong>throughput-intensive</strong> workloads (big data, log processing)</p></li><li><p>Max IOPS chá»‰ <strong>500 IOPS</strong>, khÃ´ng Ä‘á»§ 10,000 IOPS requirement</p></li><li><p>HDD khÃ´ng phÃ¹ há»£p cho database cáº§n high random IOPS</p></li></ul><p></p><p>âŒ <strong>Deploy a 2 TB Provisioned IOPS SSD (io2) volume. Set the IOPS to 10,000.</strong></p><ul><li><p><strong>io2</strong> Ä‘Ã¡p á»©ng Ä‘Æ°á»£c performance nhÆ°ng <strong>expensive hÆ¡n gp3</strong> ráº¥t nhiá»u</p></li><li><p>io2 designed cho <strong>mission-critical workloads</strong> cáº§n extreme performance (up to 64,000 IOPS)</p></li><li><p>Overkill cho requirement nÃ y, khÃ´ng pháº£i lowest cost</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"High IOPS\" (&gt;3,000)</strong> â†’ <strong>SSD (gp3 or io2)</strong>, khÃ´ng dÃ¹ng HDD</p></li><li><p><strong>\"LOWEST cost\" + IOPS &lt;16,000</strong> â†’ <strong>gp3</strong></p></li><li><p><strong>\"Extreme performance\" hoáº·c &gt;16,000 IOPS</strong> â†’ <strong>io2</strong></p></li><li><p><strong>Pattern</strong>: HDD = throughput workloads | gp3 = balanced performance/cost | io2 = mission-critical high IOPS</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html\">Amazon EBS volume types comparison</a></p></li></ul><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765273197839-5dsfm78x-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"540.1653171390013\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><h3></h3><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/general-purpose.html#gp3-performance\">gp3 volume performance</a></p></li></ul>",
            "correctAnswer": [
                "<p>Deploy a 2 TB General Purpose SSD (gp3) volume. Set the IOPS to 10,000.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Deploy a 2 TB Cold HDD (sc1) volume.</p>",
                "<p>Deploy a 2 TB Throughput Optimized HDD (st1) volume.</p>",
                "<p>Deploy a 2 TB General Purpose SSD (gp3) volume. Set the IOPS to 10,000.</p>",
                "<p>Deploy a 2 TB Provisioned IOPS SSD (io2) volume. Set the IOPS to 10,000.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 7
        },
        {
            "attemptAnswerId": 329279,
            "questionId": 6502,
            "questionText": "<p>A company recently moved its server infrastructure to Amazon EC2 instances. The company wants to use Amazon CloudWatch metrics to track instance memory utilization and available disk space.<br><br>What should a SysOps administrator do to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company Ä‘Ã£ move infrastructure sang <strong>EC2 instances</strong></p></li><li><p>Muá»‘n track <strong>memory utilization</strong> vÃ  <strong>available disk space</strong> vá»›i CloudWatch metrics</p></li><li><p>YÃªu cáº§u: giáº£i phÃ¡p Ä‘á»ƒ monitor cÃ¡c metrics nÃ y</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Install and configure the CloudWatch agent on all the instances. Attach an IAM role to allow the instances to write logs to CloudWatch.</strong></p><ul><li><p><strong>CloudWatch default metrics</strong> khÃ´ng bao gá»“m memory vÃ  disk space (chá»‰ cÃ³ CPU, network, disk I/O)</p></li><li><p>Pháº£i <strong>install CloudWatch agent</strong> Ä‘á»ƒ collect memory vÃ  disk metrics</p></li><li><p><strong>IAM role</strong> attached to EC2 instance cho phÃ©p agent gá»­i metrics vá» CloudWatch</p></li><li><p>IAM role lÃ  <strong>best practice</strong> cho EC2, tá»± Ä‘á»™ng rotate credentials vÃ  secure hÆ¡n IAM user</p></li><li><p>Agent cáº§n permissions nhÆ° <code>cloudwatch:PutMetricData</code> Ä‘á»ƒ publish custom metrics</p></li></ul><hr><p></p><p><em>Tham kháº£o: </em><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-soa/cloudwatch-agent-cai-dat-cau-hinh-amazon-linux-2023-ec2\"><em>CloudWatch Agent - CÃ i Ä‘áº·t vÃ  cáº¥u hÃ¬nh trÃªn Amazon Linux 2023 - Thu tháº­p Logs vÃ  Metrics tá»« EC2</em></a></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765273382266-5ou9wqui-image.png\" alt=\"\" title=\"\" width=\"721\" height=\"510.48302083333334\" style=\"max-width: 721px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure CloudWatch from the AWS Management Console for all the instances that require monitoring by CloudWatch. AWS automatically installs and configures the agents for the specified instances.</strong></p><ul><li><p>AWS <strong>khÃ´ng tá»± Ä‘á»™ng install</strong> CloudWatch agent tá»« Console</p></li><li><p>Pháº£i manually install agent trÃªn tá»«ng instance hoáº·c dÃ¹ng Systems Manager</p></li><li><p>CloudWatch agent khÃ´ng pháº£i pre-installed service</p></li></ul><p></p><p>âŒ <strong>Install and configure the CloudWatch agent on all the instances. Attach an IAM user to allow the instances to write logs to CloudWatch.</strong></p><ul><li><p>KhÃ´ng nÃªn dÃ¹ng <strong>IAM user credentials</strong> trÃªn EC2 instances</p></li><li><p>IAM user credentials pháº£i hardcode hoáº·c store trÃªn instance - <strong>security risk</strong></p></li><li><p><strong>IAM role</strong> lÃ  best practice, credentials tá»± Ä‘á»™ng rotate vÃ  managed by AWS</p></li></ul><p></p><p>âŒ <strong>Install and configure the CloudWatch agent on all the instances. Attach the necessary security groups to allow the instances to write logs to CloudWatch.</strong></p><ul><li><p><strong>Security groups</strong> control network traffic (inbound/outbound rules)</p></li><li><p>CloudWatch permissions Ä‘Æ°á»£c control bá»Ÿi <strong>IAM</strong>, khÃ´ng pháº£i security groups</p></li><li><p>Security groups khÃ´ng liÃªn quan Ä‘áº¿n API permissions</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Memory/disk metrics\"</strong> â†’ <strong>CloudWatch agent required</strong> (khÃ´ng pháº£i default metrics)</p></li><li><p><strong>\"EC2 permissions to AWS services\"</strong> â†’ <strong>IAM role</strong>, khÃ´ng dÃ¹ng IAM user</p></li><li><p><strong>\"Security groups\"</strong> â†’ Network traffic control, khÃ´ng pháº£i API permissions</p></li><li><p><strong>Pattern</strong>: Custom/detailed metrics = CloudWatch agent | EC2 permissions = IAM role</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-soa/cloudwatch-agent-cai-dat-cau-hinh-amazon-linux-2023-ec2\">CloudWatch Agent - CÃ i Ä‘áº·t vÃ  cáº¥u hÃ¬nh trÃªn Amazon Linux 2023 - Thu tháº­p Logs vÃ  Metrics tá»« EC2</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/install-CloudWatch-Agent-on-EC2-Instance.html\">Install CloudWatch agent to collect metrics</a></p></li></ul>",
            "correctAnswer": [
                "<p>Install and configure the CloudWatch agent on all the instances. Attach an IAM role to allow the instances to write logs to CloudWatch.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure CloudWatch from the AWS Management Console for all the instances that require monitoring by CloudWatch. AWS automatically installs and configures the agents for the specified instances.</p>",
                "<p>Install and configure the CloudWatch agent on all the instances. Attach an IAM role to allow the instances to write logs to CloudWatch.</p>",
                "<p>Install and configure the CloudWatch agent on all the instances. Attach an IAM user to allow the instances to write logs to CloudWatch.</p>",
                "<p>Install and configure the CloudWatch agent on all the instances. Attach the necessary security groups to allow the instances to write logs to CloudWatch.</p>"
            ],
            "answersPos": "[1,3,0,2]",
            "pos": 8
        },
        {
            "attemptAnswerId": 329280,
            "questionId": 6503,
            "questionText": "<p>A SysOps administrator needs to create alerts that are based on the read and write metrics of Amazon Elastic Block Store (Amazon EBS) volumes that are attached to an Amazon EC2 instance. The SysOps administrator creates and enables Amazon CloudWatch alarms for the DiskReadBytes metric and the DiskWriteBytes metric.<br><br>A custom monitoring tool that is installed on the EC2 instance with the same alarm configuration indicates that the volume metrics have exceeded the threshold. However, the CloudWatch alarms were not in ALARM state.<br><br>Which action will ensure that the CloudWatch alarms function correctly?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>SysOps admin táº¡o CloudWatch alarms cho <strong>DiskReadBytes</strong> vÃ  <strong>DiskWriteBytes</strong> metrics</p></li><li><p>Alarms gáº¯n vá»›i <strong>EBS volumes attached to EC2 instance</strong></p></li><li><p><strong>Custom monitoring tool</strong> trÃªn instance bÃ¡o metrics Ä‘Ã£ vÆ°á»£t threshold</p></li><li><p>NhÆ°ng <strong>CloudWatch alarms KHÃ”NG trigger</strong> (khÃ´ng á»Ÿ ALARM state)</p></li><li><p>YÃªu cáº§u: fix alarms Ä‘á»ƒ hoáº¡t Ä‘á»™ng Ä‘Ãºng</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Reconfigure the CloudWatch alarms to use the VolumeReadBytes metric and the VolumeWriteBytes metric for the EBS volumes.</strong></p><ul><li><p><strong>DiskReadBytes/DiskWriteBytes</strong> lÃ  <strong>EC2-level metrics</strong>, aggregated cho táº¥t cáº£ volumes attached to instance</p></li><li><p><strong>VolumeReadBytes/VolumeWriteBytes</strong> lÃ  <strong>EBS-level metrics</strong>, specific cho tá»«ng volume individual</p></li><li><p>Custom tool Ä‘ang monitor Ä‘Ãºng á»Ÿ volume level, nÃªn phÃ¡t hiá»‡n Ä‘Æ°á»£c threshold breach</p></li><li><p>CloudWatch alarms cáº§n reconfigure Ä‘á»ƒ dÃ¹ng <strong>Volume metrics vá»›i VolumeId dimension</strong> Ä‘á»ƒ monitor specific EBS volumes</p></li><li><p>ÄÃ¢y lÃ  <strong>default EBS metrics</strong>, khÃ´ng cáº§n install agent</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Install and configure the CloudWatch agent on the EC2 instance to capture the desired metrics.</strong></p><ul><li><p><strong>VolumeReadBytes/VolumeWriteBytes</strong> lÃ  <strong>default CloudWatch metrics</strong> cho EBS</p></li><li><p>KhÃ´ng cáº§n CloudWatch agent Ä‘á»ƒ capture cÃ¡c metrics nÃ y</p></li><li><p>Agent chá»‰ cáº§n cho custom metrics nhÆ° memory, disk space usage</p></li></ul><p></p><p>âŒ <strong>Install and configure AWS Systems Manager Agent on the EC2 instance to capture the desired metrics.</strong></p><ul><li><p><strong>Systems Manager Agent</strong> khÃ´ng liÃªn quan Ä‘áº¿n CloudWatch metrics collection</p></li><li><p>SSM Agent dÃ¹ng cho patch management, run commands, session manager</p></li><li><p>KhÃ´ng giáº£i quyáº¿t váº¥n Ä‘á» metrics monitoring</p></li></ul><p></p><p>âŒ <strong>Reconfigure the CloudWatch alarms to use the VolumeReadBytes metric and the VolumeWriteBytes metric for the EC2 instance.</strong></p><ul><li><p><strong>Volume metrics thuá»™c EBS namespace</strong>, khÃ´ng pháº£i EC2 namespace</p></li><li><p>Metrics dimension pháº£i lÃ  <strong>VolumeId</strong>, khÃ´ng pháº£i InstanceId</p></li><li><p>ÄÃ¡p Ã¡n nÃ y sai vá» namespace/dimension configuration</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"DiskReadBytes/DiskWriteBytes\"</strong> â†’ <strong>EC2-level metrics</strong> (aggregate all volumes)</p></li><li><p><strong>\"VolumeReadBytes/VolumeWriteBytes\"</strong> â†’ <strong>EBS-level metrics</strong> (per volume)</p></li><li><p><strong>\"Monitor specific EBS volume\"</strong> â†’ DÃ¹ng Volume metrics vá»›i VolumeId dimension</p></li><li><p><strong>Pattern</strong>: EC2 Disk metrics = aggregated | EBS Volume metrics = per-volume</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/using_cloudwatch_ebs.html\">CloudWatch metrics for Amazon EBS volumes</a></p></li></ul>",
            "correctAnswer": [
                "<p>Reconfigure the CloudWatch alarms to use the VolumeReadBytes metric and the VolumeWriteBytes metric for the EBS volumes.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Install and configure the CloudWatch agent on the EC2 instance to capture the desired metrics.</p>",
                "<p>Install and configure AWS Systems Manager Agent on the EC2 instance to capture the desired metrics.</p>",
                "<p>Reconfigure the CloudWatch alarms to use the VolumeReadBytes metric and the VolumeWriteBytes metric for the EBS volumes.</p>",
                "<p>Reconfigure the CloudWatch alarms to use the VolumeReadBytes metric and the VolumeWriteBytes metric for the EC2 instance.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 9
        },
        {
            "attemptAnswerId": 329281,
            "questionId": 6504,
            "questionText": "<p>A company is migrating its production file server to AWS. All data that is stored on the file server must remain accessible if an Availability Zone becomes unavailable or when system maintenance is performed. Users must be able to interact with the file server through the SMB protocol. Users also must have the ability to manage file permissions by using Windows ACLs.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Migrate production file server lÃªn AWS</p></li><li><p>Data pháº£i accessible ngay cáº£ khi <strong>AZ fails</strong> hoáº·c <strong>system maintenance</strong></p></li><li><p>Users tÆ°Æ¡ng tÃ¡c qua <strong>SMB protocol</strong></p></li><li><p>Users quáº£n lÃ½ permissions vá»›i <strong>Windows ACLs</strong></p></li><li><p>YÃªu cáº§u: high availability solution</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create an Amazon FSx for Windows File Server Multi-AZ file system.</strong></p><ul><li><p><strong>FSx for Windows File Server</strong> native support <strong>SMB protocol</strong> vÃ  <strong>Windows ACLs</strong></p></li><li><p><strong>Multi-AZ deployment</strong> tá»± Ä‘á»™ng replicate data across multiple AZs vá»›i synchronous replication</p></li><li><p>Built-in <strong>automatic failover</strong> khi AZ fails hoáº·c planned maintenance</p></li><li><p>Fully managed service, khÃ´ng cáº§n setup replication manually</p></li><li><p>ÄÃ¡p á»©ng Ä‘á»§ táº¥t cáº£ requirements: SMB, Windows ACLs, high availability</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a single AWS Storage Gateway file gateway.</strong></p><ul><li><p>Storage Gateway file gateway há»— trá»£ SMB nhÆ°ng <strong>single deployment</strong> = no high availability</p></li><li><p>Náº¿u AZ fails, file gateway khÃ´ng accessible</p></li><li><p>KhÃ´ng Ä‘Ã¡p á»©ng requirement vá» AZ failure resilience</p></li></ul><p></p><p>âŒ <strong>Deploy two AWS Storage Gateway file gateways across two Availability Zones. Configure an Application Load Balancer in front of the file gateways.</strong></p><ul><li><p><strong>Application Load Balancer chá»‰ support HTTP/HTTPS</strong>, khÃ´ng support SMB protocol</p></li><li><p>ALB khÃ´ng thá»ƒ load balance SMB traffic</p></li><li><p>Architecture approach sai hoÃ n toÃ n</p></li></ul><p></p><p>âŒ <strong>Deploy two Amazon FSx for Windows File Server Single-AZ 2 file systems. Configure Microsoft Distributed File System Replication (DFSR).</strong></p><ul><li><p><strong>Single-AZ FSx</strong> khÃ´ng cÃ³ built-in HA, má»—i file system chá»‰ trong 1 AZ</p></li><li><p><strong>DFSR (Distributed File System Replication)</strong> cáº§n manual setup, complex configuration vÃ  management overhead</p></li><li><p>Multi-AZ FSx Ä‘Ã£ cÃ³ sáºµn automatic replication vÃ  failover, khÃ´ng cáº§n DFSR</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"SMB protocol + Windows ACLs\"</strong> â†’ <strong>Amazon FSx for Windows File Server</strong></p></li><li><p><strong>\"High availability + AZ failure\"</strong> â†’ <strong>Multi-AZ deployment</strong></p></li><li><p><strong>\"ALB\"</strong> â†’ Chá»‰ support HTTP/HTTPS, khÃ´ng support SMB/NFS</p></li><li><p><strong>Pattern</strong>: Windows file sharing = FSx for Windows | Linux file sharing = FSx for Lustre or EFS</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/fsx/latest/WindowsGuide/high-availability-multiAZ.html\">Amazon FSx for Windows File Server Multi-AZ deployments</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an Amazon FSx for Windows File Server Multi-AZ file system.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a single AWS Storage Gateway file gateway.</p>",
                "<p>Create an Amazon FSx for Windows File Server Multi-AZ file system.</p>",
                "<p>Deploy two AWS Storage Gateway file gateways across two Availability Zones. Configure an Application Load Balancer in front of the file gateways.</p>",
                "<p>Deploy two Amazon FSx for Windows File Server Single-AZ 2 file systems. Configure Microsoft Distributed File System Replication (DFSR).</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 10
        },
        {
            "attemptAnswerId": 329282,
            "questionId": 6505,
            "questionText": "<p>A company's SysOps administrator has created an Amazon EC2 instance with custom software that will be used as a template for all new EC2 instances across multiple AWS accounts. The Amazon Elastic Block Store (Amazon EBS) volumes that are attached to the EC2 instance are encrypted with AWS managed keys.<br><br>The SysOps administrator creates an Amazon Machine Image (AMI) of the custom EC2 instance and plans to share the AMI with the company's other AWS accounts. The company requires that all AMIs are encrypted with AWS Key Management Service (AWS KMS) keys and that only authorized AWS accounts can access the shared AMIs.<br><br>Which solution will securely share the AMI with the other AWS accounts?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>EC2 instance vá»›i custom software, EBS volumes encrypted vá»›i <strong>AWS managed keys</strong></p></li><li><p>Táº¡o AMI tá»« instance, muá»‘n <strong>share vá»›i other AWS accounts</strong></p></li><li><p>Requirements:</p><ul><li><p>AMIs encrypted vá»›i <strong>AWS KMS keys</strong></p></li><li><p>Chá»‰ <strong>authorized accounts</strong> cÃ³ thá»ƒ access</p></li></ul></li><li><p>YÃªu cáº§u: secure sharing solution</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>In the account where the AMI was created, create a customer managed KMS key. Modify the key policy to provide kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant, and kms:Decrypt permissions to the AWS accounts that the AMI will be shared with. Create a copy of the AMI, and specify the KMS key. Modify the permissions on the copied AMI to specify the AWS account numbers that the AMI will be shared with.</strong></p><ul><li><p><strong>AWS managed keys khÃ´ng thá»ƒ share</strong> across accounts - khÃ´ng thá»ƒ modify key policy</p></li><li><p>Pháº£i create <strong>customer managed KMS key</strong> Ä‘á»ƒ control key policy</p></li><li><p><strong>Copy AMI</strong> vÃ  specify customer managed key Ä‘á»ƒ <strong>re-encrypt</strong> tá»« AWS managed key sang customer key</p></li><li><p><strong>Key policy</strong> grant permissions (DescribeKey, ReEncrypt, CreateGrant, Decrypt) cho target accounts Ä‘á»ƒ há» cÃ³ thá»ƒ decrypt vÃ  sá»­ dá»¥ng AMI</p></li><li><p><strong>AMI permissions</strong> chá»‰ Ä‘á»‹nh specific account numbers (authorized accounts only)</p></li><li><p>ÄÃ¢y lÃ  <strong>complete workflow</strong> Ä‘á»ƒ share encrypted AMI securely</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>In the account where the AMI was created, create a customer managed KMS key. Modify the key policy to provide kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant, and kms:Decrypt permissions to the AWS accounts that the AMI will be shared with. Modify the AMI permissions to specify the AWS account numbers that the AMI will be shared with.</strong></p><ul><li><p>Thiáº¿u bÆ°á»›c <strong>copy AMI vá»›i customer managed key</strong></p></li><li><p>AMI gá»‘c váº«n encrypted vá»›i AWS managed key, khÃ´ng thá»ƒ share</p></li><li><p>Chá»‰ modify permissions khÃ´ng Ä‘á»§ Ä‘á»ƒ share encrypted AMI</p></li></ul><p></p><p>âŒ <strong>In the account where the AMI was created, create a customer managed KMS key. Modify the key policy to provide kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant, and kms:Decrypt permissions to the AWS accounts that the AMI will be shared with. Create a copy of the AMI, and specify the KMS key Modify the permissions on the copied AMI to make it public.</strong></p><ul><li><p><strong>Encrypted AMI khÃ´ng thá»ƒ make public</strong> - AWS khÃ´ng cho phÃ©p</p></li><li><p>Vi pháº¡m requirement \"only authorized AWS accounts\"</p></li><li><p>Security risk náº¿u cÃ³ thá»ƒ public encrypted AMI</p></li></ul><p></p><p>âŒ <strong>In the account where the AMI was created, modify the key policy of the AWS managed key to provide kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant, and kms:Decrypt permissions to the AWS accounts that the AMI will be shared with. Modify the AMI permissions to specify the AWS account numbers that the AMI will be shared with.</strong></p><ul><li><p><strong>KhÃ´ng thá»ƒ modify key policy</strong> cá»§a AWS managed keys</p></li><li><p>AWS managed keys khÃ´ng support cross-account sharing</p></li><li><p>Approach hoÃ n toÃ n khÃ´ng kháº£ thi</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Share encrypted AMI across accounts\"</strong> â†’ <strong>Customer managed KMS key required</strong></p></li><li><p><strong>\"AWS managed keys\"</strong> â†’ KhÃ´ng thá»ƒ share, pháº£i copy AMI vá»›i customer key</p></li><li><p><strong>\"Only authorized accounts\"</strong> â†’ Share vá»›i specific account numbers, khÃ´ng public</p></li><li><p><strong>Pattern</strong>: Share encrypted AMI = Customer managed key + Copy AMI + Key policy + AMI permissions</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sharingamis-explicit.html\">Share an AMI with specific AWS accounts</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIEncryption.html\">Use encryption with EBS-backed AMIs</a></p></li></ul>",
            "correctAnswer": [
                "<p>In the account where the AMI was created, create a customer managed KMS key. Modify the key policy to provide kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant, and kms:Decrypt permissions to the AWS accounts that the AMI will be shared with. Create a copy of the AMI, and specify the KMS key. Modify the permissions on the copied AMI to specify the AWS account numbers that the AMI will be shared with.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>In the account where the AMI was created, create a customer managed KMS key. Modify the key policy to provide kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant, and kms:Decrypt permissions to the AWS accounts that the AMI will be shared with. Modify the AMI permissions to specify the AWS account numbers that the AMI will be shared with.</p>",
                "<p>In the account where the AMI was created, create a customer managed KMS key. Modify the key policy to provide kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant, and kms:Decrypt permissions to the AWS accounts that the AMI will be shared with. Create a copy of the AMI, and specify the KMS key. Modify the permissions on the copied AMI to specify the AWS account numbers that the AMI will be shared with.</p>",
                "<p>In the account where the AMI was created, create a customer managed KMS key. Modify the key policy to provide kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant, and kms:Decrypt permissions to the AWS accounts that the AMI will be shared with. Create a copy of the AMI, and specify the KMS key Modify the permissions on the copied AMI to make it public.</p>",
                "<p>In the account where the AMI was created, modify the key policy of the AWS managed key to provide kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant, and kms:Decrypt permissions to the AWS accounts that the AMI will be shared with. Modify the AMI permissions to specify the AWS account numbers that the AMI will be shared with.</p>"
            ],
            "answersPos": "[1,3,0,2]",
            "pos": 11
        },
        {
            "attemptAnswerId": 329283,
            "questionId": 10437,
            "questionText": "<p>A SysOps administrator is tasked with analyzing database performance. The database runs on a single Amazon RDS DB instance. The SysOps administrator finds that, during times of peak traffic, resources on the database are overutilized due to the amount of read traffic.<br><br>Which actions should the SysOps administrator take to improve RDS performance? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Database cháº¡y trÃªn <strong>single RDS DB instance</strong></p></li><li><p>Performance issue: resources <strong>overutilized (sá»­ dá»¥ng quÃ¡ má»©c)</strong> do <strong>read traffic</strong> nhiá»u</p></li><li><p>YÃªu cáº§u: improve RDS performance</p></li><li><p>Chá»n <strong>2 Ä‘Ã¡p Ã¡n</strong></p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Add a read replica</strong></p><ul><li><p><strong>Read replica</strong> offload read traffic tá»« primary database instance</p></li><li><p>Application cÃ³ thá»ƒ route <strong>read queries</strong> Ä‘áº¿n replica, write queries Ä‘áº¿n primary</p></li><li><p><strong>Asynchronous replication</strong> tá»« primary sang replica</p></li><li><p>Scale out read capacity without affecting write performance</p></li></ul><p></p><p><strong>Modify the application to use Amazon ElastiCache for Memcached.</strong></p><ul><li><p><strong>ElastiCache</strong> cache frequently accessed data trong memory</p></li><li><p><strong>Giáº£m sá»‘ read queries</strong> Ä‘áº¿n database dramatically</p></li><li><p><strong>Low latency</strong> cho cached data (microseconds vs milliseconds)</p></li><li><p><strong>Cost-effective</strong> cho read-heavy workloads, Ä‘áº·c biá»‡t vá»›i repetitive queries</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Migrate the database from RDS to Amazon DynamoDB.</strong></p><ul><li><p><strong>DynamoDB lÃ  NoSQL</strong> database, khÃ¡c architecture hoÃ n toÃ n vá»›i RDS</p></li><li><p>Requires <strong>application rewrite</strong> vÃ  data model redesign</p></li><li><p>Over-engineering, khÃ´ng pháº£i giáº£i phÃ¡p Ä‘á»ƒ improve RDS performance</p></li></ul><p></p><p>âŒ <strong>Migrate the database to Amazon EC2 with enhanced networking enabled.</strong></p><ul><li><p><strong>Enhanced networking</strong> cáº£i thiá»‡n network throughput, khÃ´ng giáº£i quyáº¿t read overload</p></li><li><p>Migrate sang EC2 tÄƒng <strong>operational overhead</strong> (patching, backups, HA)</p></li><li><p>Váº¥n Ä‘á» lÃ  database capacity, khÃ´ng pháº£i network performance</p></li></ul><p></p><p>âŒ <strong>Upgrade the database to a Multi-AZ deployment.</strong></p><ul><li><p><strong>Multi-AZ</strong> dÃ¹ng cho <strong>high availability</strong>, khÃ´ng scale read capacity</p></li><li><p><strong>Standby replica khÃ´ng serve read traffic</strong>, chá»‰ dÃ¹ng cho automatic failover</p></li><li><p>KhÃ´ng giáº£i quyáº¿t performance issue do read traffic</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Read traffic overload\"</strong> â†’ <strong>Read replica hoáº·c ElastiCache</strong></p></li><li><p><strong>\"Multi-AZ\"</strong> â†’ High availability, khÃ´ng pháº£i read scaling</p></li><li><p><strong>\"Read replica\"</strong> â†’ Offload reads | <strong>ElastiCache</strong> â†’ Cache frequent queries</p></li><li><p><strong>Pattern</strong>: Read scaling = Read replica + Caching | Write scaling = Vertical scaling or sharding</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html\">Amazon RDS read replicas</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/creating-elasticache-cluster-with-RDS-settings.html\">Using Amazon ElastiCache with RDS</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add a read replica</p>",
                "<p>Modify the application to use Amazon ElastiCache for Memcached.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add a read replica</p>",
                "<p>Modify the application to use Amazon ElastiCache for Memcached.</p>",
                "<p>Migrate the database from RDS to Amazon DynamoDB.</p>",
                "<p>Migrate the database to Amazon EC2 with enhanced networking enabled.</p>",
                "<p>Upgrade the database to a Multi-AZ deployment.</p>"
            ],
            "answersPos": "[1,3,0,2,4]",
            "pos": 12
        },
        {
            "attemptAnswerId": 329284,
            "questionId": 6507,
            "questionText": "<p>A company's VPC has connectivity to an on-premises data center through an AWS Site-to-Site VPN. The company needs Amazon EC2 instances in the VPC to send DNS queries for example.com to the DNS servers in the data center.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>VPC cÃ³ connectivity vá»›i <strong>on-premises data center</strong> qua <strong>Site-to-Site VPN</strong></p></li><li><p><strong>EC2 instances trong VPC</strong> cáº§n send DNS queries cho <strong>example.com</strong> Ä‘áº¿n <strong>on-premises DNS servers</strong></p></li><li><p>YÃªu cáº§u: solution Ä‘á»ƒ forward DNS queries tá»« VPC ra on-premises</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create an Amazon Route 53 Resolver outbound endpoint. Create a forwarding rule on the resolver that sends all queries for example.com to the on-premises DNS servers. Associate this rule with the VPC.</strong></p><ul><li><p><strong>Outbound endpoint</strong> cho phÃ©p DNS queries Ä‘i <strong>tá»« VPC ra ngoÃ i</strong> (AWS â†’ on-premises)</p></li><li><p><strong>Forwarding rule</strong> trÃªn Route 53 Resolver Ä‘á»‹nh nghÄ©a domain (example.com) cáº§n forward vÃ  target DNS servers (on-premises)</p></li><li><p><strong>Associate rule vá»›i VPC</strong> Ä‘á»ƒ EC2 instances trong VPC sá»­ dá»¥ng rule nÃ y</p></li><li><p>Traffic flow: EC2 â†’ Route 53 Resolver â†’ Outbound endpoint â†’ On-premises DNS servers qua VPN</p></li></ul><hr><p></p><p><em>HÃ¬nh mÃ¬nh hoáº¡</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765276078008-itn4n3vt-image.png\" alt=\"\" title=\"\" width=\"687\" height=\"554.00109375\" style=\"max-width: 687px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create an Amazon Route 53 Resolver inbound endpoint. Create a conditional forwarding rule on the on-premises DNS servers to forward DNS requests for example.com to the inbound endpoints.</strong></p><ul><li><p><strong>Inbound endpoint</strong> cho traffic direction ngÆ°á»£c láº¡i: <strong>on-premises â†’ AWS</strong></p></li><li><p>Use case cá»§a inbound: on-premises resources query AWS resources</p></li><li><p>KhÃ´ng phÃ¹ há»£p vÃ¬ requirement lÃ  <strong>AWS â†’ on-premises</strong>, khÃ´ng pháº£i ngÆ°á»£c láº¡i</p></li></ul><p></p><p>âŒ <strong>Create an Amazon Route 53 Resolver inbound endpoint. Create a forwarding rule on the resolver that sends all queries for example.com to the on-premises DNS servers. Associate this rule with the VPC.</strong></p><ul><li><p><strong>Inbound endpoint sai direction</strong> - dÃ¹ng cho on-premises query vÃ o AWS</p></li><li><p>Forwarding rule Ä‘Ãºng nhÆ°ng endpoint type sai</p></li><li><p>KhÃ´ng thá»ƒ forward tá»« VPC ra on-premises vá»›i inbound endpoint</p></li></ul><p></p><p>âŒ <strong>Create an Amazon Route 53 Resolver outbound endpoint. Create a conditional forwarding rule on the on-premises DNS servers to forward DNS requests for example.com to the outbound endpoints.</strong></p><ul><li><p>Outbound endpoint Ä‘Ãºng nhÆ°ng <strong>forwarding rule á»Ÿ sai chá»—</strong></p></li><li><p>Forwarding rule pháº£i táº¡o <strong>trÃªn Route 53 Resolver</strong>, khÃ´ng pháº£i on-premises DNS</p></li><li><p>On-premises DNS khÃ´ng cáº§n forward example.com vÃ¬ nÃ³ Ä‘Ã£ host domain nÃ y</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"AWS query on-premises DNS\"</strong> â†’ <strong>Outbound endpoint</strong></p></li><li><p><strong>\"On-premises query AWS DNS\"</strong> â†’ <strong>Inbound endpoint</strong></p></li><li><p><strong>\"Forwarding rule\"</strong> â†’ Táº¡o trÃªn Route 53 Resolver, associate vá»›i VPC</p></li><li><p><strong>Pattern</strong>: Outbound = AWS â†’ External | Inbound = External â†’ AWS</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/whitepapers/latest/hybrid-cloud-dns-options-for-vpc/route-53-resolver-endpoints-and-forwarding-rules.html\">Route 53 Resolver endpoints</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resolver-forwarding-outbound-queries.html\">Forwarding outbound DNS queries to your network</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an Amazon Route 53 Resolver outbound endpoint. Create a forwarding rule on the resolver that sends all queries for example.com to the on-premises DNS servers. Associate this rule with the VPC.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an Amazon Route 53 Resolver inbound endpoint. Create a conditional forwarding rule on the on-premises DNS servers to forward DNS requests for example.com to the inbound endpoints.</p>",
                "<p>Create an Amazon Route 53 Resolver inbound endpoint. Create a forwarding rule on the resolver that sends all queries for example.com to the on-premises DNS servers. Associate this rule with the VPC.</p>",
                "<p>Create an Amazon Route 53 Resolver outbound endpoint. Create a conditional forwarding rule on the on-premises DNS servers to forward DNS requests for example.com to the outbound endpoints.</p>",
                "<p>Create an Amazon Route 53 Resolver outbound endpoint. Create a forwarding rule on the resolver that sends all queries for example.com to the on-premises DNS servers. Associate this rule with the VPC.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 13
        },
        {
            "attemptAnswerId": 329285,
            "questionId": 6508,
            "questionText": "<p>A company's SysOps administrator maintains a highly available environment. The environment includes Amazon EC2 instances and an Amazon RDS Multi-AZ database. The EC2 instances are in an Auto Scaling group behind an Application Load Balancer.<br><br>Recently, the company conducted a failover test. The SysOps administrator needs to decrease the failover time of the RDS database by at least 10%.<br><br>Which solution will meet this requirement?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Highly available environment vá»›i EC2, Auto Scaling group, ALB</p></li><li><p><strong>RDS Multi-AZ database</strong></p></li><li><p>ÄÃ£ conduct failover test</p></li><li><p>YÃªu cáº§u: <strong>decrease RDS failover time by at least 10%</strong></p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create an RDS proxy. Point the application to the proxy endpoint.</strong></p><ul><li><p><strong>RDS Proxy</strong> maintains connection pool vÃ  automatically routes connections to healthy database endpoint</p></li><li><p>Khi RDS Multi-AZ failover, <strong>proxy quickly detects</strong> vÃ  redirects traffic Ä‘áº¿n standby (promoted to primary)</p></li><li><p><strong>Faster DNS resolution</strong> - proxy Ä‘Ã£ cÃ³ established connections, khÃ´ng cáº§n wait for DNS propagation</p></li><li><p>Application <strong>khÃ´ng cáº§n reconnect</strong>, RDS Proxy handle reconnection internally</p></li><li><p><strong>Giáº£m failover time</strong> tá»« ~60-120 seconds xuá»‘ng cÃ²n ~20-30 seconds (improvement &gt;10%)</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Increase the RDS instance size.</strong></p><ul><li><p>Instance size áº£nh hÆ°á»Ÿng Ä‘áº¿n <strong>compute performance</strong>, khÃ´ng áº£nh hÆ°á»Ÿng failover time</p></li><li><p>Failover time phá»¥ thuá»™c vÃ o <strong>detection vÃ  promotion process</strong>, khÃ´ng pháº£i instance capacity</p></li><li><p>KhÃ´ng giáº£i quyáº¿t váº¥n Ä‘á» failover speed</p></li></ul><p></p><p>âŒ <strong>Modify the RDS cluster to run in a single Availability Zone.</strong></p><ul><li><p><strong>Single AZ = máº¥t high availability</strong> vÃ  automatic failover capability</p></li><li><p>Vi pháº¡m requirement \"highly available environment\"</p></li><li><p>KhÃ´ng cÃ³ standby replica Ä‘á»ƒ failover, tÄƒng downtime thay vÃ¬ giáº£m</p></li></ul><p></p><p>âŒ <strong>Create a read replica in another AWS Region. Promote the read replica in case of failure.</strong></p><ul><li><p>Read replica promotion lÃ  <strong>manual process</strong>, slower than automatic Multi-AZ failover</p></li><li><p><strong>Cross-region replica</strong> cÃ³ replication lag (asynchronous)</p></li><li><p>TÄƒng failover time thay vÃ¬ giáº£m</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Decrease RDS failover time\"</strong> â†’ <strong>RDS Proxy</strong></p></li><li><p><strong>\"Multi-AZ failover\"</strong> â†’ Automatic (~60-120s) | <strong>RDS Proxy</strong> â†’ Faster (~20-30s)</p></li><li><p><strong>\"Connection pooling\"</strong> â†’ RDS Proxy benefit chÃ­nh</p></li><li><p><strong>Pattern</strong>: Faster failover = RDS Proxy | High availability = Multi-AZ | Disaster recovery = Cross-region replica</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/blogs/database/using-rds-proxy-with-amazon-rds-multi-az-db-instance-deployment-to-improve-planned-failover-time/\">Amazon RDS Proxy for improved failover times</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/blogs/database/improving-application-availability-with-amazon-rds-proxy/\">Using RDS Proxy to reduce failover time</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an RDS proxy. Point the application to the proxy endpoint.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Increase the RDS instance size.</p>",
                "<p>Modify the RDS cluster to run in a single Availability Zone.</p>",
                "<p>Create a read replica in another AWS Region. Promote the read replica in case of failure.</p>",
                "<p>Create an RDS proxy. Point the application to the proxy endpoint.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 14
        },
        {
            "attemptAnswerId": 329286,
            "questionId": 6509,
            "questionText": "<p>Application A runs on Amazon EC2 instances behind a Network Load Balancer (NLB). The EC2 instances are in an Auto Scaling group and are in the same subnet that is associated with the NLB. Other applications from an on-premises environment cannot communicate with Application A on port 8080.<br><br>To troubleshoot the issue, a SysOps administrator analyzes the flow logs. The flow logs include the following records:<br></p><pre><code>2 123456789010 eni-1235b8ca123456789 192.168.0.13 172.31.16.139 59003 8080 1 4 336 1432917027 1432917142 ACCEPT OK\n2 123456789010 eni-1235b8ca123456789 172.31.16.139 192.168.0.13 8080 59003 1 4 336 1432917094 1432917142 REJECT OK</code></pre><p></p><p>What is the reason for the rejected traffic?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application A cháº¡y trÃªn <strong>EC2 instances behind Network Load Balancer (NLB)</strong></p></li><li><p>EC2 instances vÃ  NLB trong <strong>cÃ¹ng subnet</strong></p></li><li><p><strong>On-premises applications khÃ´ng thá»ƒ communicate</strong> vá»›i Application A trÃªn <strong>port 8080</strong></p></li><li><p><strong>Flow logs show rejected traffic</strong></p></li><li><p>YÃªu cáº§u: identify reason for rejected traffic</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>The network ACL that is associated with the subnet does not allow outbound traffic for the ephemeral port range.</strong></p><ul><li><p><strong>Network ACLs lÃ  stateless</strong> - pháº£i cÃ³ explicit rules cho cáº£ inbound vÃ  outbound traffic</p></li><li><p>Request flow: On-premises â†’ NLB â†’ EC2 instances (port 8080)</p></li><li><p>Response flow: EC2 instances (port 8080) â†’ <strong>ephemeral port</strong> cá»§a on-premises client</p></li><li><p><strong>Outbound traffic</strong> tá»« subnet cáº§n rule cho <strong>ephemeral ports (1024-65535)</strong> Ä‘á»ƒ return traffic vá» client</p></li><li><p>Náº¿u thiáº¿u outbound rule cho ephemeral ports, <strong>response traffic bá»‹ REJECT</strong> bá»Ÿi network ACL</p></li><li><p>Flow logs showing REJECT indicates network ACL blocking, khÃ´ng pháº£i security group</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>The security group of the EC2 instances has no Allow rule for the traffic from the NLB.</strong></p><ul><li><p><strong>NLB preserves source IP</strong> - traffic Ä‘áº¿n EC2 cÃ³ source IP lÃ  on-premises, khÃ´ng pháº£i NLB IP</p></li><li><p>Security groups allow traffic based on source IP/CIDR, náº¿u thiáº¿u rule thÃ¬ block inbound</p></li><li><p>NhÆ°ng flow logs showing rejected traffic thÆ°á»ng indicate <strong>network ACL issue</strong>, vÃ¬ security groups khÃ´ng log rejections chi tiáº¿t nhÆ° váº­y</p></li></ul><p></p><p>âŒ <strong>The security group of the NLB has no Allow rule for the traffic from the on-premises environment.</strong></p><ul><li><p><strong>NLB khÃ´ng cÃ³ security groups</strong> - NLB operates at Layer 4, khÃ´ng support security groups</p></li><li><p>Only Application Load Balancer (ALB) vÃ  classic load balancer cÃ³ security groups</p></li><li><p>ÄÃ¡p Ã¡n nÃ y technically incorrect</p></li></ul><p></p><p>âŒ <strong>The ACL of the on-premises environment does not allow traffic to the AWS environment.</strong></p><ul><li><p>On-premises ACL configuration <strong>náº±m ngoÃ i AWS control</strong></p></li><li><p>Náº¿u on-premises ACL block traffic, khÃ´ng thá»ƒ troubleshoot qua <strong>AWS flow logs</strong></p></li><li><p>Flow logs chá»‰ capture traffic á»Ÿ AWS side (VPC level)</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Network ACL + stateless\"</strong> â†’ Cáº§n rules cho cáº£ inbound vÃ  outbound</p></li><li><p><strong>\"Ephemeral ports\"</strong> â†’ Port range 1024-65535 cho return traffic</p></li><li><p><strong>\"Flow logs show REJECT\"</strong> â†’ Network ACL issue, khÃ´ng pháº£i security group</p></li><li><p><strong>Pattern</strong>: Stateless ACL = Explicit inbound + outbound rules | Stateful security group = Auto-allow return traffic</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/vpc/latest/userguide/custom-network-acl.html\">Network ACLs and ephemeral ports</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs-troubleshooting.html\">VPC Flow Logs troubleshooting</a></p></li></ul>",
            "correctAnswer": [
                "<p>The network ACL that is associated with the subnet does not allow outbound traffic for the ephemeral port range.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>The security group of the EC2 instances has no Allow rule for the traffic from the NLB.</p>",
                "<p>The security group of the NLB has no Allow rule for the traffic from the on-premises environment.</p>",
                "<p>The ACL of the on-premises environment does not allow traffic to the AWS environment.</p>",
                "<p>The network ACL that is associated with the subnet does not allow outbound traffic for the ephemeral port range.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 15
        },
        {
            "attemptAnswerId": 329287,
            "questionId": 6510,
            "questionText": "<p>A SysOps administrator is helping a development team deploy an application to AWS. The AWS CloudFormation template includes an Amazon Linux EC2 instance, an Amazon Aurora DB cluster, and a hardcoded database password that must be rotated every 90 days.<br><br>What is the MOST secure way to manage the database password?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>CloudFormation template deploy application vá»›i <strong>Amazon Linux EC2</strong> vÃ  <strong>Aurora DB cluster</strong></p></li><li><p>Database password hiá»‡n táº¡i <strong>hardcoded</strong> trong template</p></li><li><p>Password pháº£i <strong>rotate every 90 days</strong></p></li><li><p>YÃªu cáº§u: <strong>MOST secure way</strong> to manage password</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use the AWS::SecretsManager::Secret resource with the GenerateSecretString property to automatically generate a password. Use the AWS::SecretsManager::RotationSchedule resource to define a rotation schedule for the password. Configure the application to retrieve the secret from AWS Secrets Manager to access the database.</strong></p><ul><li><p><strong>Secrets Manager</strong> Ä‘Æ°á»£c thiáº¿t káº¿ specifically cho credential management vá»›i <strong>automatic rotation</strong></p></li><li><p><strong>GenerateSecretString</strong> tá»± Ä‘á»™ng generate strong password, loáº¡i bá» hardcoding vÃ  human error</p></li><li><p><strong>AWS::SecretsManager::RotationSchedule</strong> automatically rotate password theo schedule (every 90 days)</p></li><li><p><strong>Built-in rotation</strong> integration vá»›i Aurora - Secrets Manager tá»± Ä‘á»™ng update password á»Ÿ cáº£ secret vÃ  database</p></li><li><p>Application retrieve password dynamically, khÃ´ng cáº§n redeploy khi password thay Ä‘á»•i</p></li><li><p>ÄÃ¢y lÃ  <strong>most secure</strong> vÃ¬ eliminate hardcoded credentials + automatic rotation + encrypted storage</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use the AWS::SecretsManager::Secret resource with the SecretString property Accept a password as a CloudFormation parameter Use the AllowedPattern property of the CloudFormation parameter to require a minimum length, uppercase and lowercase letters, and special characters. Configure the application to retrieve the secret from AWS Secrets Manager to access the database.</strong></p><ul><li><p>Váº«n pháº£i <strong>manually input password</strong> qua CloudFormation parameter</p></li><li><p><strong>KhÃ´ng cÃ³ automatic rotation schedule</strong> - thiáº¿u RotationSchedule resource</p></li><li><p>AllowedPattern validation tá»‘t nhÆ°ng khÃ´ng giáº£i quyáº¿t rotation requirement</p></li></ul><p></p><p>âŒ <strong>Use the AWS::SSM::Parameter resource. Accept input as a CloudFormation parameter to store the parameter as a secure string. Configure the application to retrieve the parameter from AWS Systems Manager Parameter Store to access the database.</strong></p><ul><li><p><strong>Parameter Store khÃ´ng cÃ³ built-in automatic rotation</strong> nhÆ° Secrets Manager</p></li><li><p>Pháº£i <strong>manually rotate</strong> password vÃ  update parameter</p></li><li><p>KhÃ´ng Ä‘Ã¡p á»©ng requirement \"rotate every 90 days\" tá»± Ä‘á»™ng</p></li></ul><p></p><p>âŒ <strong>Use the AWS::SSM::Parameter resource. Accept input as a CloudFormation parameter to store the parameter as a string. Configure the application to retrieve the parameter from AWS Systems Manager Parameter Store to access the database.</strong></p><ul><li><p>Store as <strong>plain string</strong> (khÃ´ng encrypted) - very insecure</p></li><li><p>KhÃ´ng cÃ³ encryption at rest</p></li><li><p>KhÃ´ng cÃ³ automatic rotation</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Rotate credentials automatically\"</strong> â†’ <strong>AWS Secrets Manager</strong></p></li><li><p><strong>\"Hardcoded password\"</strong> â†’ Use auto-generation, khÃ´ng manual input</p></li><li><p><strong>\"Parameter Store vs Secrets Manager\"</strong> â†’ Secrets Manager cÃ³ automatic rotation, Parameter Store khÃ´ng</p></li><li><p><strong>Pattern</strong>: Database credentials + auto-rotation = Secrets Manager | Configuration values = Parameter Store</p></li></ul><hr><p></p><p>ğŸ“– Reference:</p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotating-secrets.html\">AWS Secrets Manager automatic rotation</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/rds-secrets-manager.html\">Rotating secrets for Aurora databases</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use the AWS::SecretsManager::Secret resource with the GenerateSecretString property to automatically generate a password. Use the AWS::SecretsManager::RotationSchedule resource to define a rotation schedule for the password. Configure the application to retrieve the secret from AWS Secrets Manager to access the database.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use the AWS::SecretsManager::Secret resource with the GenerateSecretString property to automatically generate a password. Use the AWS::SecretsManager::RotationSchedule resource to define a rotation schedule for the password. Configure the application to retrieve the secret from AWS Secrets Manager to access the database.</p>",
                "<p>Use the AWS::SecretsManager::Secret resource with the SecretString property Accept a password as a CloudFormation parameter Use the AllowedPattern property of the CloudFormation parameter to require a minimum length, uppercase and lowercase letters, and special characters. Configure the application to retrieve the secret from AWS Secrets Manager to access the database.</p>",
                "<p>Use the AWS::SSM::Parameter resource. Accept input as a CloudFormation parameter to store the parameter as a secure string. Configure the application to retrieve the parameter from AWS Systems Manager Parameter Store to access the database.</p>",
                "<p>Use the AWS::SSM::Parameter resource. Accept input as a CloudFormation parameter to store the parameter as a string. Configure the application to retrieve the parameter from AWS Systems Manager Parameter Store to access the database.</p>"
            ],
            "answersPos": "[3,1,0,2]",
            "pos": 16
        },
        {
            "attemptAnswerId": 329288,
            "questionId": 10438,
            "questionText": "<p>A company uses Amazon S3 to aggregate raw video footage from various media teams across the US. The company recently expanded into new geographies in Europe and Australia. The technical teams located in Europe and Australia reported delays when uploading large video files into the destination S3 bucket in the United States.<br><br>What are the MOST cost effective ways to increase upload speeds into the S3 bucket? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company dÃ¹ng S3 á»Ÿ <strong>US</strong> Ä‘á»ƒ tá»•ng há»£p <strong>raw video footage</strong></p></li><li><p>Má»Ÿ rá»™ng sang <strong>Europe vÃ  Australia</strong></p></li><li><p>Teams á»Ÿ Europe vÃ  Australia gáº·p <strong>delays uploading large video files</strong> vÃ o S3 bucket á»Ÿ US</p></li><li><p>YÃªu cáº§u: <strong>MOST cost-effective</strong> ways to increase upload speeds</p></li><li><p>Chá»n <strong>2 Ä‘Ã¡p Ã¡n</strong></p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use Amazon S3 Transfer Acceleration for file uploads into the destination S3 bucket.</strong></p><ul><li><p><strong>S3 Transfer Acceleration</strong> sá»­ dá»¥ng <strong>CloudFront edge locations</strong> distributed globally</p></li><li><p>Upload vÃ o edge location gáº§n nháº¥t (Europe/Australia), sau Ä‘Ã³ transfer qua <strong>AWS backbone network</strong> Ä‘áº¿n S3 bucket á»Ÿ US</p></li><li><p><strong>Optimized network path</strong> giáº£m latency dramatically cho long-distance uploads</p></li><li><p><strong>Pay-per-GB pricing</strong> - cost-effective, chá»‰ tráº£ khi dÃ¹ng, khÃ´ng cÃ³ upfront cost</p></li><li><p>Specifically designed cho scenario nÃ y</p></li></ul><p></p><p><strong>Use multipart uploads for file uploads into the destination S3 bucket from the branch offices in Europe and Australia.</strong></p><ul><li><p><strong>Multipart upload</strong> chia large files thÃ nh nhiá»u parts vÃ  upload <strong>parallel</strong></p></li><li><p>Improve upload speed vÃ  <strong>reliability</strong> - náº¿u 1 part fail, chá»‰ cáº§n retry part Ä‘Ã³</p></li><li><p><strong>Free S3 feature</strong>, khÃ´ng tá»‘n thÃªm cost</p></li><li><p>AWS recommends multipart upload cho files <strong>&gt;100MB</strong></p></li><li><p>Káº¿t há»£p tá»‘t vá»›i Transfer Acceleration</p></li></ul><hr><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765283266973-2j61tpkl-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"448.8333333333333\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create multiple AWS Direct Connect connections between AWS and branch offices in Europe and Australia for file uploads into the destination S3 bucket.</strong></p><ul><li><p><strong>Direct Connect ráº¥t expensive</strong> - upfront setup cost + monthly port charges</p></li><li><p>Requires <strong>physical installation</strong> vÃ  long setup time</p></li><li><p>Overkill cho use case upload files, khÃ´ng cost-effective</p></li></ul><p></p><p>âŒ <strong>Create multiple AWS Site-to-Site VPN connections between AWS and branch offices in Europe and Australia for file uploads into the destination S3 bucket.</strong></p><ul><li><p><strong>VPN cÃ³ encryption overhead</strong>, cÃ³ thá»ƒ lÃ m slower upload speed</p></li><li><p>Internet-based VPN khÃ´ng optimize routing nhÆ° Transfer Acceleration</p></li><li><p>KhÃ´ng giáº£i quyáº¿t long-distance latency issue</p></li></ul><p></p><p>âŒ <strong>Use AWS Global Accelerator for file uploads into the destination S3 bucket from the branch offices in Europe and Australia.</strong></p><ul><li><p>Global Accelerator <strong>khÃ´ng support S3 directly</strong> - chá»‰ support ALB, NLB, EC2, Elastic IP endpoints</p></li><li><p>Sai use case, khÃ´ng thá»ƒ dÃ¹ng cho S3 uploads</p></li><li><p>S3 Transfer Acceleration lÃ  correct service cho S3</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Large files + long distance uploads\"</strong> â†’ <strong>S3 Transfer Acceleration + Multipart upload</strong></p></li><li><p><strong>\"Global Accelerator\"</strong> â†’ ALB/NLB/EC2, KHÃ”NG support S3</p></li><li><p><strong>\"Cost-effective\"</strong> â†’ TrÃ¡nh Direct Connect/VPN, dÃ¹ng S3 native features</p></li><li><p><strong>Pattern</strong>: Long-distance S3 uploads = Transfer Acceleration | Large files = Multipart upload | Application endpoints = Global Accelerator</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/transfer-acceleration.html\">Amazon S3 Transfer Acceleration</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html\">Multipart upload for large objects</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use Amazon S3 Transfer Acceleration for file uploads into the destination S3 bucket.</p>",
                "<p>Use multipart uploads for file uploads into the destination S3 bucket from the branch offices in Europe and Australia.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create multiple AWS Direct Connect connections between AWS and branch offices in Europe and Australia for file uploads into the destination S3 bucket.</p>",
                "<p>Create multiple AWS Site-to-Site VPN connections between AWS and branch offices in Europe and Australia for file uploads into the destination S3 bucket.</p>",
                "<p>Use Amazon S3 Transfer Acceleration for file uploads into the destination S3 bucket.</p>",
                "<p>Use AWS Global Accelerator for file uploads into the destination S3 bucket from the branch offices in Europe and Australia.</p>",
                "<p>Use multipart uploads for file uploads into the destination S3 bucket from the branch offices in Europe and Australia.</p>"
            ],
            "answersPos": "[1,0,3,4,2]",
            "pos": 17
        },
        {
            "attemptAnswerId": 329289,
            "questionId": 6512,
            "questionText": "<p>A SysOps administrator configures an Amazon S3 gateway endpoint in a VPC. The private subnets inside the VPC do not have outbound internet access. User logs in to an Amazon EC2 instance in one of the private subnets and cannot upload a file to an Amazon S3 bucket in the same AWS Region.<br><br>Which solution will solve this problem?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p><strong>S3 gateway endpoint</strong> Ä‘Ã£ Ä‘Æ°á»£c configure trong VPC</p></li><li><p><strong>Private subnets khÃ´ng cÃ³ outbound internet access</strong></p></li><li><p>EC2 instance trong private subnet <strong>khÃ´ng thá»ƒ upload file</strong> lÃªn S3 bucket (same region)</p></li><li><p>YÃªu cáº§u: giáº£i phÃ¡p Ä‘á»ƒ fix connectivity issue</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Update the EC2 subnet route table to include the S3 prefix list destination routes to the S3 gateway endpoint.</strong></p><ul><li><p><strong>S3 gateway endpoint requires route table configuration</strong> Ä‘á»ƒ hoáº¡t Ä‘á»™ng</p></li><li><p>Chá»‰ táº¡o gateway endpoint chÆ°a Ä‘á»§ - pháº£i <strong>add route</strong> vÃ o route table cá»§a subnet</p></li><li><p>Route format: Destination = <strong>S3 prefix list (pl-xxx)</strong>, Target = <strong>Gateway endpoint ID (vpce-xxx)</strong></p></li><li><p>KhÃ´ng cÃ³ route nÃ y, traffic khÃ´ng biáº¿t Ä‘i qua gateway endpoint vÃ  cá»‘ gáº¯ng reach S3 qua internet (fails vÃ¬ private subnet no internet access)</p></li><li><p>ÄÃ¢y lÃ  <strong>common mistake</strong> khi setup gateway endpoint - quÃªn update route table</p></li></ul><hr><p></p><p><em>Architecture:</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765283931640-zwszlucc-image.png\" alt=\"\" title=\"\" width=\"656\" height=\"540.79\" style=\"max-width: 656px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Update the EC2 instance role policy to include s3:PutObject access to the target S3 bucket.</strong></p><ul><li><p>IAM permission cÃ³ thá»ƒ lÃ  issue nhÆ°ng Ä‘á» bÃ i khÃ´ng mention permission error</p></li><li><p>Náº¿u lÃ  permission issue, error message sáº½ khÃ¡c (Access Denied vs connection timeout/network error)</p></li><li><p>Váº¥n Ä‘á» chÃ­nh lÃ  <strong>routing/connectivity</strong>, khÃ´ng pháº£i permissions</p></li></ul><p></p><p>âŒ <strong>Update the EC2 security group to allow outbound traffic to 0.0.0.0/0 for port 80.</strong></p><ul><li><p><strong>S3 uses HTTPS (port 443)</strong>, khÃ´ng pháº£i HTTP (port 80)</p></li><li><p>Security groups <strong>stateful</strong> - náº¿u cÃ³ outbound rule, return traffic tá»± Ä‘á»™ng allowed</p></li><li><p><strong>Gateway endpoint traffic khÃ´ng Ä‘i qua internet</strong>, nÃªn security group khÃ´ng pháº£i root cause</p></li></ul><p></p><p>âŒ <strong>Update the S3 bucket policy to allow s3:PutObject access from the private subnet CIDR block.</strong></p><ul><li><p>Bucket policy controls <strong>authorization</strong>, khÃ´ng pháº£i connectivity</p></li><li><p>Náº¿u lÃ  bucket policy issue, sáº½ nháº­n <strong>403 Forbidden</strong>, khÃ´ng pháº£i connection failure</p></li><li><p>Váº¥n Ä‘á» á»Ÿ network layer, khÃ´ng pháº£i permission layer</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"S3 gateway endpoint\"</strong> â†’ Pháº£i <strong>update route table</strong> vá»›i S3 prefix list</p></li><li><p><strong>\"Gateway endpoint khÃ´ng work\"</strong> â†’ Check route table first</p></li><li><p><strong>\"Private subnet + S3 access\"</strong> â†’ Gateway endpoint + Route table configuration</p></li><li><p><strong>Pattern</strong>: Gateway endpoint setup = Create endpoint + Update route tables | Interface endpoint = Create endpoint (auto-add routes)</p></li></ul><hr><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html\">Gateway endpoints for Amazon S3</a></p></li></ul>",
            "correctAnswer": [
                "<p>Update the EC2 subnet route table to include the S3 prefix list destination routes to the S3 gateway endpoint.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Update the EC2 instance role policy to include s3:PutObject access to the target S3 bucket.</p>",
                "<p>Update the EC2 security group to allow outbound traffic to 0.0.0.0/0 for port 80.</p>",
                "<p>Update the EC2 subnet route table to include the S3 prefix list destination routes to the S3 gateway endpoint.</p>",
                "<p>Update the S3 bucket policy to allow s3:PutObject access from the private subnet CIDR block.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 18
        },
        {
            "attemptAnswerId": 329290,
            "questionId": 6513,
            "questionText": "<p>A SysOps administrator is building a process for sharing Amazon RDS database snapshots between different accounts associated with different business units within the same company. All data must be encrypted at rest.<br><br>How should the administrator implement this process?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Share <strong>RDS database snapshots</strong> giá»¯a <strong>different AWS accounts</strong> (same company, different business units)</p></li><li><p>All data pháº£i <strong>encrypted at rest</strong></p></li><li><p>YÃªu cáº§u: cÃ¡ch implement secure sharing process</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Update the key policy to grant permission to the AWS KMS encryption key used to encrypt the snapshot with all relevant accounts, then share the snapshot with those accounts.</strong></p><ul><li><p><strong>Encrypted RDS snapshots</strong> Ä‘Æ°á»£c encrypt báº±ng <strong>KMS key</strong></p></li><li><p>Äá»ƒ share encrypted snapshot, pháº£i <strong>grant KMS key permissions</strong> cho target accounts trÆ°á»›c</p></li><li><p>Update <strong>KMS key policy</strong> Ä‘á»ƒ add statements cho phÃ©p target accounts <strong>Decrypt</strong> vÃ  <strong>CreateGrant</strong> operations</p></li><li><p>Sau Ä‘Ã³ <strong>share snapshot</strong> vá»›i target accounts qua RDS console/API</p></li><li><p>Target accounts cÃ³ thá»ƒ <strong>copy snapshot</strong> vÃ  optionally <strong>re-encrypt</strong> vá»›i their own KMS key</p></li><li><p>ÄÃ¢y lÃ  <strong>AWS recommended approach</strong> cho sharing encrypted snapshots, maintain encryption throughout</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Write a script to download the encrypted snapshot, decrypt it using the AWS KMS encryption key used to encrypt the snapshot, then create a new volume in each account.</strong></p><ul><li><p><strong>KhÃ´ng thá»ƒ download RDS snapshots</strong> nhÆ° files - RDS snapshots khÃ´ng accessible nhÆ° váº­y</p></li><li><p>Cannot manually decrypt vÃ  re-upload snapshots</p></li><li><p>Approach hoÃ n toÃ n khÃ´ng kháº£ thi vá»›i RDS</p></li></ul><p></p><p>âŒ <strong>Create an Amazon EC2 instance based on the snapshot, then save the instance's Amazon EBS volume as a snapshot and share it with the other accounts. Require each account owner to create a new volume from that snapshot and encrypt it.</strong></p><ul><li><p><strong>RDS snapshot khÃ´ng thá»ƒ táº¡o EC2 instance</strong> - chá»‰ cÃ³ thá»ƒ restore to RDS instance</p></li><li><p>Process nÃ y phá»©c táº¡p, lose RDS functionality</p></li><li><p>Táº¡o unencrypted intermediate state - vi pháº¡m \"all data must be encrypted at rest\"</p></li></ul><p></p><p>âŒ <strong>Create a new unencrypted RDS instance from the encrypted snapshot, connect to the instance using SSH/RDP, export the database contents into a file, then share this file with the other accounts.</strong></p><ul><li><p><strong>Vi pháº¡m requirement</strong> \"all data must be encrypted at rest\" - táº¡o unencrypted instance</p></li><li><p><strong>Cannot SSH/RDP</strong> vÃ o RDS instances - RDS lÃ  managed service</p></li><li><p>Export to file máº¥t database structure, configurations, vÃ  khÃ´ng scalable</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Share encrypted snapshot across accounts\"</strong> â†’ <strong>Update KMS key policy first</strong></p></li><li><p><strong>\"RDS encrypted snapshot\"</strong> â†’ Cannot decrypt manually, must maintain encryption</p></li><li><p><strong>\"Cross-account sharing\"</strong> â†’ KMS permissions + Share snapshot</p></li><li><p><strong>Pattern</strong>: Share encrypted resources = KMS key policy + Resource sharing | Unencrypted sharing = Direct resource sharing only</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-soa/share-encrypted-rds-snapshot-kms-key\">Share RDS snapshots across AWS account (CMP Blog)</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/share-encrypted-snapshot.html\">Sharing encrypted RDS snapshots</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/kms/latest/developerguide/key-policy-modifying-external-accounts.html\">AWS KMS key policies for cross-account access</a></p></li></ul>",
            "correctAnswer": [
                "<p>Update the key policy to grant permission to the AWS KMS encryption key used to encrypt the snapshot with all relevant accounts, then share the snapshot with those accounts.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Write a script to download the encrypted snapshot, decrypt it using the AWS KMS encryption key used to encrypt the snapshot, then create a new volume in each account.</p>",
                "<p>Update the key policy to grant permission to the AWS KMS encryption key used to encrypt the snapshot with all relevant accounts, then share the snapshot with those accounts.</p>",
                "<p>Create an Amazon EC2 instance based on the snapshot, then save the instance's Amazon EBS volume as a snapshot and share it with the other accounts. Require each account owner to create a new volume from that snapshot and encrypt it.</p>",
                "<p>Create a new unencrypted RDS instance from the encrypted snapshot, connect to the instance using SSH/RDP, export the database contents into a file, then share this file with the other accounts.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 19
        },
        {
            "attemptAnswerId": 329291,
            "questionId": 6514,
            "questionText": "<p>A company uses AWS CloudFormation templates to deploy cloud infrastructure. An analysis of all the company's templates shows that the company has declared the same components in multiple templates. A SysOps administrator needs to create dedicated templates that have their own parameters and conditions for these common components.<br><br>Which solution will meet this requirement?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company dÃ¹ng <strong>CloudFormation templates</strong> Ä‘á»ƒ deploy infrastructure</p></li><li><p>Analysis cho tháº¥y <strong>same components declared multiple times</strong> trong nhiá»u templates (duplicate)</p></li><li><p>Cáº§n táº¡o <strong>dedicated templates</strong> vá»›i <strong>own parameters vÃ  conditions</strong> cho common components</p></li><li><p>YÃªu cáº§u: solution Ä‘á»ƒ reuse common components</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Develop CloudFormation nested stacks.</strong></p><ul><li><p><strong>Nested stacks</strong> cho phÃ©p táº¡o <strong>separate templates</strong> cho common/reusable components</p></li><li><p>Parent stack reference child stacks qua <strong>AWS::CloudFormation::Stack</strong> resource</p></li><li><p>Má»—i nested stack cÃ³ <strong>own parameters, conditions, outputs</strong> - Ä‘á»™c láº­p vÃ  tÃ¡i sá»­ dá»¥ng</p></li><li><p><strong>Best practice</strong> cho modular infrastructure - tÃ¡ch common patterns thÃ nh reusable templates</p></li><li><p>VÃ­ dá»¥: VPC template, security group template, load balancer template - má»—i template cÃ³ parameters riÃªng vÃ  Ä‘Æ°á»£c reuse trong nhiá»u parent stacks</p></li></ul><hr><p></p><p><em>Nested stacks:</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765285855003-byclvb2k-image.png\" alt=\"\" title=\"\" width=\"361\" height=\"611.1241145833334\" style=\"max-width: 361px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Develop a CloudFormation change set.</strong></p><ul><li><p><strong>Change set</strong> dÃ¹ng Ä‘á»ƒ <strong>preview changes</strong> trÆ°á»›c khi execute stack update</p></li><li><p>KhÃ´ng pháº£i solution cho reusable components hay template modularity</p></li><li><p>HoÃ n toÃ n khÃ¡c use case</p></li></ul><p></p><p>âŒ <strong>Develop CloudFormation macros.</strong></p><ul><li><p><strong>Macros</strong> perform custom processing trÃªn templates (transform template content)</p></li><li><p>DÃ¹ng cho advanced template transformation, khÃ´ng pháº£i cÃ¡ch standard cho reusable components</p></li><li><p>Phá»©c táº¡p hÆ¡n vÃ  khÃ´ng pháº£i best practice cho scenario nÃ y</p></li></ul><p></p><p>âŒ <strong>Develop CloudFormation stack sets.</strong></p><ul><li><p><strong>Stack sets</strong> deploy stacks across <strong>multiple accounts vÃ  regions</strong></p></li><li><p>Use case cho multi-account/multi-region deployment, khÃ´ng pháº£i template reusability</p></li><li><p>KhÃ´ng giáº£i quyáº¿t váº¥n Ä‘á» duplicate components trong templates</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Reusable components + parameters\"</strong> â†’ <strong>Nested stacks</strong></p></li><li><p><strong>\"Multi-account/region deployment\"</strong> â†’ <strong>Stack sets</strong></p></li><li><p><strong>\"Preview changes\"</strong> â†’ <strong>Change sets</strong></p></li><li><p><strong>Pattern</strong>: Template modularity = Nested stacks | Cross-account deployment = Stack sets | Template transformation = Macros</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-nested-stacks.html\">Working with nested stacks</a></p></li><li><p>CloudFormation best practices for nested stacks</p></li></ul>",
            "correctAnswer": [
                "<p>Develop CloudFormation nested stacks.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Develop a CloudFormation change set.</p>",
                "<p>Develop CloudFormation macros.</p>",
                "<p>Develop CloudFormation nested stacks.</p>",
                "<p>Develop CloudFormation stack sets.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 20
        },
        {
            "attemptAnswerId": 329292,
            "questionId": 6515,
            "questionText": "<p>A company with multiple AWS accounts needs to obtain recommendations for AWS Lambda functions and identify optimal resource configurations for each Lambda function.<br><br>How should a SysOps administrator provide these recommendations?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company cÃ³ <strong>multiple AWS accounts</strong></p></li><li><p>Cáº§n nháº­n Ä‘Æ°á»£c <strong>recommendations for Lambda functions</strong></p></li><li><p>Identify <strong>optimal resource configurations</strong> cho má»—i Lambda function</p></li><li><p>YÃªu cáº§u: solution Ä‘á»ƒ provide recommendations</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Enable AWS Compute Optimizer and export the Lambda function recommendations.</strong></p><ul><li><p><strong>AWS Compute Optimizer</strong> Ä‘Æ°á»£c thiáº¿t káº¿ specifically Ä‘á»ƒ <strong>analyze vÃ  recommend</strong> optimal configurations cho compute resources</p></li><li><p>Há»— trá»£ <strong>Lambda functions</strong> - analyze execution patterns vÃ  recommend <strong>optimal memory configurations</strong></p></li><li><p>Provide recommendations vá» <strong>cost optimization</strong> vÃ  <strong>performance improvements</strong></p></li><li><p><strong>Multi-account support</strong> - cÃ³ thá»ƒ tá»•ng há»£p recommendations across multiple accounts khi enable trong Organizations</p></li><li><p><strong>Export recommendations</strong> to S3 hoáº·c view trong console vá»›i detailed metrics</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create an AWS Serverless Application Repository and export the Lambda function recommendations.</strong></p><ul><li><p><strong>Serverless Application Repository</strong> lÃ  service Ä‘á»ƒ <strong>share vÃ  deploy</strong> serverless applications</p></li><li><p>KhÃ´ng pháº£i tool cho <strong>analyzing hay recommending</strong> resource configurations</p></li><li><p>Use case hoÃ n toÃ n khÃ¡c</p></li></ul><p></p><p>âŒ <strong>Enable all features of AWS Organizations and export the recommendations from AWS CloudTrail Insights.</strong></p><ul><li><p><strong>CloudTrail Insights</strong> detect <strong>unusual API activity</strong> patterns (anomaly detection)</p></li><li><p>KhÃ´ng provide <strong>resource configuration recommendations</strong> cho Lambda</p></li><li><p>DÃ¹ng cho security vÃ  troubleshooting, khÃ´ng pháº£i optimization</p></li></ul><p></p><p>âŒ <strong>Run AWS Trusted Advisor and export the Lambda function recommendations.</strong></p><ul><li><p><strong>Trusted Advisor</strong> cÃ³ general best practice checks nhÆ°ng <strong>khÃ´ng cÃ³ detailed Lambda function configuration recommendations</strong></p></li><li><p>KhÃ´ng analyze Lambda execution patterns Ä‘á»ƒ recommend optimal memory nhÆ° Compute Optimizer</p></li><li><p>Limited Lambda-specific insights</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Lambda optimization + resource configuration\"</strong> â†’ <strong>AWS Compute Optimizer</strong></p></li><li><p><strong>\"Optimal resource configurations\"</strong> â†’ Compute Optimizer (EC2, Lambda, EBS, Auto Scaling)</p></li><li><p><strong>\"Trusted Advisor\"</strong> â†’ General best practices | <strong>Compute Optimizer</strong> â†’ Detailed resource-specific recommendations</p></li><li><p><strong>Pattern</strong>: Resource optimization = Compute Optimizer | Best practice checks = Trusted Advisor | Anomaly detection = CloudTrail Insights</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/compute-optimizer/latest/ug/view-lambda-recommendations.html\">AWS Compute Optimizer for Lambda functions</a></p></li></ul>",
            "correctAnswer": [
                "<p>Enable AWS Compute Optimizer and export the Lambda function recommendations.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an AWS Serverless Application Repository and export the Lambda function recommendations.</p>",
                "<p>Enable AWS Compute Optimizer and export the Lambda function recommendations.</p>",
                "<p>Enable all features of AWS Organizations and export the recommendations from AWS CloudTrail Insights.</p>",
                "<p>Run AWS Trusted Advisor and export the Lambda function recommendations.</p>"
            ],
            "answersPos": "[1,3,0,2]",
            "pos": 21
        },
        {
            "attemptAnswerId": 329293,
            "questionId": 6516,
            "questionText": "<p>A company has a critical serverless application that uses multiple AWS Lambda functions. Each Lambda function generates 1 GB of log data daily in its own Amazon CloudWatch Logs log group. The company's security team asks for a count of application errors, grouped by type, across all of the log groups.<br><br>What should a SysOps administrator do to meet this requirement?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Multiple <strong>Lambda functions</strong>, má»—i function cÃ³ <strong>1GB logs daily</strong> trong own CloudWatch Logs log group</p></li><li><p>Security team cáº§n <strong>count application errors, grouped by type</strong>, across <strong>all log groups</strong></p></li><li><p>YÃªu cáº§u: solution Ä‘á»ƒ query vÃ  aggregate errors</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Perform a CloudWatch Logs Insights query that uses the stats command and count function.</strong></p><ul><li><p><strong>CloudWatch Logs Insights</strong> lÃ  native query service cho CloudWatch Logs</p></li><li><p>CÃ³ thá»ƒ <strong>query across multiple log groups</strong> simultaneously</p></li><li><p><strong>stats command</strong> dÃ¹ng Ä‘á»ƒ perform aggregations (count, sum, avg, etc.)</p></li><li><p><strong>count function</strong> Ä‘áº¿m occurrences cá»§a errors grouped by type</p></li><li><p>Query syntax vÃ­ dá»¥: <code>fields @timestamp, error_type | stats count() by error_type</code></p></li><li><p><strong>No additional setup</strong> required - works directly vá»›i existing CloudWatch Logs</p></li><li><p>Fast vÃ  cost-effective cho log analysis</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Perform a CloudWatch Logs search that uses the groupby keyword and count function.</strong></p><ul><li><p>CloudWatch Logs <strong>basic filter/search</strong> khÃ´ng cÃ³ <strong>groupby keyword</strong></p></li><li><p>Filter patterns chá»‰ support simple text matching, khÃ´ng cÃ³ aggregation functions</p></li><li><p>KhÃ´ng thá»ƒ perform complex queries vá»›i grouping</p></li></ul><p></p><p>âŒ <strong>Perform an Amazon Athena query that uses the SELECT and GROUP BY keywords.</strong></p><ul><li><p><strong>Athena queries data in S3</strong>, khÃ´ng pháº£i CloudWatch Logs directly</p></li><li><p>Pháº£i <strong>export logs to S3</strong> trÆ°á»›c - additional steps, latency, vÃ  cost</p></li><li><p>Overkill cho use case nÃ y khi Logs Insights available</p></li></ul><p></p><p>âŒ <strong>Perform an Amazon RDS query that uses the SELECT and GROUP BY keywords.</strong></p><ul><li><p><strong>RDS lÃ  relational database</strong> service, khÃ´ng liÃªn quan Ä‘áº¿n log analysis</p></li><li><p>CloudWatch Logs <strong>khÃ´ng store trong RDS</strong></p></li><li><p>HoÃ n toÃ n sai service</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Query CloudWatch Logs + aggregation\"</strong> â†’ <strong>CloudWatch Logs Insights</strong></p></li><li><p><strong>\"stats command\"</strong> â†’ Aggregation operations trong Logs Insights</p></li><li><p><strong>\"Multiple log groups\"</strong> â†’ Logs Insights cÃ³ thá»ƒ query across log groups</p></li><li><p><strong>Pattern</strong>: CloudWatch log analysis = Logs Insights | S3 data analysis = Athena | Filter only = CloudWatch Logs filter</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html\">CloudWatch Logs Insights query syntax</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html\">Analyzing log data with CloudWatch Logs Insights</a></p></li></ul>",
            "correctAnswer": [
                "<p>Perform a CloudWatch Logs Insights query that uses the stats command and count function.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Perform a CloudWatch Logs Insights query that uses the stats command and count function.</p>",
                "<p>Perform a CloudWatch Logs search that uses the groupby keyword and count function.</p>",
                "<p>Perform an Amazon Athena query that uses the SELECT and GROUP BY keywords.</p>",
                "<p>Perform an Amazon RDS query that uses the SELECT and GROUP BY keywords.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 22
        },
        {
            "attemptAnswerId": 329294,
            "questionId": 6517,
            "questionText": "<p>A company applies user-defined tags to resources that are associated with the company's AWS workloads. Twenty days after applying the tags, the company notices that it cannot use the tags to filter views in the AWS Cost Explorer console.<br><br>What is the reason for this issue?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company applies <strong>user-defined tags</strong> to AWS resources</p></li><li><p><strong>20 days later</strong>, khÃ´ng thá»ƒ dÃ¹ng tags Ä‘á»ƒ <strong>filter views trong Cost Explorer</strong></p></li><li><p>YÃªu cáº§u: identify reason for issue</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>The company has not activated the user-defined tags for cost allocation.</strong></p><ul><li><p><strong>User-defined tags</strong> pháº£i Ä‘Æ°á»£c <strong>explicitly activated</strong> as <strong>cost allocation tags</strong> trong Billing Console</p></li><li><p>Chá»‰ apply tags to resources <strong>chÆ°a Ä‘á»§</strong> - pháº£i activate trong <strong>Cost Allocation Tags section</strong></p></li><li><p>Process: Billing Console â†’ Cost Allocation Tags â†’ Select user-defined tags â†’ Activate</p></li><li><p>Sau khi activate, máº¥t <strong>up to 24 hours</strong> Ä‘á»ƒ tags xuáº¥t hiá»‡n trong Cost Explorer</p></li><li><p><strong>AWS-generated tags</strong> (nhÆ° aws:createdBy) tá»± Ä‘á»™ng available, nhÆ°ng <strong>user-defined tags require manual activation</strong></p></li></ul><hr><p></p><p><em>Cost allocation tags</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765288046064-ucipymi2-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"216.53125\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p></p><p><em>Cost Explorer</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765288153776-t31upk9c-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"398.49999999999994\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>It takes at least 30 days to be able to use tags to filter views in Cost Explorer.</strong></p><ul><li><p>KhÃ´ng cÃ³ requirement <strong>30 days waiting period</strong></p></li><li><p>Sau khi activate, tags available trong <strong>~24 hours</strong>, khÃ´ng pháº£i 30 days</p></li><li><p>Thá»i gian 20 ngÃ y trong Ä‘á» khÃ´ng liÃªn quan</p></li></ul><p></p><p>âŒ <strong>The company has not created an AWS Cost and Usage Report.</strong></p><ul><li><p><strong>Cost and Usage Report</strong> lÃ  separate feature Ä‘á»ƒ export detailed billing data to S3</p></li><li><p><strong>KhÃ´ng required</strong> Ä‘á»ƒ use tags trong Cost Explorer</p></li><li><p>Cost Explorer vÃ  CUR lÃ  independent features</p></li></ul><p></p><p>âŒ <strong>The company has not created a usage budget in AWS Budgets.</strong></p><ul><li><p><strong>AWS Budgets</strong> dÃ¹ng Ä‘á»ƒ set spending alerts vÃ  thresholds</p></li><li><p><strong>KhÃ´ng liÃªn quan</strong> Ä‘áº¿n Cost Explorer tag filtering capability</p></li><li><p>Budgets vÃ  Cost Explorer filtering lÃ  separate features</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"User-defined tags + Cost Explorer\"</strong> â†’ <strong>Must activate as cost allocation tags</strong></p></li><li><p><strong>\"AWS-generated tags\"</strong> â†’ Auto-available | <strong>User-defined tags</strong> â†’ Manual activation required</p></li><li><p><strong>\"Cannot filter by tags\"</strong> â†’ Check if tags activated trong Billing Console</p></li><li><p><strong>Pattern</strong>: Tag filtering in Cost Explorer = Activate cost allocation tags | Tag resources only = Not enough</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/activating-tags.html\">Activating user-defined cost allocation tags</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html\">Using cost allocation tags in AWS Billing</a></p></li></ul>",
            "correctAnswer": [
                "<p>The company has not activated the user-defined tags for cost allocation.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>It takes at least 30 days to be able to use tags to filter views in Cost Explorer.</p>",
                "<p>The company has not activated the user-defined tags for cost allocation.</p>",
                "<p>The company has not created an AWS Cost and Usage Report.</p>",
                "<p>The company has not created a usage budget in AWS Budgets.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 23
        },
        {
            "attemptAnswerId": 329295,
            "questionId": 6518,
            "questionText": "<p>A SysOps administrator is required to monitor free space on Amazon EBS volumes attached to Microsoft Windows-based Amazon EC2 instances within a company's account. The administrator must be alerted to potential issues.<br><br>What should the administrator do to receive email alerts before low storage space affects EC2 instance performance?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Monitor <strong>free space</strong> trÃªn <strong>EBS volumes</strong> attached to <strong>Windows EC2 instances</strong></p></li><li><p>Cáº§n <strong>email alerts</strong> trÆ°á»›c khi low storage áº£nh hÆ°á»Ÿng Ä‘áº¿n performance</p></li><li><p>YÃªu cáº§u: solution Ä‘á»ƒ monitor vÃ  alert</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use the Amazon CloudWatch agent to send disk space metrics, then set up CloudWatch alarms using an Amazon SNS topic.</strong></p><ul><li><p><strong>CloudWatch default metrics KHÃ”NG bao gá»“m disk space</strong> (free space/used space)</p></li><li><p>Default metrics chá»‰ cÃ³: CPU, Network, Disk I/O (VolumeReadBytes/WriteBytes)</p></li><li><p><strong>CloudWatch agent</strong> pháº£i install Ä‘á»ƒ collect <strong>disk space metrics</strong> (disk_used_percent, disk_free)</p></li><li><p>Agent collect custom metrics tá»« OS level vÃ  push lÃªn CloudWatch</p></li><li><p>Táº¡o <strong>CloudWatch alarms</strong> dá»±a trÃªn disk space metrics vá»›i threshold (vd: disk_used_percent &gt; 80%)</p></li><li><p><strong>SNS topic</strong> trigger email notifications khi alarm state changes</p></li><li><p>ÄÃ¢y lÃ  <strong>standard approach</strong> cho monitoring disk utilization</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use built-in Amazon CloudWatch metrics, and configure CloudWatch alarms and an Amazon SNS topic for email notifications.</strong></p><ul><li><p><strong>Built-in metrics khÃ´ng cÃ³ disk space/utilization metrics</strong></p></li><li><p>Chá»‰ cÃ³ disk I/O metrics (reads/writes), khÃ´ng pháº£i free space</p></li><li><p>Cannot monitor free space without CloudWatch agent</p></li></ul><p></p><p>âŒ <strong>Use AWS CloudTrail logs and configure the trail to send notifications to an Amazon SNS topic.</strong></p><ul><li><p><strong>CloudTrail logs API calls</strong>, khÃ´ng monitor resource metrics</p></li><li><p>KhÃ´ng capture disk space utilization data</p></li><li><p>Wrong service cho monitoring use case</p></li></ul><p></p><p>âŒ <strong>Use AWS Trusted Advisor and enable email notification alerts for EC2 disk space.</strong></p><ul><li><p><strong>Trusted Advisor khÃ´ng monitor individual instance disk space</strong></p></li><li><p>Provides high-level recommendations, khÃ´ng real-time monitoring</p></li><li><p>KhÃ´ng cÃ³ specific alerts cho disk space thresholds</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Disk space/memory metrics\"</strong> â†’ <strong>CloudWatch agent required</strong></p></li><li><p><strong>\"Default CloudWatch metrics\"</strong> â†’ CPU, Network, Disk I/O (khÃ´ng cÃ³ disk space)</p></li><li><p><strong>\"Custom metrics from OS\"</strong> â†’ CloudWatch agent</p></li><li><p><strong>Pattern</strong>: Default metrics = CPU/Network/Disk I/O | Custom metrics = Agent required (memory, disk space)</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-soa/cloudwatch-agent-cai-dat-cau-hinh-amazon-linux-2023-ec2\">CloudWatch Agent - CÃ i Ä‘áº·t vÃ  cáº¥u hÃ¬nh trÃªn Amazon Linux 2023 - Thu tháº­p Logs vÃ  Metrics tá»« EC2</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/install-CloudWatch-Agent-on-EC2-Instance.html\">Install CloudWatch agent on EC2 instances</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html\">Collect metrics and logs with CloudWatch agent</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use the Amazon CloudWatch agent to send disk space metrics, then set up CloudWatch alarms using an Amazon SNS topic.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use built-in Amazon CloudWatch metrics, and configure CloudWatch alarms and an Amazon SNS topic for email notifications.</p>",
                "<p>Use AWS CloudTrail logs and configure the trail to send notifications to an Amazon SNS topic.</p>",
                "<p>Use the Amazon CloudWatch agent to send disk space metrics, then set up CloudWatch alarms using an Amazon SNS topic.</p>",
                "<p>Use AWS Trusted Advisor and enable email notification alerts for EC2 disk space.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 24
        },
        {
            "attemptAnswerId": 329296,
            "questionId": 6519,
            "questionText": "<p>A software company runs a workload on Amazon EC2 instances behind an Application Load Balancer (ALB). A SysOps administrator needs to define a custom health check for the EC2 instances.<br><br>What is the MOST operationally efficient solution?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Workload cháº¡y trÃªn <strong>EC2 instances behind Application Load Balancer (ALB)</strong></p></li><li><p>Cáº§n define <strong>custom health check</strong> cho EC2 instances</p></li><li><p>YÃªu cáº§u: <strong>MOST operationally efficient</strong> solution</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Configure the health check on the ALB and ensure that the Health Check Path setting is correct.</strong></p><ul><li><p><strong>ALB cÃ³ built-in health check mechanism</strong> - native feature khÃ´ng cáº§n additional components</p></li><li><p>ALB periodically sends <strong>HTTP/HTTPS requests</strong> Ä‘áº¿n <strong>Health Check Path</strong> (vÃ­ dá»¥: /health, /status)</p></li><li><p>Application pháº£i <strong>implement endpoint</strong> Ä‘á»ƒ return appropriate HTTP status codes (200 = healthy, 4xx/5xx = unhealthy)</p></li><li><p>CÃ³ thá»ƒ <strong>customize</strong> health check: path, protocol, interval, timeout, healthy/unhealthy thresholds</p></li><li><p><strong>Most operationally efficient</strong> vÃ¬ sá»­ dá»¥ng built-in ALB feature, khÃ´ng cáº§n infrastructure thÃªm</p></li><li><p>ÄÃ¢y lÃ  <strong>standard practice</strong> cho custom health checks vá»›i ALB</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Set up each EC2 instance so that it writes its healthy/unhealthy status into a shared Amazon S3 bucket for the ALB to read.</strong></p><ul><li><p><strong>ALB khÃ´ng read tá»« S3</strong> Ä‘á»ƒ xÃ¡c Ä‘á»‹nh health status</p></li><li><p>Requires custom mechanism Ä‘á»ƒ write/read S3 - <strong>high operational overhead</strong></p></li><li><p>KhÃ´ng pháº£i cÃ¡ch ALB health check hoáº¡t Ä‘á»™ng</p></li></ul><p></p><p>âŒ <strong>Set up Amazon ElastiCache to track the EC2 instances as they scale in and out.</strong></p><ul><li><p><strong>ElastiCache lÃ  caching service</strong>, khÃ´ng pháº£i health checking service</p></li><li><p>KhÃ´ng cÃ³ tÃ­nh nÄƒng track instance health</p></li><li><p>Sai service hoÃ n toÃ n cho use case nÃ y</p></li></ul><p></p><p>âŒ <strong>Configure an Amazon API Gateway health check to ensure custom checks on all of the EC2 instances.</strong></p><ul><li><p><strong>API Gateway khÃ´ng cÃ³ health check integration</strong> vá»›i ALB hay EC2</p></li><li><p>API Gateway lÃ  service cho managing APIs, khÃ´ng pháº£i monitoring instance health</p></li><li><p>Over-engineering vÃ  wrong service</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"ALB custom health check\"</strong> â†’ <strong>Configure Health Check Path</strong> trÃªn ALB</p></li><li><p><strong>\"Health check endpoint\"</strong> â†’ Application implement endpoint return status codes</p></li><li><p><strong>\"Operationally efficient\"</strong> â†’ Use native features, avoid custom solutions</p></li><li><p><strong>Pattern</strong>: ALB health check = Configure path + Application endpoint | No additional services needed</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/target-group-health-checks.html\">Configure health check settings for target groups</a></p></li></ul>",
            "correctAnswer": [
                "<p>Configure the health check on the ALB and ensure that the Health Check Path setting is correct.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Set up each EC2 instance so that it writes its healthy/unhealthy status into a shared Amazon S3 bucket for the ALB to read.</p>",
                "<p>Configure the health check on the ALB and ensure that the Health Check Path setting is correct.</p>",
                "<p>Set up Amazon ElastiCache to track the EC2 instances as they scale in and out.</p>",
                "<p>Configure an Amazon API Gateway health check to ensure custom checks on all of the EC2 instances.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 25
        },
        {
            "attemptAnswerId": 329297,
            "questionId": 6520,
            "questionText": "<p>A SysOps administrator is optimizing the cost of a workload. The workload is running in multiple AWS Regions and is using AWS Lambda with Amazon EC2 On-Demand Instances for the computer. The overall usage is predictable. The amount of computer that is consumed in each Region varies, depending on the users' locations.<br><br>Which approach should the SysOps administrator use to optimize this workload?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Workload cháº¡y trong <strong>multiple AWS Regions</strong></p></li><li><p>Sá»­ dá»¥ng <strong>AWS Lambda + EC2 On-Demand Instances</strong></p></li><li><p><strong>Overall usage dá»± Ä‘oÃ¡n Ä‘Æ°á»£c</strong> nhÆ°ng <strong>má»©c sá»­ dá»¥ng in each Region varies</strong> phá»¥ thuá»™c trÃªn users' locations</p></li><li><p>YÃªu cáº§u: optimize cost</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Purchase Compute Savings Plans based on the usage during the past 30 days.</strong></p><ul><li><p><strong>Compute Savings Plans</strong> lÃ  <strong>most flexible</strong> savings plan option</p></li><li><p>Apply cho <strong>Lambda, Fargate, vÃ  EC2</strong> regardless of region, instance family, size, OS, tenancy</p></li><li><p><strong>Automatically apply</strong> to usage across <strong>all regions</strong> - perfect cho workload thay Ä‘á»•i by region</p></li><li><p>Commit to <strong>consistent $/hour compute usage</strong> (measured in $/hour, not specific instances)</p></li><li><p><strong>Up to 66% savings</strong> over On-Demand pricing</p></li><li><p>VÃ¬ workload dÃ¹ng <strong>cáº£ Lambda vÃ  EC2</strong>, Compute Savings Plans lÃ  only option cover both</p></li><li><p>Flexible cho <strong>varying regional usage</strong> - savings apply wherever compute happens</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Purchase Convertible Reserved Instances by calculating the usage baseline.</strong></p><ul><li><p>Convertible RIs <strong>chá»‰ apply cho EC2</strong>, khÃ´ng cover Lambda</p></li><li><p>Less flexible than Compute Savings Plans cho multi-region scenarios</p></li><li><p>Pháº£i select specific attributes (cÃ³ thá»ƒ change nhÆ°ng cÃ³ restrictions)</p></li></ul><p></p><p>âŒ <strong>Purchase EC2 Instance Savings Plans based on the usage during the past 30 days.</strong></p><ul><li><p>EC2 Instance Savings Plans <strong>chá»‰ apply cho EC2</strong>, khÃ´ng cover Lambda</p></li><li><p>Flexible trong region vÃ  size nhÆ°ng tied to <strong>specific instance family</strong></p></li><li><p>KhÃ´ng phÃ¹ há»£p cho workload sá»­ dá»¥ng cáº£ Lambda</p></li></ul><p></p><p>âŒ <strong>Purchase Standard Reserved Instances by calculating the usage baseline.</strong></p><ul><li><p>Standard RIs <strong>chá»‰ apply cho EC2</strong>, khÃ´ng cover Lambda</p></li><li><p><strong>Least flexible</strong> - tied to specific instance type, region, OS, tenancy</p></li><li><p>KhÃ´ng tá»‘t cho multi-region workload vá»›i varying usage patterns</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Lambda + EC2\"</strong> â†’ <strong>Compute Savings Plans</strong> (only option covers both)</p></li><li><p><strong>\"Multiple regions + varying usage\"</strong> â†’ <strong>Compute Savings Plans</strong> (most flexible)</p></li><li><p><strong>\"EC2 only\"</strong> â†’ EC2 Instance Savings Plans or RIs</p></li><li><p><strong>Pattern</strong>: Multi-service + multi-region = Compute Savings Plans | EC2 only = EC2 Instance Savings Plans or RIs | Least flexible = Standard RIs</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/savingsplans/latest/userguide/plan-types.html\">AWS Savings Plans types comparison</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/savingsplans/compute-pricing/\">Compute Savings Plans for Lambda and EC2</a></p></li></ul>",
            "correctAnswer": [
                "<p>Purchase Computer Savings Plans based on the usage during the past 30 days.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Purchase Computer Savings Plans based on the usage during the past 30 days.</p>",
                "<p>Purchase Convertible Reserved Instances by calculating the usage baseline.</p>",
                "<p>Purchase EC2 Instance Savings Plans based on the usage during the past 30 days.</p>",
                "<p>Purchase Standard Reserved Instances by calculating the usage baseline.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 26
        },
        {
            "attemptAnswerId": 329298,
            "questionId": 6521,
            "questionText": "<p>Users are periodically experiencing slow response times from a relational database. The database runs on a burstable Amazon EC2 instance with a 350 GB General Purpose SSD (gp2) Amazon Elastic Block Store (Amazon EBS) volume. A SysOps administrator monitors the EC2 instance in Amazon CloudWatch and observes that the VolumeReadOps metric drops to less than 10% of its peak value during the periods of slow response.<br><br>What should the SysOps administrator do to ensure consistently high performance?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Database cháº¡y trÃªn <strong>burstable EC2 instance</strong> vá»›i <strong>350 GB gp2 volume</strong></p></li><li><p>Users experience <strong>slow response times periodically (Ä‘á»‹nh ká»³)</strong></p></li><li><p>CloudWatch monitoring: <strong>VolumeReadOps drops to &lt;10% of peak</strong> during slow periods</p></li><li><p>YÃªu cáº§u: Ä‘áº£m báº£o hiá»‡u suáº¥t cao liÃªn tá»¥c</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Convert the gp2 volume to a General Purpose SSD (gp3) EBS volume.</strong></p><ul><li><p><strong>gp2 dá»±a vÃ o burst credit model</strong> - baseline IOPS = 3 IOPS/GB, cÃ³ thá»ƒ burst lÃªn 3,000 IOPS khi cÃ³ credits</p></li><li><p><strong>350 GB gp2 = 1,050 baseline IOPS</strong> (350 * 3) - khi burst credits háº¿t, performance drop vá» baseline</p></li><li><p><strong>VolumeReadOps dropping</strong> chá»‰ ra <strong>burst credits exhausted</strong> - Ä‘Ã¢y lÃ  triá»‡u chá»©ng Ä‘iá»ƒn hÃ¬nh cá»§a gp2</p></li><li><p><strong>gp3 khÃ´ng dÃ¹ng burst credits</strong> - provide <strong>consistent baseline 3,000 IOPS</strong> (cÃ³ thá»ƒ provision up to 16,000)</p></li><li><p>gp3 <strong>predictable performance</strong> khÃ´ng bá»‹ throttle khi credits háº¿t</p></li><li><p>gp3 cÅ©ng <strong>cheaper than gp2</strong> (~20% cost savings) vá»›i better performance</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Convert the gp2 volume to a Cold HDD (sc1) EBS volume.</strong></p><ul><li><p><strong>sc1 designed cho infrequent access</strong> workloads (cold data)</p></li><li><p><strong>Max 250 IOPS</strong> - much worse than gp2, khÃ´ng phÃ¹ há»£p database</p></li><li><p>LÃ m performance tá»‡ hÆ¡n, khÃ´ng giáº£i quyáº¿t váº¥n Ä‘á»</p></li></ul><p></p><p>âŒ <strong>Convert the EC2 instance to a memory optimized instance type.</strong></p><ul><li><p><strong>Memory optimized</strong> tá»‘t cho in-memory databases nhÆ°ng khÃ´ng giáº£i quyáº¿t <strong>storage I/O bottleneck</strong></p></li><li><p>Váº¥n Ä‘á» lÃ  <strong>EBS volume performance</strong>, khÃ´ng pháº£i instance memory</p></li><li><p>VolumeReadOps metric indicates storage issue, not memory issue</p></li></ul><p></p><p>âŒ <strong>Activate unlimited mode on the EC2 instance.</strong></p><ul><li><p><strong>Unlimited mode</strong> cho phÃ©p burstable instances vÆ°á»£t CPU credits (tráº£ extra cost)</p></li><li><p>Chá»‰ Ã¡p dá»¥ng cho <strong>CPU credits</strong>, khÃ´ng pháº£i <strong>EBS burst credits</strong></p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n EBS volume performance</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"VolumeReadOps drops periodically\"</strong> â†’ <strong>gp2 burst credits exhausted</strong></p></li><li><p><strong>\"Consistent performance\"</strong> â†’ <strong>gp3</strong> (no burst credits) hoáº·c <strong>Provisioned IOPS (io2)</strong></p></li><li><p><strong>\"gp2 baseline IOPS\"</strong> â†’ 3 IOPS per GB | <strong>gp3 baseline</strong> â†’ 3,000 IOPS regardless of size</p></li><li><p><strong>Pattern</strong>: Inconsistent I/O performance = gp2 burst issue â†’ Convert to gp3 | Extreme I/O needs = io2</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html\">Amazon EBS volume types comparison</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/general-purpose.html#gp3-ebs-volume-type\">General Purpose SSD (gp3) volumes</a></p></li></ul>",
            "correctAnswer": [
                "<p>Convert the gp2 volume to a General Purpose SSD (gp3) EBS volume.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Convert the gp2 volume to a General Purpose SSD (gp3) EBS volume.</p>",
                "<p>Convert the gp2 volume to a Cold HDD (sc1) EBS volume.</p>",
                "<p>Convert the EC2 instance to a memory optimized instance type.</p>",
                "<p>Activate unlimited mode on the EC2 instance.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 27
        },
        {
            "attemptAnswerId": 329299,
            "questionId": 6522,
            "questionText": "<p>A company maintains a large set of sensitive data in an Amazon S3 bucket. The company's security team asks a SysOps administrator to help verify that all current objects in the S3 bucket are encrypted.<br><br>What is the MOST operationally efficient solution that meets these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company cÃ³ <strong>large set of sensitive data</strong> trong S3 bucket</p></li><li><p>Security team muá»‘n <strong>verify all current objects are encrypted</strong></p></li><li><p>YÃªu cáº§u: <strong>MOST operationally efficient</strong> solution</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create an S3 Inventory configuration on the S3 bucket. Include the appropriate status fields.</strong></p><ul><li><p><strong>S3 Inventory</strong> lÃ  managed feature generate <strong>automated reports</strong> vá» objects trong bucket</p></li><li><p>CÃ³ thá»ƒ include <strong>encryption status field</strong> (x-amz-server-side-encryption, x-amz-server-side-encryption-aws-kms-key-id)</p></li><li><p>Reports output to <strong>CSV hoáº·c Parquet format</strong> - dá»… analyze vÃ  query</p></li><li><p><strong>Scheduled reports</strong> (daily/weekly) - khÃ´ng cáº§n manually trigger</p></li><li><p><strong>No code required</strong> - fully managed, chá»‰ cáº§n configure</p></li><li><p>Scalable cho <strong>large datasets</strong> - AWS handle processing</p></li><li><p>ÄÃ¢y lÃ  <strong>AWS recommended approach</strong> cho auditing vÃ  compliance</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a script that runs against the S3 bucket and outputs the status of each object.</strong></p><ul><li><p>Pháº£i <strong>write vÃ  maintain custom script</strong></p></li><li><p>Vá»›i large dataset, script cháº¡y lÃ¢u vÃ  pháº£i <strong>handle pagination, rate limiting</strong></p></li><li><p><strong>High operational overhead</strong> - maintenance, error handling, scheduling</p></li><li><p>KhÃ´ng pháº£i most efficient</p></li></ul><p></p><p>âŒ <strong>Provide the security team with an IAM user that has read access to the S3 bucket.</strong></p><ul><li><p>Chá»‰ <strong>grant access</strong>, khÃ´ng giáº£i quyáº¿t viá»‡c verify encryption</p></li><li><p>Security team váº«n pháº£i <strong>manually check hoáº·c write script</strong></p></li><li><p>KhÃ´ng pháº£i solution, chá»‰ lÃ  prerequisite</p></li></ul><p></p><p>âŒ <strong>Use the AWS CLI to output a list of all objects in the S3 bucket.</strong></p><ul><li><p><code>aws s3api list-objects-v2</code> chá»‰ <strong>list objects</strong>, khÃ´ng show encryption status</p></li><li><p>Pháº£i cháº¡y <strong>additional commands</strong> (<code>head-object</code>) cho tá»«ng object</p></li><li><p><strong>Not scalable</strong> vá»›i large datasets</p></li><li><p>Manual vÃ  time-consuming</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Verify/audit S3 objects at scale\"</strong> â†’ <strong>S3 Inventory</strong></p></li><li><p><strong>\"Encryption status + large dataset\"</strong> â†’ S3 Inventory reports</p></li><li><p><strong>\"MOST operationally efficient\"</strong> â†’ Managed service, khÃ´ng custom scripts</p></li><li><p><strong>Pattern</strong>: S3 compliance auditing = S3 Inventory | One-time checks = CLI/SDK | Continuous monitoring = S3 Inventory + Athena</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/configure-inventory.html\">Amazon S3 Inventory configuration</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an S3 Inventory configuration on the S3 bucket. Include the appropriate status fields.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a script that runs against the S3 bucket and outputs the status of each object.</p>",
                "<p>Create an S3 Inventory configuration on the S3 bucket. Include the appropriate status fields.</p>",
                "<p>Provide the security team with an IAM user that has read access to the S3 bucket.</p>",
                "<p>Use the AWS CLI to output a list of all objects in the S3 bucket.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 28
        },
        {
            "attemptAnswerId": 329300,
            "questionId": 6523,
            "questionText": "<p>An errant process is known to use an entire processor and run at 100%. A SysOps administrator wants to automate restarting an Amazon EC2 instance when the problem occurs for more than 2 minutes.<br><br>How can this be accomplished?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p><strong>Errant process sá»­ dá»¥ng entire processor, cháº¡y 100% CPU</strong></p></li><li><p>Muá»‘n <strong>automate restart EC2 instance</strong> khi problem xáº£y ra <strong>&gt;2 minutes</strong></p></li><li><p>YÃªu cáº§u: automated solution Ä‘á»ƒ detect vÃ  restart</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create an Amazon CloudWatch alarm for the EC2 instance with detailed monitoring. Add an action to restart the instance.</strong></p><ul><li><p><strong>Detailed monitoring</strong> provides <strong>1-minute granularity</strong> cho EC2 metrics</p></li><li><p>CÃ³ thá»ƒ set alarm vá»›i <strong>2 consecutive data points</strong> (2 minutes) khi CPU = 100%</p></li><li><p><strong>CloudWatch alarm actions</strong> support <strong>EC2 instance reboot/stop/terminate</strong></p></li><li><p>Alarm trigger action <strong>ec2:RebootInstances</strong> khi condition met</p></li><li><p>Event-driven approach - chá»‰ restart khi thá»±c sá»± cÃ³ problem</p></li><li><p><strong>Cost-effective</strong> vÃ  automated, khÃ´ng cáº§n custom code</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create an Amazon CloudWatch alarm for the EC2 instance with basic monitoring. Add an action to restart the instance.</strong></p><ul><li><p><strong>Basic monitoring = 5-minute intervals</strong></p></li><li><p>KhÃ´ng Ä‘á»§ <strong>granular</strong> Ä‘á»ƒ detect problem trong timeframe 2 minutes</p></li><li><p>Delay detection vÃ  response time</p></li></ul><p></p><p>âŒ <strong>Create an AWS Lambda function to restart the EC2 instance, invoked on a scheduled basis every 2 minutes.</strong></p><ul><li><p><strong>Scheduled basis = restart má»—i 2 phÃºt</strong> regardless of CPU status</p></li><li><p>KhÃ´ng pháº£i <strong>event-driven</strong>, restart khÃ´ng cáº§n thiáº¿t</p></li><li><p>Disruptive vÃ  khÃ´ng giáº£i quyáº¿t root cause</p></li></ul><p></p><p>âŒ <strong>Create an AWS Lambda function to restart the EC2 instance, invoked by EC2 health checks.</strong></p><ul><li><p><strong>EC2 health checks</strong> (status checks) check <strong>instance/system reachability</strong></p></li><li><p><strong>KhÃ´ng monitor CPU utilization</strong> - chá»‰ check network connectivity vÃ  instance status</p></li><li><p>Sai trigger mechanism</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Detect within 2 minutes\"</strong> â†’ <strong>Detailed monitoring</strong> (1-minute intervals)</p></li><li><p><strong>\"Basic monitoring\"</strong> â†’ 5-minute intervals | <strong>Detailed monitoring</strong> â†’ 1-minute intervals</p></li><li><p><strong>\"CloudWatch alarm actions\"</strong> â†’ Support reboot/stop/terminate EC2 instances</p></li><li><p><strong>Pattern</strong>: CPU-based automation = CloudWatch alarm + detailed monitoring | Health-based = Status checks</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/manage-detailed-monitoring.html\">Enable detailed monitoring for EC2 instances</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/UsingAlarmActions.html\">Create CloudWatch alarms to stop, terminate, reboot EC2 instances</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an Amazon CloudWatch alarm for the EC2 instance with detailed monitoring. Add an action to restart the instance.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an Amazon CloudWatch alarm for the EC2 instance with basic monitoring. Add an action to restart the instance.</p>",
                "<p>Create an Amazon CloudWatch alarm for the EC2 instance with detailed monitoring. Add an action to restart the instance.</p>",
                "<p>Create an AWS Lambda function to restart the EC2 instance, invoked on a scheduled basis every 2 minutes.</p>",
                "<p>Create an AWS Lambda function to restart the EC2 instance, invoked by EC2 health checks.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 29
        },
        {
            "attemptAnswerId": 329301,
            "questionId": 6524,
            "questionText": "<p>A company plans to migrate several of its high performance computing (HPC) virtual machines (VMs) to Amazon EC2 instances on AWS. A SysOps administrator must identify a placement group for this deployment. The strategy must minimize network latency and must maximize network throughput between the HPC VMs.<br><br>Which strategy should the SysOps administrator choose to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Migrate <strong>HPC (High Performance Computing) VMs</strong> lÃªn EC2</p></li><li><p>Requirements:</p><ul><li><p><strong>Minimize network latency</strong></p></li><li><p><strong>Maximize network throughput</strong> giá»¯a HPC VMs</p></li></ul></li><li><p>YÃªu cáº§u: chá»n placement group strategy</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Deploy the instances in a cluster placement group in one Availability Zone.</strong></p><ul><li><p><strong>Cluster placement group</strong> Ä‘Æ°á»£c thiáº¿t káº¿ specifically cho <strong>low-latency, high-throughput</strong> workloads</p></li><li><p>Packs instances <strong>close together trong single AZ</strong> - same rack hoáº·c close proximity hardware</p></li><li><p>Provide <strong>lowest network latency</strong> (~25 Gbps or higher) vÃ  <strong>highest packet-per-second performance</strong></p></li><li><p><strong>Single AZ</strong> lÃ  required cho cluster placement - trade-off acceptable cho HPC vÃ¬ performance critical hÆ¡n multi-AZ HA</p></li><li><p><strong>AWS recommended</strong> cho tightly-coupled applications nhÆ° HPC, machine learning training</p></li><li><p>Enhanced networking required Ä‘á»ƒ fully leverage benefits</p></li></ul><hr><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765406456432-esygy670-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"434.6666666666667\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Deploy the instances in a partition placement group in two Availability Zones.</strong></p><ul><li><p><strong>Partition placement</strong> designed cho <strong>fault isolation</strong>, khÃ´ng pháº£i lowest latency</p></li><li><p>Instances spread across <strong>logical partitions</strong> vá»›i separate hardware racks</p></li><li><p><strong>Higher latency</strong> giá»¯a partitions so vá»›i cluster placement</p></li><li><p>Use case: distributed workloads (Hadoop, Cassandra), khÃ´ng pháº£i tightly-coupled HPC</p></li></ul><p></p><p>âŒ <strong>Deploy the instances in a partition placement group in one Availability Zone.</strong></p><ul><li><p>Tuy single AZ nhÆ°ng <strong>partition placement váº«n spread instances</strong> across racks</p></li><li><p>KhÃ´ng achieve <strong>minimum latency</strong> nhÆ° cluster placement</p></li><li><p>Sai strategy cho HPC requirements</p></li></ul><p></p><p>âŒ <strong>Deploy the instances in a spread placement group in two Availability Zones.</strong></p><ul><li><p><strong>Spread placement</strong> strictly places instances on <strong>distinct hardware</strong></p></li><li><p><strong>Limit 7 instances per AZ</strong> - not suitable cho large HPC clusters</p></li><li><p>Focus on <strong>high availability</strong>, khÃ´ng pháº£i performance optimization</p></li><li><p>Highest latency trong táº¥t cáº£ placement group types</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"HPC + low latency + high throughput\"</strong> â†’ <strong>Cluster placement group</strong></p></li><li><p><strong>\"Fault isolation + distributed workloads\"</strong> â†’ <strong>Partition placement</strong></p></li><li><p><strong>\"Critical instances + high availability\"</strong> â†’ <strong>Spread placement</strong> (max 7 instances/AZ)</p></li><li><p><strong>Pattern</strong>: Cluster = Performance focus | Partition = Fault isolation | Spread = HA focus</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html\">Placement groups for EC2 instances</a></p></li><li><p>Cluster placement groups for HPC workloads</p></li></ul>",
            "correctAnswer": [
                "<p>Deploy the instances in a cluster placement group in one Availability Zone.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Deploy the instances in a cluster placement group in one Availability Zone.</p>",
                "<p>Deploy the instances in a partition placement group in two Availability Zones.</p>",
                "<p>Deploy the instances in a partition placement group in one Availability Zone.</p>",
                "<p>Deploy the instances in a spread placement group in two Availability Zones.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 30
        },
        {
            "attemptAnswerId": 329302,
            "questionId": 6525,
            "questionText": "<p>A SysOps administrator notices a scale up event for an Amazon EC2 Auto Scaling group. Amazon CloudWatch shows a spike in the RequestCount metric for the associated Application Load Balancer. The administrator would like to know the IP addresses for the source of the requests.<br><br>Where can the administrator find this information?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Auto Scaling group cÃ³ <strong>scale up event</strong></p></li><li><p>CloudWatch shows <strong>spike in RequestCount metric</strong> cá»§a ALB</p></li><li><p>Administrator muá»‘n biáº¿t <strong>IP addresses cá»§a source requests</strong></p></li><li><p>YÃªu cáº§u: tÃ¬m thÃ´ng tin vá» source IPs</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Elastic Load Balancer access logs</strong></p><ul><li><p><strong>ELB access logs</strong> capture detailed information vá» <strong>má»i request</strong> sent to ALB</p></li><li><p>Logs include: <strong>client IP addresses</strong>, request paths, response codes, user agents, processing times, backend targets</p></li><li><p>Access logs stored trong <strong>S3 bucket</strong> - cÃ³ thá»ƒ query báº±ng Athena hoáº·c analyze tools</p></li><li><p>Enable access logging trÃªn ALB settings (disabled by default)</p></li><li><p>ÄÃ¢y lÃ  <strong>standard method</strong> Ä‘á»ƒ troubleshoot traffic patterns vÃ  identify request sources</p></li><li><p>CÃ³ thá»ƒ analyze logs Ä‘á»ƒ correlate spike in RequestCount vá»›i specific source IPs</p></li></ul><hr><p></p><p><em>Setting</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765406642874-2ttyz0to-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"385.625\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Auto Scaling logs</strong></p><ul><li><p>Auto Scaling logs chá»‰ record <strong>scaling activities</strong> (launch/terminate instances, health checks)</p></li><li><p><strong>KhÃ´ng capture HTTP request information</strong> hay client IP addresses</p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n traffic analysis</p></li></ul><p></p><p>âŒ <strong>AWS CloudTrail logs</strong></p><ul><li><p>CloudTrail logs <strong>AWS API calls</strong> (control plane activities)</p></li><li><p><strong>KhÃ´ng log application traffic</strong> hay HTTP requests Ä‘áº¿n ALB</p></li><li><p>Use case: audit API changes, khÃ´ng pháº£i analyze web traffic</p></li></ul><p></p><p>âŒ <strong>EC2 instance logs</strong></p><ul><li><p>EC2 instance logs cÃ³ application logs nhÆ°ng <strong>source IP bá»‹ masked</strong> bá»Ÿi ALB</p></li><li><p>Instances see ALB IP as source, khÃ´ng pháº£i original client IP (trá»« khi parse X-Forwarded-For header)</p></li><li><p>KhÃ´ng pháº£i centralized source cho ALB traffic analysis</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Source IP + ALB requests\"</strong> â†’ <strong>ELB access logs</strong></p></li><li><p><strong>\"RequestCount spike\"</strong> â†’ Analyze access logs Ä‘á»ƒ identify sources</p></li><li><p><strong>\"CloudTrail\"</strong> â†’ API calls audit | <strong>\"Access logs\"</strong> â†’ HTTP request details</p></li><li><p><strong>Pattern</strong>: Traffic analysis = ELB access logs | API auditing = CloudTrail | Scaling events = Auto Scaling logs</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html\">Access logs for Application Load Balancer</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/athena/latest/ug/application-load-balancer-logs.html\">Analyzing ALB access logs with Athena</a></p></li></ul>",
            "correctAnswer": [
                "<p>Elastic Load Balancer access logs</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Auto Scaling logs</p>",
                "<p>AWS CloudTrail logs</p>",
                "<p>EC2 instance logs</p>",
                "<p>Elastic Load Balancer access logs</p>"
            ],
            "answersPos": "[2,1,0,3]",
            "pos": 31
        },
        {
            "attemptAnswerId": 329303,
            "questionId": 6526,
            "questionText": "<p>A web application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Auto Scaling group across multiple Availability Zones. A SysOps administrator notices that some of these EC2 instances show up as healthy in the Auto Scaling group but show up as unhealthy in the ALB target group.<br><br>What is a possible reason for this issue?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>EC2 instances behind ALB trong Auto Scaling group</p></li><li><p><strong>Some instances</strong> show:</p><ul><li><p><strong>Healthy</strong> trong Auto Scaling group</p></li><li><p><strong>Unhealthy</strong> trong ALB target group</p></li></ul></li><li><p>YÃªu cáº§u: identify possible reason for discrepancy</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>The Auto Scaling group health check is configured for EC2 status checks.</strong></p><ul><li><p>Auto Scaling cÃ³ <strong>2 loáº¡i health checks</strong>: <strong>EC2 status checks</strong> vÃ  <strong>ELB health checks</strong></p></li><li><p><strong>EC2 status checks</strong> chá»‰ verify <strong>instance vÃ  system reachability</strong> - instance running vÃ  system OK</p></li><li><p><strong>EC2 status checks KHÃ”NG check application health</strong> hay network connectivity Ä‘áº¿n ALB</p></li><li><p><strong>ALB target group health checks</strong> thá»±c hiá»‡n <strong>HTTP/HTTPS requests</strong> Ä‘áº¿n application endpoint Ä‘á»ƒ verify application responding</p></li><li><p><strong>Sá»± khÃ¡c biá»‡t xáº£y ra</strong> khi: instance running OK (EC2 check pass) nhÆ°ng application unhealthy hoáº·c khÃ´ng accessible tá»« ALB (ALB check fail)</p></li><li><p><strong>AWS best practice</strong>: enable <strong>ELB health checks</strong> trong Auto Scaling group khi sá»­ dá»¥ng load balancer Ä‘á»ƒ sync health status</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Security groups are not allowing traffic between the ALB and the failing EC2 instances.</strong></p><ul><li><p>ÄÃ¢y cÃ³ thá»ƒ lÃ  <strong>one specific cause</strong> nhÆ°ng khÃ´ng pháº£i <strong>root explanation</strong> cá»§a sá»± khÃ¡c biá»‡t health check</p></li><li><p>Náº¿u SG block traffic, Ä‘Ã³ lÃ  network issue cá»¥ thá»ƒ, khÃ´ng pháº£i difference cÆ¡ báº£n giá»¯a 2 health check types</p></li><li><p>CÃ¢u há»i há»i vá» \"possible reason\" á»Ÿ architectural level</p></li></ul><p></p><p>âŒ <strong>The EC2 instances are failing to launch and failing EC2 status checks.</strong></p><ul><li><p>Náº¿u instances <strong>fail EC2 status checks</strong>, chÃºng sáº½ show <strong>unhealthy trong Auto Scaling group</strong></p></li><li><p><strong>MÃ¢u thuáº©n</strong> vá»›i Ä‘á» bÃ i: instances show healthy trong ASG</p></li><li><p>HoÃ n toÃ n sai</p></li></ul><p></p><p>âŒ <strong>The target group health check is configured with an incorrect port or path.</strong></p><ul><li><p>Náº¿u <strong>all instances</strong> dÃ¹ng same incorrect config, <strong>ALL</strong> sáº½ unhealthy trong ALB</p></li><li><p>Äá» nÃ³i \"<strong>some instances</strong>\" - biá»ƒu thá»‹ sá»± khÃ¡c biá»‡t há»‡ thá»‘ng, khÃ´ng pháº£i lÃ  cáº¥u hÃ¬nh sai</p></li><li><p>Ãt common hÆ¡n so vá»›i issue vá» health check type</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Healthy in ASG, unhealthy in ALB\"</strong> â†’ <strong>ASG dÃ¹ng EC2 status checks instead of ELB checks</strong></p></li><li><p><strong>\"EC2 status checks\"</strong> â†’ Chá»‰ check instance reachability | <strong>\"ELB health checks\"</strong> â†’ Check application health</p></li><li><p><strong>\"Best practice\"</strong> â†’ Enable ELB health checks trong ASG khi dÃ¹ng load balancer</p></li><li><p><strong>Pattern</strong>: Health check discrepancy = Different health check types | Sync ASG with ALB = Enable ELB health checks</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-health-checks.html\">Health checks for instances in an Amazon EC2 Auto Scaling group</a></p></li></ul>",
            "correctAnswer": [
                "<p>The Auto Scaling group health check is configured for EC2 status checks.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Security groups are not allowing traffic between the ALB and the failing EC2 instances.</p>",
                "<p>The Auto Scaling group health check is configured for EC2 status checks.</p>",
                "<p>The EC2 instances are failing to launch and failing EC2 status checks.</p>",
                "<p>The target group health check is configured with an incorrect port or path.</p>"
            ],
            "answersPos": "[3,2,0,1]",
            "pos": 32
        },
        {
            "attemptAnswerId": 329304,
            "questionId": 6527,
            "questionText": "<p>A SysOps administrator is testing an application that is hosted on five Amazon EC2 instances. The instances run in an Auto Scaling group behind an Application Load Balancer (ALB). High CPU utilization during load testing is causing the Auto Scaling group to scale out. The SysOps administrator must troubleshoot to find the root cause of the high CPU utilization before the Auto Scaling group scales out.<br><br>Which action should the SysOps administrator take to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application cháº¡y trÃªn <strong>5 EC2 instances</strong> trong Auto Scaling group behind ALB</p></li><li><p><strong>High CPU during load testing</strong> causing Auto Scaling group <strong>scale out</strong></p></li><li><p>Admin cáº§n <strong>troubleshoot root cause</strong> trÆ°á»›c khi Auto Scaling group scale out</p></li><li><p>YÃªu cáº§u: prevent scaling trong khi troubleshoot</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Suspend the Launch and Terminate process types.</strong></p><ul><li><p><strong>Suspend Launch process</strong> ngÄƒn Auto Scaling group <strong>launch instances má»›i</strong> (prevent scale-out)</p></li><li><p><strong>Suspend Terminate process</strong> ngÄƒn Auto Scaling group <strong>terminate instances</strong> (prevent scale-in)</p></li><li><p><strong>Freeze Auto Scaling group</strong> á»Ÿ current state Ä‘á»ƒ troubleshoot safely</p></li><li><p>Administrator cÃ³ thá»ƒ analyze existing instances mÃ  khÃ´ng lo fleet changes</p></li><li><p>Sau khi troubleshoot xong, cÃ³ thá»ƒ <strong>resume processes</strong> Ä‘á»ƒ Auto Scaling hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng</p></li><li><p>ÄÃ¢y lÃ  <strong>standard practice</strong> cho troubleshooting Auto Scaling groups</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Enable instance scale-in protection.</strong></p><ul><li><p>Scale-in protection chá»‰ ngÄƒn <strong>specific instances bá»‹ terminate</strong> khi scale-in</p></li><li><p><strong>KHÃ”NG ngÄƒn Auto Scaling launch instances má»›i</strong> (scale-out)</p></li><li><p>KhÃ´ng giáº£i quyáº¿t requirement \"prevent scale out\"</p></li></ul><p></p><p>âŒ <strong>Place the instance into the Standby state.</strong></p><ul><li><p>Standby <strong>removes instance from service</strong> temporarily</p></li><li><p>Auto Scaling <strong>CÃ“ THá»‚ launch replacement instance</strong> Ä‘á»ƒ maintain desired capacity</p></li><li><p><strong>KhÃ´ng prevent scale-out</strong>, chá»‰ isolate specific instance</p></li><li><p>CÃ³ thá»ƒ trigger additional scaling</p></li></ul><p></p><p>âŒ <strong>Remove the listener from the ALB.</strong></p><ul><li><p>Chá»‰ <strong>stop traffic</strong> Ä‘áº¿n instances</p></li><li><p><strong>KhÃ´ng áº£nh hÆ°á»Ÿng Auto Scaling behavior</strong> - Auto Scaling váº«n monitor CPU vÃ  scale out</p></li><li><p>KhÃ´ng giáº£i quyáº¿t váº¥n Ä‘á» scaling</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Prevent Auto Scaling during troubleshoot\"</strong> â†’ <strong>Suspend Launch/Terminate processes</strong></p></li><li><p><strong>\"Scale-in protection\"</strong> â†’ Protect specific instances from termination only</p></li><li><p><strong>\"Standby state\"</strong> â†’ Isolate instance, cÃ³ thá»ƒ trigger replacement</p></li><li><p><strong>Pattern</strong>:</p><ul><li><p>Freeze Auto Scaling = Suspend processes</p></li><li><p>Protect specific instances = Scale-in protection</p></li><li><p>Isolate instance = Standby</p></li></ul></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-suspend-resume-processes.html\">Suspend and resume Auto Scaling processes</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/CHAP_Troubleshooting.html\">Troubleshooting Auto Scaling groups</a></p></li></ul>",
            "correctAnswer": [
                "<p>Suspend the Launch and Terminate process types.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Enable instance scale-in protection.</p>",
                "<p>Place the instance into the Standby state.</p>",
                "<p>Remove the listener from the ALB.</p>",
                "<p>Suspend the Launch and Terminate process types.</p>"
            ],
            "answersPos": "[1,0,2,3]",
            "pos": 33
        },
        {
            "attemptAnswerId": 329305,
            "questionId": 6528,
            "questionText": "<p>A SysOps administrator is configuring AWS Client VPN to connect users on a corporate network to AWS resources that are running in a VPC. According to compliance requirements, only traffic that is destined for the VPC can travel across the VPN tunnel.<br><br>How should the SysOps administrator configure Client VPN to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Configure <strong>AWS Client VPN</strong> Ä‘á»ƒ connect corporate users to AWS resources trong VPC</p></li><li><p>Compliance requirement: <strong>ONLY traffic destined for VPC</strong> travels across VPN tunnel</p></li><li><p>Traffic khÃ¡c (internet) <strong>KHÃ”NG Ä‘Æ°á»£c Ä‘i qua VPN</strong></p></li><li><p>YÃªu cáº§u: configure Client VPN Ä‘Ãºng requirement</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>On the Client VPN endpoint, turn on the split-tunnel option.</strong></p><ul><li><p><strong>Split-tunnel mode</strong> chá»‰ route <strong>VPC-destined traffic</strong> qua VPN tunnel</p></li><li><p><strong>Internet traffic vÃ  traffic khÃ¡c</strong> Ä‘i <strong>directly qua user's local internet connection</strong>, khÃ´ng qua VPN</p></li><li><p><strong>Full-tunnel mode</strong> (default) route <strong>Táº¤T Cáº¢ traffic</strong> qua VPN, including internet traffic</p></li><li><p>Split-tunnel meets compliance requirement: \"only traffic destined for VPC can travel across VPN tunnel\"</p></li><li><p><strong>Benefits</strong>: reduced bandwidth costs, better performance cho internet traffic</p></li><li><p>Enable qua Client VPN endpoint configuration: <code>split-tunnel = enabled</code></p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Associate the Client VPN endpoint with a private subnet that has an internet route through a NAT gateway.</strong></p><ul><li><p>ÄÃ¢y lÃ  vá» <strong>AWS-side routing</strong>, khÃ´ng control client-side traffic routing</p></li><li><p>NAT gateway cho phÃ©p instances trong private subnet access internet</p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n viá»‡c control traffic nÃ o goes through VPN tunnel</p></li></ul><p></p><p>âŒ <strong>On the Client VPN endpoint, specify DNS server IP addresses.</strong></p><ul><li><p><strong>DNS server configuration</strong> chá»‰ affect <strong>name resolution</strong></p></li><li><p>KhÃ´ng control <strong>traffic routing</strong> hay tunneling behavior</p></li><li><p>KhÃ´ng giáº£i quyáº¿t requirement vá» limiting VPN traffic</p></li></ul><p></p><p>âŒ <strong>Select a private certificate to use as the identity certificate for the VPN client.</strong></p><ul><li><p>Certificate dÃ¹ng cho <strong>authentication</strong>, verify identity cá»§a VPN clients</p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n <strong>traffic routing policy</strong></p></li><li><p>Security feature, khÃ´ng pháº£i traffic control</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Only VPC traffic through VPN\"</strong> â†’ <strong>Split-tunnel enabled</strong></p></li><li><p><strong>\"All traffic through VPN\"</strong> â†’ <strong>Full-tunnel (split-tunnel disabled)</strong></p></li><li><p><strong>\"Split-tunnel\"</strong> â†’ VPC traffic qua VPN, internet direct | <strong>Full-tunnel</strong> â†’ All traffic qua VPN</p></li><li><p><strong>Pattern</strong>: </p><ul><li><p>Selective VPN routing = Split-tunnel</p></li><li><p>All traffic routing = Full-tunnel</p></li></ul></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/vpn/latest/clientvpn-admin/split-tunnel-vpn.html\">AWS Client VPN split-tunnel configuration</a></p></li></ul><pre><code>By default, when you have a Client VPN endpoint, all traffic from clients is routed over the Client VPN tunnel. When you enable split-tunnel on the Client VPN endpoint, we push the routes on the Client VPN endpoint route table to the device that is connected to the Client VPN endpoint. This ensures that only traffic with a destination to the network matching a route from the Client VPN endpoint route table is routed over the Client VPN tunnel.\n\nYou can use a split-tunnel Client VPN endpoint when you do not want all user traffic to route through the Client VPN endpoint.\n\nIn the following example, split-tunnel is enabled on the Client VPN endpoint. Only traffic that's destined for the VPC (172.31.0.0/16) is routed over the Client VPN tunnel. Traffic that's destined for on-premises resources is not routed over the Client VPN tunnel.</code></pre><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765407913957-vwl3kv1k-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"301.1666666666667\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/vpn/latest/clientvpn-admin/cvpn-working-endpoints.html\">Client VPN endpoint options</a></p></li></ul>",
            "correctAnswer": [
                "<p>On the Client VPN endpoint, turn on the split-tunnel option.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Associate the Client VPN endpoint with a private subnet that has an internet route through a NAT gateway.</p>",
                "<p>On the Client VPN endpoint, turn on the split-tunnel option.</p>",
                "<p>On the Client VPN endpoint, specify DNS server IP addresses.</p>",
                "<p>Select a private certificate to use as the identity certificate for the VPN client.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 34
        },
        {
            "attemptAnswerId": 329306,
            "questionId": 6529,
            "questionText": "<p>A company plans to launch a static website on its domain example.com and subdomain www.example.com using Amazon S3.<br><br>How should the SysOps administrator meet this requirement?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Launch <strong>static website</strong> trÃªn <strong>example.com</strong> vÃ  <strong>www.example.com</strong></p></li><li><p>Sá»­ dá»¥ng <strong>Amazon S3</strong> for hosting</p></li><li><p>YÃªu cáº§u: configure S3 buckets Ä‘á»ƒ serve cáº£ domain vÃ  subdomain</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create two S3 buckets named example.com and www.example.com. Configure the subdomain bucket to redirect requests to the domain bucket.</strong></p><ul><li><p><strong>S3 static website hosting requires bucket name exactly match domain name</strong></p></li><li><p>Pháº£i táº¡o <strong>2 separate buckets</strong>: má»™t cho example.com, má»™t cho www.example.com</p></li><li><p><strong>Primary bucket</strong> (example.com) host actual website content</p></li><li><p><strong>Redirect bucket</strong> (www.example.com) configure <strong>website redirect</strong> Ä‘áº¿n example.com</p></li><li><p>Route 53 create <strong>alias records</strong> cho cáº£ 2 domains point Ä‘áº¿n respective S3 website endpoints</p></li><li><p>ÄÃ¢y lÃ  <strong>AWS recommended pattern</strong> cho serving websites vá»›i domain vÃ  subdomain</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create one S3 bucket named example.com for both the domain and subdomain.</strong></p><ul><li><p><strong>Má»™t bucket khÃ´ng thá»ƒ serve cho multiple domains</strong> vá»›i different names</p></li><li><p>S3 bucket name pháº£i <strong>exactly match</strong> domain name</p></li><li><p>www.example.com requests sáº½ khÃ´ng resolve correctly vá»›i chá»‰ example.com bucket</p></li></ul><p></p><p>âŒ <strong>Create one S3 bucket with a wildcard named *.example.com for both the domain and subdomain.</strong></p><ul><li><p>S3 bucket names <strong>KHÃ”NG support wildcards (*)</strong></p></li><li><p>Cannot create bucket vá»›i tÃªn *.example.com</p></li><li><p>Invalid bucket naming convention</p></li></ul><p></p><p>âŒ <strong>Create two S3 buckets named http://example.com and http://*.example.com. Configure the wildcard (*) bucket to redirect requests to the domain bucket.</strong></p><ul><li><p>Bucket names <strong>khÃ´ng thá»ƒ chá»©a protocol prefix</strong> (http://)</p></li><li><p>Bucket names <strong>khÃ´ng support wildcards</strong></p></li><li><p>Invalid syntax hoÃ n toÃ n</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Domain + subdomain on S3\"</strong> â†’ <strong>2 separate buckets required</strong></p></li><li><p><strong>\"Bucket name must match domain name exactly\"</strong> â†’ example.com bucket, www.example.com bucket</p></li><li><p><strong>\"One bucket redirect\"</strong> â†’ Configure redirect to primary bucket</p></li><li><p><strong>Pattern</strong>: S3 static website = Bucket name = Domain name | Multiple domains = Multiple buckets + redirect</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/HostingWebsiteOnS3Setup.html\">Configuring a static website on Amazon S3</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/how-to-page-redirect.html\">Configuring a website redirect for S3 buckets</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create two S3 buckets named example.com and www.example.com. Configure the subdomain bucket to redirect requests to the domain bucket.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create one S3 bucket named example.com for both the domain and subdomain.</p>",
                "<p>Create one S3 bucket with a wildcard named *.example.com for both the domain and subdomain.</p>",
                "<p>Create two S3 buckets named example.com and www.example.com. Configure the subdomain bucket to redirect requests to the domain bucket.</p>",
                "<p>Create two S3 buckets named http://example.com and http://*.example.com. Configure the wildcard (*) bucket to redirect requests to the domain bucket.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 35
        },
        {
            "attemptAnswerId": 329307,
            "questionId": 6530,
            "questionText": "<p>A SysOps administrator has blocked public access to all company Amazon S3 buckets. The SysOps administrator wants to be notified when an S3 bucket becomes publicly readable in the future.<br><br>What is the MOST operationally efficient way to meet this requirement?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>ÄÃ£ <strong>block public access</strong> cho all S3 buckets</p></li><li><p>Muá»‘n <strong>notification</strong> khi S3 bucket becomes <strong>publicly readable</strong> trong future</p></li><li><p>YÃªu cáº§u: <strong>MOST operationally efficient</strong> solution</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Enable the s3-bucket-public-read-prohibited managed rule in AWS Config. Subscribe the AWS Config rule to an Amazon Simple Notification Service (Amazon SNS) topic.</strong></p><ul><li><p><strong>AWS Config managed rule</strong> <code>s3-bucket-public-read-prohibited</code> Ä‘Æ°á»£c thiáº¿t káº¿ specifically Ä‘á»ƒ <strong>detect publicly readable S3 buckets</strong></p></li><li><p>Config <strong>continuously evaluates</strong> S3 bucket configurations</p></li><li><p>Khi bucket <strong>becomes non-compliant</strong> (publicly readable), Config trigger notification</p></li><li><p><strong>SNS topic</strong> nháº­n compliance change notifications Ä‘á»ƒ alert administrators</p></li><li><p><strong>Fully managed</strong> - khÃ´ng cáº§n custom code, scripts, hay maintenance</p></li><li><p><strong>Event-driven</strong> thay vÃ¬ polling - efficient vÃ  real-time detection</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create an AWS Lambda function that periodically checks the public access settings for each S3 bucket. Set up Amazon Simple Notification Service (Amazon SNS) to send notifications.</strong></p><ul><li><p>Pháº£i <strong>write vÃ  maintain custom Lambda code</strong></p></li><li><p><strong>Polling approach</strong> - check periodically, khÃ´ng real-time</p></li><li><p><strong>Operational overhead</strong>: code maintenance, scheduling, error handling</p></li><li><p>KhÃ´ng pháº£i most efficient</p></li></ul><p></p><p>âŒ <strong>Create a cron script that uses the S3 API to check the public access settings for each S3 bucket. Set up Amazon Simple Notification Service (Amazon SNS) to send notifications.</strong></p><ul><li><p><strong>Manual scripting</strong> vÃ  scheduling vá»›i cron</p></li><li><p><strong>Very high operational overhead</strong> - maintain script, server/instance to run cron</p></li><li><p>Polling approach, khÃ´ng efficient</p></li><li><p>Least operationally efficient option</p></li></ul><p></p><p>âŒ <strong>Enable S3 Event Notifications for each S3 bucket. Subscribe S3 Event Notifications to an Amazon Simple Notification Service (Amazon SNS) topic.</strong></p><ul><li><p><strong>S3 Event Notifications track object-level events</strong> (PUT, DELETE, POST)</p></li><li><p><strong>KHÃ”NG track configuration changes</strong> nhÆ° public access settings</p></li><li><p>Sai use case hoÃ n toÃ n</p></li></ul><hr><p></p><p>ğŸ”‘<u> Tips and tricks:</u></p><ul><li><p><strong>\"S3 bucket publicly readable detection\"</strong> â†’ <strong>AWS Config s3-bucket-public-read-prohibited rule</strong></p></li><li><p><strong>\"Configuration compliance monitoring\"</strong> â†’ <strong>AWS Config</strong></p></li><li><p><strong>\"S3 Event Notifications\"</strong> â†’ Object-level events, khÃ´ng pháº£i config changes</p></li><li><p><strong>Pattern</strong>:</p><ul><li><p>Compliance monitoring = AWS Config</p></li><li><p>Object events = S3 Event Notifications</p></li><li><p>Custom logic = Lambda/Scripts</p></li></ul></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/config/latest/developerguide/managed-rules-by-aws-config.html\">List of AWS Config Managed Rules</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-public-read-prohibited.html\">s3-bucket-public-read-prohibited Config rule</a></p></li></ul>",
            "correctAnswer": [
                "<p>Enable the s3-bucket-public-read-prohibited managed rule in AWS Config. Subscribe the AWS Config rule to an Amazon Simple Notification Service (Amazon SNS) topic.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an AWS Lambda function that periodically checks the public access settings for each S3 bucket. Set up Amazon Simple Notification Service (Amazon SNS) to send notifications.</p>",
                "<p>Create a cron script that uses the S3 API to check the public access settings for each S3 bucket. Set up Amazon Simple Notification Service (Amazon SNS) to send notifications.</p>",
                "<p>Enable S3 Event Notifications for each S3 bucket. Subscribe S3 Event Notifications to an Amazon Simple Notification Service (Amazon SNS) topic.</p>",
                "<p>Enable the s3-bucket-public-read-prohibited managed rule in AWS Config. Subscribe the AWS Config rule to an Amazon Simple Notification Service (Amazon SNS) topic.</p>"
            ],
            "answersPos": "[2,0,1,3]",
            "pos": 36
        },
        {
            "attemptAnswerId": 329308,
            "questionId": 6531,
            "questionText": "<p>A company has mandated the use of multi-factor authentication (MFA) for all IAM users, and requires users to make all API calls using the CLI. However, users are not prompted to enter MFA tokens, and are able to run CLI commands without MFA. In an attempt to enforce MFA, the company attached an IAM policy to all users that denies API calls that have not been authenticated with MFA.<br><br>What additional step must be taken to ensure that API calls are authenticated using MFA?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company yÃªu cáº§u <strong>MFA for all IAM users</strong>, API calls qua <strong>CLI</strong></p></li><li><p>Users hiá»‡n <strong>KHÃ”NG Ä‘Æ°á»£c prompt MFA</strong> khi run CLI commands</p></li><li><p>ÄÃ£ attach <strong>IAM policy deny API calls without MFA</strong> nhÆ°ng váº«n chÆ°a enforce Ä‘Æ°á»£c</p></li><li><p>YÃªu cáº§u: additional step Ä‘á»ƒ ensure API calls authenticated vá»›i MFA</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Require users to use temporary credentials from the get-session token command to sign API calls.</strong></p><ul><li><p><strong>Long-term credentials</strong> (access key + secret key) <strong>khÃ´ng cÃ³ MFA context</strong> khi sign API calls</p></li><li><p><strong>aws sts get-session-token</strong> vá»›i MFA parameter generate <strong>temporary credentials</strong> cÃ³ MFA context</p></li><li><p>Command syntax: <code>aws sts get-session-token --serial-number arn:aws:iam::ACCOUNT:mfa/USER --token-code MFA_CODE</code></p></li><li><p>Temporary credentials (AccessKeyId, SecretAccessKey, SessionToken) returned cÃ³ <strong>MFA authentication flag</strong></p></li><li><p>API calls signed vá»›i temporary credentials <strong>thoáº£ mÃ£n aws:MultiFactorAuthPresent condition</strong> trong IAM policy</p></li><li><p>ÄÃ¢y lÃ  <strong>AWS documented method</strong> Ä‘á»ƒ enforce MFA cho CLI usage</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Enable MFA on IAM roles, and require IAM users to use role credentials to sign API calls.</strong></p><ul><li><p>CÃ³ thá»ƒ work nhÆ°ng <strong>more complex</strong> vÃ  khÃ´ng pháº£i direct solution</p></li><li><p>Requires additional role setup vÃ  assume-role workflow</p></li><li><p>KhÃ´ng pháº£i standard approach cho enforcing MFA vá»›i CLI</p></li></ul><p></p><p>âŒ <strong>Ask the IAM users to log into the AWS Management Console with MFA before making API calls using the CLI.</strong></p><ul><li><p><strong>Console login session khÃ´ng liÃªn quan</strong> Ä‘áº¿n CLI API calls</p></li><li><p>CLI dÃ¹ng <strong>access keys</strong>, khÃ´ng pháº£i console session credentials</p></li><li><p>KhÃ´ng giáº£i quyáº¿t váº¥n Ä‘á»</p></li></ul><p></p><p>âŒ <strong>Restrict the IAM users to use of the console, as MFA is not supported for CLI use.</strong></p><ul><li><p><strong>HoÃ n toÃ n sai</strong> - MFA CÃ“ support cho CLI usage</p></li><li><p><strong>Vi pháº¡m requirement</strong> \"requires users to make all API calls using the CLI\"</p></li><li><p>MFA enforcement cho CLI possible qua temporary credentials</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"MFA enforcement for CLI\"</strong> â†’ <strong>aws sts get-session-token</strong> with MFA</p></li><li><p><strong>\"Long-term credentials\"</strong> â†’ No MFA context | <strong>\"Temporary credentials from STS\"</strong> â†’ Have MFA context</p></li><li><p><strong>\"aws:MultiFactorAuthPresent condition\"</strong> â†’ Check MFA in IAM policies</p></li><li><p><strong>Pattern</strong>: MFA for CLI = get-session-token + temporary credentials | MFA for console = Login prompt</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://repost.aws/knowledge-center/authenticate-mfa-cli\">Using MFA with AWS CLI</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/cli/latest/reference/sts/get-session-token.html\">aws sts get-session-token with MFA</a></p></li></ul>",
            "correctAnswer": [
                "<p>Require users to use temporary credentials from the get-session token command to sign API calls.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Enable MFA on IAM roles, and require IAM users to use role credentials to sign API calls.</p>",
                "<p>Ask the IAM users to log into the AWS Management Console with MFA before making API calls using the CLI.</p>",
                "<p>Restrict the IAM users to use of the console, as MFA is not supported for CLI use.</p>",
                "<p>Require users to use temporary credentials from the get-session token command to sign API calls.</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 37
        },
        {
            "attemptAnswerId": 329309,
            "questionId": 6532,
            "questionText": "<p>A SysOps administrator must ensure that a company's Amazon EC2 instances auto scale as expected. The SysOps administrator configures an Amazon EC2 Auto Scaling lifecycle hook to send an event to Amazon EventBridge (Amazon CloudWatch Events), which then invokes an AWS Lambda function to configure the EC2 instances. When the configuration is complete, the Lambda function calls the complete-lifecycle-action event to put the EC2 instances into service. In testing, the SysOps administrator discovers that the Lambda function is not invoked when the EC2 instances auto scale.<br><br>What should the SysOps administrator do to resolve this issue?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Auto Scaling <strong>lifecycle hook</strong> send event to <strong>EventBridge</strong></p></li><li><p>EventBridge rule trigger <strong>Lambda function</strong> Ä‘á»ƒ configure EC2 instances</p></li><li><p>Lambda sau Ä‘Ã³ call <strong>complete-lifecycle-action</strong> Ä‘á»ƒ put instances into service</p></li><li><p>Váº¥n Ä‘á»: <strong>Lambda function KHÃ”NG Ä‘Æ°á»£c invoked</strong> khi auto scale</p></li><li><p>YÃªu cáº§u: resolve issue</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Add a permission to the Lambda function so that it can be invoked by the EventBridge (CloudWatch Events) rule.</strong></p><ul><li><p><strong>Lambda resource-based policy</strong> required Ä‘á»ƒ allow <strong>EventBridge invoke Lambda</strong></p></li><li><p>Khi táº¡o EventBridge rule target Lambda, pháº£i <strong>grant invoke permission</strong> cho events.amazonaws.com principal</p></li><li><p>KhÃ´ng cÃ³ permission nÃ y, EventBridge <strong>cannot trigger Lambda function</strong></p></li><li><p>Permission statement: <code>lambda:InvokeFunction</code> from <code>events.amazonaws.com</code> service principal</p></li><li><p>CÃ³ thá»ƒ add qua Lambda console, CLI command <code>aws lambda add-permission</code>, hoáº·c CloudFormation</p></li><li><p>ÄÃ¢y lÃ  <strong>common integration issue</strong> giá»¯a EventBridge vÃ  Lambda</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Change the lifecycle hook action to CONTINUE if the lifecycle hook experiences a failure or timeout.</strong></p><ul><li><p><strong>Lifecycle hook action</strong> lÃ  behavior <strong>after hook completes/times out</strong></p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n viá»‡c <strong>Lambda khÃ´ng Ä‘Æ°á»£c invoked</strong></p></li><li><p>Váº¥n Ä‘á» hiá»‡n táº¡i lÃ  event khÃ´ng reach Lambda, khÃ´ng pháº£i Lambda execution failure</p></li></ul><p></p><p>âŒ <strong>Configure a retry policy in the EventBridge (CloudWatch Events) rule to retry the Lambda function invocation upon failure.</strong></p><ul><li><p><strong>Retry policy</strong> chá»‰ há»¯u Ã­ch khi Lambda Ä‘Æ°á»£c invoked nhÆ°ng <strong>fails</strong></p></li><li><p>Váº¥n Ä‘á» lÃ  Lambda <strong>KHÃ”NG Ä‘Æ°á»£c invoked at all</strong> - permission issue</p></li><li><p>Retry khÃ´ng giáº£i quyáº¿t root cause</p></li></ul><p></p><p>âŒ <strong>Update the Lambda function execution role so that it has permission to call the complete-lifecycle-action event.</strong></p><ul><li><p><strong>Execution role</strong> lÃ  permissions Lambda cáº§n Ä‘á»ƒ <strong>call other AWS services</strong></p></li><li><p>ÄÃ¢y vá» permissions <strong>FROM Lambda</strong>, khÃ´ng pháº£i <strong>TO Lambda</strong></p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n viá»‡c EventBridge khÃ´ng invoke Ä‘Æ°á»£c Lambda</p></li><li><p>Náº¿u Lambda chÆ°a Ä‘Æ°á»£c invoke, execution role chÆ°a relevant</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"EventBridge cannot invoke Lambda\"</strong> â†’ <strong>Lambda resource-based policy missing</strong></p></li><li><p><strong>\"Lambda execution role\"</strong> â†’ Permissions FROM Lambda | <strong>\"Lambda resource-based policy\"</strong> â†’ Permissions TO Lambda</p></li><li><p><strong>\"Integration EventBridge + Lambda\"</strong> â†’ Always check invoke permissions</p></li><li><p><strong>Pattern</strong>: EventBridge â†’ Lambda = Resource-based policy required | Lambda â†’ AWS services = Execution role required</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/access-control-resource-based.html\">Using resource-based policies for Lambda</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-use-resource-based.html#eb-lambda-permissions\">Granting EventBridge permission to invoke Lambda</a></p></li></ul>",
            "correctAnswer": [
                "<p>Add a permission to the Lambda function so that it can be invoked by the EventBridge (CloudWatch Events) rule.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Add a permission to the Lambda function so that it can be invoked by the EventBridge (CloudWatch Events) rule.</p>",
                "<p>Change the lifecycle hook action to CONTINUE if the lifecycle hook experiences a failure or timeout.</p>",
                "<p>Configure a retry policy in the EventBridge (CloudWatch Events) rule to retry the Lambda function invocation upon failure.</p>",
                "<p>Update the Lambda function execution role so that it has permission to call the complete-lifecycle-action event.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 38
        },
        {
            "attemptAnswerId": 329310,
            "questionId": 6533,
            "questionText": "<p>A SysOps administrator needs to configure a solution that will deliver digital content to a set of authorized users through Amazon CloudFront. Unauthorized users must be restricted from access.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Deliver <strong>digital content</strong> qua <strong>CloudFront</strong> Ä‘áº¿n <strong>authorized users</strong> only</p></li><li><p><strong>Unauthorized users must be restricted</strong> from access</p></li><li><p>YÃªu cáº§u: secure content delivery solution</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Store the digital content in an Amazon S3 bucket that has public access blocked. Use an origin access identity (OAI) to deliver the content through CloudFront. Restrict S3 bucket access with signed URLs in CloudFront.</strong></p><ul><li><p><strong>S3 block public access</strong> ngÄƒn <strong>direct access</strong> Ä‘áº¿n bucket, force traffic qua CloudFront</p></li><li><p><strong>Origin Access Identity (OAI)</strong> cho phÃ©p <strong>ONLY CloudFront access S3</strong>, khÃ´ng ai khÃ¡c</p></li><li><p><strong>S3 bucket policy</strong> grant permissions chá»‰ cho OAI</p></li><li><p><strong>Signed URLs</strong> trong CloudFront provide <strong>time-limited, authorized access</strong> cho specific users</p></li><li><p>Combination nÃ y táº¡o <strong>complete security</strong>: S3 private â†’ CloudFront via OAI â†’ Users via signed URLs</p></li><li><p>Unauthorized users khÃ´ng thá»ƒ bypass vÃ¬ khÃ´ng cÃ³ signed URLs vÃ  S3 khÃ´ng public</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Store the digital content in an Amazon S3 bucket that does not have public access blocked. Use signed URLs to access the S3 bucket through CloudFront.</strong></p><ul><li><p><strong>S3 khÃ´ng block public access</strong> = lá»— há»•ng security</p></li><li><p>Unauthorized users cÃ³ thá»ƒ <strong>bypass CloudFront</strong> vÃ  access S3 directly</p></li><li><p>Signed URLs chá»‰ protect CloudFront layer, khÃ´ng protect S3 layer</p></li></ul><p></p><p>âŒ <strong>Store the digital content in an Amazon S3 bucket that has public access blocked. Use an origin access identity (OAI) to deliver the content through CloudFront. Enable field-level encryption.</strong></p><ul><li><p>S3 block public access + OAI = GOOD</p></li><li><p><strong>Field-level encryption</strong> protect sensitive data <strong>during transit</strong>, KHÃ”NG restrict unauthorized access</p></li><li><p>Thiáº¿u <strong>signed URLs/cookies</strong> Ä‘á»ƒ authorize users</p></li><li><p>Everyone cÃ³ thá»ƒ access CloudFront distribution</p></li></ul><p></p><p>âŒ <strong>Store the digital content in an Amazon S3 bucket that does not have public access blocked. Use signed cookies for restricted delivery of the content through CloudFront.</strong></p><ul><li><p><strong>S3 khÃ´ng block public access</strong> = same issue nhÆ° option A</p></li><li><p>Signed cookies Ä‘Ãºng nhÆ°ng users váº«n cÃ³ thá»ƒ bypass CloudFront access S3 directly</p></li><li><p>Incomplete security</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Restrict content delivery\"</strong> â†’ <strong>S3 block public + OAI + Signed URLs/Cookies</strong></p></li><li><p><strong>\"OAI\"</strong> â†’ CloudFront-only access to S3 | <strong>\"Signed URLs/Cookies\"</strong> â†’ User authorization</p></li><li><p><strong>\"Field-level encryption\"</strong> â†’ Data protection, khÃ´ng pháº£i access control</p></li><li><p><strong>Pattern</strong>: Secure CloudFront = Block S3 public + OAI + Signed URLs/Cookies | Incomplete = Missing any component</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html\">Restricting access to Amazon S3 content with OAI</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-choosing-signed-urls-cookies.html\">Using signed URLs and signed cookies for CloudFront</a></p></li></ul>",
            "correctAnswer": [
                "<p>Store the digital content in an Amazon S3 bucket that has public access blocked. Use an origin access identity (OAI) to deliver the content through CloudFront. Restrict S3 bucket access with signed URLs in CloudFront.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Store the digital content in an Amazon S3 bucket that does not have public access blocked. Use signed URLs to access the S3 bucket through CloudFront.</p>",
                "<p>Store the digital content in an Amazon S3 bucket that has public access blocked. Use an origin access identity (OAI) to deliver the content through CloudFront. Restrict S3 bucket access with signed URLs in CloudFront.</p>",
                "<p>Store the digital content in an Amazon S3 bucket that has public access blocked. Use an origin access identity (OAI) to deliver the content through CloudFront. Enable field-level encryption.</p>",
                "<p>Store the digital content in an Amazon S3 bucket that does not have public access blocked. Use signed cookies for restricted delivery of the content through CloudFront.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 39
        },
        {
            "attemptAnswerId": 329311,
            "questionId": 10509,
            "questionText": "<p>A SysOps administrator needs to delete an AWS CloudFormation stack that is no longer in use. The CloudFormation stack is in the DELETE_FAILED state. The SysOps administrator has validated the permissions that are required to delete the CloudFormation stack.<br><br>Which of the following are possible causes of the DELETE_FAILED state? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>CloudFormation stack á»Ÿ <strong>DELETE_FAILED state</strong></p></li><li><p>SysOps administrator Ä‘Ã£ <strong>validate permissions</strong> (khÃ´ng pháº£i permission issue)</p></li><li><p>YÃªu cáº§u: identify <strong>possible causes</strong> cá»§a DELETE_FAILED</p></li><li><p>Chá»n <strong>2 Ä‘Ã¡p Ã¡n</strong></p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>There are additional resources associated with a security group in the stack.</strong></p><ul><li><p><strong>Security group cÃ³ dependencies</strong> (ENI, instances, load balancers) tá»« <strong>outside the stack</strong></p></li><li><p>CloudFormation <strong>cannot delete security group</strong> khi cÃ²n resources attached</p></li><li><p><strong>Dependency violation</strong> causing DELETE_FAILED</p></li><li><p>Pháº£i <strong>manually remove dependencies</strong> trÆ°á»›c khi delete stack láº¡i</p></li></ul><p></p><p><strong>There are Amazon S3 buckets that still contain objects in the stack.</strong></p><ul><li><p><strong>S3 bucket pháº£i EMPTY</strong> trÆ°á»›c khi CloudFormation cÃ³ thá»ƒ delete</p></li><li><p>Náº¿u bucket <strong>contains objects</strong>, CloudFormation delete operation <strong>fails</strong></p></li><li><p><strong>Very common cause</strong> cá»§a DELETE_FAILED</p></li><li><p>Solution: <strong>empty bucket manually</strong> hoáº·c use <strong>DeletionPolicy: Retain</strong> trong template</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>The configured timeout to delete the stack was too low for the delete operation to complete.</strong></p><ul><li><p>CloudFormation <strong>khÃ´ng cÃ³ timeout configuration</strong> cho delete operations</p></li><li><p>Delete operations cháº¡y cho Ä‘áº¿n khi <strong>complete hoáº·c fail</strong></p></li><li><p>Timeout khÃ´ng pháº£i cause cá»§a DELETE_FAILED</p></li></ul><p></p><p>âŒ <strong>The stack contains nested stacks that must be manually deleted first.</strong></p><ul><li><p>CloudFormation <strong>automatically deletes nested stacks</strong> khi delete parent stack</p></li><li><p><strong>KhÃ´ng cáº§n manually delete</strong> nested stacks trÆ°á»›c</p></li><li><p>Nested stacks Ä‘Æ°á»£c handle automatically</p></li></ul><p></p><p>âŒ <strong>The stack was deployed with the --disable-rollback option.</strong></p><ul><li><p><code>--disable-rollback</code> chá»‰ affect <strong>CREATE hoáº·c UPDATE</strong> operations</p></li><li><p><strong>KhÃ´ng áº£nh hÆ°á»Ÿng DELETE</strong> operations</p></li><li><p>KhÃ´ng relevant cho DELETE_FAILED state</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"DELETE_FAILED common causes\"</strong> â†’ <strong>S3 non-empty buckets + Resource dependencies</strong></p></li><li><p><strong>\"Security group dependency\"</strong> â†’ ENI/instances attached from outside stack</p></li><li><p><strong>\"S3 bucket delete\"</strong> â†’ Must be empty first</p></li><li><p><strong>Pattern</strong>: CloudFormation delete fails = Resource dependencies | S3 non-empty | External references</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/troubleshooting.html\">Troubleshooting CloudFormation delete failures</a></p></li></ul>",
            "correctAnswer": [
                "<p>There are additional resources associated with a security group in the stack.</p>",
                "<p>There are Amazon S3 buckets that still contain objects in the stack.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>The configured timeout to delete the stack was too low for the delete operation to complete.</p>",
                "<p>The stack contains nested stacks that must be manually deleted first.</p>",
                "<p>The stack was deployed with the --disable-rollback option.</p>",
                "<p>There are additional resources associated with a security group in the stack.</p>",
                "<p>There are Amazon S3 buckets that still contain objects in the stack.</p>"
            ],
            "answersPos": "[3,2,0,1,4]",
            "pos": 40
        },
        {
            "attemptAnswerId": 329312,
            "questionId": 6535,
            "questionText": "<p>A company is managing many accounts by using a single organization in AWS Organizations. The organization has all features enabled. The company wants to turn on AWS Config in all the accounts of the organization and in all AWS Regions.<br><br>What should a SysOps administrator do to meet these requirements in the MOST operationally efficient way?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company quáº£n lÃ½ <strong>many accounts</strong> trong <strong>AWS Organizations</strong> (all features enabled)</p></li><li><p>Muá»‘n enable <strong>AWS Config</strong> trong <strong>all accounts</strong> vÃ  <strong>all Regions</strong></p></li><li><p>YÃªu cáº§u: <strong>MOST operationally efficient</strong> solution</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use AWS CloudFormation Stack Sets to deploy stack instances that turn on AWS Config in all accounts and in all Regions.</strong></p><ul><li><p><strong>CloudFormation StackSets</strong> Ä‘Æ°á»£c thiáº¿t káº¿ specifically cho <strong>multi-account, multi-region deployments</strong></p></li><li><p><strong>Stack instances</strong> lÃ  actual CloudFormation stacks deployed to target accounts vÃ  regions</p></li><li><p><strong>Organizations integration</strong> cho phÃ©p automatic deployment khi cÃ³ new accounts added</p></li><li><p>Deploy má»™t láº§n, apply across <strong>all accounts vÃ  all regions</strong> simultaneously</p></li><li><p><strong>Fully managed</strong> - AWS handle deployment, updates, vÃ  consistency</p></li><li><p>ÄÃ¢y lÃ  <strong>AWS recommended approach</strong> cho enabling services across organization</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Use AWS CloudFormation Stack Sets to deploy stack policies that turn on AWS Config in all accounts and in all Regions.</strong></p><ul><li><p><strong>Stack policies</strong> control <strong>update permissions</strong>, prevent accidental updates to resources</p></li><li><p>Stack policies <strong>KHÃ”NG pháº£i deployment mechanism</strong>, khÃ´ng thá»ƒ deploy AWS Config</p></li><li><p>Sai concept - confuse stack policies vá»›i stack instances</p></li></ul><p></p><p>âŒ <strong>Use service control policies (SCPs) to configure AWS Config in all accounts and in all Regions.</strong></p><ul><li><p><strong>SCPs lÃ  permission boundaries</strong> - control actions accounts CAN hoáº·c CANNOT perform</p></li><li><p>SCPs <strong>KHÃ”NG deploy resources</strong> hay configure services</p></li><li><p>SCPs chá»‰ enforce/deny permissions, khÃ´ng config AWS Config</p></li><li><p>Sai use case hoÃ n toÃ n</p></li></ul><p></p><p>âŒ <strong>Create a script that uses the AWS CLI to turn on AWS Config in all accounts in the organization. Run the script from the organization's management account.</strong></p><ul><li><p><strong>Custom scripting</strong> = high operational overhead</p></li><li><p>Pháº£i <strong>maintain script</strong>, handle errors, pagination, authentication</p></li><li><p><strong>KhÃ´ng scalable</strong> cho new accounts - pháº£i update script</p></li><li><p>Not most operationally efficient</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Multi-account + multi-region deployment\"</strong> â†’ <strong>CloudFormation StackSets</strong></p></li><li><p><strong>\"Stack instances\"</strong> â†’ Actual deployed stacks | <strong>\"Stack policies\"</strong> â†’ Update controls</p></li><li><p><strong>\"SCPs\"</strong> â†’ Permission boundaries, khÃ´ng deploy resources</p></li><li><p><strong>Pattern</strong>: Multi-account deployment = StackSets | Permission control = SCPs | One-time setup = Manual/CLI</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/organizations/latest/userguide/services-that-can-integrate-cloudformation.html\">AWS CloudFormation StackSets with Organizations</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/blogs/mt/managing-aws-organizations-accounts-using-aws-config-and-aws-cloudformation-stacksets/\">Enabling AWS Config with StackSets</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use AWS CloudFormation Stack Sets to deploy stack instances that turn on AWS Config in all accounts and in all Regions.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Use AWS CloudFormation Stack Sets to deploy stack instances that turn on AWS Config in all accounts and in all Regions.</p>",
                "<p>Use AWS CloudFormation Stack Sets to deploy stack policies that turn on AWS Config in all accounts and in all Regions.</p>",
                "<p>Use service control policies (SCPs) to configure AWS Config in all accounts and in all Regions.</p>",
                "<p>Create a script that uses the AWS CLI to turn on AWS Config in all accounts in the organization. Run the script from the organization's management account.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 41
        },
        {
            "attemptAnswerId": 329313,
            "questionId": 6536,
            "questionText": "<p>A company is creating a new multi-account architecture. A SysOps administrator must implement a login solution to centrally manage user access and permissions across all AWS accounts. The solution must be integrated with AWS Organizations and must be connected to a third-party Security Assertion Markup Language (SAML) 2.0 identity provider (IdP).<br><br>What should the SysOps administrator do to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p><strong>Multi-account architecture</strong></p></li><li><p>Centrally manage <strong>user access vÃ  permissions across ALL AWS accounts</strong></p></li><li><p>Must integrate vá»›i <strong>AWS Organizations</strong></p></li><li><p>Connect vá»›i <strong>third-party SAML 2.0 IdP</strong></p></li><li><p>YÃªu cáº§u: centralized login solution</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Enable and configure AWS Single Sign-On with the third-party IdP.</strong></p><ul><li><p><strong>AWS Single Sign-On (AWS SSO)</strong> - now called <strong>IAM Identity Center</strong> - Ä‘Æ°á»£c thiáº¿t káº¿ specifically cho <strong>multi-account access management</strong></p></li><li><p><strong>Native integration vá»›i AWS Organizations</strong> - automatically discover all accounts</p></li><li><p><strong>Built-in SAML 2.0 federation</strong> support vá»›i third-party IdPs (Okta, Azure AD, etc.)</p></li><li><p><strong>Centralized permission management</strong> - define permission sets vÃ  assign to users/groups across accounts</p></li><li><p>Users <strong>single login</strong> access multiple AWS accounts vÃ  applications</p></li><li><p>ÄÃ¢y lÃ  <strong>AWS recommended solution</strong> cho enterprise multi-account environments</p></li></ul><hr><p></p><p><u>Architecture:</u></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765410851117-46qqi9m7-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"553.3333333333334\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure an Amazon Cognito user pool. Integrate the user pool with the third-party IdP.</strong></p><ul><li><p><strong>Cognito user pools</strong> designed cho <strong>web/mobile application</strong> user authentication</p></li><li><p><strong>KHÃ”NG pháº£i solution</strong> cho AWS account access management</p></li><li><p>Use case khÃ¡c - app users, khÃ´ng pháº£i AWS account users</p></li></ul><p></p><p>âŒ <strong>Federate the third-party IdP with AWS Identity and Access Management (IAM) for each AWS account in the organization.</strong></p><ul><li><p>Pháº£i configure <strong>SAML federation separately</strong> cho Tá»ªNG account</p></li><li><p><strong>Very high operational overhead</strong> - nhiá»u accounts = nhiá»u configurations</p></li><li><p><strong>NOT centralized</strong> management</p></li><li><p>KhÃ´ng scalable vÃ  khÃ´ng efficient</p></li></ul><p></p><p>âŒ <strong>Integrate the third-party IdP directly with AWS Organizations.</strong></p><ul><li><p><strong>AWS Organizations KHÃ”NG cÃ³ IdP integration capability</strong></p></li><li><p>Organizations manage <strong>account structure</strong>, khÃ´ng pháº£i user authentication</p></li><li><p>KhÃ´ng pháº£i valid option</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Multi-account + centralized access\"</strong> â†’ <strong>AWS SSO (IAM Identity Center)</strong></p></li><li><p><strong>\"SAML 2.0 IdP + AWS\"</strong> â†’ AWS SSO support federation</p></li><li><p><strong>\"Organizations integration\"</strong> â†’ AWS SSO auto-discover accounts</p></li><li><p><strong>Pattern</strong>: Multi-account SSO = AWS SSO | App authentication = Cognito | Per-account = IAM SAML federation</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/organizations/latest/userguide/services-that-can-integrate-sso.html\">AWS Single Sign-On (IAM Identity Center) with Organizations</a></p></li><li><p>Connecting SAML 2.0 IdP to AWS SSO</p></li></ul>",
            "correctAnswer": [
                "<p>Enable and configure AWS Single Sign-On with the third-party IdP.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure an Amazon Cognito user pool. Integrate the user pool with the third-party IdP.</p>",
                "<p>Enable and configure AWS Single Sign-On with the third-party IdP.</p>",
                "<p>Federate the third-party IdP with AWS Identity and Access Management (IAM) for each AWS account in the organization.</p>",
                "<p>Integrate the third-party IdP directly with AWS Organizations.</p>"
            ],
            "answersPos": "[3,0,1,2]",
            "pos": 42
        },
        {
            "attemptAnswerId": 329314,
            "questionId": 6537,
            "questionText": "<p>A company's SysOps administrator needs to change the AWS Support plan for one of the company's AWS accounts. The account has multi-factor authentication (MFA) activated, and the MFA device is lost.<br><br>What should the SysOps administrator do to sign in?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Cáº§n <strong>change AWS Support plan</strong> cá»§a account</p></li><li><p>Account cÃ³ <strong>MFA activated</strong> nhÆ°ng <strong>MFA device bá»‹ máº¥t</strong></p></li><li><p>YÃªu cáº§u: cÃ¡ch sign in Ä‘á»ƒ thá»±c hiá»‡n task</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Sign in as a root user by using email and phone verification. Set up a new MFA device. Change the root user password.</strong></p><ul><li><p><strong>Changing AWS Support plan chá»‰ cÃ³ thá»ƒ thá»±c hiá»‡n bá»Ÿi root user</strong> - IAM users khÃ´ng cÃ³ permission</p></li><li><p>Khi <strong>MFA device lost</strong>, AWS cho phÃ©p root user sign in báº±ng <strong>alternative verification methods</strong></p></li><li><p>Process: Chá»n \"Trouble signing in?\" â†’ Verify identity qua <strong>email vÃ  phone number</strong> registered vá»›i account</p></li><li><p>Sau khi sign in successfully, <strong>deactivate lost MFA device</strong> vÃ  <strong>setup new MFA device</strong></p></li><li><p><strong>Change root password</strong> lÃ  security best practice sau recovery process</p></li><li><p>ÄÃ¢y lÃ  <strong>AWS documented recovery procedure</strong> cho root user MFA device loss</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Sign in as an IAM user with administrator permissions. Resynchronize the MFA token by using the IAM console.</strong></p><ul><li><p><strong>IAM users KHÃ”NG thá»ƒ change AWS Support plan</strong> - chá»‰ root user cÃ³ permission</p></li><li><p><strong>Resynchronize chá»‰ work</strong> khi MFA device váº«n cÃ²n nhÆ°ng <strong>out of sync</strong> (time drift)</p></li><li><p>KhÃ´ng giáº£i quyáº¿t lost device scenario</p></li></ul><p></p><p>âŒ <strong>Sign in as an IAM user with administrator permissions. Reset the MFA device for the root user by adding a new device.</strong></p><ul><li><p>IAM users khÃ´ng thá»ƒ change support plan</p></li><li><p><strong>IAM users KHÃ”NG cÃ³ permission</strong> reset MFA cho root user</p></li><li><p>Chá»‰ root user cÃ³ thá»ƒ manage root user's MFA</p></li></ul><p></p><p>âŒ <strong>Use the forgot-password process to verify the email address. Set up a new password and MFA device.</strong></p><ul><li><p><strong>Forgot-password process</strong> khÃ´ng pháº£i correct procedure cho <strong>MFA device loss</strong></p></li><li><p>Process nÃ y reset password, khÃ´ng handle MFA recovery</p></li><li><p>KhÃ´ng Ä‘áº§y Ä‘á»§ recovery steps</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Change Support plan\"</strong> â†’ <strong>Root user required</strong></p></li><li><p><strong>\"MFA device lost\"</strong> â†’ <strong>Alternative verification</strong> (email + phone)</p></li><li><p><strong>\"IAM users\"</strong> â†’ Cannot change support plan, cannot reset root MFA</p></li><li><p><strong>Pattern</strong>: Support plan changes = Root user only | MFA recovery = Alternative verification | IAM = Cannot manage root credentials</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_lost-or-broken.html\">Recovering root user access with lost MFA device</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/awssupport/latest/user/changing-support-plans.html\">Changing AWS Support plans</a></p></li></ul>",
            "correctAnswer": [
                "<p>Sign in as a root user by using email and phone verification. Set up a new MFA device. Change the root user password.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Sign in as a root user by using email and phone verification. Set up a new MFA device. Change the root user password.</p>",
                "<p>Sign in as an IAM user with administrator permissions. Resynchronize the MFA token by using the IAM console.</p>",
                "<p>Sign in as an IAM user with administrator permissions. Reset the MFA device for the root user by adding a new device.</p>",
                "<p>Use the forgot-password process to verify the email address. Set up a new password and MFA device.</p>"
            ],
            "answersPos": "[3,1,0,2]",
            "pos": 43
        },
        {
            "attemptAnswerId": 329315,
            "questionId": 6538,
            "questionText": "<p>A company updates its security policy to prohibit the public exposure of any data in Amazon S3 buckets in the company's account.<br><br>What should a SysOps administrator do to meet this requirement?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company policy: <strong>prohibit (cáº¥m) public exposure</strong> cá»§a báº¥t ká»³ data nÃ o trong S3 buckets</p></li><li><p>YÃªu cáº§u: solution enforce policy across <strong>company's account</strong></p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Turn on S3 Block Public Access from the account level.</strong></p><ul><li><p><strong>S3 Block Public Access</strong> lÃ  AWS native feature Ä‘Æ°á»£c thiáº¿t káº¿ specifically Ä‘á»ƒ <strong>prevent public access</strong> to S3 data</p></li><li><p><strong>Account-level setting</strong> applies to <strong>ALL buckets</strong> trong account (existing vÃ  future)</p></li><li><p><strong>Overrides bucket policies vÃ  ACLs</strong> - ngÄƒn public access báº¥t ká»ƒ individual bucket configurations</p></li><li><p><strong>Four settings</strong>: Block public ACLs, Ignore public ACLs, Block public bucket policies, Restrict public buckets</p></li><li><p><strong>Preventive control</strong> - block tá»« Ä‘áº§u thay vÃ¬ detect vÃ  remediate</p></li><li><p>ÄÃ¢y lÃ  <strong>AWS recommended best practice</strong> cho securing S3 at scale</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create an Amazon EventBridge (Amazon CloudWatch Events) rule to enforce that all S3 objects are private.</strong></p><ul><li><p>EventBridge <strong>cannot directly enforce</strong> object permissions</p></li><li><p><strong>Reactive approach</strong> - detect sau khi public access Ä‘Ã£ xáº£y ra</p></li><li><p>Pháº£i write custom Lambda cho remediation - operational overhead</p></li><li><p>KhÃ´ng pháº£i preventive control</p></li></ul><p></p><p>âŒ <strong>Use Amazon Inspector to search for S3 buckets and to automatically reset S3 ACLs if any public S3 buckets are found.</strong></p><ul><li><p><strong>Amazon Inspector</strong> lÃ  vulnerability scanning service cho <strong>EC2, containers, Lambda functions</strong></p></li><li><p><strong>KHÃ”NG scan S3 bucket configurations</strong> hay manage ACLs</p></li><li><p>Sai service hoÃ n toÃ n</p></li></ul><p></p><p>âŒ <strong>Use S3 Object Lambda to examine S3 ACLs and to change any public S3 ACLs to private.</strong></p><ul><li><p><strong>S3 Object Lambda</strong> transform/process <strong>S3 object data</strong> when retrieved (e.g., resize images, redact data)</p></li><li><p><strong>KHÃ”NG manage ACLs</strong> hay bucket configurations</p></li><li><p>Sai use case - Object Lambda for data transformation, not access control</p></li></ul><hr><p></p><p><em>S3 Object Lambda</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765411324780-hwiznezo-image.png\" alt=\"\" title=\"\" width=\"766\" height=\"389.14395833333333\" style=\"max-width: 766px\" data-keep-ratio=\"true\"></span></span></p><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Prohibit public S3 access company-wide\"</strong> â†’ <strong>S3 Block Public Access at account level</strong></p></li><li><p><strong>\"Preventive control\"</strong> â†’ Block Public Access | <strong>\"Detective control\"</strong> â†’ AWS Config rules</p></li><li><p><strong>\"Inspector\"</strong> â†’ EC2/container/Lambda scanning, khÃ´ng pháº£i S3</p></li><li><p><strong>Pattern</strong>: S3 public access prevention = Block Public Access | Data transformation = Object Lambda | Vulnerability scanning = Inspector</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html\">Amazon S3 Block Public Access</a></p></li></ul>",
            "correctAnswer": [
                "<p>Turn on S3 Block Public Access from the account level.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Turn on S3 Block Public Access from the account level.</p>",
                "<p>Create an Amazon Event Bridge (Amazon CloudWatch Events) rule to enforce that all S3 objects are private.</p>",
                "<p>Use Amazon Inspector to search for S3 buckets and to automatically reset S3 ACLs if any public S3 buckets are found.</p>",
                "<p>Use S3 Object Lambda to examine S3 ACLs and to change any public S3 ACLs to private.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 44
        },
        {
            "attemptAnswerId": 329316,
            "questionId": 6539,
            "questionText": "<p>A SysOps administrator wants to monitor the free disk space that is available on a set of Amazon EC2 instances that have Amazon Elastic Block Store (Amazon EBS) volumes attached. The SysOps administrator wants to receive a notification when the used disk space of the EBS volumes exceeds a threshold value, but only when the DiskReadOps metric also exceeds a threshold value. The SysOps administrator has set up an Amazon Simple Notification Service (Amazon SNS) topic.<br><br>How can the SysOps administrator receive notification only when both metrics exceed their threshold values?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Monitor <strong>free disk space</strong> trÃªn EC2 instances vá»›i EBS volumes</p></li><li><p>Muá»‘n <strong>notification</strong> chá»‰ khi:</p><ul><li><p><strong>Used disk space exceeds threshold</strong> VÃ€</p></li><li><p><strong>DiskReadOps metric ALSO exceeds threshold</strong></p></li></ul></li><li><p>ÄÃ£ setup SNS topic</p></li><li><p>YÃªu cáº§u: notification chá»‰ khi <strong>Cáº¢ 2 metrics exceed</strong></p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Install the Amazon CloudWatch agent on the EC2 instances. Create a metric alarm for the disk space and a metric alarm for the DiskReadOps metric. Create a composite alarm that includes the two metric alarms to publish a notification to the SNS topic.</strong></p><ul><li><p><strong>CloudWatch agent required</strong> Ä‘á»ƒ collect <strong>disk space metrics</strong> (default metrics khÃ´ng cÃ³)</p></li><li><p>Táº¡o <strong>2 separate metric alarms</strong>: má»™t cho disk space, má»™t cho DiskReadOps</p></li><li><p><strong>Composite alarm</strong> combine multiple metric alarms vá»›i <strong>AND/OR logic</strong></p></li><li><p>Configure composite alarm vá»›i <strong>AND condition</strong> - trigger chá»‰ khi <strong>BOTH child alarms in ALARM state</strong></p></li><li><p><strong>Composite alarm publish to SNS</strong> - single notification khi both conditions met</p></li><li><p>ÄÃ¢y lÃ  <strong>correct pattern</strong> cho multi-metric alerting vá»›i complex conditions</p></li></ul><hr><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765412021001-ld7jc2o8-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"450.375\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Install the Amazon CloudWatch agent on the EC2 instances. Create a metric alarm for the disk space and a metric alarm for the DiskReadOps metric. Configure each alarm to publish a notification to the SNS topic.</strong></p><ul><li><p>CloudWatch agent Ä‘Ãºng</p></li><li><p>2 metric alarms Ä‘Ãºng</p></li><li><p>NHÆ¯NG <strong>each alarm publish separately</strong> = nháº­n <strong>2 separate notifications</strong></p></li><li><p><strong>KhÃ´ng Ä‘áº£m báº£o \"only when BOTH exceed\"</strong> - cÃ³ thá»ƒ nháº­n notification khi chá»‰ 1 metric exceeds</p></li></ul><p></p><p>âŒ <strong>Create a metric alarm for the EBSByteBalance% metric and a metric alarm for the DiskReadOps metric. Create a composite alarm that includes the two metric alarms to publish a notification to the SNS topic.</strong></p><ul><li><p><strong>EBSByteBalance%</strong> lÃ  <strong>burst balance metric</strong> cho gp2/gp3 volumes</p></li><li><p><strong>KHÃ”NG pháº£i disk space metric</strong></p></li><li><p>Sai metric choice, khÃ´ng monitor disk usage</p></li></ul><p></p><p>âŒ <strong>Configure detailed monitoring for the EC2 instances. Create a metric alarm for the disk space and a metric alarm for the DiskReadOps metric. Create a composite alarm that includes the two metric alarms to publish a notification to the SNS topic.</strong></p><ul><li><p><strong>Detailed monitoring</strong> chá»‰ increase frequency cá»§a <strong>default metrics</strong> (1-minute intervals)</p></li><li><p><strong>KHÃ”NG provide disk space metrics</strong> - disk space requires CloudWatch agent</p></li><li><p>KhÃ´ng thá»ƒ create alarm cho disk space without agent</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Disk space metrics\"</strong> â†’ <strong>CloudWatch agent required</strong></p></li><li><p><strong>\"Only when BOTH/ALL conditions met\"</strong> â†’ <strong>Composite alarm with AND logic</strong></p></li><li><p><strong>\"Multiple separate alarms\"</strong> â†’ Each triggers independently | <strong>\"Composite alarm\"</strong> â†’ Combined logic</p></li><li><p><strong>Pattern</strong>: Multi-condition alerting = Composite alarm | Single metric = Metric alarm | Disk metrics = CloudWatch agent</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Create_Composite_Alarm.html\">CloudWatch composite alarms</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html\">Install CloudWatch agent for disk metrics</a></p></li></ul>",
            "correctAnswer": [
                "<p>Install the Amazon CloudWatch agent on the EC2 instances. Create a metric alarm for the disk space and a metric alarm for the DiskReadOps metric. Create a composite alarm that includes the two metric alarms to publish a notification to the SNS topic.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Install the Amazon CloudWatch agent on the EC2 instances. Create a metric alarm for the disk space and a metric alarm for the DiskReadOps metric. Create a composite alarm that includes the two metric alarms to publish a notification to the SNS topic.</p>",
                "<p>Install the Amazon CloudWatch agent on the EC2 instances. Create a metric alarm for the disk space and a metric alarm for the DiskReadOps metric. Configure each alarm to publish a notification to the SNS topic.</p>",
                "<p>Create a metric alarm for the EBSByteBalance% metric and a metric alarm for the DiskReadOps metric. Create a composite alarm that includes the two metric alarms to publish a notification to the SNS topic.</p>",
                "<p>Configure detailed monitoring for the EC2 instances. Create a metric alarm for the disk space and a metric alarm for the DiskReadOps metric. Create a composite alarm that includes the two metric alarms to publish a notification to the SNS topic.</p>"
            ],
            "answersPos": "[3,1,2,0]",
            "pos": 45
        },
        {
            "attemptAnswerId": 329317,
            "questionId": 6540,
            "questionText": "<p>A company runs a website from Sydney, Australia. Users in the United States (US) and Europe are reporting that images and videos are taking a long time to load. However, local testing in Australia indicates no performance issues. The website has a large amount of static content in the form of images and videos that are stored in Amazon S3.<br><br>Which solution will result in the MOST improvement in the user experience for users in the US and Europe?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Website cháº¡y tá»« <strong>Sydney, Australia</strong></p></li><li><p>Users á»Ÿ <strong>US vÃ  Europe</strong> bÃ¡o <strong>images/videos load slow</strong></p></li><li><p>Local testing á»Ÿ <strong>Australia OK</strong> - no performance issues</p></li><li><p><strong>Large amount of static content</strong> (images, videos) stored trong <strong>Amazon S3</strong></p></li><li><p>YÃªu cáº§u: <strong>MOST improvement</strong> cho US vÃ  Europe users</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create an Amazon CloudFront distribution. Distribute the static content to the CloudFront edge locations.</strong></p><ul><li><p><strong>CloudFront lÃ  CDN (Content Delivery Network)</strong> - designed specifically cho <strong>global static content delivery</strong></p></li><li><p><strong>Cache content táº¡i edge locations</strong> gáº§n users (US vÃ  Europe cÃ³ nhiá»u edge locations)</p></li><li><p><strong>First request</strong> fetch tá»« S3 origin (Sydney), subsequent requests serve tá»« <strong>local cache</strong> táº¡i edge</p></li><li><p><strong>Dramatically reduce latency</strong> - users access content tá»« edge location gáº§n nháº¥t thay vÃ¬ Sydney</p></li><li><p><strong>Optimize cho images/videos</strong> - static content caching lÃ  core use case cá»§a CloudFront</p></li><li><p><strong>AWS recommended solution</strong> cho improving global content delivery performance</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure AWS PrivateLink for Amazon S3.</strong></p><ul><li><p><strong>PrivateLink</strong> provide <strong>private connectivity</strong> tá»« VPC Ä‘áº¿n AWS services qua private endpoint</p></li><li><p>KhÃ´ng giáº£i quyáº¿t <strong>geographic latency</strong> issue</p></li><li><p>Use case: secure, private access, khÃ´ng pháº£i performance improvement</p></li></ul><p></p><p>âŒ <strong>Configure S3 Transfer Acceleration.</strong></p><ul><li><p><strong>Transfer Acceleration</strong> optimize <strong>upload speed TO S3</strong> tá»« global locations</p></li><li><p>DÃ¹ng CloudFront edge locations Ä‘á»ƒ accelerate <strong>uploads</strong>, khÃ´ng pháº£i <strong>downloads</strong></p></li><li><p>KhÃ´ng improve content delivery performance cho end users</p></li></ul><p></p><p>âŒ <strong>Create an Amazon API Gateway API in each AWS Region. Cache the content locally.</strong></p><ul><li><p><strong>API Gateway KHÃ”NG pháº£i CDN</strong>, khÃ´ng designed cho static content delivery</p></li><li><p>Pháº£i <strong>manually create APIs</strong> á»Ÿ multiple regions - high operational overhead</p></li><li><p>API Gateway caching designed cho API responses, khÃ´ng pháº£i large static files</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Global users + slow static content\"</strong> â†’ <strong>CloudFront CDN</strong></p></li><li><p><strong>\"S3 Transfer Acceleration\"</strong> â†’ Upload optimization, khÃ´ng pháº£i download</p></li><li><p><strong>\"Static content delivery\"</strong> â†’ CloudFront | <strong>\"Dynamic content\"</strong> â†’ Global Accelerator or multi-region</p></li><li><p><strong>Pattern</strong>: Global static content = CloudFront | File uploads = Transfer Acceleration | Private connectivity = PrivateLink</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/getting-started-cloudfront-overview.html\">Amazon CloudFront for static content delivery</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://blog.cloudmentor.pro/blog/aws-saa-dva/how-to-deploy-react-app-with-s3-and-cloudfront\">How to Deploy React App with S3 and CloudFront</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create an Amazon CloudFront distribution. Distribute the static content to the CloudFront edge locations.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure AWS PrivateLink for Amazon S3.</p>",
                "<p>Configure S3 Transfer Acceleration.</p>",
                "<p>Create an Amazon CloudFront distribution. Distribute the static content to the CloudFront edge locations.</p>",
                "<p>Create an Amazon API Gateway API in each AWS Region. Cache the content locally.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 46
        },
        {
            "attemptAnswerId": 329318,
            "questionId": 6541,
            "questionText": "<p>A company updates its security policy to clarify cloud hosting arrangements for regulated workloads. Workloads that are identified as sensitive must run on hardware that is not shared with other customers or with other AWS accounts within the company.<br><br>Which solution will ensure compliance with this policy?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company security policy cho <strong>regulated/sensitive workloads</strong></p></li><li><p>Requirements: hardware <strong>KHÃ”NG share vá»›i</strong>:</p><ul><li><p><strong>Other customers</strong> VÃ€</p></li><li><p><strong>Other AWS accounts within the company</strong></p></li></ul></li><li><p>YÃªu cáº§u: solution ensure compliance</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Deploy workloads only to Dedicated Hosts.</strong></p><ul><li><p><strong>Dedicated Hosts</strong> lÃ  <strong>physical servers dedicated</strong> exclusively for your use</p></li><li><p>Provide <strong>full hardware isolation</strong> - khÃ´ng share vá»›i other AWS customers</p></li><li><p>Cung cáº¥p kháº£ nÄƒng hiá»ƒn thá»‹ vÃ  kiá»ƒm soÃ¡t vá»‹ trÃ­ Ä‘áº·t phiÃªn báº£n trÃªn mÃ¡y chá»§ váº­t lÃ½ cá»¥ thá»ƒ.</p></li><li><p><strong>Account-level isolation</strong> - cÃ³ thá»ƒ control exactly which instances run on host</p></li><li><p><strong>KHÃ”NG share hardware</strong> vá»›i other AWS accounts, including other accounts trong same company</p></li><li><p>Meet compliance requirements cho <strong>regulated workloads</strong> requiring hardware isolation</p></li><li><p>Support <strong>bring your own license (BYOL)</strong> for compliance</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Deploy workloads only to Dedicated Instances.</strong></p><ul><li><p><strong>Dedicated Instances</strong> run on hardware dedicated to <strong>single customer</strong></p></li><li><p>Hardware KHÃ”NG share vá»›i <strong>other AWS customers</strong> âœ“</p></li><li><p>NHÆ¯NG hardware <strong>CÃ“ THá»‚ share</strong> vá»›i instances from <strong>other AWS accounts</strong> cá»§a cÃ¹ng customer (within the company) âœ—</p></li><li><p><strong>KhÃ´ng Ä‘áº£m báº£o account-level isolation</strong> nhÆ° requirement</p></li><li><p>Ãt strict hÆ¡n Dedicated Hosts</p></li></ul><p></p><p>âŒ <strong>Deploy workloads only to Reserved Instances.</strong></p><ul><li><p><strong>Reserved Instances</strong> lÃ  <strong>pricing/billing model</strong>, khÃ´ng pháº£i deployment option</p></li><li><p>Instances váº«n cÃ³ thá»ƒ cháº¡y trÃªn <strong>shared hardware</strong> (default)</p></li><li><p>KhÃ´ng provide hardware isolation</p></li><li><p>KhÃ´ng meet compliance requirement</p></li></ul><p></p><p>âŒ <strong>Place all instances in a dedicated placement group.</strong></p><ul><li><p><strong>KhÃ´ng cÃ³ khÃ¡i niá»‡m \"dedicated placement group\"</strong> trong AWS</p></li><li><p><strong>Placement groups</strong> (cluster, partition, spread) control <strong>instance placement strategy</strong>, khÃ´ng pháº£i hardware isolation</p></li><li><p>KhÃ´ng provide hardware isolation from other customers/accounts</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Hardware NOT shared with other accounts\"</strong> â†’ <strong>Dedicated Hosts</strong> (full isolation)</p></li><li><p><strong>\"Hardware NOT shared with other customers only\"</strong> â†’ <strong>Dedicated Instances</strong> (customer-level)</p></li><li><p><strong>\"Dedicated Hosts vs Instances\"</strong> â†’ Hosts = account-level isolation | Instances = customer-level isolation</p></li><li><p><strong>Pattern</strong>: Regulated workloads + account isolation = Dedicated Hosts | Customer isolation only = Dedicated Instances | Pricing only = Reserved Instances</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/ec2/dedicated-hosts/\">Amazon EC2 Dedicated Hosts</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://medium.com/@nisargpendal/dedicated-host-vs-dedicated-instance-ceb6544942f2\">Dedicated Hosts vs Dedicated Instances comparison</a></p></li></ul>",
            "correctAnswer": [
                "<p>Deploy workloads only to Dedicated Hosts.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Deploy workloads only to Dedicated Hosts.</p>",
                "<p>Deploy workloads only to Dedicated Instances.</p>",
                "<p>Deploy workloads only to Reserved Instances.</p>",
                "<p>Place all instances in a dedicated placement group.</p>"
            ],
            "answersPos": "[2,1,3,0]",
            "pos": 47
        },
        {
            "attemptAnswerId": 329319,
            "questionId": 6542,
            "questionText": "<p>A SysOps administrator creates an AWS CloudFormation template to define an application stack that can be deployed in multiple AWS Regions. The SysOps administrator also creates an Amazon CloudWatch dashboard by using the AWS Management Console. Each deployment of the application requires its own CloudWatch dashboard.<br><br>How can the SysOps administrator automate the creation of the CloudWatch dashboard each time the application is deployed?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>CloudFormation template deploy <strong>application stack</strong> trong <strong>multiple AWS Regions</strong></p></li><li><p>ÄÃ£ táº¡o <strong>CloudWatch dashboard manually</strong> qua Console</p></li><li><p><strong>Each deployment</strong> cáº§n <strong>own CloudWatch dashboard</strong></p></li><li><p>YÃªu cáº§u: <strong>automate dashboard creation</strong> má»—i khi application deployed</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Export the existing CloudWatch dashboard as JSON. Update the CloudFormation template to define an AWS::CloudWatch::Dashboard resource. Include the exported JSON in the resource's DashboardBody property.</strong></p><ul><li><p><strong>CloudWatch dashboard cÃ³ thá»ƒ export</strong> ra JSON format tá»« Console (Actions â†’ View/edit source)</p></li><li><p><strong>AWS::CloudWatch::Dashboard</strong> lÃ  CloudFormation resource type Ä‘á»ƒ define dashboards</p></li><li><p><strong>DashboardBody property</strong> chá»©a <strong>JSON definition</strong> cá»§a dashboard configuration (widgets, metrics, etc.)</p></li><li><p>Má»—i khi <strong>deploy CloudFormation stack</strong>, dashboard tá»± Ä‘á»™ng created vá»›i same configuration</p></li><li><p><strong>Fully automated</strong> - khÃ´ng cáº§n manual intervention</p></li><li><p><strong>Scalable</strong> across multiple regions vÃ  deployments</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a script by using the AWS CLI to run the aws cloudformation put-dashboard command with the name of the dashboard. Run the command each time a new CloudFormation stack is created.</strong></p><ul><li><p><strong>KhÃ´ng cÃ³ command</strong> <code>aws cloudformation put-dashboard</code></p></li><li><p>CloudWatch dashboard commands lÃ  <code>aws cloudwatch put-dashboard</code>, khÃ´ng pháº£i cloudformation</p></li><li><p><strong>Manual script execution</strong> - khÃ´ng automated trong CloudFormation workflow</p></li></ul><p></p><p>âŒ <strong>Update the CloudFormation template to define an AWS::CloudWatch::Dashboard resource. Use the Intrinsic Ref function to reference the ID of the existing CloudWatch dashboard.</strong></p><ul><li><p><strong>Ref function</strong> reference resources <strong>TRONG cÃ¹ng template</strong>, khÃ´ng pháº£i existing external resources</p></li><li><p>KhÃ´ng <strong>create new dashboard</strong>, chá»‰ reference</p></li><li><p>KhÃ´ng giáº£i quyáº¿t requirement má»—i deployment cáº§n own dashboard</p></li></ul><p></p><p>âŒ <strong>Update the CloudFormation template to define an AWS::CloudWatch::Dashboard resource. Specify the name of the existing dashboard in the DashboardName property.</strong></p><ul><li><p>Chá»‰ specify <strong>dashboard name</strong>, khÃ´ng define <strong>dashboard content/configuration</strong></p></li><li><p><strong>KhÃ´ng create dashboard</strong> vá»›i widgets vÃ  metrics</p></li><li><p>Táº¥t cáº£ deployments conflict vÃ¬ cÃ¹ng name</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Automate dashboard creation in CloudFormation\"</strong> â†’ <strong>AWS::CloudWatch::Dashboard resource</strong></p></li><li><p><strong>\"DashboardBody property\"</strong> â†’ Chá»©a JSON definition exported tá»« existing dashboard</p></li><li><p><strong>\"Export dashboard\"</strong> â†’ Console â†’ Actions â†’ View/edit source</p></li><li><p><strong>Pattern</strong>: Automate dashboard = CloudFormation resource + exported JSON | Manual = Console/CLI scripts</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-resource-cloudwatch-dashboard.html\">AWS::CloudWatch::Dashboard CloudFormation resource</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://repost.aws/questions/QUzarTQVN5TgqAVeXR6_h6Bg/cloudwatch-dashboard-source-json\">Exporting CloudWatch dashboard JSON</a></p></li></ul>",
            "correctAnswer": [
                "<p>Export the existing CloudWatch dashboard as JSON. Update the CloudFormation template to define an AWS::CloudWatch::Dashboard resource. Include the exported JSON in the resourceâ€™s DashboardBody property.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a script by using the AWS CLI to run the aws cloudformation put-dashboard command with the name of the dashboard. Run the command each time a new CloudFormation stack is created.</p>",
                "<p>Export the existing CloudWatch dashboard as JSON. Update the CloudFormation template to define an AWS::CloudWatch::Dashboard resource. Include the exported JSON in the resourceâ€™s DashboardBody property.</p>",
                "<p>Update the CloudFormation template to define an AWS::CloudWatch::Dashboard resource. Use the Intrinsic Ref function to reference the ID of the existing CloudWatch dashboard.</p>",
                "<p>Update the CloudFormation template to define an AWS::CloudWatch::Dashboard resource. Specify the name of the existing dashboard in the DashboardName property.</p>"
            ],
            "answersPos": "[3,0,1,2]",
            "pos": 48
        },
        {
            "attemptAnswerId": 329320,
            "questionId": 6543,
            "questionText": "<p>A company is deploying a third-party unit testing solution that is delivered as an Amazon EC2 Amazon Machine Image (AMI). All system configuration data is stored in Amazon DynamoDB. The testing results are stored in Amazon S3.<br><br>A minimum of three EC2 instances are required to operate the product. The companyâ€™s testing team wants to use an additional three EC2 instances when the Spot Instance prices are at a certain threshold. A SysOps administrator must implement a highly available solution that provides this functionality.<br><br>Which solution will meet these requirements with the LEAST operational overhead?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Third-party testing solution cháº¡y trÃªn <strong>EC2 AMI</strong></p></li><li><p><strong>Minimum 3 instances required</strong> (core capacity)</p></li><li><p>Muá»‘n <strong>additional 3 Spot Instances</strong> khi Spot price á»Ÿ <strong>certain threshold (ngÆ°á»¡ng nháº¥t Ä‘á»‹nh)</strong></p></li><li><p>Requirements: <strong>highly available</strong> vá»›i <strong>LEAST operational overhead</strong></p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Define an Amazon EC2 Auto Scaling group by using a launch template. Use the provided AMI in the launch template. Configure three On-Demand Instances and three Spot Instances. Configure a maximum Spot Instance price in the launch template.</strong></p><ul><li><p><strong>Single Auto Scaling group</strong> vá»›i <strong>mixed instances policy</strong> = least operational overhead, dá»… manage nháº¥t</p></li><li><p><strong>Launch template</strong> (not launch configuration) lÃ  <strong>AWS recommended</strong>, support mixed instances (On-Demand + Spot)</p></li><li><p>Configure <strong>3 On-Demand as base capacity</strong> - always running Ä‘á»ƒ meet minimum requirement</p></li><li><p>Configure <strong>3 Spot as additional capacity</strong> - launch chá»‰ khi Spot price â‰¤ max price threshold</p></li><li><p><strong>Max Spot price</strong> trong launch template ensure Spot instances chá»‰ launch khi price acceptable</p></li><li><p><strong>Single ASG</strong> easier to manage scaling policies, monitoring, vÃ  configuration</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Define an Amazon EC2 Auto Scaling group by using a launch configuration. Use the provided AMI in the launch configuration. Configure three On-Demand Instances and three Spot Instances. Configure a maximum Spot Instance price in the launch configuration.</strong></p><ul><li><p><strong>Launch configuration is deprecated (lá»—i thá»i)</strong> - AWS recommends launch templates</p></li><li><p>Launch configuration cÃ³ <strong>fewer features</strong> vÃ  khÃ´ng Ä‘Æ°á»£c updated</p></li><li><p>Approach Ä‘Ãºng nhÆ°ng using outdated technology</p></li></ul><p></p><p>âŒ <strong>Define two Amazon EC2 Auto Scaling groups by using launch configurations. Use the provided AMI in the launch configurations. Configure three On-Demand Instances for one Auto Scaling group. Configure three Spot Instances for the other Auto Scaling group. Configure a maximum Spot Instance price in the launch configuration for the Auto Scaling group that has Spot Instances.</strong></p><ul><li><p><strong>Two separate Auto Scaling groups</strong> = <strong>higher operational overhead</strong></p></li><li><p>Pháº£i manage <strong>2 ASGs separately</strong> - policies, monitoring, configurations</p></li><li><p>Launch configuration deprecated</p></li><li><p>More complex than necessary</p></li></ul><p></p><p>âŒ <strong>Define two Amazon EC2 Auto Scaling groups by using launch templates. Use the provides AMI in the launch templates. Configure three On-Demand Instances for one Auto Scaling group. Configure three Spot Instances for the other Auto Scaling group. Configure a maximum Spot Instance price in the launch template for the Auto Scaling group that has Spot Instances.</strong></p><ul><li><p>Launch template Ä‘Ãºng</p></li><li><p>NHÆ¯NG <strong>two separate ASGs</strong> = unnecessary complexity</p></li><li><p><strong>NOT least operational overhead</strong> - pháº£i manage 2 ASGs</p></li><li><p>Single ASG vá»›i mixed instances Ä‘Æ¡n giáº£n hÆ¡n</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Least operational overhead\" + On-Demand + Spot</strong> â†’ <strong>Single ASG with mixed instances</strong></p></li><li><p><strong>\"Launch template vs launch configuration\"</strong> â†’ Always use <strong>launch template</strong> (recommended, not deprecated)</p></li><li><p><strong>\"Mixed instances policy\"</strong> â†’ Support On-Demand base + Spot additional capacity</p></li><li><p><strong>Pattern</strong>: Least overhead = Single ASG | More control = Separate ASGs | Modern = Launch template | Deprecated = Launch configuration</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html\">Auto Scaling groups with mixed instances</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/autoscaling/ec2/userguide/launch-templates.html\">Launch templates for Auto Scaling</a></p></li></ul>",
            "correctAnswer": [
                "<p>Define an Amazon EC2 Auto Scaling group by using a launch template. Use the provided AMI in the launch template. Configure three On-Demand Instances and three Spot instances. Configure a maximum Spot Instance price in the launch template.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Define an Amazon EC2 Auto Scaling group by using a launch configuration. Use the provided AMI in the launch configuration. Configure three On-Demand Instances and three Spot Instances. Configure a maximum Spot Instance price in the launch configuration.</p>",
                "<p>Define an Amazon EC2 Auto Scaling group by using a launch template. Use the provided AMI in the launch template. Configure three On-Demand Instances and three Spot instances. Configure a maximum Spot Instance price in the launch template.</p>",
                "<p>Define two Amazon EC2 Auto Scaling groups by using launch configurations. Use the provided AMI in the launch configurations. Configure three On-Demand Instances for one Auto Scaling group. Configure three Spot Instances for the other Auto Scaling group. Configure a maximum Spot Instance price in the launch configuration for the Auto Scaling group that has Spot Instances.</p>",
                "<p>Define two Amazon EC2 Auto Scaling groups by using launch templates. Use the provides AMI in the launch templates. Configure three On-Demand Instances for one Auto Scaling group. Configure three Spot Instances for the other Auto Scaling group. Configure a maximum Spot Instance price in the launch template for the Auto Scaling group that has Spot Instances.</p>"
            ],
            "answersPos": "[3,2,1,0]",
            "pos": 49
        },
        {
            "attemptAnswerId": 329321,
            "questionId": 6544,
            "questionText": "<p>A companyâ€™s application currently uses an IAM role that allows all access to all AWS services. A SysOps administrator must ensure that the companyâ€™s IAM policies allow only the permissions that the application requires.<br><br>How can the SysOps administrator create a policy to meet this requirement?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application Ä‘ang dÃ¹ng <strong>IAM role allows ALL access to ALL AWS services</strong> (overly permissive)</p></li><li><p>Cáº§n ensure IAM policies <strong>only allow permissions application requires</strong> (least privilege)</p></li><li><p>YÃªu cáº§u: táº¡o policy based on actual usage</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Turn on AWS CloudTrail. Generate a policy by using AWS Identity and Access Management Access Analyzer.</strong></p><ul><li><p><strong>CloudTraail logs táº¥t cáº£ API calls</strong> vÃ  actions performed by IAM role</p></li><li><p><strong>IAM Access Analyzer</strong> cÃ³ feature <strong>policy generation based on CloudTrail logs</strong></p></li><li><p>Access Analyzer <strong>analyze actual usage</strong> trong CloudTrail (past 90 days) Ä‘á»ƒ identify permissions thá»±c sá»± Ä‘Æ°á»£c sá»­ dá»¥ng</p></li><li><p><strong>Generate policy</strong> chá»‰ include permissions application Ä‘Ã£ sá»­ dá»¥ng - follow <strong>least privilege principle</strong></p></li><li><p>Process: Enable CloudTrail â†’ Access Analyzer analyze logs â†’ Generate policy â†’ Review vÃ  apply</p></li><li><p>ÄÃ¢y lÃ  <strong>AWS recommended approach</strong> cho right-sizing IAM permissions</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Turn on AWS CloudTrail. Generate a policy by using AWS Security Hub.</strong></p><ul><li><p>CloudTrail Ä‘Ãºng Ä‘á»ƒ log activity</p></li><li><p><strong>Security Hub KHÃ”NG cÃ³ policy generation feature</strong></p></li><li><p>Security Hub lÃ  security posture management service, detect compliance violations</p></li><li><p>KhÃ´ng pháº£i tool cho generating least privilege policies</p></li></ul><p></p><p>âŒ <strong>Turn on Amazon EventBridge (Amazon CloudWatch Events). Generate a policy by using AWS Identity and Access Management Access Analyzer.</strong></p><ul><li><p><strong>EventBridge khÃ´ng track API usage</strong> cho policy generation</p></li><li><p><strong>CloudTrail lÃ  required data source</strong>, khÃ´ng pháº£i EventBridge</p></li><li><p>Access Analyzer policy generation requires CloudTrail logs</p></li><li><p>EventBridge dÃ¹ng cho event-driven automation, khÃ´ng pháº£i usage tracking</p></li></ul><p></p><p>âŒ <strong>Use the AWS CLI to run the get-generated-policy command in AWS Identity and Access Management Access Analyzer.</strong></p><ul><li><p>Command <code>get-generated-policy</code> <strong>requires CloudTrail enabled</strong> vÃ  data collected trÆ°á»›c</p></li><li><p><strong>Cannot generate policy without CloudTrail logs</strong></p></li><li><p>Thiáº¿u prerequisite step (enable CloudTrail)</p></li><li><p>Incomplete solution</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"Right-size IAM permissions\"</strong> â†’ <strong>IAM Access Analyzer policy generation</strong></p></li><li><p><strong>\"Policy generation requires\"</strong> â†’ <strong>CloudTrail logs</strong> (API activity data)</p></li><li><p><strong>\"Security Hub\"</strong> â†’ Security posture, khÃ´ng pháº£i policy generation</p></li><li><p><strong>Pattern</strong>: Least privilege = CloudTrail + Access Analyzer | Security compliance = Security Hub | Event automation = EventBridge</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/access-analyzer-policy-generation.html\">IAM Access Analyzer policy generation</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_reduce-permissions-edit-policy.html\">Generate policies based on CloudTrail logs</a></p></li></ul>",
            "correctAnswer": [
                "<p>Turn on AWS CloudTrail. Generate a policy by using AWS Identity and Access Management Access Analyzer.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Turn on AWS CloudTrail. Generate a policy by using AWS Security Hub.</p>",
                "<p>Turn on Amazon EventBridge (Amazon CloudWatch Events). Generate a policy by using AWS Identity and Access Management Access Analyzer.</p>",
                "<p>Use the AWS CLI to run the get-generated-policy command in AWS Identity and Access Management Access Analyzer.</p>",
                "<p>Turn on AWS CloudTrail. Generate a policy by using AWS Identity and Access Management Access Analyzer.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 50
        },
        {
            "attemptAnswerId": 329322,
            "questionId": 6545,
            "questionText": "<p>A company wants to collect data from an application to use for analytics. For the first 90 days, the data will be infrequently accessed but must remain highly available. During this time, the companyâ€™s analytics team requires access to the data in milliseconds. However, after 90 days, the company must retain the data for the long term at a lower cost. The retrieval time after 90 days must be less than 5 hours.<br><br>Which solution will meet these requirements MOST cost-effectively?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><p><strong>First 90 days:</strong></p><ul><li><p>Data <strong>infrequently accessed</strong></p></li><li><p>Must remain <strong>highly available</strong></p></li><li><p>Access trong <strong>milliseconds</strong></p></li></ul><p></p><p><strong>After 90 days:</strong></p><ul><li><p>Long-term retention, <strong>lower cost</strong></p></li><li><p><strong>Retrieval time &lt; 5 hours</strong></p></li></ul><p>YÃªu cáº§u: <strong>MOST cost-effective</strong> solution</p><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Store the data in S3 Standard-Infrequent Access (S3 Standard-IA) for the first 90 days. Set up an S3 Lifecycle rule to move the data to S3 Glacier Flexible Retrieval after 90 days.</strong></p><ul><li><p><strong>S3 Standard-IA</strong> meets first 90 days requirements:</p><ul><li><p><strong>Infrequent access</strong> use case - cost-effective cho data Ã­t access</p></li><li><p><strong>Highly available</strong> - stored across multiple AZs</p></li><li><p><strong>Millisecond latency</strong> - instant retrieval</p></li></ul></li><li><p><strong>S3 Glacier Flexible Retrieval</strong> meets after 90 days requirements:</p><ul><li><p><strong>Low cost</strong> cho long-term archival</p></li><li><p><strong>Retrieval options</strong>: Expedited (1-5 min), Standard (3-5 hours), Bulk (5-12 hours)</p></li><li><p>Standard retrieval <strong>&lt; 5 hours</strong> meets requirement</p></li></ul></li><li><p><strong>Most cost-effective</strong> vÃ¬ dÃ¹ng IA thay vÃ¬ Standard cho first 90 days (data infrequently accessed)</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Store the data in S3 One Zone-Infrequent Access (S3 One Zone-IA) for the first 90 days. Set up an S3 Lifecycle rule to move the data to S3 Glacier Deep Archive after 90 days.</strong></p><ul><li><p><strong>One Zone-IA stores data trong SINGLE AZ</strong> - <strong>NOT highly available</strong></p></li><li><p>Vi pháº¡m requirement \"must remain highly available\"</p></li><li><p><strong>Glacier Deep Archive retrieval = 12-48 hours</strong> - vi pháº¡m \"&lt;5 hours\" requirement</p></li></ul><p></p><p>âŒ <strong>Store the data in S3 Standard for the first 90 days. Set up an S3 Lifecycle rule to move the data to S3 Glacier Flexible Retrieval after 90 days.</strong></p><ul><li><p>S3 Standard meets requirements nhÆ°ng <strong>NOT most cost-effective</strong></p></li><li><p><strong>Standard more expensive</strong> than Standard-IA cho infrequently accessed data</p></li><li><p>Waste money khi data infrequently accessed</p></li></ul><p></p><p>âŒ <strong>Store the data in S3 Standard for the first 90 days. Set up an S3 Lifecycle rule to move the data to S3 Glacier Deep Archive after 90 days.</strong></p><ul><li><p>S3 Standard not cost-effective</p></li><li><p><strong>Glacier Deep Archive retrieval = 12-48 hours</strong> - vi pháº¡m \"&lt;5 hours\" requirement</p></li></ul><hr><p></p><p>ğŸ”‘ Tips and tricks:</p><ul><li><p><strong>\"Highly available\"</strong> â†’ <strong>Multi-AZ storage</strong> (Standard, Standard-IA), NOT One Zone-IA</p></li><li><p><strong>\"Infrequently accessed\"</strong> â†’ <strong>IA storage classes</strong> cost-effective hÆ¡n Standard</p></li><li><p><strong>\"Retrieval &lt; 5 hours\"</strong> â†’ <strong>Glacier Flexible Retrieval</strong> (Standard: 3-5h) | Deep Archive = 12-48h</p></li><li><p><strong>Pattern</strong>: Millisecond access = S3 Standard/IA | Minutes-hours retrieval = Glacier Flexible | 12+ hours = Deep Archive</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://aws.amazon.com/s3/storage-classes/\">Amazon S3 storage classes comparison</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.html\">S3 Glacier retrieval options</a></p></li></ul>",
            "correctAnswer": [
                "<p>Store the data in S3 Standard-Infrequent Access (S3 Standard-IA) for the first 90 days. Set up an S3 Lifecycle rule to move the data to S3 Glacier Flexible Retrieval after 90 days.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Store the data in S3 Standard-Infrequent Access (S3 Standard-IA) for the first 90 days. Set up an S3 Lifecycle rule to move the data to S3 Glacier Flexible Retrieval after 90 days.</p>",
                "<p>Store the data in S3 One Zone-Infrequent Access (S3 One Zone-IA) for the first 90 days. Set up an S3 Lifecycle rule to move the data to S3 Glacier Deep Archive after 90 days.</p>",
                "<p>Store the data in S3 Standard for the first 90 days. Set up an S3 Lifecycle rule to move the data to S3 Glacier Flexible Retrieval after 90 days.</p>",
                "<p>Store the data in S3 Standard for the first 90 days. Set up an S3 Lifecycle rule to move the data to S3 Glacier Deep Archive after 90 days.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 51
        },
        {
            "attemptAnswerId": 329323,
            "questionId": 6546,
            "questionText": "<p>A SysOps administrator creates an Amazon Elastic Kubernetes Service (Amazon EKS) cluster that uses AWS Fargate. The cluster is deployed successfully. The SysOps administrator needs to manage the cluster by using the kubectl command line tool.<br><br>Which of the following must be configured on the SysOps administratorâ€™s machine so that kubectl can communicate with the cluster API server?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>ÄÃ£ create <strong>Amazon EKS cluster</strong> vá»›i <strong>AWS Fargate</strong></p></li><li><p>Cluster deployed successfully</p></li><li><p>SysOps administrator cáº§n <strong>manage cluster báº±ng kubectl</strong></p></li><li><p>YÃªu cáº§u: configure gÃ¬ trÃªn admin's machine Ä‘á»ƒ kubectl communicate vá»›i cluster API server</p></li></ul><hr><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>The kubeconfig file</strong></p><ul><li><p><strong>kubeconfig file</strong> chá»©a <strong>configuration information</strong> kubectl cáº§n Ä‘á»ƒ connect to Kubernetes cluster</p></li><li><p>File includes: <strong>cluster endpoint URL</strong>, <strong>authentication credentials</strong>, <strong>certificate authority data</strong>, <strong>context</strong></p></li><li><p>AWS CLI command generate kubeconfig cho EKS: <code>aws eks update-kubeconfig --region REGION --name CLUSTER_NAME</code></p></li><li><p>Command tá»± Ä‘á»™ng <strong>update ~/.kube/config</strong> file vá»›i EKS cluster information</p></li><li><p><strong>Required</strong> Ä‘á»ƒ kubectl biáº¿t cluster nÃ o connect, credentials nÃ o dÃ¹ng</p></li><li><p>ÄÃ¢y lÃ  <strong>standard Kubernetes practice</strong> cho cluster access configuration</p></li></ul><hr><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>The kube-proxy Amazon EKS add-on</strong></p><ul><li><p><strong>kube-proxy</strong> lÃ  <strong>network proxy</strong> cháº¡y <strong>on worker nodes</strong>, maintain network rules</p></li><li><p>Enable pod-to-pod communication vÃ  service networking</p></li><li><p><strong>KHÃ”NG liÃªn quan</strong> Ä‘áº¿n kubectl client configuration</p></li><li><p>Runs inside cluster, not on admin's machine</p></li></ul><p></p><p>âŒ <strong>The Fargate profile</strong></p><ul><li><p><strong>Fargate profile</strong> define <strong>which pods run on Fargate</strong> (selector based on namespace/labels)</p></li><li><p>Configure <strong>workload placement</strong>, khÃ´ng pháº£i client access</p></li><li><p>KhÃ´ng liÃªn quan Ä‘áº¿n kubectl communication vá»›i API server</p></li></ul><p></p><p>âŒ <strong>The eks-connector.yaml file</strong></p><ul><li><p><strong>EKS Connector</strong> dÃ¹ng Ä‘á»ƒ <strong>connect external/on-premises Kubernetes clusters</strong> to EKS console</p></li><li><p><strong>KHÃ”NG dÃ¹ng cho EKS-managed clusters</strong></p></li><li><p>Sai use case hoÃ n toÃ n</p></li></ul><hr><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>\"kubectl communicate with EKS\"</strong> â†’ <strong>kubeconfig file</strong></p></li><li><p><strong>\"Generate kubeconfig\"</strong> â†’ <code>aws eks update-kubeconfig</code> command</p></li><li><p><strong>\"kube-proxy\"</strong> â†’ Node component, khÃ´ng pháº£i client config</p></li><li><p><strong>Pattern</strong>: kubectl access = kubeconfig file | Workload placement = Fargate profile | External cluster = EKS Connector</p></li></ul><hr><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html\">Configure kubectl for Amazon EKS</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/eks/latest/userguide/create-kubeconfig.html\">Creating kubeconfig for EKS cluster</a></p></li></ul>",
            "correctAnswer": [
                "<p>The kubeconfig file</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>The kubeconfig file</p>",
                "<p>The kube-proxy Amazon EKS add-on</p>",
                "<p>The Fargate profile</p>",
                "<p>The eks-connector.yaml file</p>"
            ],
            "answersPos": "[2,1,3,0]",
            "pos": 52
        },
        {
            "attemptAnswerId": 329324,
            "questionId": 6547,
            "questionText": "<p>A company is expanding globally and needs to back up data on Amazon Elastic Block Store (Amazon EBS) volumes to a different AWS Region. Most of the EBS volumes that store the data are encrypted, but some of the EBS volumes are unencrypted. The company needs the backup data from all the EBS volumes to be encrypted.<br><br>Which solution will meet these requirements with the LEAST management overhead?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company expanding globally cáº§n backup <strong>EBS volumes</strong> to different AWS Region</p></li><li><p><strong>Háº§u háº¿t volumes Ä‘Ã£ encrypted</strong>, má»™t sá»‘ <strong>unencrypted</strong></p></li><li><p>YÃªu cáº§u: <strong>ALL backup data pháº£i encrypted</strong></p></li><li><p>Cáº§n solution vá»›i <strong>LEAST management overhead</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Configure a lifecycle policy in Amazon Data Lifecycle Manager (Amazon DLM) to create the EBS volume snapshots with cross-Region backups enabled. Encrypt the snapshot copies by using AWS Key Management Service (AWS KMS).</strong></p><ul><li><p><strong>Amazon DLM</strong> lÃ  <strong>fully managed service</strong> cho automated snapshot lifecycle management - <strong>least overhead</strong></p></li><li><p>DLM natively support <strong>cross-Region snapshot copy</strong></p></li><li><p>Khi copy snapshot cross-Region, DLM <strong>tá»± Ä‘á»™ng encrypt snapshot copies</strong> báº±ng <strong>KMS key</strong> (cÃ³ thá»ƒ specify key)</p></li><li><p>DLM automatically handle <strong>cáº£ encrypted vÃ  unencrypted source volumes</strong> - encrypt <strong>táº¥t cáº£ snapshot copies</strong></p></li><li><p><strong>Automated scheduling</strong>, retention policies, vÃ  monitoring built-in</p></li><li><p><strong>No custom code</strong>, <strong>no manual intervention</strong> needed</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a point-in-time snapshot of the EBS volumes. When the snapshot status is COMPLETED, copy the snapshots to another Region and set the Encrypted parameter to False.</strong></p><ul><li><p>Set <strong>Encrypted=False</strong> vi pháº¡m requirement \"<strong>ALL backup data must be encrypted</strong>\"</p></li><li><p><strong>Manual process</strong> - high overhead, khÃ´ng automated</p></li><li><p>Sai hoÃ n toÃ n yÃªu cáº§u</p></li></ul><p></p><p>âŒ <strong>Create a point-in-time snapshot of the EBS volumes. Copy the snapshots to an Amazon S3 bucket that uses server-side encryption. Turn on S3 Cross-Region Replication on the S3 bucket.</strong></p><ul><li><p><strong>KHÃ”NG thá»ƒ copy EBS snapshots directly to S3 bucket</strong></p></li><li><p>EBS snapshots stored trong <strong>AWS-managed S3 infrastructure</strong> (khÃ´ng access trá»±c tiáº¿p)</p></li><li><p><strong>Technically incorrect</strong> approach</p></li></ul><p></p><p>âŒ <strong>Schedule an AWS Lambda function with the Python runtime. Configure the Lambda function to create the EBS volume snapshots, encrypt the unencrypted snapshots, and copy the snapshots to another Region.</strong></p><ul><li><p><strong>HIGH management overhead</strong> - pháº£i write vÃ  maintain custom Python code</p></li><li><p>Need handle <strong>error handling</strong>, <strong>retry logic</strong>, monitoring, logging</p></li><li><p><strong>Unnecessary complexity</strong> khi DLM lÃ  managed service available</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p>\"Automated EBS snapshot management\" â†’ <strong>Amazon Data Lifecycle Manager (DLM)</strong></p></li><li><p>\"Least overhead + backup\" â†’ <strong>Managed service (DLM)</strong>, NOT custom Lambda</p></li><li><p>\"Cross-Region snapshot copy\" â†’ DLM natively support + <strong>auto-encrypt</strong></p></li><li><p><strong>Pattern:</strong> Snapshot automation = DLM | Custom logic only = Lambda | S3 replication â‰  EBS snapshots</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/snapshot-lifecycle.html\">Amazon Data Lifecycle Manager for EBS snapshots</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/ebs-copy-snapshot.html\">Copying encrypted snapshots across Regions</a></p></li></ul>",
            "correctAnswer": [
                "<p>Configure a lifecycle policy in Amazon Data Lifecycle Manager (Amazon DLM) to create the EBS volume snapshots with cross-Region backups enabled. Encrypt the snapshot copies by using AWS Key Management Service (AWS KMS).</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure a lifecycle policy in Amazon Data Lifecycle Manager (Amazon DLM) to create the EBS volume snapshots with cross-Region backups enabled. Encrypt the snapshot copies by using AWS Key Management Service (AWS KMS).</p>",
                "<p>Create a point-in-time snapshot of the EBS volumes. When the snapshot status is COMPLETED, copy the snapshots to another Region and set the Encrypted parameter to False.</p>",
                "<p>Create a point-in-time snapshot of the EBS volumes. Copy the snapshots to an Amazon S3 bucket that uses server-side encryption. Turn on S3 Cross-Region Replication on the S3 bucket.</p>",
                "<p>Schedule an AWS Lambda function with the Python runtime. Configure the Lambda function to create the EBS volume snapshots, encrypt the unencrypted snapshots, and copy the snapshots to another Region.</p>"
            ],
            "answersPos": "[2,3,0,1]",
            "pos": 53
        },
        {
            "attemptAnswerId": 329325,
            "questionId": 6548,
            "questionText": "<p>A company is attempting to manage its costs in the AWS Cloud. A SysOps administrator needs specific company-defined tags that are assigned to resources to appear on the billing report.<br><br>What should the SysOps administrator do to meet this requirement?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company muá»‘n manage costs trong AWS Cloud</p></li><li><p>Cáº§n <strong>company-defined tags</strong> Ä‘Æ°á»£c assign cho resources</p></li><li><p>YÃªu cáº§u: tags pháº£i <strong>appear on billing report</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Activate the tags as user-defined cost allocation tags.</strong></p><ul><li><p><strong>Company-defined tags</strong> = <strong>user-defined cost allocation tags</strong> (tags do company tá»± táº¡o)</p></li><li><p>Sau khi táº¡o tags vÃ  assign cho resources, pháº£i <strong>activate tags</strong> trong <strong>Billing and Cost Management console</strong></p></li><li><p>Activate process enable tags Ä‘á»ƒ <strong>appear in Cost and Usage Reports</strong> vÃ  <strong>Cost Explorer</strong></p></li><li><p>Sau khi activate, cÃ³ thá»ƒ máº¥t <strong>up to 24 hours</strong> Ä‘á»ƒ tags xuáº¥t hiá»‡n trong billing reports</p></li><li><p>Cho phÃ©p <strong>track costs by tag</strong>, filter vÃ  group costs theo custom tags</p></li></ul><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765416724706-18ivl6af-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"287.3333333333333\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765416739228-4plxupp0-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"398.4583333333333\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Activate the tags as AWS generated cost allocation tags.</strong></p><ul><li><p><strong>AWS-generated tags</strong> lÃ  tags AWS tá»± Ä‘á»™ng táº¡o (nhÆ° <strong>aws:createdBy</strong>, <strong>aws:cloudformation:stack-name</strong>)</p></li><li><p>Äá» bÃ i yÃªu cáº§u <strong>company-defined tags</strong>, KHÃ”NG pháº£i AWS-generated tags</p></li><li><p>Sai loáº¡i tag</p></li></ul><p></p><p>âŒ <strong>Create a new cost category. Select the account billing dimension.</strong></p><ul><li><p><strong>Cost categories</strong> dÃ¹ng Ä‘á»ƒ <strong>group costs based on rules</strong>, khÃ´ng pháº£i activate tags</p></li><li><p>KhÃ´ng giáº£i quyáº¿t váº¥n Ä‘á» tags appear on billing report</p></li><li><p>Sai approach hoÃ n toÃ n</p></li></ul><p></p><p>âŒ <strong>Create a new AWS Cost and Usage Report. Include the resource IDs.</strong></p><ul><li><p>Chá»‰ include <strong>resource IDs</strong> KHÃ”NG lÃ m tags xuáº¥t hiá»‡n</p></li><li><p>Thiáº¿u bÆ°á»›c <strong>activate user-defined tags</strong></p></li><li><p>Cost and Usage Report sáº½ show tags SAU KHI tags Ä‘Ã£ Ä‘Æ°á»£c activated</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p>\"Company-defined tags on billing\" â†’ <strong>Activate user-defined cost allocation tags</strong></p></li><li><p>\"AWS-generated tags\" â†’ Tags AWS tá»± táº¡o (aws:createdBy, aws:cloudformation:*)</p></li><li><p>\"User-defined tags\" â†’ Tags company tá»± táº¡o (Environment, CostCenter, Project...)</p></li><li><p><strong>Pattern:</strong> Custom tags on billing = Activate user-defined tags | AWS tags = AWS-generated tags | Group costs = Cost categories</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/custom-tags.html\">User-defined cost allocation tags</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/activating-tags.html\">Activating user-defined tags for cost allocation</a></p></li></ul>",
            "correctAnswer": [
                "<p>Activate the tags as user-defined cost allocation tags.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Activate the tags as AWS generated cost allocation tags.</p>",
                "<p>Activate the tags as user-defined cost allocation tags.</p>",
                "<p>Create a new cost category. Select the account billing dimension.</p>",
                "<p>Create a new AWS Cost and Usage Report. Include the resource IDs.</p>"
            ],
            "answersPos": "[0,3,2,1]",
            "pos": 54
        },
        {
            "attemptAnswerId": 329326,
            "questionId": 6549,
            "questionText": "<p>A company hosts a web application on an Amazon EC2 instance. The web server logs are published to Amazon CloudWatch Logs. The log events have the same structure and include the HTTP response codes that are associated with the user requests. The company needs to monitor the number of times that the web server returns an HTTP 404 response.<br><br>What is the MOST operationally efficient solution that meets these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Web application cháº¡y trÃªn <strong>EC2 instance</strong></p></li><li><p><strong>Web server logs</strong> published to <strong>CloudWatch Logs</strong></p></li><li><p>Log events cÃ³ <strong>same structure</strong>, include <strong>HTTP response codes</strong></p></li><li><p>YÃªu cáº§u: <strong>monitor sá»‘ láº§n</strong> web server returns <strong>HTTP 404 response</strong></p></li><li><p>Cáº§n <strong>MOST operationally efficient</strong> solution</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create a CloudWatch Logs metric filter that counts the number of times that the web server returns an HTTP 404 response.</strong></p><ul><li><p><strong>CloudWatch Logs metric filter</strong> lÃ  AWS recommended approach Ä‘á»ƒ <strong>extract metrics tá»« log data</strong></p></li><li><p>Metric filter <strong>tá»± Ä‘á»™ng scan logs</strong> vÃ  count sá»± kiá»‡n cá»§a specific pattern (HTTP 404)</p></li><li><p>Táº¡o <strong>CloudWatch custom metric</strong> cÃ³ thá»ƒ dÃ¹ng cho <strong>alarms</strong>, <strong>dashboards</strong>, monitoring</p></li><li><p><strong>Fully managed</strong>, <strong>real-time monitoring</strong>, <strong>no custom code</strong> needed</p></li><li><p>Set up once, runs continuously - <strong>most operationally efficient</strong></p></li><li><p>CÃ³ thá»ƒ set CloudWatch alarm khi 404 count vÆ°á»£t threshold</p></li></ul><p></p><p><em>CloudWatch Logs metric filter</em></p><p><span class=\"node-imageComponent\"><span class=\"image-component\"><img class=\"resizable-image\" src=\"https://static.cloudexam.pro/courses/10/1765416988807-2ty9ly9n-image.png\" alt=\"\" title=\"\" width=\"800\" height=\"368.375\" style=\"max-width: 800px\" data-keep-ratio=\"true\"></span></span></p><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a CloudWatch Logs subscription filter that counts the number of times that the web server returns an HTTP 404 response.</strong></p><ul><li><p><strong>Subscription filter</strong> dÃ¹ng Ä‘á»ƒ <strong>stream logs to other services</strong> (Lambda, Kinesis, Firehose)</p></li><li><p>KHÃ”NG dÃ¹ng Ä‘á»ƒ count metrics hay monitoring</p></li><li><p>Sai use case hoÃ n toÃ n</p></li></ul><p></p><p>âŒ <strong>Create an AWS Lambda function that runs a CloudWatch Logs Insights query that counts the number of 404 codes in the log events during the past hour.</strong></p><ul><li><p><strong>CloudWatch Logs Insights</strong> lÃ  <strong>query tool</strong>, khÃ´ng pháº£i real-time monitoring solution</p></li><li><p>Lambda adds <strong>operational overhead</strong> - need schedule, manage code, handle errors</p></li><li><p>Query \"past hour\" - <strong>not continuous monitoring</strong></p></li></ul><p></p><p>âŒ <strong>Create a script that runs a CloudWatch Logs Insights query that counts the number of 404 codes in the log events during the past hour.</strong></p><ul><li><p>Similar to Lambda nhÆ°ng <strong>worse</strong> - need manually run hoáº·c schedule script</p></li><li><p><strong>High operational overhead</strong> - maintain script, scheduling, execution environment</p></li><li><p>Not automated, not continuous monitoring</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p>\"Extract metrics from CloudWatch Logs\" â†’ <strong>CloudWatch Logs metric filter</strong></p></li><li><p>\"Stream logs to other services\" â†’ <strong>Subscription filter</strong></p></li><li><p>\"Ad-hoc log analysis/query\" â†’ <strong>CloudWatch Logs Insights</strong></p></li><li><p><strong>Pattern:</strong> Count/monitor from logs = Metric filter | Stream logs = Subscription filter | Query logs = Logs Insights</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/MonitoringPolicyExamples.html\">Creating CloudWatch Logs metric filters</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/MonitoringLogData.html\">Using metric filters to extract metrics from logs</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a CloudWatch Logs metric filter that counts the number of times that the web server returns an HTTP 404 response.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a CloudWatch Logs metric filter that counts the number of times that the web server returns an HTTP 404 response.</p>",
                "<p>Create a CloudWatch Logs subscription filter that counts the number of times that the web server returns an HTTP 404 response.</p>",
                "<p>Create an AWS Lambda function that runs a CloudWatch Logs Insights query that counts the number of 404 codes in the log events during the past hour.</p>",
                "<p>Create a script that runs a CloudWatch Logs Insights query that counts the number of 404 codes in the log events during the past hour.</p>"
            ],
            "answersPos": "[0,3,2,1]",
            "pos": 55
        },
        {
            "attemptAnswerId": 329327,
            "questionId": 6550,
            "questionText": "<p>A companyâ€™s AWS Lambda function is experiencing performance issues. The Lambda function performs many CPU-intensive operations. The Lambda function is not running fast enough and is creating bottlenecks in the system.<br><br>What should a SysOps administrator do to resolve this issue?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p><strong>Lambda function</strong> experiencing <strong>performance issues</strong></p></li><li><p>Lambda performs <strong>many CPU-intensive operations</strong></p></li><li><p><strong>Not running fast enough</strong>, creating <strong>bottlenecks</strong> in system</p></li><li><p>YÃªu cáº§u: resolve performance issue</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Increase the amount of memory for the Lambda function.</strong></p><ul><li><p><strong>Lambda's CPU power scales tá»· lá»‡ vá»›i memory allocation</strong></p></li><li><p>AWS <strong>KHÃ”NG cho configure CPU directly</strong> - chá»‰ cÃ³ thá»ƒ Ä‘iá»u chá»‰nh memory</p></li><li><p>Khi <strong>increase memory</strong> â†’ Lambda <strong>automatically allocates more CPU power</strong></p></li><li><p>Memory range: <strong>128 MB to 10,240 MB</strong> (10 GB)</p></li><li><p>At <strong>1,769 MB memory</strong> = equivalent to <strong>1 vCPU</strong> (full vCPU core)</p></li><li><p>ÄÃ¢y lÃ  AWS recommended approach Ä‘á»ƒ improve Lambda performance cho CPU-intensive workloads</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>In the CPU launch options for the Lambda function, activate hyperthreading.</strong></p><ul><li><p>Lambda <strong>KHÃ”NG cÃ³ CPU launch options</strong> Ä‘á»ƒ configure</p></li><li><p>AWS <strong>fully manages underlying infrastructure</strong> - users cannot configure CPU settings</p></li><li><p>Hyperthreading activation khÃ´ng available cho Lambda</p></li></ul><p></p><p>âŒ <strong>Turn off the AWS managed encryption.</strong></p><ul><li><p>Encryption <strong>khÃ´ng impact CPU-intensive operations</strong> performance</p></li><li><p>Lambda encryption chá»‰ for <strong>data at rest/in transit security</strong></p></li><li><p>Turning off encryption khÃ´ng giáº£i quyáº¿t CPU bottleneck</p></li></ul><p></p><p>âŒ <strong>Load the required code into a custom layer.</strong></p><ul><li><p><strong>Lambda layers</strong> dÃ¹ng Ä‘á»ƒ <strong>share code, libraries, dependencies</strong> across functions</p></li><li><p>KHÃ”NG improve <strong>CPU performance</strong></p></li><li><p>Chá»‰ giÃºp reduce deployment package size, code reuse</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p>\"Lambda CPU performance slow\" â†’ <strong>Increase memory</strong> (CPU scales with memory)</p></li><li><p>\"Lambda cannot configure CPU directly\" â†’ Only <strong>memory</strong> adjustable</p></li><li><p>\"1,769 MB memory\" = <strong>1 full vCPU</strong></p></li><li><p><strong>Pattern:</strong> Lambda CPU issue = Increase memory | Share code = Lambda layers | Security = Encryption</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-memory.html\">Configuring Lambda function memory</a></p></li></ul>",
            "correctAnswer": [
                "<p>Increase the amount of memory for the Lambda function.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>In the CPU launch options for the Lambda function, activate hyperthreading.</p>",
                "<p>Turn off the AWS managed encryption.</p>",
                "<p>Increase the amount of memory for the Lambda function.</p>",
                "<p>Load the required code into a custom layer.</p>"
            ],
            "answersPos": "[0,1,2,3]",
            "pos": 56
        },
        {
            "attemptAnswerId": 329328,
            "questionId": 6551,
            "questionText": "<p>A company needs to archive all audit logs for 10 years. The company must protect the logs from any future edits.<br><br>Which solution will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company cáº§n <strong>archive audit logs</strong> for <strong>10 years</strong></p></li><li><p>YÃªu cáº§u: <strong>protect logs from ANY future edits</strong> (immutability)</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Store the data in an Amazon S3 Glacier vault. Configure a vault lock policy for write-once, read-many (WORM) access.</strong></p><ul><li><p><strong>S3 Glacier</strong> lÃ  <strong>long-term archival storage</strong> - cost-effective cho 10 years retention</p></li><li><p><strong>Glacier Vault Lock</strong> enforce <strong>WORM (Write-Once-Read-Many)</strong> compliance</p></li><li><p>Vault lock policy <strong>CANNOT be changed or deleted</strong> sau khi locked - <strong>báº¥t biáº¿n vÄ©nh viá»…n</strong></p></li><li><p>Prevent <strong>anyone</strong> (including root user) from <strong>editing or deleting</strong> archived data</p></li><li><p>AWS recommended solution cho <strong>regulatory compliance</strong> vÃ  audit log retention</p></li><li><p>Meet both requirements: long-term archival + protection from edits</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. Configure AWS Key Management Service (AWS KMS) encryption.</strong></p><ul><li><p><strong>EBS</strong> KHÃ”NG pháº£i archival storage - dÃ¹ng cho <strong>block storage attached to EC2</strong></p></li><li><p><strong>KMS encryption</strong> chá»‰ <strong>encrypt data</strong>, KHÃ”NG prevent edits/deletes</p></li><li><p>Not cost-effective cho 10-year retention</p></li></ul><p></p><p>âŒ <strong>Store the data in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Configure server-side encryption.</strong></p><ul><li><p><strong>S3 Standard-IA</strong> KHÃ”NG pháº£i archival class - <strong>expensive</strong> cho 10 years</p></li><li><p><strong>Server-side encryption</strong> chá»‰ encrypt, KHÃ”NG provide immutability</p></li><li><p>Data váº«n cÃ³ thá»ƒ edited/deleted</p></li></ul><p></p><p>âŒ <strong>Store the data in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Configure multi-factor authentication (MFA).</strong></p><ul><li><p>S3 Standard-IA not cost-effective cho long-term archival</p></li><li><p><strong>MFA Delete</strong> chá»‰ protect <strong>delete operations</strong>, KHÃ”NG prevent edits</p></li><li><p>KHÃ”NG enforce WORM compliance</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p>\"Archive + protect from edits\" â†’ <strong>S3 Glacier Vault Lock</strong> (WORM)</p></li><li><p>\"Immutability/compliance\" â†’ <strong>Vault Lock</strong> hoáº·c <strong>S3 Object Lock</strong></p></li><li><p>\"Encryption only\" â†’ KHÃ”NG prevent edits, chá»‰ encrypt data</p></li><li><p><strong>Pattern:</strong> Long-term archive + immutability = Glacier Vault Lock | Encryption = KMS/SSE | Access control = MFA</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/solutions/latest/data-transfer-from-amazon-s3-glacier-vaults-to-amazon-s3/amazon-s3-glacier-vault-lock-policy-considerations.html\">S3 Glacier Vault Lock for compliance</a></p></li></ul>",
            "correctAnswer": [
                "<p>Store the data in an Amazon S3 Glacier vault. Configure a vault lock policy for write-once, read-many (WORM) access.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. Configure AWS Key Management Service (AWS KMS) encryption.</p>",
                "<p>Store the data in an Amazon S3 Glacier vault. Configure a vault lock policy for write-once, read-many (WORM) access.</p>",
                "<p>Store the data in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Configure server-side encryption.</p>",
                "<p>Store the data in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Configure multi-factor authentication (MFA).</p>"
            ],
            "answersPos": "[2,3,1,0]",
            "pos": 57
        },
        {
            "attemptAnswerId": 329329,
            "questionId": 6552,
            "questionText": "<p>A SysOps administrator needs to track the costs of data transfer between AWS Regions. The SysOps administrator must implement a solution to send alerts to an email distribution list when transfer costs reach 75% of a specific threshold.<br><br>What should the SysOps administrator do to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>SysOps administrator cáº§n <strong>track costs</strong> of <strong>data transfer between AWS Regions</strong></p></li><li><p>YÃªu cáº§u: send <strong>alerts to email distribution list</strong> when transfer costs reach <strong>75% of specific threshold</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Use AWS Budgets to create a cost budget for data transfer costs. Set an alert at 75% of the budgeted amount. Configure the budget to send a notification to the email distribution list when costs reach 75% of the threshold.</strong></p><ul><li><p><strong>AWS Budgets</strong> cho phÃ©p create budgets vá»›i <strong>specific cost filters</strong> (service, usage type, region, etc.)</p></li><li><p>CÃ³ thá»ƒ specifically filter <strong>Data Transfer costs between Regions</strong></p></li><li><p><strong>Built-in notification system</strong> - send alerts to email addresses khi costs reach threshold</p></li><li><p>Support <strong>multiple alert thresholds</strong> (75%, 90%, 100% of budget)</p></li><li><p><strong>Forecasted alerts</strong> available - predict khi costs sáº½ exceed budget</p></li><li><p>Most straightforward solution vá»›i <strong>least operational overhead</strong></p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create an AWS Cost and Usage Report. Analyze the results in Amazon Athena. Configure an alarm to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic when costs reach 75% of the threshold. Subscribe the email distribution list to the topic.</strong></p><ul><li><p>Overly complex solution - need Cost and Usage Report, Athena queries, custom CloudWatch alarm</p></li><li><p><strong>High operational overhead</strong> - maintain queries, alarms, integrations</p></li><li><p>AWS Budgets provides built-in solution Ä‘Æ¡n giáº£n hÆ¡n</p></li></ul><p></p><p>âŒ <strong>Create an Amazon CloudWatch billing alarm to detect when costs reach 75% of the threshold. Configure the alarm to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the email distribution list to the topic.</strong></p><ul><li><p>CloudWatch billing alarms chá»‰ show <strong>TOTAL estimated charges</strong></p></li><li><p><strong>KHÃ”NG support filtering</strong> by specific cost types (nhÆ° data transfer between regions)</p></li><li><p>Cannot track specific data transfer costs</p></li></ul><p></p><p>âŒ <strong>Set up a VPC flow log. Set up a subscription filter to an AWS Lambda function to analyze data transfer. Configure the Lambda function to send a notification to the email distribution list when costs reach 75% of the threshold.</strong></p><ul><li><p><strong>VPC Flow Logs</strong> track <strong>network traffic</strong>, NOT costs</p></li><li><p>Flow logs KHÃ”NG cÃ³ cost information</p></li><li><p>Sai approach hoÃ n toÃ n</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p>\"Track specific cost types + alerts\" â†’ <strong>AWS Budgets</strong> with cost filters</p></li><li><p>\"Total AWS spending alerts\" â†’ CloudWatch billing alarms</p></li><li><p>\"Detailed cost analysis\" â†’ Cost and Usage Reports + Athena</p></li><li><p><strong>Pattern:</strong></p><ul><li><p>Specific cost budgets = AWS Budgets</p></li><li><p>Total spending = CloudWatch billing alarms</p></li><li><p>Traffic monitoring = VPC Flow Logs</p></li></ul></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/cost-management/latest/userguide/budgets-create-filters.html\">Creating AWS Budgets with cost filters</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/cost-management/latest/userguide/budgets-managing-costs.html\">AWS Budgets notifications and alerts</a></p></li></ul>",
            "correctAnswer": [
                "<p>Use AWS Budgets to create a cost budget for data transfer costs. Set an alert at 75% of the budgeted amount. Configure the budget to send a notification to the email distribution list when costs reach 75% of the threshold.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create an AWS Cost and Usage Report. Analyze the results in Amazon Athena. Configure an alarm to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic when costs reach 75% of the threshold. Subscribe the email distribution list to the topic.</p>",
                "<p>Create an Amazon CloudWatch billing alarm to detect when costs reach 75% of the threshold. Configure the alarm to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the email distribution list to the topic.</p>",
                "<p>Use AWS Budgets to create a cost budget for data transfer costs. Set an alert at 75% of the budgeted amount. Configure the budget to send a notification to the email distribution list when costs reach 75% of the threshold.</p>",
                "<p>Set up a VPC flow log. Set up a subscription filter to an AWS Lambda function to analyze data transfer. Configure the Lambda function to send a notification to the email distribution list when costs reach 75% of the threshold.</p>"
            ],
            "answersPos": "[1,0,2,3]",
            "pos": 58
        },
        {
            "attemptAnswerId": 329330,
            "questionId": 6553,
            "questionText": "<p>A company is storing backups in an Amazon S3 bucket. The backups must not be deleted for at least 3 months after the backups are created.<br><br>What should a SysOps administrator do to meet this requirement?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company storing <strong>backups</strong> in <strong>S3 bucket</strong></p></li><li><p>Backups <strong>must NOT be deleted</strong> for at least <strong>3 months</strong> after creation</p></li><li><p>YÃªu cáº§u: enforce retention period</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Enable S3 Object Lock on a new S3 bucket in compliance mode. Place all backups in the new S3 bucket with a retention period of 3 months.</strong></p><ul><li><p><strong>S3 Object Lock COMPLIANCE mode</strong> enforce <strong>WORM (Write-Once-Read-Many)</strong> protection</p></li><li><p><strong>COMPLIANCE mode</strong>: <strong>NO ONE</strong> (including root user) can delete objects trong retention period</p></li><li><p><strong>Retention period tá»± Ä‘á»™ng enforce</strong> - khÃ´ng cáº§n manual intervention sau 3 months</p></li><li><p><strong>Object Lock pháº£i enable khi CREATE bucket</strong> - cannot enable on existing bucket</p></li><li><p>Meet requirement: absolute protection, backups cannot be deleted for 3 months</p></li><li><p>AWS recommended cho <strong>regulatory compliance</strong> vÃ  <strong>data retention requirements</strong></p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure an IAM policy that denies the s3:DeleteObject action for all users. Three months after an object is written, remove the policy.</strong></p><ul><li><p><strong>Manual process</strong> - pháº£i manually remove policy sau 3 months cho EACH object</p></li><li><p><strong>High operational overhead</strong>, khÃ´ng scalable</p></li><li><p>Users with <strong>admin/root permissions</strong> cÃ³ thá»ƒ change/remove IAM policy</p></li></ul><p></p><p>âŒ <strong>Enable S3 Versioning on the existing S3 bucket. Configure S3 Lifecycle rules to protect the backups.</strong></p><ul><li><p><strong>S3 Versioning</strong> chá»‰ keep multiple versions, KHÃ”NG prevent deletion</p></li><li><p><strong>Lifecycle rules</strong> cÃ³ thá»ƒ MOVE hoáº·c DELETE objects, khÃ´ng pháº£i PROTECT</p></li><li><p>Users váº«n cÃ³ thá»ƒ delete objects</p></li></ul><p></p><p>âŒ <strong>Enable S3 Object Lock on a new S3 bucket in governance mode. Place all backups in the new S3 bucket with a retention period of 3 months.</strong></p><ul><li><p><strong>GOVERNANCE mode</strong>: users with <strong>s3:BypassGovernanceRetention permission</strong> CÃ“ THá»‚ delete objects</p></li><li><p>KHÃ”NG Ä‘áº£m báº£o \"must not be deleted\" requirement</p></li><li><p>Weaker protection than COMPLIANCE mode</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p>\"Must NOT be deleted\" + retention â†’ <strong>S3 Object Lock COMPLIANCE mode</strong></p></li><li><p><strong>COMPLIANCE mode</strong> = NO ONE can delete | <strong>GOVERNANCE mode</strong> = Users with bypass permission can delete</p></li><li><p><strong>Object Lock pháº£i enable khi CREATE bucket</strong> - khÃ´ng thá»ƒ enable on existing bucket</p></li><li><p><strong>Pattern:</strong> Strict immutability = COMPLIANCE mode | Flexible retention = GOVERNANCE mode | Versioning â‰  Retention protection</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html\">S3 Object Lock compliance and governance modes</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-configure.html\">Configuring S3 Object Lock retention periods</a></p></li></ul>",
            "correctAnswer": [
                "<p>Enable S3 Object Lock on a new S3 bucket in compliance mode. Place all backups in the new S3 bucket with a retention period of 3 months.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure an IAM policy that denies the s3:DeleteObject action for all users. Three months after an object is written, remove the policy.</p>",
                "<p>Enable S3 Object Lock on a new S3 bucket in compliance mode. Place all backups in the new S3 bucket with a retention period of 3 months.</p>",
                "<p>Enable S3 Versioning on the existing S3 bucket. Configure S3 Lifecycle rules to protect the backups.</p>",
                "<p>Enable S3 Object Lock on a new S3 bucket in governance mode. Place all backups in the new S3 bucket with a retention period of 3 months.</p>"
            ],
            "answersPos": "[1,3,0,2]",
            "pos": 59
        },
        {
            "attemptAnswerId": 329331,
            "questionId": 6554,
            "questionText": "<p>A SysOps administrator receives an alert from Amazon GuardDuty about suspicious network activity on an Amazon EC2 instance. The GuardDuty finding lists a new external IP address as a traffic destination. The SysOps administrator does not recognize the external IP address. The SysOps administrator must block traffic to the external IP address that GuardDuty identified.</p><p></p><p>Which solution will meet this requirement?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p><strong>GuardDuty alert</strong> vá» <strong>suspicious network activity (hoáº·t Ä‘á»™ng netwok Ä‘Ã¡ng ngá»)</strong> trÃªn EC2 instance</p></li><li><p>Traffic destination lÃ  <strong>new external IP address</strong> (khÃ´ng nháº­n ra)</p></li><li><p>YÃªu cáº§u: <strong>block traffic TO external IP address</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create a network ACL. Add an outbound deny rule for traffic to the external IP address.</strong></p><ul><li><p><strong>Network ACLs</strong> support <strong>both ALLOW and DENY rules</strong> (khÃ¡c vá»›i security groups)</p></li><li><p>CÃ³ thá»ƒ add <strong>explicit OUTBOUND DENY rule</strong> for specific IP address</p></li><li><p>Network ACL applies at <strong>subnet level</strong> - protect táº¥t cáº£ instances trong subnet</p></li><li><p><strong>STATELESS</strong> - outbound deny rule sáº½ block traffic Ä‘i external IP</p></li><li><p>ÄÃ¢y lÃ  AWS recommended approach Ä‘á»ƒ <strong>block specific IPs</strong> at network layer</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Create a new security group to block traffic to the external IP address. Assign the new security group to the EC2 instance.</strong></p><ul><li><p><strong>Security groups chá»‰ support ALLOW rules</strong>, CANNOT create DENY rules</p></li><li><p>Security groups default <strong>allow all outbound traffic</strong></p></li><li><p>Cannot explicitly block specific IP addresses</p></li></ul><p></p><p>âŒ <strong>Use VPC flow logs with Amazon Athena to block traffic to the external IP address.</strong></p><ul><li><p><strong>VPC Flow Logs</strong> chá»‰ lÃ  <strong>monitoring/logging tool</strong></p></li><li><p>KHÃ”NG cÃ³ capability Ä‘á»ƒ <strong>block traffic</strong></p></li><li><p>Athena dÃ¹ng Ä‘á»ƒ query logs, khÃ´ng control traffic</p></li></ul><p></p><p>âŒ <strong>Create a new security group to block traffic to the external IP address. Assign the new security group to the entire VPC.</strong></p><ul><li><p>Security groups <strong>CANNOT be assigned to VPC</strong></p></li><li><p>Security groups assign to <strong>instances/ENIs only</strong></p></li><li><p>Security groups cannot create deny rules</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p>\"Block specific IP address\" â†’ <strong>Network ACL with DENY rule</strong></p></li><li><p><strong>Security groups</strong> = ALLOW only, STATEFUL, instance-level</p></li><li><p><strong>Network ACLs</strong> = ALLOW + DENY, STATELESS, subnet-level</p></li><li><p>\"VPC Flow Logs\" â†’ Monitoring only, cannot block traffic</p></li><li><p><strong>Pattern:</strong> Block traffic = Network ACL DENY | Allow traffic = Security group | Monitor traffic = VPC Flow Logs</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html\">Network ACLs for blocking traffic</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a network ACL. Add an outbound deny rule for traffic to the external IP address.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a new security group to block traffic to the external IP address. Assign the new security group to the EC2 instance.</p>",
                "<p>Use VPC flow logs with Amazon Athena to block traffic to the external IP address.</p>",
                "<p>Create a network ACL. Add an outbound deny rule for traffic to the external IP address.</p>",
                "<p>Create a new security group to block traffic to the external IP address. Assign the new security group to the entire VPC.</p>"
            ],
            "answersPos": "[3,0,2,1]",
            "pos": 60
        },
        {
            "attemptAnswerId": 329332,
            "questionId": 6555,
            "questionText": "<p>A company has an application that is deployed to two AWS Regions in an active-passive configuration. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB) in each Region. The instances are in an Amazon EC2 Auto Scaling group in each Region. The application uses an Amazon Route 53 hosted zone for DNS. A SysOps administrator needs to configure automatic failover to the secondary Region.<br><br>What should the SysOps administrator do to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Application deployed to <strong>2 AWS Regions</strong> (active-passive configuration)</p></li><li><p>EC2 instances behind <strong>ALB in each Region</strong></p></li><li><p><strong>Auto Scaling group</strong> in each Region</p></li><li><p>Use <strong>Route 53 hosted zone</strong> for DNS</p></li><li><p>YÃªu cáº§u: configure <strong>automatic failover to secondary Region</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Configure Route 53 alias records that point to each ALB. Choose a failover routing policy. Set Evaluate Target Health to Yes.</strong></p><ul><li><p><strong>Route 53 alias records</strong> lÃ  AWS recommended cho AWS resources (ALB, CloudFront, S3 website)</p></li><li><p><strong>Failover routing policy</strong> support <strong>active-passive</strong> configuration vá»›i primary vÃ  secondary records</p></li><li><p><strong>Evaluate Target Health = Yes</strong>: Route 53 <strong>tá»± Ä‘á»™ng monitor ALB health</strong> checks</p></li><li><p>Khi primary ALB <strong>unhealthy</strong>, Route 53 <strong>automatically route traffic</strong> to secondary ALB</p></li><li><p><strong>No additional cost</strong> for alias record queries (unlike CNAME)</p></li><li><p><strong>Fully automated failover</strong> - no manual intervention needed</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Configure CNAME records that point to each ALB. Choose a failover routing policy. Set Evaluate Target Health to Yes.</strong></p><ul><li><p>CNAME cÃ³ thá»ƒ work nhÆ°ng <strong>NOT AWS recommended</strong> cho AWS resources</p></li><li><p><strong>Cannot use CNAME at zone apex</strong> (root domain)</p></li><li><p><strong>Charges for queries</strong> (alias records are free)</p></li></ul><p></p><p>âŒ <strong>Configure Elastic Load Balancing (ELB) health checks for the Auto Scaling group. Add a target group to the ALB in the primary Region. Include the EC2 instances in the secondary Region as targets.</strong></p><ul><li><p><strong>ALB CANNOT route traffic cross-region</strong></p></li><li><p>ALB chá»‰ cÃ³ thá»ƒ target instances trong <strong>same Region</strong></p></li><li><p>Cross-region failover requires <strong>Route 53</strong>, not ALB</p></li></ul><p></p><p>âŒ <strong>Configure EC2 health checks for the Auto Scaling group. Add a target group to the ALB in the primary Region. Include the EC2 instances in the secondary Region as targets.</strong></p><ul><li><p>Similar previous answer - ALB khÃ´ng support cross-region targets</p></li><li><p>EC2 instances pháº£i trong same Region vá»›i ALB</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p>\"Cross-region failover\" â†’ <strong>Route 53 failover routing policy</strong></p></li><li><p>\"Automatic health check failover\" â†’ <strong>Evaluate Target Health = Yes</strong></p></li><li><p>\"AWS resources (ALB, S3, CloudFront)\" â†’ <strong>Alias records</strong> (not CNAME)</p></li><li><p><strong>Pattern:</strong> Cross-region = Route 53 | Same-region = ALB/NLB | Active-passive = Failover routing policy</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-failover.html\">Route 53 failover routing policy</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html\">Configuring DNS failover with health checks</a></p></li></ul>",
            "correctAnswer": [
                "<p>Configure Route 53 alias records that point to each ALB. Choose a failover routing policy. Set Evaluate Target Health to Yes.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Configure Route 53 alias records that point to each ALB. Choose a failover routing policy. Set Evaluate Target Health to Yes.</p>",
                "<p>Configure CNAME records that point to each ALChoose a failover routing policy. Set Evaluate Target Health to Yes.</p>",
                "<p>Configure Elastic Load Balancing (ELB) health checks for the Auto Scaling group. Add a target group to the ALB in the primary Region. Include the EC2 instances in the secondary Region as targets.</p>",
                "<p>Configure EC2 health checks for the Auto Scaling group. Add a target group to the ALB in the primary Region. Include the EC2 instances in the secondary Region as targets.</p>"
            ],
            "answersPos": "[1,3,2,0]",
            "pos": 61
        },
        {
            "attemptAnswerId": 329333,
            "questionId": 6556,
            "questionText": "<p>A company needs to deploy a new workload on AWS. The company must encrypt all data at rest and must rotate the encryption keys once each year. The workload uses an Amazon RDS for MySQL Multi-AZ database for data storage.<br><br>Which configuration approach will meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Company cáº§n deploy workload trÃªn AWS</p></li><li><p>YÃªu cáº§u: <strong>encrypt all data at rest</strong> + <strong>rotate encryption keys once each year</strong></p></li><li><p>Workload uses <strong>RDS for MySQL Multi-AZ</strong> database</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create a new AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Enable RDS encryption on the database at creation time by using the KMS key.</strong></p><ul><li><p><strong>Customer managed KMS key</strong> provides <strong>full control</strong> over encryption key lifecycle</p></li><li><p><strong>Automatic key rotation</strong> khi enabled sáº½ rotate key <strong>every 365 days</strong> (1 year) - Ä‘Ãºng requirement</p></li><li><p><strong>RDS encryption must be enabled at creation time</strong> - cannot enable on existing DB</p></li><li><p>Specify customer managed KMS key khi create RDS instance</p></li><li><p>Customer managed key cho phÃ©p control <strong>key policies</strong>, <strong>rotation schedule</strong>, <strong>audit logs</strong></p></li><li><p>AWS recommended approach cho compliance vÃ  regulatory requirements</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Enable Transparent Data Encryption (TDE) in the MySQL configuration file. Manually rotate the key every 12 months.</strong></p><ul><li><p>MySQL <strong>KHÃ”NG support TDE</strong> nhÆ° Oracle/SQL Server</p></li><li><p><strong>Manual rotation</strong> = high operational overhead</p></li><li><p>Not AWS recommended approach for RDS</p></li></ul><p></p><p>âŒ <strong>Enable RDS encryption on the database at creation time by using the AWS managed key for Amazon RDS.</strong></p><ul><li><p>AWS managed key <strong>tá»± Ä‘á»™ng rotate every 3 years</strong>, KHÃ”NG pháº£i 1 year</p></li><li><p><strong>Cannot control rotation schedule</strong> vá»›i AWS managed keys</p></li><li><p>KhÃ´ng meet requirement \"rotate once each year\"</p></li></ul><p></p><p>âŒ <strong>Create a new AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Enable encryption on the Amazon Elastic Block Store (Amazon EBS) volumes that are attached to the RDS DB instance.</strong></p><ul><li><p><strong>KHÃ”NG thá»ƒ directly encrypt EBS volumes</strong> cho RDS instances</p></li><li><p>RDS encryption managed at <strong>RDS level</strong>, not EBS level</p></li><li><p>Users khÃ´ng cÃ³ direct access to underlying EBS volumes</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p>\"Encrypt data at rest + control rotation\" â†’ <strong>Customer managed KMS key</strong></p></li><li><p>\"RDS encryption\" â†’ <strong>Must enable at creation time</strong> (cannot enable later)</p></li><li><p><strong>AWS managed key rotation</strong> = 3 years | <strong>Customer managed key</strong> = 1 year (when enabled)</p></li><li><p><strong>Pattern:</strong> Control key rotation = Customer managed key | Default encryption = AWS managed key | MySQL â‰  TDE support</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.Keys.html\">RDS encryption with KMS customer managed keys</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/kms/latest/developerguide/rotating-keys-enable.html\">KMS automatic key rotation configuration</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a new AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Enable RDS encryption on the database at creation time by using the KMS key.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Enable Transparent Data Encryption (TDE) in the MySQL configuration file. Manually rotate the key every 12 months.</p>",
                "<p>Enable RDS encryption on the database at creation time by using the AWS managed key for Amazon RDS.</p>",
                "<p>Create a new AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Enable RDS encryption on the database at creation time by using the KMS key.</p>",
                "<p>Create a new AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Enable encryption on the Amazon Elastic Block Store (Amazon EBS) volumes that are attached to the RDS DB instance.</p>"
            ],
            "answersPos": "[0,3,1,2]",
            "pos": 62
        },
        {
            "attemptAnswerId": 329334,
            "questionId": 6557,
            "questionText": "<p>A company runs hundreds of Amazon EC2 instances in a single AWS Region. Each EC2 instance has two attached 1 GiB General Purpose SSD (gp2) Amazon Elastic Block Store (Amazon EBS) volumes. A critical workload is using all the available IOPS capacity on the EBS volumes.<br><br>According to company policy, the company cannot change instance types or EBS volume types without completing lengthy acceptance tests to validate that the companyâ€™s applications will function properly. A SysOps administrator needs to increase the I/O performance of the EBS volumes as quickly as possible.<br><br>Which action should the SysOps administrator take to meet these requirements?</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Hundreds of EC2 instances, má»—i instance cÃ³ 2 attached <strong>1 GiB gp2 EBS volumes</strong></p></li><li><p>Critical workload <strong>using ALL available IOPS capacity</strong> (IOPS cáº¡n kiá»‡t)</p></li><li><p>Company policy: <strong>CANNOT change instance types or EBS volume types</strong> without lengthy tests</p></li><li><p>YÃªu cáº§u: increase I/O performance <strong>as quickly as possible</strong></p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Increase the size of the 1 GiB EBS volumes.</strong></p><ul><li><p><strong>gp2 volumes</strong>: IOPS scale <strong>tuyáº¿n tÃ­nh vá»›i volume size</strong> (3 IOPS per GiB)</p></li><li><p><strong>1 GiB gp2 volume</strong> = <strong>100 IOPS</strong> (minimum baseline)</p></li><li><p>Increase size to example <strong>334 GiB</strong> = <strong>1,000 IOPS</strong> (10x improvement)</p></li><li><p><strong>Can modify volume size without changing volume type</strong> - váº«n lÃ  gp2, comply with policy</p></li><li><p><strong>Quick operation</strong> - volume modification online, no instance restart needed</p></li><li><p>Most effective way to increase IOPS for gp2 volumes</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Add two additional elastic network interfaces on each EC2 instance.</strong></p><ul><li><p><strong>ENI (Elastic Network Interface)</strong> cho <strong>networking</strong>, KHÃ”NG related to EBS IOPS</p></li><li><p>IOPS performance depends on <strong>EBS volume characteristics</strong>, not network interfaces</p></li><li><p>KhÃ´ng giáº£i quyáº¿t váº¥n Ä‘á»</p></li></ul><p></p><p>âŒ <strong>Turn on Transfer Acceleration on the EBS volumes in the Region.</strong></p><ul><li><p><strong>Transfer Acceleration</strong> lÃ  feature cá»§a <strong>S3</strong>, KHÃ”NG pháº£i EBS</p></li><li><p>EBS khÃ´ng cÃ³ Transfer Acceleration feature</p></li><li><p>Technically incorrect</p></li></ul><p></p><p>âŒ <strong>Add all the EC2 instances to a cluster placement group.</strong></p><ul><li><p><strong>Placement groups</strong> optimize <strong>network latency between instances</strong></p></li><li><p>KHÃ”NG áº£nh hÆ°á»Ÿng Ä‘áº¿n <strong>EBS IOPS performance</strong></p></li><li><p>EBS performance independent cá»§a placement group</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p><strong>gp2 IOPS formula</strong> = 3 IOPS per GiB (minimum 100 IOPS, max 16,000 IOPS)</p></li><li><p>\"Increase gp2 performance without changing type\" â†’ <strong>Increase volume size</strong></p></li><li><p>\"Transfer Acceleration\" â†’ S3 only, NOT EBS</p></li><li><p><strong>Pattern:</strong> gp2 performance = Volume size | Network performance = ENI/Placement groups | S3 transfers = Transfer Acceleration</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html\">Amazon EBS gp2 volume performance</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/ebs/latest/userguide/requesting-ebs-volume-modifications.html\">Modifying EBS volume size and performance</a></p></li></ul>",
            "correctAnswer": [
                "<p>Increase the size of the 1 GiB EBS volumes.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Increase the size of the 1 GiB EBS volumes.</p>",
                "<p>Add two additional elastic network interfaces on each EC2 instance.</p>",
                "<p>Turn on Transfer Acceleration on the EBS volumes in the Region.</p>",
                "<p>Add all the EC2 instances to a cluster placement group.</p>"
            ],
            "answersPos": "[0,1,3,2]",
            "pos": 63
        },
        {
            "attemptAnswerId": 329335,
            "questionId": 10510,
            "questionText": "<p>A companyâ€™s SysOps administrator must ensure that all Amazon EC2 Windows instances that are launched in an AWS account have a third-party agent installed. The third-party agent has an .msi package. The company uses AWS Systems Manager for patching, and the Windows instances are tagged appropriately. The third-party agent requires periodic updates as new versions are released. The SysOps administrator must deploy these updates automatically.<br><br>Which combination of steps will meet these requirements with the LEAST operational effort? (Choose two.)</p>",
            "explanation": "<p>ğŸ“ <u>TÃ³m táº¯t Ä‘á»:</u></p><ul><li><p>Táº¥t cáº£ <strong>EC2 Windows instances</strong> pháº£i cÃ³ <strong>third-party agent installed</strong> (.msi package)</p></li><li><p>Use <strong>Systems Manager</strong> for patching, instances <strong>tagged appropriately (Ä‘Ã¡nh tag thÃ­ch há»£p)</strong></p></li><li><p>Agent requires <strong>periodic (Ä‘á»‹nh ká»³) updates</strong> as new versions released</p></li><li><p>YÃªu cáº§u: <strong>deploy updates automatically</strong> vá»›i <strong>LEAST operational effort</strong></p></li><li><p><strong>Choose TWO</strong> answers</p></li></ul><p></p><p>âœ… <u>ÄÃ¡p Ã¡n Ä‘Ãºng:</u></p><p><strong>Create a Systems Manager Distributor package for the third-party agent.</strong></p><ul><li><p><strong>Systems Manager Distributor</strong> lÃ  AWS service Ä‘á»ƒ <strong>package vÃ  distribute software</strong></p></li><li><p>Natively support <strong>.msi packages</strong> cho Windows</p></li><li><p>Centralized storage cho agent vÃ  <strong>all versions</strong></p></li><li><p>Khi upload new version, Distributor automatically manage versioning</p></li><li><p>Required prerequisite Ä‘á»ƒ use vá»›i State Manager</p></li></ul><p></p><p><strong>Create a Systems Manager State Manager association to run the AWS-ConfigureAWSPackage document. Populate the details of the third-party agent package. Specify instance tags based on the appropriate tag value for Windows with a schedule of 1 day.</strong></p><ul><li><p><strong>State Manager association</strong> cho phÃ©p <strong>run documents on schedule</strong> across instances</p></li><li><p><strong>AWS-ConfigureAWSPackage</strong> document specifically designed Ä‘á»ƒ <strong>install/update packages tá»« Distributor</strong></p></li><li><p>Target instances <strong>by tags</strong> - automatically apply to matching instances</p></li><li><p><strong>Schedule 1 day</strong>: regularly check for updates vÃ  auto-deploy new versions</p></li><li><p><strong>Least operational effort</strong> - fully automated, no manual intervention</p></li></ul><p></p><p><u>CÃ¡c Ä‘Ã¡p Ã¡n sai:</u></p><p>âŒ <strong>Make sure that Systems Manager Inventory is configured. If Systems Manager Inventory is not configured, set up a new inventory for instances that is based on the appropriate tag value for Windows.</strong></p><ul><li><p><strong>Inventory</strong> dÃ¹ng Ä‘á»ƒ <strong>collect metadata</strong> vá» instances (installed apps, configurations)</p></li><li><p>KHÃ”NG deploy hoáº·c update software</p></li><li><p>Not required cho deployment automation</p></li></ul><p></p><p>âŒ <strong>Create a Systems Manager State Manager association to run the AWS-RunRemoteScript document. Populate the details of the third-party agent package. Specify instance tags based on the appropriate tag value for Windows with a schedule of 1 day.</strong></p><ul><li><p><strong>AWS-RunRemoteScript</strong> dÃ¹ng Ä‘á»ƒ <strong>run custom scripts</strong></p></li><li><p>KHÃ”NG tá»± Ä‘á»™ng handle <strong>package versioning</strong> hoáº·c updates</p></li><li><p>Higher overhead than AWS-ConfigureAWSPackage</p></li></ul><p></p><p>âŒ <strong>Create a Systems Manager OpsItem with the tag value for Windows. Attach the Systems Manager Distributor package to the OpsItem. Create a maintenance window that is specific to the package deployment. Configure the maintenance window to cover 24 hours a day.</strong></p><ul><li><p><strong>OpsItem</strong> lÃ  <strong>operational work item tracking tool</strong></p></li><li><p>KHÃ”NG dÃ¹ng Ä‘á»ƒ deploy hoáº·c schedule package updates</p></li><li><p>Overly complex approach</p></li></ul><p></p><p>ğŸ”‘ <u>Tips and tricks:</u></p><ul><li><p>\"Deploy software packages automatically\" â†’ <strong>Distributor + State Manager</strong></p></li><li><p><strong>AWS-ConfigureAWSPackage</strong> â†’ Install/update Distributor packages</p></li><li><p><strong>AWS-RunRemoteScript</strong> â†’ Run custom scripts (not for package management)</p></li><li><p>\"Periodic updates\" â†’ <strong>State Manager scheduled association</strong></p></li><li><p><strong>Pattern:</strong> Package distribution = Distributor | Auto-deployment = State Manager + AWS-ConfigureAWSPackage | Tracking work = OpsItem</p></li></ul><p></p><p>ğŸ“– <u>Reference:</u></p><ul><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/distributor.html\">AWS Systems Manager Distributor</a></p></li><li><p><a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/distributor-working-with-packages-deploy.html\">Using State Manager associations with Distributor packages</a></p></li></ul>",
            "correctAnswer": [
                "<p>Create a Systems Manager Distributor package for the third-party agent.</p>",
                "<p>Create a Systems Manager State Manager association to run the AWS-ConfigureAWSPackage document. Populate the details of the third-party agent package. Specify instance tags based on the appropriate tag value for Windows with a schedule of 1 day.</p>"
            ],
            "selectedAnswers": null,
            "isCorrect": null,
            "isFlagged": false,
            "answers": [
                "<p>Create a Systems Manager Distributor package for the third-party agent.</p>",
                "<p>Make sure that Systems Manager Inventory is configured. If Systems Manager Inventory is not configured, set up a new inventory for instances that is based on the appropriate tag value for Windows.</p>",
                "<p>Create a Systems Manager State Manager association to run the AWS-RunRemoteScript document. Populate the details of the third-party agent package. Specify instance tags based on the appropriate tag value for Windows with a schedule of 1 day.</p>",
                "<p>Create a Systems Manager State Manager association to run the AWS-ConfigureAWSPackage document. Populate the details of the third-party agent package. Specify instance tags based on the appropriate tag value for Windows with a schedule of 1 day.</p>",
                "<p>Create a Systems Manager OpsItem with the tag value for Windows. Attach the Systems Manager Distributor package to the OpsItem. Create a maintenance window that is specific to the package deployment. Configure the maintenance window to cover 24 hours a day.</p>"
            ],
            "answersPos": "[0,1,2,3,4]",
            "pos": 64
        }
    ],
    "statistics": {
        "correctCount": 0,
        "incorrectCount": 0,
        "skippedCount": 65,
        "flaggedCount": 0
    },
    "examName": "Practice Test 04",
    "courseName": "Practice Exams | AWS Certified CloudOps Engineer - SOA-C03",
    "slug": "practice-exams-aws-certified-cloudops-engineer-soa-c03"
}